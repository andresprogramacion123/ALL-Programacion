{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>INTRODUCCION A LAS REDES NEURONALES ARTIFICIALES (ANN) Y PERCEPTRON MULTICAPA (MLP) </H1>\n",
    "<img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcRmG-myUULUM1PvulLReDUM72u8hY9oIjpsIR_Y6X3DQJIueJnZ&usqp=CAU\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los ANN están en el núcleo de Deep Learning. Son versátiles, potentes y escalables, lo que los hace ideales para abordar tareas de Aprendizaje automático grandes y muy complejas, como clasificar miles de millones de imágenes (por ejemplo, Google Images), potenciar servicios de reconocimiento de voz (por ejemplo, Siri de Apple), recomendar los mejores videos para ver a cientos de millones de usuarios todos los días (por ejemplo, YouTube), o aprender a vencer al campeón del mundo en el juego de Go al examinar millones de juegos pasados y luego jugar contra sí mismo (AlphaMo de DeepMind).\n",
    "En este capítulo, introduciremos redes neuronales artificiales, comenzando con un recorrido rápido por las primeras arquitecturas de ANN. Luego, presentaremos Perceptrones de múltiples capas (MLP) e implementaremos uno utilizando TensorFlow para abordar el problema de clasificación de dígitos MNIST "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>El Perceptron</h3>\n",
    "<img src=\"https://images.deepai.org/glossary-terms/perceptron-6168423.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El Perceptron es una de las arquitecturas de ANN más simples, inventada en 1957 por Frank Rosenblatt. Se basa en una neurona artificial ligeramente diferente llamada unidad de umbral lineal (LTU): las entradas y la salida ahora son números (en lugar de valores binarios de activación / desactivación) y cada conexión de entrada está asociada con un peso. La LTU calcula una suma ponderada de sus entradas <br>\n",
    "(z = w1 x1 + w2 x2 + ⋯ + wn xn = wT · x),<br>\n",
    "luego aplica una función escalonada a esa suma y genera el resultado: hw (x) = paso (z) = paso (wT · x). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función de paso más común utilizada en Perceptrons es la función de paso de Heaviside. A veces se usa la función de signo en su lugar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://circuitoselectricosupb.files.wordpress.com/2012/11/funcion-paso.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://3.bp.blogspot.com/-N3I1wvPtg2U/WRSkKUOXl_I/AAAAAAAAal8/aUqffh8Ivz8NS5lkR2rDkZXWe4Kxdz1gwCLcB/s1600/Funci%25C3%25B3n_Signo.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede usar una sola LTU para la clasificación binaria lineal simple. Calcula una combinación lineal de las entradas y, si el resultado supera un umbral, genera la clase positiva o, si no, la clase negativa (como un clasificador de Regresión logística o un SVM lineal). Por ejemplo, podría usar un solo LTU para clasificar las flores del iris según la longitud y el ancho del pétalo (también se agrega una característica de sesgo adicional x0 = 1, como hicimos en los capítulos anteriores). Entrenar un LTU significa encontrar los valores correctos para w0, w1 y w2 (el algoritmo de entrenamiento se discute en breve).\n",
    "Un Perceptron está compuesto simplemente de una sola capa de LTU, con cada neurona conectada a todas las entradas. Estas conexiones a menudo se representan mediante el paso de neuronas especiales llamadas neuronas de entrada: simplemente emiten la entrada que reciben."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además, generalmente se agrega una característica de sesgo adicional (x0 = 1). Esta característica de sesgo suele representarse mediante un tipo especial de neurona llamada neurona de sesgo, que solo genera 1 todo el tiempo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1523361626/linear_vs_logistic_regression_h8voek.jpg\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 2)\n",
      "(150, 1)\n",
      "[[1.4 0.2]\n",
      " [1.4 0.2]\n",
      " [1.3 0.2]\n",
      " [1.5 0.2]\n",
      " [1.4 0.2]\n",
      " [1.7 0.4]\n",
      " [1.4 0.3]\n",
      " [1.5 0.2]\n",
      " [1.4 0.2]\n",
      " [1.5 0.1]\n",
      " [1.5 0.2]\n",
      " [1.6 0.2]\n",
      " [1.4 0.1]\n",
      " [1.1 0.1]\n",
      " [1.2 0.2]\n",
      " [1.5 0.4]\n",
      " [1.3 0.4]\n",
      " [1.4 0.3]\n",
      " [1.7 0.3]\n",
      " [1.5 0.3]\n",
      " [1.7 0.2]\n",
      " [1.5 0.4]\n",
      " [1.  0.2]\n",
      " [1.7 0.5]\n",
      " [1.9 0.2]\n",
      " [1.6 0.2]\n",
      " [1.6 0.4]\n",
      " [1.5 0.2]\n",
      " [1.4 0.2]\n",
      " [1.6 0.2]\n",
      " [1.6 0.2]\n",
      " [1.5 0.4]\n",
      " [1.5 0.1]\n",
      " [1.4 0.2]\n",
      " [1.5 0.2]\n",
      " [1.2 0.2]\n",
      " [1.3 0.2]\n",
      " [1.4 0.1]\n",
      " [1.3 0.2]\n",
      " [1.5 0.2]\n",
      " [1.3 0.3]\n",
      " [1.3 0.3]\n",
      " [1.3 0.2]\n",
      " [1.6 0.6]\n",
      " [1.9 0.4]\n",
      " [1.4 0.3]\n",
      " [1.6 0.2]\n",
      " [1.4 0.2]\n",
      " [1.5 0.2]\n",
      " [1.4 0.2]\n",
      " [4.7 1.4]\n",
      " [4.5 1.5]\n",
      " [4.9 1.5]\n",
      " [4.  1.3]\n",
      " [4.6 1.5]\n",
      " [4.5 1.3]\n",
      " [4.7 1.6]\n",
      " [3.3 1. ]\n",
      " [4.6 1.3]\n",
      " [3.9 1.4]\n",
      " [3.5 1. ]\n",
      " [4.2 1.5]\n",
      " [4.  1. ]\n",
      " [4.7 1.4]\n",
      " [3.6 1.3]\n",
      " [4.4 1.4]\n",
      " [4.5 1.5]\n",
      " [4.1 1. ]\n",
      " [4.5 1.5]\n",
      " [3.9 1.1]\n",
      " [4.8 1.8]\n",
      " [4.  1.3]\n",
      " [4.9 1.5]\n",
      " [4.7 1.2]\n",
      " [4.3 1.3]\n",
      " [4.4 1.4]\n",
      " [4.8 1.4]\n",
      " [5.  1.7]\n",
      " [4.5 1.5]\n",
      " [3.5 1. ]\n",
      " [3.8 1.1]\n",
      " [3.7 1. ]\n",
      " [3.9 1.2]\n",
      " [5.1 1.6]\n",
      " [4.5 1.5]\n",
      " [4.5 1.6]\n",
      " [4.7 1.5]\n",
      " [4.4 1.3]\n",
      " [4.1 1.3]\n",
      " [4.  1.3]\n",
      " [4.4 1.2]\n",
      " [4.6 1.4]\n",
      " [4.  1.2]\n",
      " [3.3 1. ]\n",
      " [4.2 1.3]\n",
      " [4.2 1.2]\n",
      " [4.2 1.3]\n",
      " [4.3 1.3]\n",
      " [3.  1.1]\n",
      " [4.1 1.3]\n",
      " [6.  2.5]\n",
      " [5.1 1.9]\n",
      " [5.9 2.1]\n",
      " [5.6 1.8]\n",
      " [5.8 2.2]\n",
      " [6.6 2.1]\n",
      " [4.5 1.7]\n",
      " [6.3 1.8]\n",
      " [5.8 1.8]\n",
      " [6.1 2.5]\n",
      " [5.1 2. ]\n",
      " [5.3 1.9]\n",
      " [5.5 2.1]\n",
      " [5.  2. ]\n",
      " [5.1 2.4]\n",
      " [5.3 2.3]\n",
      " [5.5 1.8]\n",
      " [6.7 2.2]\n",
      " [6.9 2.3]\n",
      " [5.  1.5]\n",
      " [5.7 2.3]\n",
      " [4.9 2. ]\n",
      " [6.7 2. ]\n",
      " [4.9 1.8]\n",
      " [5.7 2.1]\n",
      " [6.  1.8]\n",
      " [4.8 1.8]\n",
      " [4.9 1.8]\n",
      " [5.6 2.1]\n",
      " [5.8 1.6]\n",
      " [6.1 1.9]\n",
      " [6.4 2. ]\n",
      " [5.6 2.2]\n",
      " [5.1 1.5]\n",
      " [5.6 1.4]\n",
      " [6.1 2.3]\n",
      " [5.6 2.4]\n",
      " [5.5 1.8]\n",
      " [4.8 1.8]\n",
      " [5.4 2.1]\n",
      " [5.6 2.4]\n",
      " [5.1 2.3]\n",
      " [5.1 1.9]\n",
      " [5.9 2.3]\n",
      " [5.7 2.5]\n",
      " [5.2 2.3]\n",
      " [5.  1.9]\n",
      " [5.2 2. ]\n",
      " [5.4 2.3]\n",
      " [5.1 1.8]]\n",
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_iris\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "iris = load_iris()\n",
    "xr = iris.data[:, (2, 3)]\n",
    "yr = (iris.target == 0).astype(np.int).reshape([-1,1])\n",
    "print(xr.shape)\n",
    "print(yr.shape)\n",
    "print(xr)\n",
    "print(yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(shape=[None,2], dtype=tf.float32)\n",
    "y = tf.placeholder(shape=[None,1], dtype=tf.float32)\n",
    "\n",
    "W = tf.Variable(tf.random_uniform([2, 1]))\n",
    "b = tf.Variable(tf.random_uniform([1, 1]))\n",
    "z_pred = tf.matmul(X, W)+b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcion sigmoid para regresion logistica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://analyticsindiamag.com/wp-content/uploads/2018/01/sigmoid-equation.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tf.sigmoid(z_pred) #Acotado entre 0 y 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcion de costo: entropia cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*gNuP7PN6sC42vAYWvoAMMA.png\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "xentropy = -y*tf.log(y_pred)-(1-y)*tf.log(1-y_pred)\n",
    "loss = tf.reduce_mean(xentropy)\n",
    "learning_rate = 0.1\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca 0 Cross Entropy = 2.3594487\n",
      "Epoca 100 Cross Entropy = 0.099438995\n",
      "Epoca 200 Cross Entropy = 0.04273257\n",
      "Epoca 300 Cross Entropy = 0.025497882\n",
      "Epoca 400 Cross Entropy = 0.017518569\n",
      "Epoca 500 Cross Entropy = 0.0130188465\n",
      "[[-1.8720123]\n",
      " [-4.380847 ]]\n",
      "[[7.9730024]]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 600\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        _,cur_xentropy=sess.run([training_op,loss],feed_dict={X:xr,y:yr})\n",
    "        if epoch % 100 == 0: print(\"Epoca\", epoch, \"Cross Entropy =\", cur_xentropy)\n",
    "    \n",
    "    valW = W.eval()\n",
    "    valb = b.eval()\n",
    "    print(valW)\n",
    "    print(valb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = -valW[0] / valW[1]\n",
    "b = -valb[0] / valW[1]\n",
    "\n",
    "axes = [0, 7, 0, 3]\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(xr[yr.reshape(-1)==0,0], xr[yr.reshape(-1)==0,1], \"bs\", label=\"Not Iris-Setosa\")\n",
    "plt.plot(xr[yr.reshape(-1)==1,0], xr[yr.reshape(-1)==1,1], \"yo\", label=\"Iris-Setosa\")\n",
    "plt.plot([axes[0], axes[1]], [a * axes[0] + b, a * axes[1] + b], \"k-\", linewidth=3)\n",
    "\n",
    "plt.xlabel(\"Petal length\", fontsize=14)\n",
    "plt.ylabel(\"Petal width\", fontsize=14)\n",
    "plt.legend(loc=\"lower right\", fontsize=14)\n",
    "plt.axis(axes)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces, ¿cómo se entrena un Perceptrón? <br>\n",
    "El algoritmo de entrenamiento Perceptron propuesto por Frank Rosenblatt se inspiró en gran medida en la regla de Hebb. En su libro The Organization of Behavior, publicado en 1949, Donald Hebb sugirió que cuando se utiliza una neurona biológica, el nombre Perceptron se usa a veces para referirse a una pequeña red con una sola unidad de manejo. A menudo se desencadena otra neurona, la conexión entre estas dos neuronas se hace más fuerte. Esta idea fue resumida más tarde por Siegrid Löwel en esta frase pegadiza:<br>\n",
    "“Las células que se disparan juntas, se conectan entre sí”. Esta regla más tarde se conoció como la regla de Hebb (o aprendizaje Hebbian); es decir, el peso de conexión entre dos neuronas aumenta cada vez que tienen la misma salida. Los perceptrones se entrenan usando una variante de esta regla que toma en cuenta el error cometido por la red; no refuerza las conexiones que conducen a una salida incorrecta. Más específicamente, el Perceptron se alimenta una instancia de entrenamiento a la vez, y para cada instancia hace sus predicciones.\n",
    "Para cada neurona de salida que produjo una predicción incorrecta, refuerza los pesos de conexión de las entradas que habrían contribuido a la predicción correcta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://res.cloudinary.com/practicaldev/image/fetch/s--IGMiNYwp--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://slideplayer.com/slide/5098348/16/images/13/Perceptron%2BTraining%2BRule.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• wi, j es el peso de conexión entre la neurona de entrada ith y la neurona de salida jth.<br>\n",
    "• xi es el valor de entrada i de la instancia de entrenamiento actual.<br>\n",
    "• yj es la salida de la neurona de salida jth para la instancia de entrenamiento actual.<br>\n",
    "• yj es la salida objetivo de la neurona de salida jth para la instancia de entrenamiento actual.<br>\n",
    "• η es la tasa de aprendizaje.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El límite de decisión de cada neurona de salida es lineal, por lo que los Perceptrones son incapaces de aprender patrones complejos (como los clasificadores de Regresión logística). Sin embargo, si las instancias de entrenamiento son linealmente separables, Rosenblatt demostró que este algoritmo convergería en una solución.7 Esto se conoce como el teorema de convergencia de Perceptron. Scikit-Learn proporciona una clase de Perceptron que implementa una única red de LTU. Se puede usar prácticamente como se esperaría, por ejemplo, en el conjunto de datos del iris (introducido en el Capítulo 4):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "iris = load_iris()\n",
    "X = iris.data[:, (2, 3)] # petal length, petal width\n",
    "y = (iris.target == 0).astype(np.int) # Iris Setosa?\n",
    "per_clf = Perceptron(random_state=42)\n",
    "per_clf.fit(X, y)\n",
    "y_pred = per_clf.predict([[2, 0.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es posible que haya reconocido que el algoritmo de aprendizaje Perceptron se parece mucho a la pendiente de gradiente estocástica. De hecho, la clase Perceptron de Scikit-Learn es equivalente a usar un clasificador SGDC con los siguientes hiperparámetros: pérdida = \"perceptrón\", learning_rate = \"constante\", eta0 = 1 (la tasa de aprendizaje) y penalización = Ninguna (sin regularización)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenga en cuenta que, a diferencia de los clasificadores de Regresión logística, los Perceptrones no generan una probabilidad de clase; más bien, simplemente hacen predicciones basadas en un umbral difícil. Esta es una de las buenas razones para preferir la regresión logística sobre los perceptrones. En su monografía de 1969 titulada Perceptrons, Marvin Minsky y Seymour Papert destacaron varias debilidades serias de los Perceptrons, en particular el hecho de que son incapaces de resolver algunos problemas triviales (por ejemplo, el problema de clasificación Exclusivo OR (XOR); vea el lado izquierdo de la figura 10-6). Por supuesto, esto también se aplica a cualquier otro modelo de clasificación lineal (como los clasificadores de Regresión logística), pero los investigadores esperaban mucho más de los Perceptrones, y su decepción fue grande: como resultado, muchos investigadores abandonaron el conexionismo (es decir, el estudio de redes neuronales) a favor de problemas de nivel superior, como la lógica, la resolución de problemas y la búsqueda.\n",
    "Sin embargo, resulta que algunas de las limitaciones de los Perceptrons pueden eliminarse apilando múltiples Perceptrons. La ANN resultante se llama Perceptrón de múltiples capas (MLP). En particular, un MLP puede resolver el problema XOR, como puede verificar al calcular la salida del MLP representado a la derecha de la Figura 10-6, para cada combinación de entradas: con entradas (0, 0) o (1, 1 ) la red genera 0, y con las entradas (0, 1) o (1, 0) genera 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data:image/png;base64,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\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Perceptrón multicapa (MLP) y Backpropagation (MUY IMPORTANTE)</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un MLP se compone de una capa de entrada (pasante), una o más capas de LTU, llamadas capas ocultas, y una capa final de LTU llamada capa de salida. Cada capa, excepto la capa de salida, incluye una neurona de polarización y está completamente conectada a la siguiente capa. Cuando una ANN tiene dos o más capas ocultas, se denomina red neuronal profunda (DNN)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/6/64/RedNeuronalArtificial.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.linkedin.com/media-proxy/ext?w=397&h=375&hash=NAlhTWBMHhR4IaSC%2F69eu32BVoA%3D&ora=1%2CaFBCTXdkRmpGL2lvQUFBPQ%2CxAVta5g-0R69hAxUwxAt4ayOuFuz7VVEUIvIES7yBHi1v5XcPya9OtibIff89gNHIXBCj1VhO7buEXS4Tc2hctTyLMEszsuhfcy1fwIUJAwzl2pK_MUpNhdpu5GzF-r8LSBLxvtXfySCIbLWZlM8NSw6_OuMf8nSOVo\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durante muchos años, los investigadores lucharon por encontrar una manera de entrenar a las MLP, sin éxito.\n",
    "Pero en 1986, D. E. Rumelhart et al. publicó un artículo innovador que presenta el algoritmo de entrenamiento de la propagación hacia atrás (backpropagation). Hoy lo describiríamos como Pendiente descendente (gradiente descendente) utilizando el modo automático en modo inverso (autodiff) (la Pendiente descendente se introdujo en el Capítulo 4, y la Autodifusión se analizó en el Capítulo 9).\n",
    "Para cada instancia de entrenamiento, el algoritmo lo alimenta a la red y calcula la salida de cada neurona en cada capa consecutiva (este es el paso hacia adelante, al igual que cuando se hacen predicciones). Luego mide el error de salida de la red (es decir, la diferencia entre la salida deseada y la salida real de la red) y calcula cuánto contribuyó cada neurona en la última capa oculta al error de cada neurona de salida. Luego procede a medir la cantidad de estas contribuciones de error provenientes de cada neurona en la capa oculta anterior, y así sucesivamente hasta que el algoritmo alcance la capa de entrada. Esta pasada inversa mide de manera eficiente el gradiente de error en todos los pesos de conexión en la red propagando el gradiente de error hacia atrás en la red (de ahí el nombre del algoritmo). Si consulta los algoritmo de modo automático de modo inverso en el Apéndice D, encontrará que los pasos de avance y retroceso de la propagación hacia atrás simplemente realizan el modo automático de modo inverso. El último paso del algoritmo de propagación hacia atrás es un paso de descenso de gradiente en todos los pesos de conexión en la red, utilizando los gradientes de error medidos anteriormente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hagamos esto aún más corto: para cada instancia de entrenamiento, el algoritmo de propagación hacia atrás primero hace una predicción (pase hacia adelante), mide el error, luego pasa a través de cada capa en reversa para medir la contribución de error de cada conexión (paso en reversa), y finalmente, ajusta ligeramente los pesos de conexión para reducir el error (paso de descenso de gradiente).<br>\n",
    "Para que este algoritmo funcione correctamente, los autores hicieron un cambio clave en la arquitectura de MLP: reemplazaron la función de pasos con la función logística, σ (z) = 1 / (1 + exp (–z)). Esto fue esencial porque la función de escalón solo contiene segmentos planos, por lo que no hay un gradiente con el que trabajar (la pendiente descendente no se puede mover sobre una superficie plana), mientras que la función logística tiene un derivado distinto de cero bien definido en todas partes.<br>\n",
    "permitiendo que Gradient Descent progrese en cada paso. El algoritmo de propagación hacia atrás puede usarse con otras funciones de activación, en lugar de la función logística. Otras dos funciones de activación populares son: La función tangente hiperbólica tanh (z) = 2σ (2z) - 1<br>\n",
    "Al igual que la función logística, tiene forma de S, continua y diferenciable, pero su valor de salida varía de –1 a 1 (en lugar de 0 a 1 en el caso de la función logística), lo que tiende a aumentar la salida de cada capa. menos normalizado (es decir, centrado alrededor de 0) al comienzo del entrenamiento. Esto a menudo ayuda a acelerar la convergencia.<br>\n",
    "La función ReLU (introducida en el Capítulo 9) ReLU (z) = max (0, z). Es continuo, pero desafortunadamente no es diferenciable en z = 0 (la pendiente cambia bruscamente, lo que puede hacer que el Descenso Gradiente rebote). Sin embargo, en la práctica funciona muy bien y tiene la ventaja de ser rápido de calcular. Lo más importante es que el hecho de que no tenga un valor de salida máximo también ayuda a reducir algunos problemas durante el descenso gradual "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Algunas funciones de activacion</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://ai-master.gitbooks.io/logistic-regression/assets/sigmoid_function.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://mathworld.wolfram.com/images/interactive/TanhReal.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relu (la mas recomendada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/1000/1*3JUMOqugWKB2SDra6x6v0A.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A menudo se usa un MLP para la clasificación, con cada salida correspondiente a una clase binaria diferente (por ejemplo, correo no deseado / correo no deseado, urgente / no urgente, etc.). Cuando las clases son exclusivas (por ejemplo, las clases 0 a 9 para la clasificación de imágenes de dígitos), la capa de salida generalmente se modifica al reemplazar las funciones de activación individuales por una función de softmax compartida. La salida de cada neurona corresponde a la probabilidad estimada de la clase correspondiente. Tenga en cuenta que la señal fluye solo en una dirección (desde las entradas a las salidas), por lo que esta arquitectura es un ejemplo de una <b>red neuronal de avance (FNN)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Modelo de Red Neuronal para la clasificacion de clases exclusivas (FNN and MLP) (MUY IMPORTANTE)</H3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.oreilly.com/library/view/neural-networks-and/9781492037354/assets/mlst_1009.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Capacitación de un MLP con la API de alto nivel de TensorFlow</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La forma más sencilla de entrenar un MLP con TensorFlow es usar la API de alto nivel TF.Learn, que es bastante similar a la API de Scikit-Learn. La clase DNNClassifier hace que sea trivial entrenar una red neuronal profunda con cualquier número de capas ocultas y una capa de salida de softmax para generar probabilidades de clase estimadas. Por ejemplo, el siguiente código entrena un DNN para la clasificación con dos capas ocultas (una con 300 neuronas y la otra con 100 neuronas) y una capa de salida de softmax con 10 neuronas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-97cf3e47223f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfeature_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_real_valued_columns_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdnn_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDNNClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeature_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdnn_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "feature_columns = tf.contrib.learn.infer_real_valued_columns_from_input(X_train)\n",
    "dnn_clf = tf.contrib.learn.DNNClassifier(hidden_units=[300, 100], n_classes=10,feature_columns=feature_columns)\n",
    "dnn_clf.fit(x=X_train, y=y_train, batch_size=50, steps=40000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si ejecuta este código en el conjunto de datos MNIST (después de escalarlo, por ejemplo, al utilizar el StandardScaler de Scikit-Learn), ¡en realidad puede obtener un modelo que logre una precisión superior al 98,1% en el conjunto de pruebas! Eso es mejor que el mejor modelo que entrenamos en el Capítulo 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dnn_clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-8a47312a1b58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdnn_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dnn_clf' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = list(dnn_clf.predict(X_test))\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La biblioteca TF.Learn también proporciona algunas funciones de conveniencia para evaluar modelos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_clf.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bajo el capó, la clase DNNClassifier crea todas las capas de neuronas, según la función de activación ReLU (podemos cambiar esto configurando el hiperparámetro de activación_fn).\n",
    "La capa de salida se basa en la función softmax, y la función de costo es la entropía cruzada (introducida en el Capítulo 4).\n",
    "La API de TF.Learn es todavía bastante nueva, por lo que algunos de los nombres y funciones utilizados en estos ejemplos pueden evolucionar un poco para cuando lea este libro. Sin embargo, las ideas generales no deben cambiar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Entrenando un DNN usando el TensorFlow plano</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si desea más control sobre la arquitectura de la red, puede preferir usar la API de Python de nivel inferior de TensorFlow (presentada en el Capítulo 9). En esta sección, construiremos el mismo modelo que antes de usar esta API e implementaremos Minibatch Gradient Descent para entrenarlo en el conjunto de datos MNIST. El primer paso es la fase de construcción, construyendo el gráfico TensorFlow. El segundo paso es la fase de ejecución, donde realmente ejecutas el gráfico para entrenar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fase de construcción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empecemos. Primero necesitamos importar la biblioteca tensorflow. Luego debemos especificar el número de entradas y salidas, y establecer el número de neuronas ocultas en cada capa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "n_inputs = 28*28 #MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, al igual que lo hizo en el Capítulo 9, puede utilizar los nodos de marcador de posición para representar los datos y objetivos de la capacitación. La forma de X está solo parcialmente definida. Sabemos que será un tensor 2D (es decir, una matriz), con instancias a lo largo de la primera dimensión y características a lo largo de la segunda dimensión, y sabemos que la cantidad de características será de 28 x 28 (una característica por píxel) , pero aún no sabemos cuántas instancias contendrá cada lote de entrenamiento. Así que la forma de X es (Ninguna, n_inputs). De manera similar, sabemos que y será un tensor 1D con una entrada por instancia, pero nuevamente no sabemos el tamaño del lote de entrenamiento en este punto, por lo que la forma es (Ninguna)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a crear la red neuronal real. El marcador de posición X actuará como la capa de entrada; durante la fase de ejecución, se reemplazará con un lote de entrenamiento a la vez (tenga en cuenta que todas las instancias en un lote de entrenamiento serán procesadas simultáneamente por la red neuronal). Ahora necesitas crear las dos capas ocultas y la capa de salida.\n",
    "Las dos capas ocultas son casi idénticas: solo se diferencian por las entradas a las que están conectadas y por el número de neuronas que contienen. La capa de salida también es muy similar, pero utiliza una función de activación de softmax en lugar de una función de activación de ReLU. Así que vamos a crear una función neuron_layer () que usaremos para crear una capa a la vez. Necesitará parámetros para especificar las entradas, el número de neuronas, la función de activación y el nombre de la capa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuron_layer(X, n_neurons, name, activation=None):\n",
    "    with tf.name_scope(name):\n",
    "        n_inputs = int(np.shape(X)[1])\n",
    "        stddev = 2 / np.sqrt(n_inputs)\n",
    "        init = tf.truncated_normal((n_inputs, n_neurons), stddev=stddev)\n",
    "        W = tf.Variable(init, name=\"weights\")\n",
    "        b = tf.Variable(tf.zeros([n_neurons]), name=\"biases\")\n",
    "        z = tf.matmul(X, W) + b\n",
    "        if activation==\"relu\":\n",
    "            return tf.nn.relu(z)\n",
    "        else:\n",
    "            return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Primero, creamos un ámbito de nombre utilizando el nombre de la capa: contendrá todos los nodos de cálculo para esta capa de neurona. Esto es opcional, pero el gráfico se verá mucho mejor en TensorBoard si sus nodos están bien organizados.\n",
    "2. A continuación, obtenemos el número de entradas buscando la forma de la matriz de entrada y obteniendo el tamaño de la segunda dimensión (la primera dimensión es para instancias).\n",
    "3. Las siguientes tres líneas crean una variable W que contendrá la matriz de pesos. Será un tensor 2D que contiene todos los pesos de conexión entre cada entrada y cada neurona; Por lo tanto, su forma será (n_inputs, n_neurons). Se inicializará aleatoriamente, utilizando una distribución truncada 10 normal (gaussiana) con una desviación estándar de 2 / ninputs. El uso de esta desviación estándar específica ayuda a que el algoritmo converja mucho más rápido (lo discutiremos con mayor detalle en el Capítulo 11; es uno de esos pequeños ajustes en las redes neuronales que han tenido un impacto tremendo en su eficiencia).\n",
    "Es importante inicializar los pesos de conexión aleatoriamente para todas las capas ocultas para evitar cualquier simetría que el algoritmo de descenso de gradiente no pueda romper.\n",
    "4. La siguiente línea crea una variable b para los sesgos, inicializada a 0 (no hay problema de simetría en este caso), con un parámetro de sesgo por neurona.\n",
    "5. Luego creamos un subgrafo para calcular z = X · W + b. Esta implementación vectorizada computará de manera eficiente las sumas ponderadas de las entradas más el término de sesgo para todas y cada una de las neuronas en la capa, para todas las instancias en el lote en una sola toma.\n",
    "6. Finalmente, si el parámetro de activación se configura en \"relu\", el código devuelve relu (z) (es decir, max (0, z)), o simplemente devuelve z."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bien, ahora tienes una buena función para crear una capa neuronal. ¡Vamos a usarlo para crear la red neuronal profunda! La primera capa oculta toma X como su entrada. El segundo toma la salida de la primera capa oculta como su entrada. Y, finalmente, la capa de salida toma la salida de la segunda capa oculta como su entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Input 'b' of 'MatMul' Op has type float32 that does not match type float64 of argument 'a'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/Escritorio/PROYECTOS/entorno1/lib/python3.6/site-packages/tensorflow_core/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    527\u001b[0m                 \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_ref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m                 preferred_dtype=default_dtype)\n\u001b[0m\u001b[1;32m    529\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Escritorio/PROYECTOS/entorno1/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1272\u001b[0m           \u001b[0;34m\"Tensor conversion requested dtype %s for Tensor with dtype %s: %r\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1273\u001b[0;31m           (dtype.name, value.dtype.name, value))\n\u001b[0m\u001b[1;32m   1274\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor conversion requested dtype float64 for Tensor with dtype float32: <tf.Tensor 'dnn_2/hidden1/weights/read:0' shape=(2, 300) dtype=float32>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-877be61d13cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dnn\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mhidden1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneuron_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_hidden1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"hidden1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mhidden2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneuron_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_hidden2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"hidden2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneuron_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"outputs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-25be20337f0f>\u001b[0m in \u001b[0;36mneuron_layer\u001b[0;34m(X, n_neurons, name, activation)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"weights\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_neurons\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"biases\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Escritorio/PROYECTOS/entorno1/lib/python3.6/site-packages/tensorflow_core/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Escritorio/PROYECTOS/entorno1/lib/python3.6/site-packages/tensorflow_core/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[1;32m   2752\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2753\u001b[0m       return gen_math_ops.mat_mul(\n\u001b[0;32m-> 2754\u001b[0;31m           a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[1;32m   2755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Escritorio/PROYECTOS/entorno1/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   6134\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m   6135\u001b[0m         \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6136\u001b[0;31m                   name=name)\n\u001b[0m\u001b[1;32m   6137\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6138\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Escritorio/PROYECTOS/entorno1/lib/python3.6/site-packages/tensorflow_core/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    562\u001b[0m                   \u001b[0;34m\"%s type %s of argument '%s'.\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                   (prefix, dtypes.as_dtype(attrs[input_arg.type_attr]).name,\n\u001b[0;32m--> 564\u001b[0;31m                    inferred_from[input_arg.type_attr]))\n\u001b[0m\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m           \u001b[0mtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Input 'b' of 'MatMul' Op has type float32 that does not match type float64 of argument 'a'."
     ]
    }
   ],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = neuron_layer(X, n_hidden1, \"hidden1\", activation=\"relu\")\n",
    "    hidden2 = neuron_layer(hidden1, n_hidden2, \"hidden2\", activation=\"relu\")\n",
    "    logits = neuron_layer(hidden2, n_outputs, \"outputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenga en cuenta que una vez más usamos un ámbito de nombre para mayor claridad. También tenga en cuenta que logits es la salida de la red neuronal antes de pasar por la función de activación de softmax: por razones de optimización, manejaremos el cálculo de softmax más adelante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como es de esperar, TensorFlow viene con muchas funciones prácticas para crear capas de red neuronal estándar, por lo que a menudo no hay necesidad de definir su propia función neuron_layer () como acabamos de hacer. Por ejemplo, la función totalmente_conectada () de TensorFlow crea una capa completamente conectada, donde todas las entradas están conectadas a todas las neuronas en la capa. Se encarga de crear las variables de ponderaciones y sesgos, con la estrategia de inicialización adecuada, y utiliza la función de activación ReLU de forma predeterminada (podemos cambiar esto utilizando el argumento activation_fn). Como veremos en el Capítulo 11, también admite parámetros de regularización y normalización. Modifiquemos el código anterior para usar la función fully_connected () en lugar de nuestra función neuron_layer (). Simplemente importe la función y reemplace la sección de construcción de dnn con el siguiente código: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/andres/Escritorio/PROYECTOS/entorno1/lib/python3.6/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1866: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.contrib.layers import fully_connected\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = fully_connected(X, n_hidden1, scope=\"hidden1\")\n",
    "    hidden2 = fully_connected(hidden1, n_hidden2, scope=\"hidden2\")\n",
    "    logits = fully_connected(hidden2, n_outputs, scope=\"outputs\",activation_fn=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El paquete tensorflow.contrib contiene muchas funciones útiles, pero es un lugar para el código experimental que aún no se ha graduado para formar parte de la API principal de TensorFlow. Por lo tanto, la función full_connected () (y cualquier otro código contrib) puede cambiar o moverse en el futuro.\n",
    "Ahora que tenemos el modelo de red neuronal listo para funcionar, debemos definir la función de costo que usaremos para entrenarlo. Al igual que hicimos para la Regresión de Softmax en el Capítulo 4, usaremos la entropía cruzada. Como comentamos anteriormente, la entropía cruzada penalizará los modelos que estiman una probabilidad baja para la clase objetivo. TensorFlow proporciona varias funciones para calcular la entropía cruzada. Usaremos sparse_softmax_cross_entropy_with_logits (): calcula la entropía cruzada según los \"logits\" (es decir, la salida de la red antes de pasar por la función de activación de softmax), y espera etiquetas en forma de enteros que van desde 0 hasta el número de clases menos 1 (en nuestro caso, de 0 a 9). Esto nos dará un tensor 1D que contiene la entropía cruzada para cada instancia. Luego podemos usar la función reductor () de TensorFlow para calcular la entropía cruzada media en todas las instancias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función sparse_softmax_cross_entropy_with_logits () es equivalente a aplicar la función de activación de softmax y luego calcular la entropía cruzada, pero es más eficiente y cuida adecuadamente los casos de esquina como logits iguales a 0. Por este motivo no aplicamos la activación de softmax funciona antes También hay otra función llamada softmax_cross_entropy_with_logits (), que toma etiquetas en forma de vectores calientes (en lugar de ints desde 0 hasta el número de clases menos 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos el modelo de red neuronal, tenemos la función de costo, y ahora necesitamos definir un GradientDescentOptimizer que modificará los parámetros del modelo para minimizar la función de costo. Nada nuevo; Es como lo hicimos en el Capítulo 9:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El último paso importante en la fase de construcción es especificar cómo evaluar el modelo. Simplemente utilizaremos la precisión como nuestra medida de rendimiento. Primero, para cada instancia, determine si la predicción de la red neuronal es correcta verificando si el logit más alto corresponde o no a la clase objetivo. Para esto puedes usar la función in_top_k (). Esto devuelve un tensor 1D lleno de valores booleanos, por lo que necesitamos convertir estos booleanos en flotantes y luego calcular el promedio. Esto nos dará la precisión general de la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Input 'predictions' of 'InTopKV2' Op has type float64 that does not match expected type of float32.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/Escritorio/PROYECTOS/entorno1/lib/python3.6/site-packages/tensorflow_core/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    527\u001b[0m                 \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_ref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m                 preferred_dtype=default_dtype)\n\u001b[0m\u001b[1;32m    529\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Escritorio/PROYECTOS/entorno1/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1272\u001b[0m           \u001b[0;34m\"Tensor conversion requested dtype %s for Tensor with dtype %s: %r\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1273\u001b[0;31m           (dtype.name, value.dtype.name, value))\n\u001b[0m\u001b[1;32m   1274\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor conversion requested dtype float32 for Tensor with dtype float64: <tf.Tensor 'dnn_3/outputs/BiasAdd:0' shape=(150, 10) dtype=float64>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-a6920ed79eb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"eval\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_top_k\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Escritorio/PROYECTOS/entorno1/lib/python3.6/site-packages/tensorflow_core/python/ops/nn_ops.py\u001b[0m in \u001b[0;36min_top_k\u001b[0;34m(predictions, targets, k, name)\u001b[0m\n\u001b[1;32m   4841\u001b[0m   \"\"\"\n\u001b[1;32m   4842\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"in_top_k\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4843\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_nn_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_top_kv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Escritorio/PROYECTOS/entorno1/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36min_top_kv2\u001b[0;34m(predictions, targets, k, name)\u001b[0m\n\u001b[1;32m   5040\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5041\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m-> 5042\u001b[0;31m         \"InTopKV2\", predictions=predictions, targets=targets, k=k, name=name)\n\u001b[0m\u001b[1;32m   5043\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5044\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Escritorio/PROYECTOS/entorno1/lib/python3.6/site-packages/tensorflow_core/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtypes_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDT_INVALID\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m               raise TypeError(\"%s expected type of %s.\" %\n\u001b[0;32m--> 551\u001b[0;31m                               (prefix, dtypes.as_dtype(input_arg.type).name))\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m               \u001b[0;31m# Update the maps with the default, if needed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Input 'predictions' of 'InTopKV2' Op has type float64 that does not match expected type of float32."
     ]
    }
   ],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y, como es habitual, debemos crear un nodo para inicializar todas las variables, y también crearemos un protector para guardar los parámetros de nuestro modelo entrenado en el disco:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Uf! Con esto concluye la fase de construcción. Esto fue menos de 40 líneas de código, pero fue bastante intenso: creamos marcadores de posición para las entradas y los objetivos, creamos una función para construir una capa de neurona, la usamos para crear el DNN, definimos la función de costo, Creamos un optimizador, y finalmente definimos la medida de rendimiento. Ahora a la fase de ejecución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fase de ejecución"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta parte es mucho más corta y más simple. Primero, carguemos MNIST. Podríamos usar Scikit-Learn para eso como lo hicimos en los capítulos anteriores, pero TensorFlow ofrece su propio ayudante que obtiene los datos, los escala (entre 0 y 1), los baraja y proporciona una función simple para cargar un mini lote. hora. Así que vamos a usarlo en su lugar: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ahora definimos el número de épocas que queremos ejecutar, así como el tamaño de los mini lotes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 400\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y ahora podemos entrenar el modelo: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "init.run()\n",
    "for epoch in range(n_epochs):\n",
    "for iteration in range(mnist.train.num_examples // batch_size):\n",
    "X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "acc_test = accuracy.eval(feed_dict={X: mnist.test.images,\n",
    "y: mnist.test.labels})\n",
    "print(epoch, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test)\n",
    "save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código abre una sesión de TensorFlow y ejecuta el nodo de inicio que inicializa todas las variables. Luego ejecuta el ciclo de entrenamiento principal: en cada época, el código se itera a través de varios mini lotes que corresponden al tamaño del conjunto de entrenamiento. Cada mini lote se obtiene a través del método next_batch (), y luego el código simplemente ejecuta la operación de entrenamiento, y le proporciona los datos y objetivos de entrada del mini lote actual. A continuación, al final de cada época, el código evalúa el modelo en el último mini lote y en el conjunto completo de entrenamiento, e imprime el resultado. Finalmente, los parámetros del modelo se guardan en el disco."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando la red neuronal\n",
    "Ahora que la red neuronal está entrenada, puedes usarla para hacer predicciones. Para hacer eso, puede reutilizar la misma fase de construcción, pero cambiar la fase de ejecución de esta manera: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "X_new_scaled = [...] # some new images (scaled from 0 to 1)\n",
    "Z = logits.eval(feed_dict={X: X_new_scaled})\n",
    "y_pred = np.argmax(Z, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero el código carga los parámetros del modelo desde el disco. Luego carga algunas imágenes nuevas que quieres clasificar. Recuerde aplicar la misma función de escala que para los datos de entrenamiento (en este caso, escale de 0 a 1). Luego el código evalúa el nodo logits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si quisiera conocer todas las probabilidades estimadas de la clase, tendría que aplicar la función softmax () a los logits, pero si solo quiere predecir una clase, simplemente puede elegir la clase que tenga el valor logit más alto (usando la función argmax () hace el truco)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Hiperparámetros de red neuronal de ajuste fino</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://unipython.com/wp-content/uploads/2018/04/deeplLearning-python3-min-840x430.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La flexibilidad de las redes neuronales es también uno de sus principales inconvenientes: hay muchos hiperparámetros para modificar. No solo puede usar cualquier topología de red imaginable (cómo se interconectan las neuronas), sino que incluso en un MLP simple puede cambiar el número de capas, el número de neuronas por capa, el tipo de función de activación que se debe usar en cada capa, el peso Lógica de inicialización, y mucho más. ¿Cómo sabes qué combinación de hiperparámetros es la mejor para tu tarea? Por supuesto, puede usar la búsqueda en cuadrícula con validación cruzada para encontrar los hiperparámetros correctos, como lo hizo en los capítulos anteriores, pero ya que hay muchos parámetros para sintonizar, y desde el entrenamiento de una red neuronal en un gran conjunto de datos lleva mucho tiempo, solo podrá explorar una pequeña parte del espacio del hiperparámetro en un tiempo razonable. Es mucho mejor utilizar la búsqueda aleatoria, como vimos en el Capítulo 2. Otra opción es usar una herramienta como Oscar, que implementa algoritmos más complejos para ayudarlo a encontrar rápidamente un buen conjunto de hiperparámetros.\n",
    "Es útil tener una idea de qué valores son razonables para cada hiperparámetro, de modo que pueda restringir el espacio de búsqueda. Vamos a empezar con el número de capas ocultas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Número de capas ocultas</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para muchos problemas, puede comenzar con una sola capa oculta y obtendrá resultados razonables. En realidad, se ha demostrado que una MLP con una sola capa oculta puede modelar incluso las funciones más complejas siempre que tenga suficientes neuronas. Durante mucho tiempo, estos hechos convencieron a los investigadores de que no había necesidad de investigar redes neuronales más profundas. Pero pasaron por alto el hecho de que las redes profundas tienen una eficacia de parámetros mucho más alta que las superficiales: <b>pueden modelar funciones complejas utilizando exponencialmente menos neuronas que redes poco profundas, lo que las hace mucho más rápidas para entrenar.</b><br>\n",
    "Para entender por qué, suponga que se le pide que dibuje un bosque utilizando algún software de dibujo, pero está prohibido copiar / pegar. Tendrías que dibujar cada árbol individualmente, rama por rama, hoja por hoja. Si en cambio podría dibujar una hoja, cópiela / pegue para dibujar una rama, luego copie / pegue esa rama para crear un árbol, y finalmente copie / pegue este árbol para hacer un bosque, terminará en poco tiempo. Los datos del mundo real a menudo se estructuran de forma jerárquica y los DNN aprovechan automáticamente este hecho: las capas ocultas inferiores modelan estructuras de bajo nivel (por ejemplo, segmentos de línea de varias formas y orientaciones), las capas ocultas intermedias combinan estas estructuras de bajo nivel para modelar las estructuras de nivel intermedio (por ejemplo, cuadrados, círculos) y las capas ocultas más altas y la capa de salida combinan estas estructuras intermedias para modelar estructuras de alto nivel (por ejemplo, caras).\n",
    "Esta arquitectura jerárquica no solo ayuda a los DNN a converger más rápido a una buena solución, sino que también mejora su capacidad para generalizar a nuevos conjuntos de datos.<b> Por ejemplo, si ya ha entrenado a un modelo para reconocer rostros en imágenes y ahora desea entrenar a una nueva red neuronal para reconocer los peinados, entonces puede comenzar el entrenamiento al reutilizar las capas inferiores de la primera red. En lugar de inicializar aleatoriamente los pesos y sesgos de las primeras capas de la nueva red neuronal, puede inicializarlos con el valor de los pesos y sesgos de las capas inferiores de la primera red.<br>\n",
    "De esta manera, la red no tendrá que aprender desde cero todas las estructuras de bajo nivel que se producen en la mayoría de las imágenes; solo tendrá que aprender las estructuras de nivel superior (por ejemplo, peinados)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En resumen, para muchos problemas, puede comenzar con solo una o dos capas ocultas y funcionará bien (por ejemplo, puede alcanzar fácilmente una precisión superior al 97% en el conjunto de datos MNIST utilizando solo una capa oculta con unos pocos cientos de neuronas, y más 98% de precisión usando dos capas ocultas con la misma cantidad total de neuronas, en aproximadamente la misma cantidad de tiempo de entrenamiento). Para problemas más complejos, puede aumentar gradualmente el número de capas ocultas, hasta que comience a adaptar excesivamente el conjunto de entrenamiento. Las tareas muy complejas, como la clasificación de imágenes grandes o el reconocimiento de voz, generalmente requieren redes con una docena de capas (o incluso cientos, pero no totalmente conectadas, como veremos en el Capítulo 13), y necesitan una gran cantidad de datos de entrenamiento. <b>Sin embargo, rara vez tendrá que capacitar a dichas redes desde cero: es mucho más común reutilizar partes de una red de vanguardia pre-entrenada que realiza una tarea similar.\n",
    "La capacitación será mucho más rápida y requerirá menos datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Número de neuronas por capa oculta</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviamente, el número de neuronas en las capas de entrada y salida está determinado por el tipo de entrada y salida que requiere su tarea. Por ejemplo, la tarea MNIST requiere 28 x 28 = 784 neuronas de entrada y 10 neuronas de salida. <b>En cuanto a las capas ocultas, una práctica común es dimensionarlas para formar un embudo, con cada vez menos neuronas en cada capa; la razón es que muchas características de bajo nivel pueden unirse en muchas menos características de alto nivel.</b> Por ejemplo, una red neuronal típica para MNIST puede tener dos capas ocultas, la primera con 300 neuronas y la segunda con 100. Sin embargo, esta práctica no es tan común ahora, y simplemente puede usar el mismo tamaño para todas las capas ocultas, para Por ejemplo, todas las capas ocultas con 150 neuronas: eso es solo un hiperparámetro para sintonizar en lugar de uno por capa. Al igual que para la cantidad de capas, puede intentar aumentar la cantidad de neuronas gradualmente hasta que la red comience a sobrecargarse. En general, obtendrás más beneficios por aumentar la cantidad de capas que la cantidad de neuronas por capa. Desafortunadamente, como puedes ver, encontrar la cantidad perfecta de neuronas sigue siendo un arte negro.<br>\n",
    "Un enfoque más sencillo es elegir un modelo con más capas y neuronas de las que realmente necesita, luego usar una parada temprana para evitar que se adapte (y otras técnicas de regularización, especialmente la deserción). Esto se ha denominado el enfoque de “pantalones elásticos”:  en lugar de perder el tiempo buscando pantalones que se ajusten perfectamente a su talla, solo use pantalones elásticos grandes que se reducirán al tamaño correcto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Funciones de activacion</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>En la mayoría de los casos, puede usar la función de activación ReLU en las capas ocultas (o una de sus variantes).</b> Es un poco más rápido de computar que otras funciones de activación, y Gradient Descent no se atasca tanto en las mesetas,\n",
    "gracias al hecho de que no se satura para valores de entrada grandes (a diferencia de la función logística o la función de tangente hiperbólica, que saturan en 1).\n",
    "<b>Para la capa de salida, la función de activación de softmax es generalmente una buena opción para tareas de clasificación (cuando las clases son mutuamente excluyentes). Para las tareas de regresión, simplemente no puede utilizar ninguna función de activación.</b>\n",
    "Con esto concluye esta introducción a las redes neuronales artificiales. En los siguientes capítulos, analizaremos técnicas para entrenar redes muy profundas y distribuir capacitación a través de múltiples servidores y GPU. Luego exploraremos algunas otras arquitecturas de redes neuronales populares: redes neuronales convolucionales, redes neuronales recurrentes y autocodificadores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta aca tenemos el tema de introduccion a las Redes Neuronales. Si tienes alguna duda no olvides escribir a <br>\n",
    "<b>andres.programacion123@gmail.com</b>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>INTRODUCCION A TENSORFLOW</h1>\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/1/11/TensorFlowLogo.svg/1200px-TensorFlowLogo.svg.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow es una biblioteca de código abierto para aprendizaje automático a través de un rango de tareas, y desarrollado por Google para satisfacer sus necesidades de sistemas capaces de construir y entrenar redes neuronales para detectar y descifrar patrones y correlaciones, análogos al aprendizaje y razonamiento usados por los humanos. Actualmente es utilizado tanto en la investigación como en los productos de Google.\n",
    "TensorFlow puede correr en múltiple CPUs y GPUs (con extensiones opcionales de CUDA para informática de propósito general en unidades de procesamiento gráfico). TensorFlow está disponible para Windows, Linux, macOS, y plataformas móviles que incluyen Android e iOS.\n",
    "\n",
    "El nombre TensorFlow deriva de las operaciones que tales redes neuronales realizan sobre arrays multidimensionales de datos. Estos arrays multidimensionales son referidos como \"tensores\". En una primera versión los computos de TensorFlow se expresaban como stateful dataflow graphs , sin embargo, con la evolución de la biblioteca la forma de codificar estas redes se ha vuelto más imperativa.\n",
    "TensorFlow 2.012 se centra en la simplicidad y la facilidad de uso, con actualizaciones importantes como (1) el modelo de ejecución (modo eager), consolidar el uso de una API intuitivas de alto nivel (basada en Keras) y el despliegue flexible de modelos en cualquier plataforma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.adictosaltrabajo.com/wp-content/uploads/2018/03/tensorflow_programming_environment.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://developers.google.com/machine-learning/crash-course/images/TFHierarchy.svg?hl=es-419\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Su principio básico es simple: primero define en Python un gráfico de cómputos para realizar (por ejemplo, el de la Figura 9-1), y luego TensorFlow toma ese gráfico y lo ejecuta de manera eficiente utilizando el código de C ++ optimizado. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/1816/0*uLG6xpaZISYSSHkD\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.gmv.com/blog_gmv/wp-content/uploads/Tools1.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://d1m75rqqgidzqn.cloudfront.net/wp-data/2020/03/06094458/image-1024x508.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo más importante es que es posible dividir el gráfico en varios fragmentos y ejecutarlos en paralelo en múltiples CPU o GPU (como se muestra en la Figura 9-2). TensorFlow también admite la computación distribuida, por lo que puede entrenar redes neuronales colosales en conjuntos de capacitación gigantescos en un tiempo razonable dividiendo los cálculos en cientos de servidores (consulte el Capítulo 12). TensorFlow puede entrenar una red con millones de parámetros en un conjunto de entrenamiento compuesto de miles de millones de instancias con millones de funciones cada uno. Esto no debería ser una sorpresa, ya que TensorFlow fue desarrollado por el equipo de Google Brain y potencia muchos de los servicios a gran escala de Google, como Google Cloud Speech, Google Photos y Google Search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://preview.redd.it/zumj51eh01g41.png?width=529&format=png&auto=webp&s=4905a3ca77867326c72e86223c964a41ddf8a12d\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando TensorFlow fue de código abierto en noviembre de 2015, ya existían muchas bibliotecas de código abierto populares para el Aprendizaje Profundo (la Tabla 9-1 enumera algunas), y para ser justos, la mayoría de las funciones de TensorFlow ya existían en una biblioteca u otra. Sin embargo, el diseño limpio, la escalabilidad, la flexibilidad 1 de TensorFlow y la excelente documentación (sin mencionar el nombre de Google) lo llevaron rápidamente a la cima de la lista. En resumen, TensorFlow fue diseñado para ser flexible, escalable y listo para la producción, y los marcos existentes probablemente solo alcanzan a dos de los tres. Éstos son algunos de los aspectos más destacados de TensorFlow:<br>\n",
    "• Se ejecuta no solo en Windows, Linux y macOS, sino también en dispositivos móviles, incluidos iOS y Android.\n",
    "1 TensorFlow no se limita a redes neuronales o incluso a Aprendizaje automático; Podrías ejecutar simulaciones de física cuántica si quisieras.<br>\n",
    "• Proporciona una API de Python muy simple llamada TF.Learn2 (tensorflow.con trib.learn), compatible con Scikit-Learn. Como verá, puede usarlo para entrenar varios tipos de redes neuronales en solo unas pocas líneas de código. Anteriormente era un proyecto independiente llamado Scikit Flow (o skflow).<br>\n",
    "• También proporciona otra API simple llamada TF-slim (tensorflow.contrib.slim) para simplificar la construcción, entrenamiento y evaluación de redes neuronales.<br>\n",
    "• Varias otras API de alto nivel se han construido de manera independiente sobre TensorFlow, como Keras o Pretty Tensor.<br>\n",
    "• Su API principal de Python ofrece mucha más flexibilidad (a costa de una mayor complejidad) para crear todo tipo de cálculos, incluida cualquier arquitectura de red neuronal que se pueda imaginar.<br>\n",
    "• Incluye implementaciones en C ++ altamente eficientes de muchas operaciones de LD, en particular las necesarias para construir redes neuronales. También hay una API de C ++ para definir sus propias operaciones de alto rendimiento.<br>\n",
    "• Proporciona varios nodos de optimización avanzada para buscar los parámetros que minimizan una función de costo. Son muy fáciles de usar, ya que TensorFlow se encarga automáticamente de calcular los gradientes de las funciones que define. Esto se denomina diferenciación automática (o autodiff).<br>\n",
    "• También viene con una gran herramienta de visualización llamada TensorBoard que le permite navegar por el gráfico de cómputo, ver las curvas de aprendizaje y más.<br>\n",
    "• Google también lanzó un servicio en la nube para ejecutar gráfos TensorFlow.<br>\n",
    "• Por último, pero no menos importante, tiene un equipo dedicado de desarrolladores apasionados y serviciales, y una comunidad en crecimiento que contribuye a mejorarlo. Es uno de los proyectos de código abierto más populares en GitHub, y se están construyendo cada vez más grandes proyectos (por ejemplo, visite la página de recursos en https://www.tensorflow.org/, o https: //github.com/jtoy/awesome-tensorflow). Para hacer preguntas técnicas, debe usar http://stackoverflow.com/ y etiquetar su pregunta con \"tensorflow\". Puede archivar errores y solicitudes de características a través de GitHub.<br>\n",
    "Para discusiones generales, únete al grupo de Google.<br>\n",
    "En este capítulo, veremos los conceptos básicos de TensorFlow, desde la instalación hasta la creación, ejecución, guardado y visualización de gráficos computacionales simples. Dominar estos conceptos básicos es importante antes de construir su primera red neuronal (lo cual haremos en el próximo capítulo).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instalación\n",
    "¡Empecemos! Suponiendo que instaló Jupyter y Scikit Learn siguiendo las instrucciones de instalación en el Capítulo 2, simplemente puede usar pip para instalar TensorFlow. Si creó un entorno aislado usando virtualenv, primero debe activarlo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, instale TensorFlow:<br>\n",
    "<b>$ pip3 install --upgrade tensorflow<br></b>\n",
    "    \n",
    "Para el soporte de GPU, necesita instalar tensorflow-gpu en lugar de tensorflow. Vea el Capítulo 12 para más detalles.<br>\n",
    "Para probar su instalación, escriba el siguiente comando. Debe mostrar la versión de TensorFlow que instaló.<br>\n",
    "<b>python3 -c 'import tensorflow; print(tensorflow.__version__)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "<h3>Creando tu primer gráfico y ejecutándolo en una sesión</h3><br>\n",
    "El siguiente código crea el gráfico representado en la Figura 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.AttrValue is deprecated. Please use tf.compat.v1.AttrValue instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.COMPILER_VERSION is deprecated. Please use tf.version.COMPILER_VERSION instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.CXX11_ABI_FLAG is deprecated. Please use tf.sysconfig.CXX11_ABI_FLAG instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.ConditionalAccumulator is deprecated. Please use tf.compat.v1.ConditionalAccumulator instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.ConditionalAccumulatorBase is deprecated. Please use tf.compat.v1.ConditionalAccumulatorBase instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.Dimension is deprecated. Please use tf.compat.v1.Dimension instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.Event is deprecated. Please use tf.compat.v1.Event instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.FIFOQueue is deprecated. Please use tf.queue.FIFOQueue instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.FixedLenSequenceFeature is deprecated. Please use tf.io.FixedLenSequenceFeature instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.GIT_VERSION is deprecated. Please use tf.version.GIT_VERSION instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.GRAPH_DEF_VERSION is deprecated. Please use tf.version.GRAPH_DEF_VERSION instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.GRAPH_DEF_VERSION_MIN_CONSUMER is deprecated. Please use tf.version.GRAPH_DEF_VERSION_MIN_CONSUMER instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.GRAPH_DEF_VERSION_MIN_PRODUCER is deprecated. Please use tf.version.GRAPH_DEF_VERSION_MIN_PRODUCER instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.GraphOptions is deprecated. Please use tf.compat.v1.GraphOptions instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.HistogramProto is deprecated. Please use tf.compat.v1.HistogramProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.InteractiveSession is deprecated. Please use tf.compat.v1.InteractiveSession instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.LogMessage is deprecated. Please use tf.compat.v1.LogMessage instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.MONOLITHIC_BUILD is deprecated. Please use tf.sysconfig.MONOLITHIC_BUILD instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.MetaGraphDef is deprecated. Please use tf.compat.v1.MetaGraphDef instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.NameAttrList is deprecated. Please use tf.compat.v1.NameAttrList instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.NoGradient is deprecated. Please use tf.no_gradient instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.NodeDef is deprecated. Please use tf.compat.v1.NodeDef instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.NotDifferentiable is deprecated. Please use tf.no_gradient instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.OpError is deprecated. Please use tf.errors.OpError instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.OptimizerOptions is deprecated. Please use tf.compat.v1.OptimizerOptions instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.PaddingFIFOQueue is deprecated. Please use tf.queue.PaddingFIFOQueue instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.PriorityQueue is deprecated. Please use tf.queue.PriorityQueue instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.QUANTIZED_DTYPES is deprecated. Please use tf.dtypes.QUANTIZED_DTYPES instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.QueueBase is deprecated. Please use tf.queue.QueueBase instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.RandomShuffleQueue is deprecated. Please use tf.queue.RandomShuffleQueue instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.ReaderBase is deprecated. Please use tf.compat.v1.ReaderBase instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.RunMetadata is deprecated. Please use tf.compat.v1.RunMetadata instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.RunOptions is deprecated. Please use tf.compat.v1.RunOptions instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.SessionLog is deprecated. Please use tf.compat.v1.SessionLog instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.SparseConditionalAccumulator is deprecated. Please use tf.compat.v1.SparseConditionalAccumulator instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.SparseFeature is deprecated. Please use tf.io.SparseFeature instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.SparseTensorValue is deprecated. Please use tf.compat.v1.SparseTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.SummaryMetadata is deprecated. Please use tf.compat.v1.SummaryMetadata instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.TensorInfo is deprecated. Please use tf.compat.v1.TensorInfo instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.VERSION is deprecated. Please use tf.version.VERSION instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.VariableScope is deprecated. Please use tf.compat.v1.VariableScope instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.accumulate_n is deprecated. Please use tf.math.accumulate_n instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.add_check_numerics_ops is deprecated. Please use tf.compat.v1.add_check_numerics_ops instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.add_to_collections is deprecated. Please use tf.compat.v1.add_to_collections instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.angle is deprecated. Please use tf.math.angle instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.arg_max is deprecated. Please use tf.argmax instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.arg_min is deprecated. Please use tf.argmin instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.assert_greater is deprecated. Please use tf.compat.v1.assert_greater instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.assert_greater_equal is deprecated. Please use tf.compat.v1.assert_greater_equal instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.assert_integer is deprecated. Please use tf.compat.v1.assert_integer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.assert_less is deprecated. Please use tf.compat.v1.assert_less instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.assert_near is deprecated. Please use tf.compat.v1.assert_near instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.assert_negative is deprecated. Please use tf.compat.v1.assert_negative instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.assert_non_negative is deprecated. Please use tf.compat.v1.assert_non_negative instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.assert_non_positive is deprecated. Please use tf.compat.v1.assert_non_positive instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.assert_none_equal is deprecated. Please use tf.compat.v1.assert_none_equal instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.assert_positive is deprecated. Please use tf.compat.v1.assert_positive instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.assert_proper_iterable is deprecated. Please use tf.debugging.assert_proper_iterable instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.assert_rank is deprecated. Please use tf.compat.v1.assert_rank instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.assert_rank_at_least is deprecated. Please use tf.compat.v1.assert_rank_at_least instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.assert_rank_in is deprecated. Please use tf.compat.v1.assert_rank_in instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.assert_same_float_dtype is deprecated. Please use tf.debugging.assert_same_float_dtype instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.assert_scalar is deprecated. Please use tf.compat.v1.assert_scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.assert_type is deprecated. Please use tf.compat.v1.assert_type instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.assert_variables_initialized is deprecated. Please use tf.compat.v1.assert_variables_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.assign_sub is deprecated. Please use tf.compat.v1.assign_sub instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.batch_to_space_nd is deprecated. Please use tf.batch_to_space instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.betainc is deprecated. Please use tf.math.betainc instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.bincount is deprecated. Please use tf.math.bincount instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.ceil is deprecated. Please use tf.math.ceil instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.check_numerics is deprecated. Please use tf.debugging.check_numerics instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.cholesky is deprecated. Please use tf.linalg.cholesky instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.cholesky_solve is deprecated. Please use tf.linalg.cholesky_solve instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.confusion_matrix is deprecated. Please use tf.math.confusion_matrix instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.conj is deprecated. Please use tf.math.conj instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.container is deprecated. Please use tf.compat.v1.container instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.control_flow_v2_enabled is deprecated. Please use tf.compat.v1.control_flow_v2_enabled instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.convert_to_tensor_or_indexed_slices is deprecated. Please use tf.compat.v1.convert_to_tensor_or_indexed_slices instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.convert_to_tensor_or_sparse_tensor is deprecated. Please use tf.compat.v1.convert_to_tensor_or_sparse_tensor instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.cross is deprecated. Please use tf.linalg.cross instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.cumprod is deprecated. Please use tf.math.cumprod instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.decode_base64 is deprecated. Please use tf.io.decode_base64 instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.decode_compressed is deprecated. Please use tf.io.decode_compressed instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.decode_csv is deprecated. Please use tf.io.decode_csv instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.decode_json_example is deprecated. Please use tf.io.decode_json_example instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.delete_session_tensor is deprecated. Please use tf.compat.v1.delete_session_tensor instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.depth_to_space is deprecated. Please use tf.compat.v1.depth_to_space instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.dequantize is deprecated. Please use tf.quantization.dequantize instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.deserialize_many_sparse is deprecated. Please use tf.io.deserialize_many_sparse instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.diag is deprecated. Please use tf.linalg.tensor_diag instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.diag_part is deprecated. Please use tf.linalg.tensor_diag_part instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.digamma is deprecated. Please use tf.math.digamma instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.dimension_at_index is deprecated. Please use tf.compat.dimension_at_index instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.dimension_value is deprecated. Please use tf.compat.dimension_value instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.disable_control_flow_v2 is deprecated. Please use tf.compat.v1.disable_control_flow_v2 instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.disable_eager_execution is deprecated. Please use tf.compat.v1.disable_eager_execution instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.disable_tensor_equality is deprecated. Please use tf.compat.v1.disable_tensor_equality instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.disable_v2_behavior is deprecated. Please use tf.compat.v1.disable_v2_behavior instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.disable_v2_tensorshape is deprecated. Please use tf.compat.v1.disable_v2_tensorshape instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.div_no_nan is deprecated. Please use tf.math.divide_no_nan instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.enable_control_flow_v2 is deprecated. Please use tf.compat.v1.enable_control_flow_v2 instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.enable_eager_execution is deprecated. Please use tf.compat.v1.enable_eager_execution instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.enable_tensor_equality is deprecated. Please use tf.compat.v1.enable_tensor_equality instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.enable_v2_behavior is deprecated. Please use tf.compat.v1.enable_v2_behavior instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.enable_v2_tensorshape is deprecated. Please use tf.compat.v1.enable_v2_tensorshape instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.encode_base64 is deprecated. Please use tf.io.encode_base64 instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.erf is deprecated. Please use tf.math.erf instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.erfc is deprecated. Please use tf.math.erfc instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.expm1 is deprecated. Please use tf.math.expm1 instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.fake_quant_with_min_max_args is deprecated. Please use tf.quantization.fake_quant_with_min_max_args instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.fake_quant_with_min_max_args_gradient is deprecated. Please use tf.quantization.fake_quant_with_min_max_args_gradient instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.fake_quant_with_min_max_vars is deprecated. Please use tf.quantization.fake_quant_with_min_max_vars instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.fake_quant_with_min_max_vars_gradient is deprecated. Please use tf.quantization.fake_quant_with_min_max_vars_gradient instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.fake_quant_with_min_max_vars_per_channel is deprecated. Please use tf.quantization.fake_quant_with_min_max_vars_per_channel instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.fake_quant_with_min_max_vars_per_channel_gradient is deprecated. Please use tf.quantization.fake_quant_with_min_max_vars_per_channel_gradient instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.fft is deprecated. Please use tf.signal.fft instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.fft2d is deprecated. Please use tf.signal.fft2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.fft3d is deprecated. Please use tf.signal.fft3d instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.fixed_size_partitioner is deprecated. Please use tf.compat.v1.fixed_size_partitioner instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.floor_div is deprecated. Please use tf.math.floordiv instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.floordiv is deprecated. Please use tf.math.floordiv instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.floormod is deprecated. Please use tf.math.floormod instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.get_collection_ref is deprecated. Please use tf.compat.v1.get_collection_ref instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.get_local_variable is deprecated. Please use tf.compat.v1.get_local_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.get_seed is deprecated. Please use tf.compat.v1.get_seed instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.get_session_handle is deprecated. Please use tf.compat.v1.get_session_handle instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.get_session_tensor is deprecated. Please use tf.compat.v1.get_session_tensor instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.ifft is deprecated. Please use tf.signal.ifft instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.ifft2d is deprecated. Please use tf.signal.ifft2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.ifft3d is deprecated. Please use tf.signal.ifft3d instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.igamma is deprecated. Please use tf.math.igamma instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.igammac is deprecated. Please use tf.math.igammac instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.imag is deprecated. Please use tf.math.imag instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.invert_permutation is deprecated. Please use tf.math.invert_permutation instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.is_inf is deprecated. Please use tf.math.is_inf instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.is_non_decreasing is deprecated. Please use tf.math.is_non_decreasing instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.is_numeric_tensor is deprecated. Please use tf.debugging.is_numeric_tensor instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.is_strictly_increasing is deprecated. Please use tf.math.is_strictly_increasing instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.lbeta is deprecated. Please use tf.math.lbeta instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.lgamma is deprecated. Please use tf.math.lgamma instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.lin_space is deprecated. Please use tf.linspace instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.local_variables is deprecated. Please use tf.compat.v1.local_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.log1p is deprecated. Please use tf.math.log1p instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.log_sigmoid is deprecated. Please use tf.math.log_sigmoid instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.logical_xor is deprecated. Please use tf.math.logical_xor instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.make_template is deprecated. Please use tf.compat.v1.make_template instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.make_tensor_proto is deprecated. Please use tf.compat.v1.make_tensor_proto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.matching_files is deprecated. Please use tf.io.matching_files instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.matrix_band_part is deprecated. Please use tf.linalg.band_part instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.matrix_determinant is deprecated. Please use tf.linalg.det instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.matrix_diag is deprecated. Please use tf.linalg.diag instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.matrix_diag_part is deprecated. Please use tf.linalg.diag_part instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.matrix_set_diag is deprecated. Please use tf.linalg.set_diag instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.matrix_solve is deprecated. Please use tf.linalg.solve instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.matrix_solve_ls is deprecated. Please use tf.linalg.lstsq instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.matrix_transpose is deprecated. Please use tf.linalg.matrix_transpose instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.matrix_triangular_solve is deprecated. Please use tf.linalg.triangular_solve instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.min_max_variable_partitioner is deprecated. Please use tf.compat.v1.min_max_variable_partitioner instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.mod is deprecated. Please use tf.math.mod instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.model_variables is deprecated. Please use tf.compat.v1.model_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.moving_average_variables is deprecated. Please use tf.compat.v1.moving_average_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.no_regularizer is deprecated. Please use tf.compat.v1.no_regularizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.op_scope is deprecated. Please use tf.compat.v1.op_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.parse_example is deprecated. Please use tf.io.parse_example instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.parse_single_sequence_example is deprecated. Please use tf.io.parse_single_sequence_example instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.parse_tensor is deprecated. Please use tf.io.parse_tensor instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.polygamma is deprecated. Please use tf.math.polygamma instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.qr is deprecated. Please use tf.linalg.qr instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.quantize is deprecated. Please use tf.quantization.quantize instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.quantized_concat is deprecated. Please use tf.quantization.quantized_concat instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.random_crop is deprecated. Please use tf.image.random_crop instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.random_gamma is deprecated. Please use tf.random.gamma instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.random_poisson is deprecated. Please use tf.random.poisson instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.read_file is deprecated. Please use tf.io.read_file instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.real is deprecated. Please use tf.math.real instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.reciprocal is deprecated. Please use tf.math.reciprocal instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.regex_replace is deprecated. Please use tf.strings.regex_replace instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.report_uninitialized_variables is deprecated. Please use tf.compat.v1.report_uninitialized_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.resource_variables_enabled is deprecated. Please use tf.compat.v1.resource_variables_enabled instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.reverse_v2 is deprecated. Please use tf.reverse instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.rint is deprecated. Please use tf.math.rint instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.rsqrt is deprecated. Please use tf.math.rsqrt instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.scatter_add is deprecated. Please use tf.compat.v1.scatter_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.scatter_div is deprecated. Please use tf.compat.v1.scatter_div instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.scatter_max is deprecated. Please use tf.compat.v1.scatter_max instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.scatter_min is deprecated. Please use tf.compat.v1.scatter_min instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.scatter_mul is deprecated. Please use tf.compat.v1.scatter_mul instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.scatter_nd_add is deprecated. Please use tf.compat.v1.scatter_nd_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.scatter_nd_sub is deprecated. Please use tf.compat.v1.scatter_nd_sub instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.scatter_nd_update is deprecated. Please use tf.compat.v1.scatter_nd_update instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.scatter_sub is deprecated. Please use tf.compat.v1.scatter_sub instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.scatter_update is deprecated. Please use tf.compat.v1.scatter_update instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.segment_max is deprecated. Please use tf.math.segment_max instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.segment_mean is deprecated. Please use tf.math.segment_mean instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.segment_min is deprecated. Please use tf.math.segment_min instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.segment_prod is deprecated. Please use tf.math.segment_prod instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.segment_sum is deprecated. Please use tf.math.segment_sum instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.self_adjoint_eig is deprecated. Please use tf.linalg.eigh instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.self_adjoint_eigvals is deprecated. Please use tf.linalg.eigvalsh instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.serialize_many_sparse is deprecated. Please use tf.compat.v1.serialize_many_sparse instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.serialize_sparse is deprecated. Please use tf.compat.v1.serialize_sparse instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.serialize_tensor is deprecated. Please use tf.io.serialize_tensor instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.space_to_batch_nd is deprecated. Please use tf.space_to_batch instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.space_to_depth is deprecated. Please use tf.compat.v1.space_to_depth instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.sparse_fill_empty_rows is deprecated. Please use tf.sparse.fill_empty_rows instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.sparse_mask is deprecated. Please use tf.sparse.mask instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.sparse_matmul is deprecated. Please use tf.linalg.matmul instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.sparse_maximum is deprecated. Please use tf.sparse.maximum instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.sparse_minimum is deprecated. Please use tf.sparse.minimum instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.sparse_placeholder is deprecated. Please use tf.compat.v1.sparse_placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.sparse_reorder is deprecated. Please use tf.sparse.reorder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.sparse_reset_shape is deprecated. Please use tf.sparse.reset_shape instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.sparse_reshape is deprecated. Please use tf.sparse.reshape instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.sparse_retain is deprecated. Please use tf.sparse.retain instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.sparse_segment_mean is deprecated. Please use tf.compat.v1.sparse_segment_mean instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.sparse_segment_sqrt_n is deprecated. Please use tf.compat.v1.sparse_segment_sqrt_n instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.sparse_segment_sum is deprecated. Please use tf.compat.v1.sparse_segment_sum instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.sparse_slice is deprecated. Please use tf.sparse.slice instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.sparse_softmax is deprecated. Please use tf.sparse.softmax instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.sparse_tensor_dense_matmul is deprecated. Please use tf.sparse.sparse_dense_matmul instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.sparse_to_indicator is deprecated. Please use tf.sparse.to_indicator instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.sparse_transpose is deprecated. Please use tf.sparse.transpose instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.squared_difference is deprecated. Please use tf.math.squared_difference instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.string_join is deprecated. Please use tf.strings.join instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.string_strip is deprecated. Please use tf.strings.strip instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.string_to_hash_bucket is deprecated. Please use tf.strings.to_hash_bucket instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.string_to_hash_bucket_fast is deprecated. Please use tf.strings.to_hash_bucket_fast instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.string_to_hash_bucket_strong is deprecated. Please use tf.strings.to_hash_bucket_strong instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.string_to_number is deprecated. Please use tf.strings.to_number instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.svd is deprecated. Please use tf.linalg.svd instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.tables_initializer is deprecated. Please use tf.compat.v1.tables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.tensor_scatter_add is deprecated. Please use tf.tensor_scatter_nd_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.tensor_scatter_sub is deprecated. Please use tf.tensor_scatter_nd_sub instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.tensor_scatter_update is deprecated. Please use tf.tensor_scatter_nd_update instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.trace is deprecated. Please use tf.linalg.trace instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.unsorted_segment_max is deprecated. Please use tf.math.unsorted_segment_max instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.unsorted_segment_mean is deprecated. Please use tf.math.unsorted_segment_mean instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.unsorted_segment_min is deprecated. Please use tf.math.unsorted_segment_min instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.unsorted_segment_prod is deprecated. Please use tf.math.unsorted_segment_prod instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.unsorted_segment_sqrt_n is deprecated. Please use tf.math.unsorted_segment_sqrt_n instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.unsorted_segment_sum is deprecated. Please use tf.math.unsorted_segment_sum instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.variable_axis_size_partitioner is deprecated. Please use tf.compat.v1.variable_axis_size_partitioner instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.variable_op_scope is deprecated. Please use tf.compat.v1.variable_op_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.verify_tensor_all_finite is deprecated. Please use tf.compat.v1.verify_tensor_all_finite instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.where_v2 is deprecated. Please use tf.compat.v2.where instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.wrap_function is deprecated. Please use tf.compat.v1.wrap_function instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.write_file is deprecated. Please use tf.io.write_file instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/inspect.py:342: The name tf.zeta is deprecated. Please use tf.math.zeta instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/andres/Escritorio/PROYECTOS/entorno1/lib/python3.6/site-packages/tensorflow_core/python/util/decorator_utils.py:145: GraphKeys.VARIABLES (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.GraphKeys.GLOBAL_VARIABLES` instead.\n",
      "Help on package tensorflow:\n",
      "\n",
      "NAME\n",
      "    tensorflow - TensorFlow root package\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    _api (package)\n",
      "    app (package)\n",
      "    audio (package)\n",
      "    autograph (package)\n",
      "    bitwise (package)\n",
      "    compat (package)\n",
      "    compiler (package)\n",
      "    config (package)\n",
      "    contrib (package)\n",
      "    core (package)\n",
      "    data (package)\n",
      "    debugging (package)\n",
      "    distribute (package)\n",
      "    distributions (package)\n",
      "    dtypes (package)\n",
      "    errors (package)\n",
      "    estimator (package)\n",
      "    examples (package)\n",
      "    experimental (package)\n",
      "    feature_column (package)\n",
      "    gfile (package)\n",
      "    graph_util (package)\n",
      "    image (package)\n",
      "    initializers (package)\n",
      "    io (package)\n",
      "    keras (package)\n",
      "    layers (package)\n",
      "    linalg (package)\n",
      "    lite (package)\n",
      "    logging (package)\n",
      "    lookup (package)\n",
      "    losses (package)\n",
      "    manip (package)\n",
      "    math (package)\n",
      "    metrics (package)\n",
      "    nest (package)\n",
      "    nn (package)\n",
      "    profiler (package)\n",
      "    python (package)\n",
      "    python_io (package)\n",
      "    quantization (package)\n",
      "    queue (package)\n",
      "    ragged (package)\n",
      "    random (package)\n",
      "    raw_ops (package)\n",
      "    resource_loader (package)\n",
      "    saved_model (package)\n",
      "    sets (package)\n",
      "    signal (package)\n",
      "    sparse (package)\n",
      "    spectral (package)\n",
      "    strings (package)\n",
      "    summary (package)\n",
      "    sysconfig (package)\n",
      "    test (package)\n",
      "    tools (package)\n",
      "    tpu (package)\n",
      "    train (package)\n",
      "    user_ops (package)\n",
      "    v1\n",
      "    version (package)\n",
      "    xla (package)\n",
      "\n",
      "SUBMODULES\n",
      "    _deprecation\n",
      "    flags\n",
      "\n",
      "CLASSES\n",
      "    builtins.Exception(builtins.BaseException)\n",
      "        tensorflow.python.framework.errors_impl.OpError\n",
      "    builtins.object\n",
      "        tensorflow.python.eager.backprop.GradientTape\n",
      "        tensorflow.python.framework.dtypes.DType\n",
      "        tensorflow.python.framework.ops.Graph\n",
      "        tensorflow.python.framework.ops.GraphKeys\n",
      "        tensorflow.python.framework.ops.Operation\n",
      "        tensorflow.python.framework.ops.RegisterGradient\n",
      "        tensorflow.python.framework.ops.name_scope\n",
      "        tensorflow.python.framework.tensor_shape.Dimension\n",
      "        tensorflow.python.framework.tensor_shape.TensorShape\n",
      "        tensorflow.python.framework.type_spec.TypeSpec\n",
      "            tensorflow.python.data.ops.optional_ops.OptionalSpec\n",
      "            tensorflow.python.framework.indexed_slices.IndexedSlicesSpec\n",
      "            tensorflow.python.ops.tensor_array_ops.TensorArraySpec\n",
      "        tensorflow.python.ops.critical_section_ops.CriticalSection\n",
      "        tensorflow.python.ops.data_flow_ops.ConditionalAccumulatorBase\n",
      "            tensorflow.python.ops.data_flow_ops.ConditionalAccumulator\n",
      "            tensorflow.python.ops.data_flow_ops.SparseConditionalAccumulator\n",
      "        tensorflow.python.ops.data_flow_ops.QueueBase\n",
      "            tensorflow.python.ops.data_flow_ops.FIFOQueue\n",
      "            tensorflow.python.ops.data_flow_ops.PaddingFIFOQueue\n",
      "            tensorflow.python.ops.data_flow_ops.PriorityQueue\n",
      "            tensorflow.python.ops.data_flow_ops.RandomShuffleQueue\n",
      "        tensorflow.python.ops.gradients_util.AggregationMethod\n",
      "        tensorflow.python.ops.io_ops.ReaderBase\n",
      "            tensorflow.python.ops.io_ops.FixedLengthRecordReader\n",
      "            tensorflow.python.ops.io_ops.IdentityReader\n",
      "            tensorflow.python.ops.io_ops.LMDBReader\n",
      "            tensorflow.python.ops.io_ops.TFRecordReader\n",
      "            tensorflow.python.ops.io_ops.TextLineReader\n",
      "            tensorflow.python.ops.io_ops.WholeFileReader\n",
      "        tensorflow.python.ops.tensor_array_ops.TensorArray\n",
      "        tensorflow.python.ops.variable_scope.VariableScope\n",
      "        tensorflow.python.ops.variable_scope.variable_scope\n",
      "    builtins.tuple(builtins.object)\n",
      "        tensorflow.python.framework.sparse_tensor.SparseTensorValue\n",
      "    enum.Enum(builtins.object)\n",
      "        tensorflow.python.ops.unconnected_gradients.UnconnectedGradients\n",
      "        tensorflow.python.ops.variables.VariableAggregation\n",
      "        tensorflow.python.ops.variables.VariableSynchronization\n",
      "    google.protobuf.message.Message(builtins.object)\n",
      "        tensorflow.core.framework.attr_value_pb2.AttrValue(google.protobuf.pyext._message.CMessage, google.protobuf.message.Message)\n",
      "        tensorflow.core.framework.attr_value_pb2.NameAttrList(google.protobuf.pyext._message.CMessage, google.protobuf.message.Message)\n",
      "        tensorflow.core.framework.graph_pb2.GraphDef(google.protobuf.pyext._message.CMessage, google.protobuf.message.Message)\n",
      "        tensorflow.core.framework.node_def_pb2.NodeDef(google.protobuf.pyext._message.CMessage, google.protobuf.message.Message)\n",
      "        tensorflow.core.framework.summary_pb2.HistogramProto(google.protobuf.pyext._message.CMessage, google.protobuf.message.Message)\n",
      "        tensorflow.core.framework.summary_pb2.Summary(google.protobuf.pyext._message.CMessage, google.protobuf.message.Message)\n",
      "        tensorflow.core.framework.summary_pb2.SummaryMetadata(google.protobuf.pyext._message.CMessage, google.protobuf.message.Message)\n",
      "        tensorflow.core.protobuf.config_pb2.ConfigProto(google.protobuf.pyext._message.CMessage, google.protobuf.message.Message)\n",
      "        tensorflow.core.protobuf.config_pb2.GPUOptions(google.protobuf.pyext._message.CMessage, google.protobuf.message.Message)\n",
      "        tensorflow.core.protobuf.config_pb2.GraphOptions(google.protobuf.pyext._message.CMessage, google.protobuf.message.Message)\n",
      "        tensorflow.core.protobuf.config_pb2.OptimizerOptions(google.protobuf.pyext._message.CMessage, google.protobuf.message.Message)\n",
      "        tensorflow.core.protobuf.config_pb2.RunMetadata(google.protobuf.pyext._message.CMessage, google.protobuf.message.Message)\n",
      "        tensorflow.core.protobuf.config_pb2.RunOptions(google.protobuf.pyext._message.CMessage, google.protobuf.message.Message)\n",
      "        tensorflow.core.protobuf.meta_graph_pb2.MetaGraphDef(google.protobuf.pyext._message.CMessage, google.protobuf.message.Message)\n",
      "        tensorflow.core.protobuf.meta_graph_pb2.TensorInfo(google.protobuf.pyext._message.CMessage, google.protobuf.message.Message)\n",
      "        tensorflow.core.util.event_pb2.Event(google.protobuf.pyext._message.CMessage, google.protobuf.message.Message)\n",
      "        tensorflow.core.util.event_pb2.LogMessage(google.protobuf.pyext._message.CMessage, google.protobuf.message.Message)\n",
      "        tensorflow.core.util.event_pb2.SessionLog(google.protobuf.pyext._message.CMessage, google.protobuf.message.Message)\n",
      "    google.protobuf.pyext._message.CMessage(builtins.object)\n",
      "        tensorflow.core.framework.attr_value_pb2.AttrValue(google.protobuf.pyext._message.CMessage, google.protobuf.message.Message)\n",
      "        tensorflow.core.framework.attr_value_pb2.NameAttrList(google.protobuf.pyext._message.CMessage, google.protobuf.message.Message)\n",
      "        tensorflow.core.framework.graph_pb2.GraphDef(google.protobuf.pyext._message.CMessage, google.protobuf.message.Message)\n",
      "        tensorflow.core.framework.node_def_pb2.NodeDef(google.protobuf.pyext._message.CMessage, google.protobuf.message.Message)\n",
      "        tensorflow.core.framework.summary_pb2.HistogramProto(google.protobuf.pyext._message.CMessage, google.protobuf.message.Message)\n",
      "        tensorflow.core.framework.summary_pb2.Summary(google.protobuf.pyext._message.CMessage, google.protobuf.message.Message)\n",
      "        tensorflow.core.framework.summary_pb2.SummaryMetadata(google.protobuf.pyext._message.CMessage, google.protobuf.message.Message)\n",
      "        tensorflow.core.protobuf.config_pb2.ConfigProto(google.protobuf.pyext._message.CMessage, google.protobuf.message.Message)\n",
      "        tensorflow.core.protobuf.config_pb2.GPUOptions(google.protobuf.pyext._message.CMessage, google.protobuf.message.Message)\n",
      "        tensorflow.core.protobuf.config_pb2.GraphOptions(google.protobuf.pyext._message.CMessage, google.protobuf.message.Message)\n",
      "        tensorflow.core.protobuf.config_pb2.OptimizerOptions(google.protobuf.pyext._message.CMessage, google.protobuf.message.Message)\n",
      "        tensorflow.core.protobuf.config_pb2.RunMetadata(google.protobuf.pyext._message.CMessage, google.protobuf.message.Message)\n",
      "        tensorflow.core.protobuf.config_pb2.RunOptions(google.protobuf.pyext._message.CMessage, google.protobuf.message.Message)\n",
      "        tensorflow.core.protobuf.meta_graph_pb2.MetaGraphDef(google.protobuf.pyext._message.CMessage, google.protobuf.message.Message)\n",
      "        tensorflow.core.protobuf.meta_graph_pb2.TensorInfo(google.protobuf.pyext._message.CMessage, google.protobuf.message.Message)\n",
      "        tensorflow.core.util.event_pb2.Event(google.protobuf.pyext._message.CMessage, google.protobuf.message.Message)\n",
      "        tensorflow.core.util.event_pb2.LogMessage(google.protobuf.pyext._message.CMessage, google.protobuf.message.Message)\n",
      "        tensorflow.core.util.event_pb2.SessionLog(google.protobuf.pyext._message.CMessage, google.protobuf.message.Message)\n",
      "    tensorflow.python.client.session.BaseSession(tensorflow.python.client.session.SessionInterface)\n",
      "        tensorflow.python.client.session.InteractiveSession\n",
      "        tensorflow.python.client.session.Session\n",
      "    tensorflow.python.framework.composite_tensor.CompositeTensor(builtins.object)\n",
      "        tensorflow.python.framework.indexed_slices.IndexedSlices(tensorflow.python.framework.tensor_like._TensorLike, tensorflow.python.framework.composite_tensor.CompositeTensor)\n",
      "        tensorflow.python.framework.sparse_tensor.SparseTensor(tensorflow.python.framework.tensor_like._TensorLike, tensorflow.python.framework.composite_tensor.CompositeTensor)\n",
      "        tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor\n",
      "    tensorflow.python.framework.device_spec.DeviceSpecV2(builtins.object)\n",
      "        tensorflow.python.framework.device_spec.DeviceSpecV1\n",
      "    tensorflow.python.framework.tensor_like._TensorLike(builtins.object)\n",
      "        tensorflow.python.framework.indexed_slices.IndexedSlices(tensorflow.python.framework.tensor_like._TensorLike, tensorflow.python.framework.composite_tensor.CompositeTensor)\n",
      "        tensorflow.python.framework.ops.Tensor\n",
      "        tensorflow.python.framework.sparse_tensor.SparseTensor(tensorflow.python.framework.tensor_like._TensorLike, tensorflow.python.framework.composite_tensor.CompositeTensor)\n",
      "    tensorflow.python.framework.type_spec.BatchableTypeSpec(tensorflow.python.framework.type_spec.TypeSpec)\n",
      "        tensorflow.python.framework.sparse_tensor.SparseTensorSpec\n",
      "        tensorflow.python.framework.tensor_spec.TensorSpec\n",
      "        tensorflow.python.ops.ragged.ragged_tensor.RaggedTensorSpec\n",
      "    tensorflow.python.ops.init_ops.Initializer(builtins.object)\n",
      "        tensorflow.python.ops.init_ops.Constant\n",
      "        tensorflow.python.ops.init_ops.Ones\n",
      "        tensorflow.python.ops.init_ops.Orthogonal\n",
      "        tensorflow.python.ops.init_ops.RandomNormal\n",
      "        tensorflow.python.ops.init_ops.RandomUniform\n",
      "        tensorflow.python.ops.init_ops.TruncatedNormal\n",
      "        tensorflow.python.ops.init_ops.UniformUnitScaling\n",
      "        tensorflow.python.ops.init_ops.VarianceScaling\n",
      "            tensorflow.python.ops.init_ops.GlorotNormal\n",
      "            tensorflow.python.ops.init_ops.GlorotUniform\n",
      "        tensorflow.python.ops.init_ops.Zeros\n",
      "    tensorflow.python.ops.parsing_ops.FixedLenFeature(builtins.tuple)\n",
      "        tensorflow.python.ops.parsing_ops.FixedLenFeature\n",
      "    tensorflow.python.ops.parsing_ops.FixedLenSequenceFeature(builtins.tuple)\n",
      "        tensorflow.python.ops.parsing_ops.FixedLenSequenceFeature\n",
      "    tensorflow.python.ops.parsing_ops.SparseFeature(builtins.tuple)\n",
      "        tensorflow.python.ops.parsing_ops.SparseFeature\n",
      "    tensorflow.python.ops.parsing_ops.VarLenFeature(builtins.tuple)\n",
      "        tensorflow.python.ops.parsing_ops.VarLenFeature\n",
      "    tensorflow.python.ops.variables.Variable(tensorflow.python.training.tracking.base.Trackable)\n",
      "        tensorflow.python.ops.variables.VariableV1\n",
      "    tensorflow.python.training.tracking.tracking.AutoTrackable(tensorflow.python.training.tracking.base.Trackable)\n",
      "        tensorflow.python.module.module.Module\n",
      "    \n",
      "    class AggregationMethod(builtins.object)\n",
      "     |  A class listing aggregation methods used to combine gradients.\n",
      "     |  \n",
      "     |  Computing partial derivatives can require aggregating gradient\n",
      "     |  contributions. This class lists the various methods that can\n",
      "     |  be used to combine gradients in the graph.\n",
      "     |  \n",
      "     |  The following aggregation methods are part of the stable API for\n",
      "     |  aggregating gradients:\n",
      "     |  \n",
      "     |  *  `ADD_N`: All of the gradient terms are summed as part of one\n",
      "     |     operation using the \"AddN\" op (see `tf.add_n`). This\n",
      "     |     method has the property that all gradients must be ready and\n",
      "     |     buffered separately in memory before any aggregation is performed.\n",
      "     |  *  `DEFAULT`: The system-chosen default aggregation method.\n",
      "     |  \n",
      "     |  The following aggregation methods are experimental and may not\n",
      "     |  be supported in future releases:\n",
      "     |  \n",
      "     |  * `EXPERIMENTAL_TREE`: Gradient terms are summed in pairs using\n",
      "     |    using the \"AddN\" op. This method of summing gradients may reduce\n",
      "     |    performance, but it can improve memory utilization because the\n",
      "     |    gradients can be released earlier.\n",
      "     |  \n",
      "     |  * `EXPERIMENTAL_ACCUMULATE_N`: Gradient terms are summed using the\n",
      "     |    \"AccumulateN\" op (see `tf.accumulate_n`), which accumulates the\n",
      "     |    overall sum in a single buffer that is shared across threads.\n",
      "     |    This method of summing gradients can result in a lower memory footprint\n",
      "     |    and lower latency at the expense of higher CPU/GPU utilization.\n",
      "     |    For gradients of types that \"AccumulateN\" does not support, this\n",
      "     |    summation method falls back on the behavior of `EXPERIMENTAL_TREE`\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  ADD_N = 0\n",
      "     |  \n",
      "     |  DEFAULT = 0\n",
      "     |  \n",
      "     |  EXPERIMENTAL_ACCUMULATE_N = 2\n",
      "     |  \n",
      "     |  EXPERIMENTAL_TREE = 1\n",
      "    \n",
      "    class AttrValue(google.protobuf.pyext._message.CMessage, google.protobuf.message.Message)\n",
      "     |  A ProtocolMessage\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      AttrValue\n",
      "     |      google.protobuf.pyext._message.CMessage\n",
      "     |      google.protobuf.message.Message\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  b\n",
      "     |      Field tensorflow.AttrValue.b\n",
      "     |  \n",
      "     |  f\n",
      "     |      Field tensorflow.AttrValue.f\n",
      "     |  \n",
      "     |  func\n",
      "     |      Field tensorflow.AttrValue.func\n",
      "     |  \n",
      "     |  i\n",
      "     |      Field tensorflow.AttrValue.i\n",
      "     |  \n",
      "     |  list\n",
      "     |      Field tensorflow.AttrValue.list\n",
      "     |  \n",
      "     |  placeholder\n",
      "     |      Field tensorflow.AttrValue.placeholder\n",
      "     |  \n",
      "     |  s\n",
      "     |      Field tensorflow.AttrValue.s\n",
      "     |  \n",
      "     |  shape\n",
      "     |      Field tensorflow.AttrValue.shape\n",
      "     |  \n",
      "     |  tensor\n",
      "     |      Field tensorflow.AttrValue.tensor\n",
      "     |  \n",
      "     |  type\n",
      "     |      Field tensorflow.AttrValue.type\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  DESCRIPTOR = <google.protobuf.pyext._message.MessageDescriptor object>\n",
      "     |  \n",
      "     |  ListValue = <class 'tensorflow.core.framework.attr_value_pb2.ListValue...\n",
      "     |      A ProtocolMessage\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.pyext._message.CMessage:\n",
      "     |  \n",
      "     |  ByteSize(...)\n",
      "     |      Returns the size of the message in bytes.\n",
      "     |  \n",
      "     |  Clear(...)\n",
      "     |      Clears the message.\n",
      "     |  \n",
      "     |  ClearExtension(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  ClearField(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  CopyFrom(...)\n",
      "     |      Copies a protocol message into the current message.\n",
      "     |  \n",
      "     |  DiscardUnknownFields(...)\n",
      "     |      Discards the unknown fields.\n",
      "     |  \n",
      "     |  FindInitializationErrors(...)\n",
      "     |      Finds unset required fields.\n",
      "     |  \n",
      "     |  FromString(...) from google.protobuf.pyext.cpp_message.GeneratedProtocolMessageType\n",
      "     |      Creates new method instance from given serialized data.\n",
      "     |  \n",
      "     |  HasExtension(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  HasField(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  IsInitialized(...)\n",
      "     |      Checks if all required fields of a protocol message are set.\n",
      "     |  \n",
      "     |  ListFields(...)\n",
      "     |      Lists all set fields of a message.\n",
      "     |  \n",
      "     |  MergeFrom(...)\n",
      "     |      Merges a protocol message into the current message.\n",
      "     |  \n",
      "     |  MergeFromString(...)\n",
      "     |      Merges a serialized message into the current message.\n",
      "     |  \n",
      "     |  ParseFromString(...)\n",
      "     |      Parses a serialized message into the current message.\n",
      "     |  \n",
      "     |  RegisterExtension(...) from google.protobuf.pyext.cpp_message.GeneratedProtocolMessageType\n",
      "     |      Registers an extension with the current message.\n",
      "     |  \n",
      "     |  SerializePartialToString(...)\n",
      "     |      Serializes the message to a string, even if it isn't initialized.\n",
      "     |  \n",
      "     |  SerializeToString(...)\n",
      "     |      Serializes the message to a string, only for initialized messages.\n",
      "     |  \n",
      "     |  SetInParent(...)\n",
      "     |      Sets the has bit of the given field in its parent message.\n",
      "     |  \n",
      "     |  UnknownFields(...)\n",
      "     |      Parse unknown field set\n",
      "     |  \n",
      "     |  WhichOneof(...)\n",
      "     |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      Makes a deep copy of the class.\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from google.protobuf.pyext._message.MessageMeta\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  __unicode__(...)\n",
      "     |      Outputs a unicode representation of the message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google.protobuf.pyext._message.CMessage:\n",
      "     |  \n",
      "     |  Extensions\n",
      "     |      Extension dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from google.protobuf.pyext._message.CMessage:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Support the pickle protocol.\n",
      "    \n",
      "    class ConditionalAccumulator(ConditionalAccumulatorBase)\n",
      "     |  A conditional accumulator for aggregating gradients.\n",
      "     |  \n",
      "     |  Up-to-date gradients (i.e., time step at which gradient was computed is\n",
      "     |  equal to the accumulator's time step) are added to the accumulator.\n",
      "     |  \n",
      "     |  Extraction of the average gradient is blocked until the required number of\n",
      "     |  gradients has been accumulated.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ConditionalAccumulator\n",
      "     |      ConditionalAccumulatorBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, dtype, shape=None, shared_name=None, name='conditional_accumulator', reduction_type='MEAN')\n",
      "     |      Creates a new ConditionalAccumulator.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        dtype: Datatype of the accumulated gradients.\n",
      "     |        shape: Shape of the accumulated gradients.\n",
      "     |        shared_name: Optional. If non-empty, this accumulator will be shared under\n",
      "     |          the given name across multiple sessions.\n",
      "     |        name: Optional name for the accumulator.\n",
      "     |        reduction_type: Reduction type to use when taking the gradient.\n",
      "     |  \n",
      "     |  apply_grad(self, grad, local_step=0, name=None)\n",
      "     |      Attempts to apply a gradient to the accumulator.\n",
      "     |      \n",
      "     |      The attempt is silently dropped if the gradient is stale, i.e., local_step\n",
      "     |      is less than the accumulator's global time step.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        grad: The gradient tensor to be applied.\n",
      "     |        local_step: Time step at which the gradient was computed.\n",
      "     |        name: Optional name for the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The operation that (conditionally) applies a gradient to the accumulator.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If grad is of the wrong shape\n",
      "     |  \n",
      "     |  take_grad(self, num_required, name=None)\n",
      "     |      Attempts to extract the average gradient from the accumulator.\n",
      "     |      \n",
      "     |      The operation blocks until sufficient number of gradients have been\n",
      "     |      successfully applied to the accumulator.\n",
      "     |      \n",
      "     |      Once successful, the following actions are also triggered:\n",
      "     |      \n",
      "     |      - Counter of accumulated gradients is reset to 0.\n",
      "     |      - Aggregated gradient is reset to 0 tensor.\n",
      "     |      - Accumulator's internal time step is incremented by 1.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        num_required: Number of gradients that needs to have been aggregated\n",
      "     |        name: Optional name for the operation\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A tensor holding the value of the average gradient.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        InvalidArgumentError: If num_required < 1\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ConditionalAccumulatorBase:\n",
      "     |  \n",
      "     |  num_accumulated(self, name=None)\n",
      "     |      Number of gradients that have currently been aggregated in accumulator.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: Optional name for the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        Number of accumulated gradients currently in accumulator.\n",
      "     |  \n",
      "     |  set_global_step(self, new_global_step, name=None)\n",
      "     |      Sets the global time step of the accumulator.\n",
      "     |      \n",
      "     |      The operation logs a warning if we attempt to set to a time step that is\n",
      "     |      lower than the accumulator's own time step.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        new_global_step: Value of new time step. Can be a variable or a constant\n",
      "     |        name: Optional name for the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        Operation that sets the accumulator's time step.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from ConditionalAccumulatorBase:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  accumulator_ref\n",
      "     |      The underlying accumulator reference.\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      The datatype of the gradients accumulated by this accumulator.\n",
      "     |  \n",
      "     |  name\n",
      "     |      The name of the underlying accumulator.\n",
      "    \n",
      "    class ConditionalAccumulatorBase(builtins.object)\n",
      "     |  A conditional accumulator for aggregating gradients.\n",
      "     |  \n",
      "     |  Up-to-date gradients (i.e., time step at which gradient was computed is\n",
      "     |  equal to the accumulator's time step) are added to the accumulator.\n",
      "     |  \n",
      "     |  Extraction of the average gradient is blocked until the required number of\n",
      "     |  gradients has been accumulated.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, dtype, shape, accumulator_ref)\n",
      "     |      Creates a new ConditionalAccumulator.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        dtype: Datatype of the accumulated gradients.\n",
      "     |        shape: Shape of the accumulated gradients.\n",
      "     |        accumulator_ref: A handle to the conditional accumulator, created by sub-\n",
      "     |          classes\n",
      "     |  \n",
      "     |  num_accumulated(self, name=None)\n",
      "     |      Number of gradients that have currently been aggregated in accumulator.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: Optional name for the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        Number of accumulated gradients currently in accumulator.\n",
      "     |  \n",
      "     |  set_global_step(self, new_global_step, name=None)\n",
      "     |      Sets the global time step of the accumulator.\n",
      "     |      \n",
      "     |      The operation logs a warning if we attempt to set to a time step that is\n",
      "     |      lower than the accumulator's own time step.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        new_global_step: Value of new time step. Can be a variable or a constant\n",
      "     |        name: Optional name for the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        Operation that sets the accumulator's time step.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  accumulator_ref\n",
      "     |      The underlying accumulator reference.\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      The datatype of the gradients accumulated by this accumulator.\n",
      "     |  \n",
      "     |  name\n",
      "     |      The name of the underlying accumulator.\n",
      "    \n",
      "    class ConfigProto(google.protobuf.pyext._message.CMessage, google.protobuf.message.Message)\n",
      "     |  A ProtocolMessage\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ConfigProto\n",
      "     |      google.protobuf.pyext._message.CMessage\n",
      "     |      google.protobuf.message.Message\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  allow_soft_placement\n",
      "     |      Field tensorflow.ConfigProto.allow_soft_placement\n",
      "     |  \n",
      "     |  cluster_def\n",
      "     |      Field tensorflow.ConfigProto.cluster_def\n",
      "     |  \n",
      "     |  device_count\n",
      "     |      Field tensorflow.ConfigProto.device_count\n",
      "     |  \n",
      "     |  device_filters\n",
      "     |      Field tensorflow.ConfigProto.device_filters\n",
      "     |  \n",
      "     |  experimental\n",
      "     |      Field tensorflow.ConfigProto.experimental\n",
      "     |  \n",
      "     |  gpu_options\n",
      "     |      Field tensorflow.ConfigProto.gpu_options\n",
      "     |  \n",
      "     |  graph_options\n",
      "     |      Field tensorflow.ConfigProto.graph_options\n",
      "     |  \n",
      "     |  inter_op_parallelism_threads\n",
      "     |      Field tensorflow.ConfigProto.inter_op_parallelism_threads\n",
      "     |  \n",
      "     |  intra_op_parallelism_threads\n",
      "     |      Field tensorflow.ConfigProto.intra_op_parallelism_threads\n",
      "     |  \n",
      "     |  isolate_session_state\n",
      "     |      Field tensorflow.ConfigProto.isolate_session_state\n",
      "     |  \n",
      "     |  log_device_placement\n",
      "     |      Field tensorflow.ConfigProto.log_device_placement\n",
      "     |  \n",
      "     |  operation_timeout_in_ms\n",
      "     |      Field tensorflow.ConfigProto.operation_timeout_in_ms\n",
      "     |  \n",
      "     |  placement_period\n",
      "     |      Field tensorflow.ConfigProto.placement_period\n",
      "     |  \n",
      "     |  rpc_options\n",
      "     |      Field tensorflow.ConfigProto.rpc_options\n",
      "     |  \n",
      "     |  session_inter_op_thread_pool\n",
      "     |      Field tensorflow.ConfigProto.session_inter_op_thread_pool\n",
      "     |  \n",
      "     |  use_per_session_threads\n",
      "     |      Field tensorflow.ConfigProto.use_per_session_threads\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  DESCRIPTOR = <google.protobuf.pyext._message.MessageDescriptor object>\n",
      "     |  \n",
      "     |  DeviceCountEntry = <class 'tensorflow.core.protobuf.config_pb2.DeviceC...\n",
      "     |      A ProtocolMessage\n",
      "     |  \n",
      "     |  Experimental = <class 'tensorflow.core.protobuf.config_pb2.Experimenta...\n",
      "     |      A ProtocolMessage\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.pyext._message.CMessage:\n",
      "     |  \n",
      "     |  ByteSize(...)\n",
      "     |      Returns the size of the message in bytes.\n",
      "     |  \n",
      "     |  Clear(...)\n",
      "     |      Clears the message.\n",
      "     |  \n",
      "     |  ClearExtension(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  ClearField(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  CopyFrom(...)\n",
      "     |      Copies a protocol message into the current message.\n",
      "     |  \n",
      "     |  DiscardUnknownFields(...)\n",
      "     |      Discards the unknown fields.\n",
      "     |  \n",
      "     |  FindInitializationErrors(...)\n",
      "     |      Finds unset required fields.\n",
      "     |  \n",
      "     |  FromString(...) from google.protobuf.pyext.cpp_message.GeneratedProtocolMessageType\n",
      "     |      Creates new method instance from given serialized data.\n",
      "     |  \n",
      "     |  HasExtension(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  HasField(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  IsInitialized(...)\n",
      "     |      Checks if all required fields of a protocol message are set.\n",
      "     |  \n",
      "     |  ListFields(...)\n",
      "     |      Lists all set fields of a message.\n",
      "     |  \n",
      "     |  MergeFrom(...)\n",
      "     |      Merges a protocol message into the current message.\n",
      "     |  \n",
      "     |  MergeFromString(...)\n",
      "     |      Merges a serialized message into the current message.\n",
      "     |  \n",
      "     |  ParseFromString(...)\n",
      "     |      Parses a serialized message into the current message.\n",
      "     |  \n",
      "     |  RegisterExtension(...) from google.protobuf.pyext.cpp_message.GeneratedProtocolMessageType\n",
      "     |      Registers an extension with the current message.\n",
      "     |  \n",
      "     |  SerializePartialToString(...)\n",
      "     |      Serializes the message to a string, even if it isn't initialized.\n",
      "     |  \n",
      "     |  SerializeToString(...)\n",
      "     |      Serializes the message to a string, only for initialized messages.\n",
      "     |  \n",
      "     |  SetInParent(...)\n",
      "     |      Sets the has bit of the given field in its parent message.\n",
      "     |  \n",
      "     |  UnknownFields(...)\n",
      "     |      Parse unknown field set\n",
      "     |  \n",
      "     |  WhichOneof(...)\n",
      "     |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      Makes a deep copy of the class.\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from google.protobuf.pyext._message.MessageMeta\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  __unicode__(...)\n",
      "     |      Outputs a unicode representation of the message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google.protobuf.pyext._message.CMessage:\n",
      "     |  \n",
      "     |  Extensions\n",
      "     |      Extension dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from google.protobuf.pyext._message.CMessage:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Support the pickle protocol.\n",
      "    \n",
      "    class CriticalSection(builtins.object)\n",
      "     |  Critical section.\n",
      "     |  \n",
      "     |  A `CriticalSection` object is a resource in the graph which executes subgraphs\n",
      "     |  in **serial** order.  A common example of a subgraph one may wish to run\n",
      "     |  exclusively is the one given by the following function:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  v = resource_variable_ops.ResourceVariable(0.0, name=\"v\")\n",
      "     |  \n",
      "     |  def count():\n",
      "     |    value = v.read_value()\n",
      "     |    with tf.control_dependencies([value]):\n",
      "     |      with tf.control_dependencies([v.assign_add(1)]):\n",
      "     |        return tf.identity(value)\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Here, a snapshot of `v` is captured in `value`; and then `v` is updated.\n",
      "     |  The snapshot value is returned.\n",
      "     |  \n",
      "     |  If multiple workers or threads all execute `count` in parallel, there is no\n",
      "     |  guarantee that access to the variable `v` is atomic at any point within\n",
      "     |  any thread's calculation of `count`.  In fact, even implementing an atomic\n",
      "     |  counter that guarantees that the user will see each value `0, 1, ...,` is\n",
      "     |  currently impossible.\n",
      "     |  \n",
      "     |  The solution is to ensure any access to the underlying resource `v` is\n",
      "     |  only processed through a critical section:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  cs = CriticalSection()\n",
      "     |  f1 = cs.execute(count)\n",
      "     |  f2 = cs.execute(count)\n",
      "     |  output = f1 + f2\n",
      "     |  session.run(output)\n",
      "     |  ```\n",
      "     |  The functions `f1` and `f2` will be executed serially, and updates to `v`\n",
      "     |  will be atomic.\n",
      "     |  \n",
      "     |  **NOTES**\n",
      "     |  \n",
      "     |  All resource objects, including the critical section and any captured\n",
      "     |  variables of functions executed on that critical section, will be\n",
      "     |  colocated to the same device (host and cpu/gpu).\n",
      "     |  \n",
      "     |  When using multiple critical sections on the same resources, there is no\n",
      "     |  guarantee of exclusive access to those resources.  This behavior is disallowed\n",
      "     |  by default (but see the kwarg `exclusive_resource_access`).\n",
      "     |  \n",
      "     |  For example, running the same function in two separate critical sections\n",
      "     |  will not ensure serial execution:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  v = tf.compat.v1.get_variable(\"v\", initializer=0.0, use_resource=True)\n",
      "     |  def accumulate(up):\n",
      "     |    x = v.read_value()\n",
      "     |    with tf.control_dependencies([x]):\n",
      "     |      with tf.control_dependencies([v.assign_add(up)]):\n",
      "     |        return tf.identity(x)\n",
      "     |  ex1 = CriticalSection().execute(\n",
      "     |    accumulate, 1.0, exclusive_resource_access=False)\n",
      "     |  ex2 = CriticalSection().execute(\n",
      "     |    accumulate, 1.0, exclusive_resource_access=False)\n",
      "     |  bad_sum = ex1 + ex2\n",
      "     |  sess.run(v.initializer)\n",
      "     |  sess.run(bad_sum)  # May return 0.0\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, name=None, shared_name=None, critical_section_def=None, import_scope=None)\n",
      "     |      Creates a critical section.\n",
      "     |  \n",
      "     |  execute(self, fn, exclusive_resource_access=True, name=None)\n",
      "     |      Execute function `fn()` inside the critical section.\n",
      "     |      \n",
      "     |      `fn` should not accept any arguments.  To add extra arguments to when\n",
      "     |      calling `fn` in the critical section, create a lambda:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      critical_section.execute(lambda: fn(*my_args, **my_kwargs))\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        fn: The function to execute.  Must return at least one tensor.\n",
      "     |        exclusive_resource_access: Whether the resources required by\n",
      "     |          `fn` should be exclusive to this `CriticalSection`.  Default: `True`.\n",
      "     |          You may want to set this to `False` if you will be accessing a\n",
      "     |          resource in read-only mode in two different CriticalSections.\n",
      "     |        name: The name to use when creating the execute operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The tensors returned from `fn()`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `fn` attempts to lock this `CriticalSection` in any nested\n",
      "     |          or lazy way that may cause a deadlock.\n",
      "     |        ValueError: If `exclusive_resource_access == True` and\n",
      "     |          another `CriticalSection` has an execution requesting the same\n",
      "     |          resources as `fn``.  Note, even if `exclusive_resource_access` is\n",
      "     |          `True`, if another execution in another `CriticalSection` was created\n",
      "     |          without `exclusive_resource_access=True`, a `ValueError` will be raised.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  name\n",
      "    \n",
      "    class DType(builtins.object)\n",
      "     |  Represents the type of the elements in a `Tensor`.\n",
      "     |  \n",
      "     |  The following `DType` objects are defined:\n",
      "     |  \n",
      "     |  * `tf.float16`: 16-bit half-precision floating-point.\n",
      "     |  * `tf.float32`: 32-bit single-precision floating-point.\n",
      "     |  * `tf.float64`: 64-bit double-precision floating-point.\n",
      "     |  * `tf.bfloat16`: 16-bit truncated floating-point.\n",
      "     |  * `tf.complex64`: 64-bit single-precision complex.\n",
      "     |  * `tf.complex128`: 128-bit double-precision complex.\n",
      "     |  * `tf.int8`: 8-bit signed integer.\n",
      "     |  * `tf.uint8`: 8-bit unsigned integer.\n",
      "     |  * `tf.uint16`: 16-bit unsigned integer.\n",
      "     |  * `tf.uint32`: 32-bit unsigned integer.\n",
      "     |  * `tf.uint64`: 64-bit unsigned integer.\n",
      "     |  * `tf.int16`: 16-bit signed integer.\n",
      "     |  * `tf.int32`: 32-bit signed integer.\n",
      "     |  * `tf.int64`: 64-bit signed integer.\n",
      "     |  * `tf.bool`: Boolean.\n",
      "     |  * `tf.string`: String.\n",
      "     |  * `tf.qint8`: Quantized 8-bit signed integer.\n",
      "     |  * `tf.quint8`: Quantized 8-bit unsigned integer.\n",
      "     |  * `tf.qint16`: Quantized 16-bit signed integer.\n",
      "     |  * `tf.quint16`: Quantized 16-bit unsigned integer.\n",
      "     |  * `tf.qint32`: Quantized 32-bit signed integer.\n",
      "     |  * `tf.resource`: Handle to a mutable resource.\n",
      "     |  * `tf.variant`: Values of arbitrary types.\n",
      "     |  \n",
      "     |  The `tf.as_dtype()` function converts numpy types and string type\n",
      "     |  names to a `DType` object.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Returns True iff this DType refers to the same type as `other`.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __init__(self, type_enum)\n",
      "     |      Creates a new `DataType`.\n",
      "     |      \n",
      "     |      NOTE(mrry): In normal circumstances, you should not need to\n",
      "     |      construct a `DataType` object directly. Instead, use the\n",
      "     |      `tf.as_dtype()` function.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        type_enum: A `types_pb2.DataType` enum value.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If `type_enum` is not a value `types_pb2.DataType`.\n",
      "     |  \n",
      "     |  __ne__(self, other)\n",
      "     |      Returns True iff self != other.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  is_compatible_with(self, other)\n",
      "     |      Returns True if the `other` DType will be converted to this DType.\n",
      "     |      \n",
      "     |      The conversion rules are as follows:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      DType(T)       .is_compatible_with(DType(T))        == True\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: A `DType` (or object that may be converted to a `DType`).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        True if a Tensor of the `other` `DType` will be implicitly converted to\n",
      "     |        this `DType`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  as_datatype_enum\n",
      "     |      Returns a `types_pb2.DataType` enum value based on this `DType`.\n",
      "     |  \n",
      "     |  as_numpy_dtype\n",
      "     |      Returns a `numpy.dtype` based on this `DType`.\n",
      "     |  \n",
      "     |  base_dtype\n",
      "     |      Returns a non-reference `DType` based on this `DType`.\n",
      "     |  \n",
      "     |  is_bool\n",
      "     |      Returns whether this is a boolean data type\n",
      "     |  \n",
      "     |  is_complex\n",
      "     |      Returns whether this is a complex floating point type.\n",
      "     |  \n",
      "     |  is_floating\n",
      "     |      Returns whether this is a (non-quantized, real) floating point type.\n",
      "     |  \n",
      "     |  is_integer\n",
      "     |      Returns whether this is a (non-quantized) integer type.\n",
      "     |  \n",
      "     |  is_numpy_compatible\n",
      "     |  \n",
      "     |  is_quantized\n",
      "     |      Returns whether this is a quantized data type.\n",
      "     |  \n",
      "     |  is_unsigned\n",
      "     |      Returns whether this type is unsigned.\n",
      "     |      \n",
      "     |      Non-numeric, unordered, and quantized types are not considered unsigned, and\n",
      "     |      this function returns `False`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        Whether a `DType` is unsigned.\n",
      "     |  \n",
      "     |  limits\n",
      "     |      Return intensity limits, i.e.\n",
      "     |      \n",
      "     |      (min, max) tuple, of the dtype.\n",
      "     |      Args:\n",
      "     |        clip_negative : bool, optional If True, clip the negative range (i.e.\n",
      "     |          return 0 for min intensity) even if the image dtype allows negative\n",
      "     |          values. Returns\n",
      "     |        min, max : tuple Lower and upper intensity limits.\n",
      "     |  \n",
      "     |  max\n",
      "     |      Returns the maximum representable value in this data type.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: if this is a non-numeric, unordered, or quantized type.\n",
      "     |  \n",
      "     |  min\n",
      "     |      Returns the minimum representable value in this data type.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: if this is a non-numeric, unordered, or quantized type.\n",
      "     |  \n",
      "     |  name\n",
      "     |      Returns the string name for this `DType`.\n",
      "     |  \n",
      "     |  real_dtype\n",
      "     |      Returns the dtype correspond to this dtype's real part.\n",
      "     |  \n",
      "     |  size\n",
      "    \n",
      "    DeviceSpec = class DeviceSpecV1(DeviceSpecV2)\n",
      "     |  Represents a (possibly partial) specification for a TensorFlow device.\n",
      "     |  \n",
      "     |  `DeviceSpec`s are used throughout TensorFlow to describe where state is stored\n",
      "     |  and computations occur. Using `DeviceSpec` allows you to parse device spec\n",
      "     |  strings to verify their validity, merge them or compose them programmatically.\n",
      "     |  \n",
      "     |  Example:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  # Place the operations on device \"GPU:0\" in the \"ps\" job.\n",
      "     |  device_spec = DeviceSpec(job=\"ps\", device_type=\"GPU\", device_index=0)\n",
      "     |  with tf.device(device_spec):\n",
      "     |    # Both my_var and squared_var will be placed on /job:ps/device:GPU:0.\n",
      "     |    my_var = tf.Variable(..., name=\"my_variable\")\n",
      "     |    squared_var = tf.square(my_var)\n",
      "     |  ```\n",
      "     |  \n",
      "     |  If a `DeviceSpec` is partially specified, it will be merged with other\n",
      "     |  `DeviceSpec`s according to the scope in which it is defined. `DeviceSpec`\n",
      "     |  components defined in inner scopes take precedence over those defined in\n",
      "     |  outer scopes.\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  with tf.device(DeviceSpec(job=\"train\", )):\n",
      "     |    with tf.device(DeviceSpec(job=\"ps\", device_type=\"GPU\", device_index=0):\n",
      "     |      # Nodes created here will be assigned to /job:ps/device:GPU:0.\n",
      "     |    with tf.device(DeviceSpec(device_type=\"GPU\", device_index=1):\n",
      "     |      # Nodes created here will be assigned to /job:train/device:GPU:1.\n",
      "     |  ```\n",
      "     |  \n",
      "     |  A `DeviceSpec` consists of 5 components -- each of\n",
      "     |  which is optionally specified:\n",
      "     |  \n",
      "     |  * Job: The job name.\n",
      "     |  * Replica: The replica index.\n",
      "     |  * Task: The task index.\n",
      "     |  * Device type: The device type string (e.g. \"CPU\" or \"GPU\").\n",
      "     |  * Device index: The device index.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      DeviceSpecV1\n",
      "     |      DeviceSpecV2\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  merge_from(self, dev)\n",
      "     |      Merge the properties of \"dev\" into this `DeviceSpec`.\n",
      "     |      \n",
      "     |      Note: Will be removed in TensorFlow 2.x since DeviceSpecs will become\n",
      "     |            immutable.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        dev: a `DeviceSpec`.\n",
      "     |  \n",
      "     |  parse_from_string(self, spec)\n",
      "     |      Parse a `DeviceSpec` name into its components.\n",
      "     |      \n",
      "     |      2.x behavior change:\n",
      "     |        In TensorFlow 1.x, this function mutates its own state and returns itself.\n",
      "     |        In 2.x, DeviceSpecs are immutable, and this function will return a\n",
      "     |          DeviceSpec which contains the spec.\n",
      "     |      \n",
      "     |        Recommended:\n",
      "     |          ```\n",
      "     |          # my_spec and my_updated_spec are unrelated.\n",
      "     |          my_spec = tf.DeviceSpec.from_string(\"/CPU:0\")\n",
      "     |          my_updated_spec = tf.DeviceSpec.from_string(\"/GPU:0\")\n",
      "     |          with tf.device(my_updated_spec):\n",
      "     |            ...\n",
      "     |          ```\n",
      "     |      \n",
      "     |        Will work in 1.x and 2.x (though deprecated in 2.x):\n",
      "     |          ```\n",
      "     |          my_spec = tf.DeviceSpec.from_string(\"/CPU:0\")\n",
      "     |          my_updated_spec = my_spec.parse_from_string(\"/GPU:0\")\n",
      "     |          with tf.device(my_updated_spec):\n",
      "     |            ...\n",
      "     |          ```\n",
      "     |      \n",
      "     |        Will NOT work in 2.x:\n",
      "     |          ```\n",
      "     |          my_spec = tf.DeviceSpec.from_string(\"/CPU:0\")\n",
      "     |          my_spec.parse_from_string(\"/GPU:0\")  # <== Will not update my_spec\n",
      "     |          with tf.device(my_spec):\n",
      "     |            ...\n",
      "     |          ```\n",
      "     |      \n",
      "     |        In general, `DeviceSpec.from_string` should completely replace\n",
      "     |        `DeviceSpec.parse_from_string`, and `DeviceSpec.replace` should\n",
      "     |        completely replace setting attributes directly.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        spec: an optional string of the form\n",
      "     |         /job:<name>/replica:<id>/task:<id>/device:CPU:<id>\n",
      "     |        or\n",
      "     |         /job:<name>/replica:<id>/task:<id>/device:GPU:<id>\n",
      "     |        as cpu and gpu are mutually exclusive.\n",
      "     |        All entries are optional.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The `DeviceSpec`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: if the spec was not valid.\n",
      "     |  \n",
      "     |  to_string(self)\n",
      "     |      Return a string representation of this `DeviceSpec`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        a string of the form\n",
      "     |        /job:<name>/replica:<id>/task:<id>/device:<device_type>:<id>.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  device_index\n",
      "     |  \n",
      "     |  device_type\n",
      "     |  \n",
      "     |  job\n",
      "     |  \n",
      "     |  replica\n",
      "     |  \n",
      "     |  task\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from DeviceSpecV2:\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Checks if the `other` DeviceSpec is same as the current instance, eg have\n",
      "     |      \n",
      "     |         same value for all the internal fields.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another DeviceSpec\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        Return `True` if `other` is also a DeviceSpec instance and has same value\n",
      "     |        as the current instance.\n",
      "     |        Return `False` otherwise.\n",
      "     |  \n",
      "     |  __init__(self, job=None, replica=None, task=None, device_type=None, device_index=None)\n",
      "     |      Create a new `DeviceSpec` object.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        job: string.  Optional job name.\n",
      "     |        replica: int.  Optional replica index.\n",
      "     |        task: int.  Optional task index.\n",
      "     |        device_type: Optional device type string (e.g. \"CPU\" or \"GPU\")\n",
      "     |        device_index: int.  Optional device index.  If left\n",
      "     |          unspecified, device represents 'any' device_index.\n",
      "     |  \n",
      "     |  make_merged_spec(self, dev)\n",
      "     |      Returns a new DeviceSpec which incorporates `dev`.\n",
      "     |      \n",
      "     |      When combining specs, `dev` will take precidence over the current spec.\n",
      "     |      So for instance:\n",
      "     |      ```\n",
      "     |      first_spec = tf.DeviceSpec(job=0, device_type=\"CPU\")\n",
      "     |      second_spec = tf.DeviceSpec(device_type=\"GPU\")\n",
      "     |      combined_spec = first_spec.make_merged_spec(second_spec)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      is equivalent to:\n",
      "     |      ```\n",
      "     |      combined_spec = tf.DeviceSpec(job=0, device_type=\"GPU\")\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        dev: a `DeviceSpec`\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A new `DeviceSpec` which combines `self` and `dev`\n",
      "     |  \n",
      "     |  replace(self, **kwargs)\n",
      "     |      Convenience method for making a new DeviceSpec by overriding fields.\n",
      "     |      \n",
      "     |      For instance:\n",
      "     |      ```\n",
      "     |      my_spec = DeviceSpec=(job=\"my_job\", device=\"CPU\")\n",
      "     |      my_updated_spec = my_spec.replace(device=\"GPU\")\n",
      "     |      my_other_spec = my_spec.replace(device=None)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        **kwargs: This method takes the same args as the DeviceSpec constructor\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A DeviceSpec with the fields specified in kwargs overridden.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from DeviceSpecV2:\n",
      "     |  \n",
      "     |  from_string(spec) from builtins.type\n",
      "     |      Construct a `DeviceSpec` from a string.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        spec: a string of the form\n",
      "     |         /job:<name>/replica:<id>/task:<id>/device:CPU:<id>\n",
      "     |        or\n",
      "     |         /job:<name>/replica:<id>/task:<id>/device:GPU:<id>\n",
      "     |        as cpu and gpu are mutually exclusive.\n",
      "     |        All entries are optional.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A DeviceSpec.\n",
      "    \n",
      "    class Dimension(builtins.object)\n",
      "     |  Represents the value of one dimension in a TensorShape.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __add__(self, other)\n",
      "     |      Returns the sum of `self` and `other`.\n",
      "     |      \n",
      "     |      Dimensions are summed as follows:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      tf.compat.v1.Dimension(m)    + tf.compat.v1.Dimension(n)     ==\n",
      "     |      tf.compat.v1.Dimension(m + n)\n",
      "     |      tf.compat.v1.Dimension(m)    + tf.compat.v1.Dimension(None)  # equiv. to\n",
      "     |      tf.compat.v1.Dimension(None)\n",
      "     |      tf.compat.v1.Dimension(None) + tf.compat.v1.Dimension(n)     # equiv. to\n",
      "     |      tf.compat.v1.Dimension(None)\n",
      "     |      tf.compat.v1.Dimension(None) + tf.compat.v1.Dimension(None)  # equiv. to\n",
      "     |      tf.compat.v1.Dimension(None)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another Dimension, or a value accepted by `as_dimension`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A Dimension whose value is the sum of `self` and `other`.\n",
      "     |  \n",
      "     |  __div__(self, other)\n",
      "     |      DEPRECATED: Use `__floordiv__` via `x // y` instead.\n",
      "     |      \n",
      "     |      This function exists only for backwards compatibility purposes; new code\n",
      "     |      should use `__floordiv__` via the syntax `x // y`.  Using `x // y`\n",
      "     |      communicates clearly that the result rounds down, and is forward compatible\n",
      "     |      to Python 3.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another `Dimension`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Dimension` whose value is the integer quotient of `self` and `other`.\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Returns true if `other` has the same known value as this Dimension.\n",
      "     |  \n",
      "     |  __floordiv__(self, other)\n",
      "     |      Returns the quotient of `self` and `other` rounded down.\n",
      "     |      \n",
      "     |      Dimensions are divided as follows:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      tf.compat.v1.Dimension(m)    // tf.compat.v1.Dimension(n)     ==\n",
      "     |      tf.compat.v1.Dimension(m // n)\n",
      "     |      tf.compat.v1.Dimension(m)    // tf.compat.v1.Dimension(None)  # equiv. to\n",
      "     |      tf.compat.v1.Dimension(None)\n",
      "     |      tf.compat.v1.Dimension(None) // tf.compat.v1.Dimension(n)     # equiv. to\n",
      "     |      tf.compat.v1.Dimension(None)\n",
      "     |      tf.compat.v1.Dimension(None) // tf.compat.v1.Dimension(None)  # equiv. to\n",
      "     |      tf.compat.v1.Dimension(None)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another Dimension, or a value accepted by `as_dimension`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Dimension` whose value is the integer quotient of `self` and `other`.\n",
      "     |  \n",
      "     |  __ge__(self, other)\n",
      "     |      Returns True if `self` is known to be greater than or equal to `other`.\n",
      "     |      \n",
      "     |      Dimensions are compared as follows:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      (tf.compat.v1.Dimension(m)    >= tf.compat.v1.Dimension(n))    == (m >= n)\n",
      "     |      (tf.compat.v1.Dimension(m)    >= tf.compat.v1.Dimension(None)) == None\n",
      "     |      (tf.compat.v1.Dimension(None) >= tf.compat.v1.Dimension(n))    == None\n",
      "     |      (tf.compat.v1.Dimension(None) >= tf.compat.v1.Dimension(None)) == None\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another Dimension.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The value of `self.value >= other.value` if both are known, otherwise\n",
      "     |        None.\n",
      "     |  \n",
      "     |  __gt__(self, other)\n",
      "     |      Returns True if `self` is known to be greater than `other`.\n",
      "     |      \n",
      "     |      Dimensions are compared as follows:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      (tf.compat.v1.Dimension(m)    > tf.compat.v1.Dimension(n))    == (m > n)\n",
      "     |      (tf.compat.v1.Dimension(m)    > tf.compat.v1.Dimension(None)) == None\n",
      "     |      (tf.compat.v1.Dimension(None) > tf.compat.v1.Dimension(n))    == None\n",
      "     |      (tf.compat.v1.Dimension(None) > tf.compat.v1.Dimension(None)) == None\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another Dimension.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The value of `self.value > other.value` if both are known, otherwise\n",
      "     |        None.\n",
      "     |  \n",
      "     |  __index__(self)\n",
      "     |  \n",
      "     |  __init__(self, value)\n",
      "     |      Creates a new Dimension with the given value.\n",
      "     |  \n",
      "     |  __int__(self)\n",
      "     |  \n",
      "     |  __le__(self, other)\n",
      "     |      Returns True if `self` is known to be less than or equal to `other`.\n",
      "     |      \n",
      "     |      Dimensions are compared as follows:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      (tf.compat.v1.Dimension(m)    <= tf.compat.v1.Dimension(n))    == (m <= n)\n",
      "     |      (tf.compat.v1.Dimension(m)    <= tf.compat.v1.Dimension(None)) == None\n",
      "     |      (tf.compat.v1.Dimension(None) <= tf.compat.v1.Dimension(n))    == None\n",
      "     |      (tf.compat.v1.Dimension(None) <= tf.compat.v1.Dimension(None)) == None\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another Dimension.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The value of `self.value <= other.value` if both are known, otherwise\n",
      "     |        None.\n",
      "     |  \n",
      "     |  __long__(self)\n",
      "     |      # This is needed for Windows.\n",
      "     |      # See https://github.com/tensorflow/tensorflow/pull/9780\n",
      "     |  \n",
      "     |  __lt__(self, other)\n",
      "     |      Returns True if `self` is known to be less than `other`.\n",
      "     |      \n",
      "     |      Dimensions are compared as follows:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      (tf.compat.v1.Dimension(m)    < tf.compat.v1.Dimension(n))    == (m < n)\n",
      "     |      (tf.compat.v1.Dimension(m)    < tf.compat.v1.Dimension(None)) == None\n",
      "     |      (tf.compat.v1.Dimension(None) < tf.compat.v1.Dimension(n))    == None\n",
      "     |      (tf.compat.v1.Dimension(None) < tf.compat.v1.Dimension(None)) == None\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another Dimension.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The value of `self.value < other.value` if both are known, otherwise\n",
      "     |        None.\n",
      "     |  \n",
      "     |  __mod__(self, other)\n",
      "     |      Returns `self` modulo `other`.\n",
      "     |      \n",
      "     |      Dimension moduli are computed as follows:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      tf.compat.v1.Dimension(m)    % tf.compat.v1.Dimension(n)     ==\n",
      "     |      tf.compat.v1.Dimension(m % n)\n",
      "     |      tf.compat.v1.Dimension(m)    % tf.compat.v1.Dimension(None)  # equiv. to\n",
      "     |      tf.compat.v1.Dimension(None)\n",
      "     |      tf.compat.v1.Dimension(None) % tf.compat.v1.Dimension(n)     # equiv. to\n",
      "     |      tf.compat.v1.Dimension(None)\n",
      "     |      tf.compat.v1.Dimension(None) % tf.compat.v1.Dimension(None)  # equiv. to\n",
      "     |      tf.compat.v1.Dimension(None)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another Dimension, or a value accepted by `as_dimension`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A Dimension whose value is `self` modulo `other`.\n",
      "     |  \n",
      "     |  __mul__(self, other)\n",
      "     |      Returns the product of `self` and `other`.\n",
      "     |      \n",
      "     |      Dimensions are summed as follows:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      tf.compat.v1.Dimension(m)    * tf.compat.v1.Dimension(n)     ==\n",
      "     |      tf.compat.v1.Dimension(m * n)\n",
      "     |      tf.compat.v1.Dimension(m)    * tf.compat.v1.Dimension(None)  # equiv. to\n",
      "     |      tf.compat.v1.Dimension(None)\n",
      "     |      tf.compat.v1.Dimension(None) * tf.compat.v1.Dimension(n)     # equiv. to\n",
      "     |      tf.compat.v1.Dimension(None)\n",
      "     |      tf.compat.v1.Dimension(None) * tf.compat.v1.Dimension(None)  # equiv. to\n",
      "     |      tf.compat.v1.Dimension(None)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another Dimension, or a value accepted by `as_dimension`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A Dimension whose value is the product of `self` and `other`.\n",
      "     |  \n",
      "     |  __ne__(self, other)\n",
      "     |      Returns true if `other` has a different known value from `self`.\n",
      "     |  \n",
      "     |  __radd__(self, other)\n",
      "     |      Returns the sum of `other` and `self`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another Dimension, or a value accepted by `as_dimension`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A Dimension whose value is the sum of `self` and `other`.\n",
      "     |  \n",
      "     |  __rdiv__(self, other)\n",
      "     |      Use `__floordiv__` via `x // y` instead.\n",
      "     |      \n",
      "     |      This function exists only to have a better error message. Instead of:\n",
      "     |      `TypeError: unsupported operand type(s) for /: 'int' and 'Dimension'`,\n",
      "     |      this function will explicitly call for usage of `//` instead.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another `Dimension`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __rfloordiv__(self, other)\n",
      "     |      Returns the quotient of `other` and `self` rounded down.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another Dimension, or a value accepted by `as_dimension`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Dimension` whose value is the integer quotient of `self` and `other`.\n",
      "     |  \n",
      "     |  __rmod__(self, other)\n",
      "     |      Returns `other` modulo `self`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another Dimension, or a value accepted by `as_dimension`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A Dimension whose value is `other` modulo `self`.\n",
      "     |  \n",
      "     |  __rmul__(self, other)\n",
      "     |      Returns the product of `self` and `other`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another Dimension, or a value accepted by `as_dimension`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A Dimension whose value is the product of `self` and `other`.\n",
      "     |  \n",
      "     |  __rsub__(self, other)\n",
      "     |      Returns the subtraction of `self` from `other`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another Dimension, or a value accepted by `as_dimension`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A Dimension whose value is the subtraction of `self` from `other`.\n",
      "     |  \n",
      "     |  __rtruediv__(self, other)\n",
      "     |      Use `__floordiv__` via `x // y` instead.\n",
      "     |      \n",
      "     |      This function exists only to have a better error message. Instead of:\n",
      "     |      `TypeError: unsupported operand type(s) for /: 'int' and 'Dimension'`,\n",
      "     |      this function will explicitly call for usage of `//` instead.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another `Dimension`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError.\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  __sub__(self, other)\n",
      "     |      Returns the subtraction of `other` from `self`.\n",
      "     |      \n",
      "     |      Dimensions are subtracted as follows:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      tf.compat.v1.Dimension(m)    - tf.compat.v1.Dimension(n)     ==\n",
      "     |      tf.compat.v1.Dimension(m - n)\n",
      "     |      tf.compat.v1.Dimension(m)    - tf.compat.v1.Dimension(None)  # equiv. to\n",
      "     |      tf.compat.v1.Dimension(None)\n",
      "     |      tf.compat.v1.Dimension(None) - tf.compat.v1.Dimension(n)     # equiv. to\n",
      "     |      tf.compat.v1.Dimension(None)\n",
      "     |      tf.compat.v1.Dimension(None) - tf.compat.v1.Dimension(None)  # equiv. to\n",
      "     |      tf.compat.v1.Dimension(None)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another Dimension, or a value accepted by `as_dimension`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A Dimension whose value is the subtraction of `other` from `self`.\n",
      "     |  \n",
      "     |  __truediv__(self, other)\n",
      "     |      Use `__floordiv__` via `x // y` instead.\n",
      "     |      \n",
      "     |      This function exists only to have a better error message. Instead of:\n",
      "     |      `TypeError: unsupported operand type(s) for /: 'Dimension' and 'int'`,\n",
      "     |      this function will explicitly call for usage of `//` instead.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another `Dimension`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError.\n",
      "     |  \n",
      "     |  assert_is_compatible_with(self, other)\n",
      "     |      Raises an exception if `other` is not compatible with this Dimension.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another Dimension.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `self` and `other` are not compatible (see\n",
      "     |          is_compatible_with).\n",
      "     |  \n",
      "     |  is_compatible_with(self, other)\n",
      "     |      Returns true if `other` is compatible with this Dimension.\n",
      "     |      \n",
      "     |      Two known Dimensions are compatible if they have the same value.\n",
      "     |      An unknown Dimension is compatible with all other Dimensions.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another Dimension.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        True if this Dimension and `other` are compatible.\n",
      "     |  \n",
      "     |  merge_with(self, other)\n",
      "     |      Returns a Dimension that combines the information in `self` and `other`.\n",
      "     |      \n",
      "     |      Dimensions are combined as follows:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      tf.compat.v1.Dimension(n)   .merge_with(tf.compat.v1.Dimension(n))     ==\n",
      "     |      tf.compat.v1.Dimension(n)\n",
      "     |      tf.compat.v1.Dimension(n)   .merge_with(tf.compat.v1.Dimension(None))  ==\n",
      "     |      tf.compat.v1.Dimension(n)\n",
      "     |      tf.compat.v1.Dimension(None).merge_with(tf.compat.v1.Dimension(n))     ==\n",
      "     |      tf.compat.v1.Dimension(n)\n",
      "     |      # equivalent to tf.compat.v1.Dimension(None)\n",
      "     |      tf.compat.v1.Dimension(None).merge_with(tf.compat.v1.Dimension(None))\n",
      "     |      \n",
      "     |      # raises ValueError for n != m\n",
      "     |      tf.compat.v1.Dimension(n)   .merge_with(tf.compat.v1.Dimension(m))\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another Dimension.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A Dimension containing the combined information of `self` and\n",
      "     |        `other`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `self` and `other` are not compatible (see\n",
      "     |          is_compatible_with).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  value\n",
      "     |      The value of this dimension, or None if it is unknown.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "    \n",
      "    class Event(google.protobuf.pyext._message.CMessage, google.protobuf.message.Message)\n",
      "     |  A ProtocolMessage\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Event\n",
      "     |      google.protobuf.pyext._message.CMessage\n",
      "     |      google.protobuf.message.Message\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  file_version\n",
      "     |      Field tensorflow.Event.file_version\n",
      "     |  \n",
      "     |  graph_def\n",
      "     |      Field tensorflow.Event.graph_def\n",
      "     |  \n",
      "     |  log_message\n",
      "     |      Field tensorflow.Event.log_message\n",
      "     |  \n",
      "     |  meta_graph_def\n",
      "     |      Field tensorflow.Event.meta_graph_def\n",
      "     |  \n",
      "     |  session_log\n",
      "     |      Field tensorflow.Event.session_log\n",
      "     |  \n",
      "     |  step\n",
      "     |      Field tensorflow.Event.step\n",
      "     |  \n",
      "     |  summary\n",
      "     |      Field tensorflow.Event.summary\n",
      "     |  \n",
      "     |  tagged_run_metadata\n",
      "     |      Field tensorflow.Event.tagged_run_metadata\n",
      "     |  \n",
      "     |  wall_time\n",
      "     |      Field tensorflow.Event.wall_time\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  DESCRIPTOR = <google.protobuf.pyext._message.MessageDescriptor object>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.pyext._message.CMessage:\n",
      "     |  \n",
      "     |  ByteSize(...)\n",
      "     |      Returns the size of the message in bytes.\n",
      "     |  \n",
      "     |  Clear(...)\n",
      "     |      Clears the message.\n",
      "     |  \n",
      "     |  ClearExtension(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  ClearField(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  CopyFrom(...)\n",
      "     |      Copies a protocol message into the current message.\n",
      "     |  \n",
      "     |  DiscardUnknownFields(...)\n",
      "     |      Discards the unknown fields.\n",
      "     |  \n",
      "     |  FindInitializationErrors(...)\n",
      "     |      Finds unset required fields.\n",
      "     |  \n",
      "     |  FromString(...) from google.protobuf.pyext.cpp_message.GeneratedProtocolMessageType\n",
      "     |      Creates new method instance from given serialized data.\n",
      "     |  \n",
      "     |  HasExtension(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  HasField(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  IsInitialized(...)\n",
      "     |      Checks if all required fields of a protocol message are set.\n",
      "     |  \n",
      "     |  ListFields(...)\n",
      "     |      Lists all set fields of a message.\n",
      "     |  \n",
      "     |  MergeFrom(...)\n",
      "     |      Merges a protocol message into the current message.\n",
      "     |  \n",
      "     |  MergeFromString(...)\n",
      "     |      Merges a serialized message into the current message.\n",
      "     |  \n",
      "     |  ParseFromString(...)\n",
      "     |      Parses a serialized message into the current message.\n",
      "     |  \n",
      "     |  RegisterExtension(...) from google.protobuf.pyext.cpp_message.GeneratedProtocolMessageType\n",
      "     |      Registers an extension with the current message.\n",
      "     |  \n",
      "     |  SerializePartialToString(...)\n",
      "     |      Serializes the message to a string, even if it isn't initialized.\n",
      "     |  \n",
      "     |  SerializeToString(...)\n",
      "     |      Serializes the message to a string, only for initialized messages.\n",
      "     |  \n",
      "     |  SetInParent(...)\n",
      "     |      Sets the has bit of the given field in its parent message.\n",
      "     |  \n",
      "     |  UnknownFields(...)\n",
      "     |      Parse unknown field set\n",
      "     |  \n",
      "     |  WhichOneof(...)\n",
      "     |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      Makes a deep copy of the class.\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from google.protobuf.pyext._message.MessageMeta\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  __unicode__(...)\n",
      "     |      Outputs a unicode representation of the message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google.protobuf.pyext._message.CMessage:\n",
      "     |  \n",
      "     |  Extensions\n",
      "     |      Extension dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from google.protobuf.pyext._message.CMessage:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Support the pickle protocol.\n",
      "    \n",
      "    class FIFOQueue(QueueBase)\n",
      "     |  A queue implementation that dequeues elements in first-in first-out order.\n",
      "     |  \n",
      "     |  See `tf.queue.QueueBase` for a description of the methods on\n",
      "     |  this class.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      FIFOQueue\n",
      "     |      QueueBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, capacity, dtypes, shapes=None, names=None, shared_name=None, name='fifo_queue')\n",
      "     |      Creates a queue that dequeues elements in a first-in first-out order.\n",
      "     |      \n",
      "     |      A `FIFOQueue` has bounded capacity; supports multiple concurrent\n",
      "     |      producers and consumers; and provides exactly-once delivery.\n",
      "     |      \n",
      "     |      A `FIFOQueue` holds a list of up to `capacity` elements. Each\n",
      "     |      element is a fixed-length tuple of tensors whose dtypes are\n",
      "     |      described by `dtypes`, and whose shapes are optionally described\n",
      "     |      by the `shapes` argument.\n",
      "     |      \n",
      "     |      If the `shapes` argument is specified, each component of a queue\n",
      "     |      element must have the respective fixed shape. If it is\n",
      "     |      unspecified, different queue elements may have different shapes,\n",
      "     |      but the use of `dequeue_many` is disallowed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        capacity: An integer. The upper bound on the number of elements\n",
      "     |          that may be stored in this queue.\n",
      "     |        dtypes:  A list of `DType` objects. The length of `dtypes` must equal\n",
      "     |          the number of tensors in each queue element.\n",
      "     |        shapes: (Optional.) A list of fully-defined `TensorShape` objects\n",
      "     |          with the same length as `dtypes`, or `None`.\n",
      "     |        names: (Optional.) A list of string naming the components in the queue\n",
      "     |          with the same length as `dtypes`, or `None`.  If specified the dequeue\n",
      "     |          methods return a dictionary with the names as keys.\n",
      "     |        shared_name: (Optional.) If non-empty, this queue will be shared under\n",
      "     |          the given name across multiple sessions.\n",
      "     |        name: Optional name for the queue operation.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from QueueBase:\n",
      "     |  \n",
      "     |  close(self, cancel_pending_enqueues=False, name=None)\n",
      "     |      Closes this queue.\n",
      "     |      \n",
      "     |      This operation signals that no more elements will be enqueued in\n",
      "     |      the given queue. Subsequent `enqueue` and `enqueue_many`\n",
      "     |      operations will fail. Subsequent `dequeue` and `dequeue_many`\n",
      "     |      operations will continue to succeed if sufficient elements remain\n",
      "     |      in the queue. Subsequently dequeue and dequeue_many operations\n",
      "     |      that would otherwise block waiting for more elements (if close\n",
      "     |      hadn't been called) will now fail immediately.\n",
      "     |      \n",
      "     |      If `cancel_pending_enqueues` is `True`, all pending requests will also\n",
      "     |      be canceled.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        cancel_pending_enqueues: (Optional.) A boolean, defaulting to\n",
      "     |          `False` (described above).\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The operation that closes the queue.\n",
      "     |  \n",
      "     |  dequeue(self, name=None)\n",
      "     |      Dequeues one element from this queue.\n",
      "     |      \n",
      "     |      If the queue is empty when this operation executes, it will block\n",
      "     |      until there is an element to dequeue.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed, the queue is empty, and there are no pending\n",
      "     |      enqueue operations that can fulfill this request,\n",
      "     |      `tf.errors.OutOfRangeError` will be raised. If the session is\n",
      "     |      `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The tuple of tensors that was dequeued.\n",
      "     |  \n",
      "     |  dequeue_many(self, n, name=None)\n",
      "     |      Dequeues and concatenates `n` elements from this queue.\n",
      "     |      \n",
      "     |      This operation concatenates queue-element component tensors along\n",
      "     |      the 0th dimension to make a single component tensor.  All of the\n",
      "     |      components in the dequeued tuple will have size `n` in the 0th dimension.\n",
      "     |      \n",
      "     |      If the queue is closed and there are less than `n` elements left, then an\n",
      "     |      `OutOfRange` exception is raised.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed, the queue contains fewer than `n` elements, and\n",
      "     |      there are no pending enqueue operations that can fulfill this\n",
      "     |      request, `tf.errors.OutOfRangeError` will be raised. If the\n",
      "     |      session is `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        n: A scalar `Tensor` containing the number of elements to dequeue.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The list of concatenated tensors that was dequeued.\n",
      "     |  \n",
      "     |  dequeue_up_to(self, n, name=None)\n",
      "     |      Dequeues and concatenates `n` elements from this queue.\n",
      "     |      \n",
      "     |      **Note** This operation is not supported by all queues.  If a queue does not\n",
      "     |      support DequeueUpTo, then a `tf.errors.UnimplementedError` is raised.\n",
      "     |      \n",
      "     |      This operation concatenates queue-element component tensors along\n",
      "     |      the 0th dimension to make a single component tensor. If the queue\n",
      "     |      has not been closed, all of the components in the dequeued tuple\n",
      "     |      will have size `n` in the 0th dimension.\n",
      "     |      \n",
      "     |      If the queue is closed and there are more than `0` but fewer than\n",
      "     |      `n` elements remaining, then instead of raising a\n",
      "     |      `tf.errors.OutOfRangeError` like `tf.QueueBase.dequeue_many`,\n",
      "     |      less than `n` elements are returned immediately.  If the queue is\n",
      "     |      closed and there are `0` elements left in the queue, then a\n",
      "     |      `tf.errors.OutOfRangeError` is raised just like in `dequeue_many`.\n",
      "     |      Otherwise the behavior is identical to `dequeue_many`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        n: A scalar `Tensor` containing the number of elements to dequeue.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The tuple of concatenated tensors that was dequeued.\n",
      "     |  \n",
      "     |  enqueue(self, vals, name=None)\n",
      "     |      Enqueues one element to this queue.\n",
      "     |      \n",
      "     |      If the queue is full when this operation executes, it will block\n",
      "     |      until the element has been enqueued.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed before this operation runs,\n",
      "     |      `tf.errors.CancelledError` will be raised. If this operation is\n",
      "     |      blocked, and either (i) the queue is closed by a close operation\n",
      "     |      with `cancel_pending_enqueues=True`, or (ii) the session is\n",
      "     |      `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        vals: A tensor, a list or tuple of tensors, or a dictionary containing\n",
      "     |          the values to enqueue.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The operation that enqueues a new tuple of tensors to the queue.\n",
      "     |  \n",
      "     |  enqueue_many(self, vals, name=None)\n",
      "     |      Enqueues zero or more elements to this queue.\n",
      "     |      \n",
      "     |      This operation slices each component tensor along the 0th dimension to\n",
      "     |      make multiple queue elements. All of the tensors in `vals` must have the\n",
      "     |      same size in the 0th dimension.\n",
      "     |      \n",
      "     |      If the queue is full when this operation executes, it will block\n",
      "     |      until all of the elements have been enqueued.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed before this operation runs,\n",
      "     |      `tf.errors.CancelledError` will be raised. If this operation is\n",
      "     |      blocked, and either (i) the queue is closed by a close operation\n",
      "     |      with `cancel_pending_enqueues=True`, or (ii) the session is\n",
      "     |      `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        vals: A tensor, a list or tuple of tensors, or a dictionary\n",
      "     |          from which the queue elements are taken.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The operation that enqueues a batch of tuples of tensors to the queue.\n",
      "     |  \n",
      "     |  is_closed(self, name=None)\n",
      "     |      Returns true if queue is closed.\n",
      "     |      \n",
      "     |      This operation returns true if the queue is closed and false if the queue\n",
      "     |      is open.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        True if the queue is closed and false if the queue is open.\n",
      "     |  \n",
      "     |  size(self, name=None)\n",
      "     |      Compute the number of elements in this queue.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A scalar tensor containing the number of elements in this queue.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from QueueBase:\n",
      "     |  \n",
      "     |  from_list(index, queues)\n",
      "     |      Create a queue using the queue reference from `queues[index]`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        index: An integer scalar tensor that determines the input that gets\n",
      "     |          selected.\n",
      "     |        queues: A list of `QueueBase` objects.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `QueueBase` object.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: When `queues` is not a list of `QueueBase` objects,\n",
      "     |          or when the data types of `queues` are not all the same.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from QueueBase:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  dtypes\n",
      "     |      The list of dtypes for each component of a queue element.\n",
      "     |  \n",
      "     |  name\n",
      "     |      The name of the underlying queue.\n",
      "     |  \n",
      "     |  names\n",
      "     |      The list of names for each component of a queue element.\n",
      "     |  \n",
      "     |  queue_ref\n",
      "     |      The underlying queue reference.\n",
      "     |  \n",
      "     |  shapes\n",
      "     |      The list of shapes for each component of a queue element.\n",
      "    \n",
      "    class FixedLenFeature(FixedLenFeature)\n",
      "     |  Configuration for parsing a fixed-length input feature.\n",
      "     |  \n",
      "     |  To treat sparse input as dense, provide a `default_value`; otherwise,\n",
      "     |  the parse functions will fail on any examples missing this feature.\n",
      "     |  \n",
      "     |  Fields:\n",
      "     |    shape: Shape of input data.\n",
      "     |    dtype: Data type of input.\n",
      "     |    default_value: Value to be used if an example is missing this feature. It\n",
      "     |        must be compatible with `dtype` and of the specified `shape`.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      FixedLenFeature\n",
      "     |      FixedLenFeature\n",
      "     |      builtins.tuple\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(cls, shape, dtype, default_value=None)\n",
      "     |      Create new instance of FixedLenFeature(shape, dtype, default_value)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  _tf_api_names = ('io.FixedLenFeature',)\n",
      "     |  \n",
      "     |  _tf_api_names_v1 = ['io.FixedLenFeature', 'FixedLenFeature']\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from FixedLenFeature:\n",
      "     |  \n",
      "     |  __getnewargs__(self)\n",
      "     |      Return self as a plain tuple.  Used by copy and pickle.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return a nicely formatted representation string\n",
      "     |  \n",
      "     |  _asdict(self)\n",
      "     |      Return a new OrderedDict which maps field names to their values.\n",
      "     |  \n",
      "     |  _replace(_self, **kwds)\n",
      "     |      Return a new FixedLenFeature object replacing specified fields with new values\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from FixedLenFeature:\n",
      "     |  \n",
      "     |  _make(iterable, new=<built-in method __new__ of type object at 0x9d43a0>, len=<built-in function len>) from builtins.type\n",
      "     |      Make a new FixedLenFeature object from a sequence or iterable\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from FixedLenFeature:\n",
      "     |  \n",
      "     |  shape\n",
      "     |      Alias for field number 0\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      Alias for field number 1\n",
      "     |  \n",
      "     |  default_value\n",
      "     |      Alias for field number 2\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from FixedLenFeature:\n",
      "     |  \n",
      "     |  _fields = ('shape', 'dtype', 'default_value')\n",
      "     |  \n",
      "     |  _source = \"from builtins import property as _property, tupl..._itemget...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.tuple:\n",
      "     |  \n",
      "     |  __add__(self, value, /)\n",
      "     |      Return self+value.\n",
      "     |  \n",
      "     |  __contains__(self, key, /)\n",
      "     |      Return key in self.\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __hash__(self, /)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __mul__(self, value, /)\n",
      "     |      Return self*value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __rmul__(self, value, /)\n",
      "     |      Return value*self.\n",
      "     |  \n",
      "     |  count(...)\n",
      "     |      T.count(value) -> integer -- return number of occurrences of value\n",
      "     |  \n",
      "     |  index(...)\n",
      "     |      T.index(value, [start, [stop]]) -> integer -- return first index of value.\n",
      "     |      Raises ValueError if the value is not present.\n",
      "    \n",
      "    class FixedLenSequenceFeature(FixedLenSequenceFeature)\n",
      "     |  Configuration for parsing a variable-length input feature into a `Tensor`.\n",
      "     |  \n",
      "     |  The resulting `Tensor` of parsing a single `SequenceExample` or `Example` has\n",
      "     |  a static `shape` of `[None] + shape` and the specified `dtype`.\n",
      "     |  The resulting `Tensor` of parsing a `batch_size` many `Example`s has\n",
      "     |  a static `shape` of `[batch_size, None] + shape` and the specified `dtype`.\n",
      "     |  The entries in the `batch` from different `Examples` will be padded with\n",
      "     |  `default_value` to the maximum length present in the `batch`.\n",
      "     |  \n",
      "     |  To treat a sparse input as dense, provide `allow_missing=True`; otherwise,\n",
      "     |  the parse functions will fail on any examples missing this feature.\n",
      "     |  \n",
      "     |  Fields:\n",
      "     |    shape: Shape of input data for dimension 2 and higher. First dimension is\n",
      "     |      of variable length `None`.\n",
      "     |    dtype: Data type of input.\n",
      "     |    allow_missing: Whether to allow this feature to be missing from a feature\n",
      "     |      list item. Is available only for parsing `SequenceExample` not for\n",
      "     |      parsing `Examples`.\n",
      "     |    default_value: Scalar value to be used to pad multiple `Example`s to their\n",
      "     |      maximum length. Irrelevant for parsing a single `Example` or\n",
      "     |      `SequenceExample`. Defaults to \"\" for dtype string and 0 otherwise\n",
      "     |      (optional).\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      FixedLenSequenceFeature\n",
      "     |      FixedLenSequenceFeature\n",
      "     |      builtins.tuple\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(cls, shape, dtype, allow_missing=False, default_value=None)\n",
      "     |      Create new instance of FixedLenSequenceFeature(shape, dtype, allow_missing, default_value)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  _tf_api_names = ('io.FixedLenSequenceFeature',)\n",
      "     |  \n",
      "     |  _tf_api_names_v1 = ['io.FixedLenSequenceFeature', 'FixedLenSequenceFea...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from FixedLenSequenceFeature:\n",
      "     |  \n",
      "     |  __getnewargs__(self)\n",
      "     |      Return self as a plain tuple.  Used by copy and pickle.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return a nicely formatted representation string\n",
      "     |  \n",
      "     |  _asdict(self)\n",
      "     |      Return a new OrderedDict which maps field names to their values.\n",
      "     |  \n",
      "     |  _replace(_self, **kwds)\n",
      "     |      Return a new FixedLenSequenceFeature object replacing specified fields with new values\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from FixedLenSequenceFeature:\n",
      "     |  \n",
      "     |  _make(iterable, new=<built-in method __new__ of type object at 0x9d43a0>, len=<built-in function len>) from builtins.type\n",
      "     |      Make a new FixedLenSequenceFeature object from a sequence or iterable\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from FixedLenSequenceFeature:\n",
      "     |  \n",
      "     |  shape\n",
      "     |      Alias for field number 0\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      Alias for field number 1\n",
      "     |  \n",
      "     |  allow_missing\n",
      "     |      Alias for field number 2\n",
      "     |  \n",
      "     |  default_value\n",
      "     |      Alias for field number 3\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from FixedLenSequenceFeature:\n",
      "     |  \n",
      "     |  _fields = ('shape', 'dtype', 'allow_missing', 'default_value')\n",
      "     |  \n",
      "     |  _source = \"from builtins import property as _property, tupl..._itemget...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.tuple:\n",
      "     |  \n",
      "     |  __add__(self, value, /)\n",
      "     |      Return self+value.\n",
      "     |  \n",
      "     |  __contains__(self, key, /)\n",
      "     |      Return key in self.\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __hash__(self, /)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __mul__(self, value, /)\n",
      "     |      Return self*value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __rmul__(self, value, /)\n",
      "     |      Return value*self.\n",
      "     |  \n",
      "     |  count(...)\n",
      "     |      T.count(value) -> integer -- return number of occurrences of value\n",
      "     |  \n",
      "     |  index(...)\n",
      "     |      T.index(value, [start, [stop]]) -> integer -- return first index of value.\n",
      "     |      Raises ValueError if the value is not present.\n",
      "    \n",
      "    class FixedLengthRecordReader(ReaderBase)\n",
      "     |  A Reader that outputs fixed-length records from a file.\n",
      "     |  \n",
      "     |  See ReaderBase for supported methods.\n",
      "     |  \n",
      "     |  @compatibility(eager)\n",
      "     |  Readers are not compatible with eager execution. Instead, please\n",
      "     |  use `tf.data` to get data into your model.\n",
      "     |  @end_compatibility\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      FixedLengthRecordReader\n",
      "     |      ReaderBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, record_bytes, header_bytes=None, footer_bytes=None, hop_bytes=None, name=None, encoding=None)\n",
      "     |      Create a FixedLengthRecordReader. (deprecated)\n",
      "     |      \n",
      "     |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.FixedLengthRecordDataset`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        record_bytes: An int.\n",
      "     |        header_bytes: An optional int. Defaults to 0.\n",
      "     |        footer_bytes: An optional int. Defaults to 0.\n",
      "     |        hop_bytes: An optional int. Defaults to 0.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |        encoding: The type of encoding for the file. Defaults to none.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ReaderBase:\n",
      "     |  \n",
      "     |  num_records_produced(self, name=None)\n",
      "     |      Returns the number of records this reader has produced.\n",
      "     |      \n",
      "     |      This is the same as the number of Read executions that have\n",
      "     |      succeeded.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An int64 Tensor.\n",
      "     |  \n",
      "     |  num_work_units_completed(self, name=None)\n",
      "     |      Returns the number of work units this reader has finished processing.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An int64 Tensor.\n",
      "     |  \n",
      "     |  read(self, queue, name=None)\n",
      "     |      Returns the next record (key, value) pair produced by a reader.\n",
      "     |      \n",
      "     |      Will dequeue a work unit from queue if necessary (e.g. when the\n",
      "     |      Reader needs to start reading from a new file since it has\n",
      "     |      finished with the previous file).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        queue: A Queue or a mutable string Tensor representing a handle\n",
      "     |          to a Queue, with string work items.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A tuple of Tensors (key, value).\n",
      "     |        key: A string scalar Tensor.\n",
      "     |        value: A string scalar Tensor.\n",
      "     |  \n",
      "     |  read_up_to(self, queue, num_records, name=None)\n",
      "     |      Returns up to num_records (key, value) pairs produced by a reader.\n",
      "     |      \n",
      "     |      Will dequeue a work unit from queue if necessary (e.g., when the\n",
      "     |      Reader needs to start reading from a new file since it has\n",
      "     |      finished with the previous file).\n",
      "     |      It may return less than num_records even before the last batch.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        queue: A Queue or a mutable string Tensor representing a handle\n",
      "     |          to a Queue, with string work items.\n",
      "     |        num_records: Number of records to read.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A tuple of Tensors (keys, values).\n",
      "     |        keys: A 1-D string Tensor.\n",
      "     |        values: A 1-D string Tensor.\n",
      "     |  \n",
      "     |  reset(self, name=None)\n",
      "     |      Restore a reader to its initial clean state.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The created Operation.\n",
      "     |  \n",
      "     |  restore_state(self, state, name=None)\n",
      "     |      Restore a reader to a previously saved state.\n",
      "     |      \n",
      "     |      Not all Readers support being restored, so this can produce an\n",
      "     |      Unimplemented error.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        state: A string Tensor.\n",
      "     |          Result of a SerializeState of a Reader with matching type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The created Operation.\n",
      "     |  \n",
      "     |  serialize_state(self, name=None)\n",
      "     |      Produce a string tensor that encodes the state of a reader.\n",
      "     |      \n",
      "     |      Not all Readers support being serialized, so this can produce an\n",
      "     |      Unimplemented error.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A string Tensor.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from ReaderBase:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  reader_ref\n",
      "     |      Op that implements the reader.\n",
      "     |  \n",
      "     |  supports_serialize\n",
      "     |      Whether the Reader implementation can serialize its state.\n",
      "    \n",
      "    class GPUOptions(google.protobuf.pyext._message.CMessage, google.protobuf.message.Message)\n",
      "     |  A ProtocolMessage\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      GPUOptions\n",
      "     |      google.protobuf.pyext._message.CMessage\n",
      "     |      google.protobuf.message.Message\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  allocator_type\n",
      "     |      Field tensorflow.GPUOptions.allocator_type\n",
      "     |  \n",
      "     |  allow_growth\n",
      "     |      Field tensorflow.GPUOptions.allow_growth\n",
      "     |  \n",
      "     |  deferred_deletion_bytes\n",
      "     |      Field tensorflow.GPUOptions.deferred_deletion_bytes\n",
      "     |  \n",
      "     |  experimental\n",
      "     |      Field tensorflow.GPUOptions.experimental\n",
      "     |  \n",
      "     |  force_gpu_compatible\n",
      "     |      Field tensorflow.GPUOptions.force_gpu_compatible\n",
      "     |  \n",
      "     |  per_process_gpu_memory_fraction\n",
      "     |      Field tensorflow.GPUOptions.per_process_gpu_memory_fraction\n",
      "     |  \n",
      "     |  polling_active_delay_usecs\n",
      "     |      Field tensorflow.GPUOptions.polling_active_delay_usecs\n",
      "     |  \n",
      "     |  polling_inactive_delay_msecs\n",
      "     |      Field tensorflow.GPUOptions.polling_inactive_delay_msecs\n",
      "     |  \n",
      "     |  visible_device_list\n",
      "     |      Field tensorflow.GPUOptions.visible_device_list\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  DESCRIPTOR = <google.protobuf.pyext._message.MessageDescriptor object>\n",
      "     |  \n",
      "     |  Experimental = <class 'tensorflow.core.protobuf.config_pb2.Experimenta...\n",
      "     |      A ProtocolMessage\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.pyext._message.CMessage:\n",
      "     |  \n",
      "     |  ByteSize(...)\n",
      "     |      Returns the size of the message in bytes.\n",
      "     |  \n",
      "     |  Clear(...)\n",
      "     |      Clears the message.\n",
      "     |  \n",
      "     |  ClearExtension(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  ClearField(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  CopyFrom(...)\n",
      "     |      Copies a protocol message into the current message.\n",
      "     |  \n",
      "     |  DiscardUnknownFields(...)\n",
      "     |      Discards the unknown fields.\n",
      "     |  \n",
      "     |  FindInitializationErrors(...)\n",
      "     |      Finds unset required fields.\n",
      "     |  \n",
      "     |  FromString(...) from google.protobuf.pyext.cpp_message.GeneratedProtocolMessageType\n",
      "     |      Creates new method instance from given serialized data.\n",
      "     |  \n",
      "     |  HasExtension(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  HasField(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  IsInitialized(...)\n",
      "     |      Checks if all required fields of a protocol message are set.\n",
      "     |  \n",
      "     |  ListFields(...)\n",
      "     |      Lists all set fields of a message.\n",
      "     |  \n",
      "     |  MergeFrom(...)\n",
      "     |      Merges a protocol message into the current message.\n",
      "     |  \n",
      "     |  MergeFromString(...)\n",
      "     |      Merges a serialized message into the current message.\n",
      "     |  \n",
      "     |  ParseFromString(...)\n",
      "     |      Parses a serialized message into the current message.\n",
      "     |  \n",
      "     |  RegisterExtension(...) from google.protobuf.pyext.cpp_message.GeneratedProtocolMessageType\n",
      "     |      Registers an extension with the current message.\n",
      "     |  \n",
      "     |  SerializePartialToString(...)\n",
      "     |      Serializes the message to a string, even if it isn't initialized.\n",
      "     |  \n",
      "     |  SerializeToString(...)\n",
      "     |      Serializes the message to a string, only for initialized messages.\n",
      "     |  \n",
      "     |  SetInParent(...)\n",
      "     |      Sets the has bit of the given field in its parent message.\n",
      "     |  \n",
      "     |  UnknownFields(...)\n",
      "     |      Parse unknown field set\n",
      "     |  \n",
      "     |  WhichOneof(...)\n",
      "     |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      Makes a deep copy of the class.\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from google.protobuf.pyext._message.MessageMeta\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  __unicode__(...)\n",
      "     |      Outputs a unicode representation of the message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google.protobuf.pyext._message.CMessage:\n",
      "     |  \n",
      "     |  Extensions\n",
      "     |      Extension dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from google.protobuf.pyext._message.CMessage:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Support the pickle protocol.\n",
      "    \n",
      "    class GradientTape(builtins.object)\n",
      "     |  Record operations for automatic differentiation.\n",
      "     |  \n",
      "     |  Operations are recorded if they are executed within this context manager and\n",
      "     |  at least one of their inputs is being \"watched\".\n",
      "     |  \n",
      "     |  Trainable variables (created by `tf.Variable` or `tf.compat.v1.get_variable`,\n",
      "     |  where `trainable=True` is default in both cases) are automatically watched.\n",
      "     |  Tensors can be manually watched by invoking the `watch` method on this context\n",
      "     |  manager.\n",
      "     |  \n",
      "     |  For example, consider the function `y = x * x`. The gradient at `x = 3.0` can\n",
      "     |  be computed as:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  x = tf.constant(3.0)\n",
      "     |  with tf.GradientTape() as g:\n",
      "     |    g.watch(x)\n",
      "     |    y = x * x\n",
      "     |  dy_dx = g.gradient(y, x) # Will compute to 6.0\n",
      "     |  ```\n",
      "     |  \n",
      "     |  GradientTapes can be nested to compute higher-order derivatives. For example,\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  x = tf.constant(3.0)\n",
      "     |  with tf.GradientTape() as g:\n",
      "     |    g.watch(x)\n",
      "     |    with tf.GradientTape() as gg:\n",
      "     |      gg.watch(x)\n",
      "     |      y = x * x\n",
      "     |    dy_dx = gg.gradient(y, x)     # Will compute to 6.0\n",
      "     |  d2y_dx2 = g.gradient(dy_dx, x)  # Will compute to 2.0\n",
      "     |  ```\n",
      "     |  \n",
      "     |  By default, the resources held by a GradientTape are released as soon as\n",
      "     |  GradientTape.gradient() method is called. To compute multiple gradients over\n",
      "     |  the same computation, create a persistent gradient tape. This allows multiple\n",
      "     |  calls to the gradient() method as resources are released when the tape object\n",
      "     |  is garbage collected. For example:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  x = tf.constant(3.0)\n",
      "     |  with tf.GradientTape(persistent=True) as g:\n",
      "     |    g.watch(x)\n",
      "     |    y = x * x\n",
      "     |    z = y * y\n",
      "     |  dz_dx = g.gradient(z, x)  # 108.0 (4*x^3 at x = 3)\n",
      "     |  dy_dx = g.gradient(y, x)  # 6.0\n",
      "     |  del g  # Drop the reference to the tape\n",
      "     |  ```\n",
      "     |  \n",
      "     |  By default GradientTape will automatically watch any trainable variables that\n",
      "     |  are accessed inside the context. If you want fine grained control over which\n",
      "     |  variables are watched you can disable automatic tracking by passing\n",
      "     |  `watch_accessed_variables=False` to the tape constructor:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  with tf.GradientTape(watch_accessed_variables=False) as tape:\n",
      "     |    tape.watch(variable_a)\n",
      "     |    y = variable_a ** 2  # Gradients will be available for `variable_a`.\n",
      "     |    z = variable_b ** 3  # No gradients will be available since `variable_b` is\n",
      "     |                         # not being watched.\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Note that when using models you should ensure that your variables exist when\n",
      "     |  using `watch_accessed_variables=False`. Otherwise it's quite easy to make your\n",
      "     |  first iteration not have any gradients:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  a = tf.keras.layers.Dense(32)\n",
      "     |  b = tf.keras.layers.Dense(32)\n",
      "     |  \n",
      "     |  with tf.GradientTape(watch_accessed_variables=False) as tape:\n",
      "     |    tape.watch(a.variables)  # Since `a.build` has not been called at this point\n",
      "     |                             # `a.variables` will return an empty list and the\n",
      "     |                             # tape will not be watching anything.\n",
      "     |    result = b(a(inputs))\n",
      "     |    tape.gradient(result, a.variables)  # The result of this computation will be\n",
      "     |                                        # a list of `None`s since a's variables\n",
      "     |                                        # are not being watched.\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Note that only tensors with real or complex dtypes are differentiable.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __del__(self)\n",
      "     |  \n",
      "     |  __enter__(self)\n",
      "     |      Enters a context inside which operations are recorded on this tape.\n",
      "     |  \n",
      "     |  __exit__(self, typ, value, traceback)\n",
      "     |      Exits the recording context, no further operations are traced.\n",
      "     |  \n",
      "     |  __init__(self, persistent=False, watch_accessed_variables=True)\n",
      "     |      Creates a new GradientTape.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        persistent: Boolean controlling whether a persistent gradient tape\n",
      "     |          is created. False by default, which means at most one call can\n",
      "     |          be made to the gradient() method on this object.\n",
      "     |        watch_accessed_variables: Boolean controlling whether the tape will\n",
      "     |          automatically `watch` any (trainable) variables accessed while the tape\n",
      "     |          is active. Defaults to True meaning gradients can be requested from any\n",
      "     |          result computed in the tape derived from reading a trainable `Variable`.\n",
      "     |          If False users must explicitly `watch` any `Variable`s they want to\n",
      "     |          request gradients from.\n",
      "     |  \n",
      "     |  batch_jacobian(self, target, source, unconnected_gradients=<UnconnectedGradients.NONE: 'none'>, parallel_iterations=None, experimental_use_pfor=True)\n",
      "     |      Computes and stacks per-example jacobians.\n",
      "     |      \n",
      "     |      See [wikipedia article](http://en.wikipedia.org/wiki/jacobian_matrix_and_determinant) for the\n",
      "     |      definition of a Jacobian. This function is essentially an efficient\n",
      "     |      implementation of the following:\n",
      "     |      \n",
      "     |      `tf.stack([self.jacobian(y[i], x[i]) for i in range(x.shape[0])])`.\n",
      "     |      \n",
      "     |      Note that compared to `GradientTape.jacobian` which computes gradient of\n",
      "     |      each output value w.r.t each input value, this function is useful when\n",
      "     |      `target[i,...]` is independent of `source[j,...]` for `j != i`. This\n",
      "     |      assumption allows more efficient computation as compared to\n",
      "     |      `GradientTape.jacobian`. The output, as well as intermediate activations,\n",
      "     |      are lower dimensional and avoid a bunch of redundant zeros which would\n",
      "     |      result in the jacobian computation given the independence assumption.\n",
      "     |      \n",
      "     |      Example usage:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      with tf.GradientTape() as g:\n",
      "     |        x = tf.constant([[1., 2.], [3., 4.]], dtype=tf.float32)\n",
      "     |        g.watch(x)\n",
      "     |        y = x * x\n",
      "     |      batch_jacobian = g.batch_jacobian(y, x)\n",
      "     |      # batch_jacobian is [[[2,  0], [0,  4]], [[6,  0], [0,  8]]]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        target: A tensor with rank 2 or higher and with shape [b, y1, ..., y_n].\n",
      "     |          `target[i,...]` should only depend on `source[i,...]`.\n",
      "     |        source: A tensor with rank 2 or higher and with shape [b, x1, ..., x_m].\n",
      "     |        unconnected_gradients: a value which can either hold 'none' or 'zero' and\n",
      "     |          alters the value which will be returned if the target and sources are\n",
      "     |          unconnected. The possible values and effects are detailed in\n",
      "     |          'UnconnectedGradients' and it defaults to 'none'.\n",
      "     |        parallel_iterations: A knob to control how many iterations are dispatched\n",
      "     |          in parallel. This knob can be used to control the total memory usage.\n",
      "     |        experimental_use_pfor: If true, uses pfor for computing the Jacobian. Else\n",
      "     |          uses a tf.while_loop.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A tensor `t` with shape [b, y_1, ..., y_n, x1, ..., x_m] where `t[i, ...]`\n",
      "     |        is the jacobian of `target[i, ...]` w.r.t. `source[i, ...]`, i.e. stacked\n",
      "     |        per-example jacobians.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        RuntimeError: If called on a non-persistent tape with eager execution\n",
      "     |          enabled and without enabling experimental_use_pfor.\n",
      "     |        ValueError: If vectorization of jacobian computation fails or if first\n",
      "     |          dimension of `target` and `source` do not match.\n",
      "     |  \n",
      "     |  gradient(self, target, sources, output_gradients=None, unconnected_gradients=<UnconnectedGradients.NONE: 'none'>)\n",
      "     |      Computes the gradient using operations recorded in context of this tape.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        target: a list or nested structure of Tensors or Variables to be\n",
      "     |          differentiated.\n",
      "     |        sources: a list or nested structure of Tensors or Variables. `target`\n",
      "     |          will be differentiated against elements in `sources`.\n",
      "     |        output_gradients: a list of gradients, one for each element of\n",
      "     |          target. Defaults to None.\n",
      "     |        unconnected_gradients: a value which can either hold 'none' or 'zero' and\n",
      "     |          alters the value which will be returned if the target and sources are\n",
      "     |          unconnected. The possible values and effects are detailed in\n",
      "     |          'UnconnectedGradients' and it defaults to 'none'.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        a list or nested structure of Tensors (or IndexedSlices, or None),\n",
      "     |        one for each element in `sources`. Returned structure is the same as\n",
      "     |        the structure of `sources`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        RuntimeError: if called inside the context of the tape, or if called more\n",
      "     |         than once on a non-persistent tape.\n",
      "     |        ValueError: if the target is a variable or if unconnected gradients is\n",
      "     |         called with an unknown value.\n",
      "     |  \n",
      "     |  jacobian(self, target, sources, unconnected_gradients=<UnconnectedGradients.NONE: 'none'>, parallel_iterations=None, experimental_use_pfor=True)\n",
      "     |      Computes the jacobian using operations recorded in context of this tape.\n",
      "     |      \n",
      "     |      See [wikipedia article](http://en.wikipedia.org/wiki/jacobian_matrix_and_determinant) for the\n",
      "     |      definition of a Jacobian.\n",
      "     |      \n",
      "     |      Example usage:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      with tf.GradientTape() as g:\n",
      "     |        x  = tf.constant([1.0, 2.0])\n",
      "     |        g.watch(x)\n",
      "     |        y = x * x\n",
      "     |      jacobian = g.jacobian(y, x)\n",
      "     |      # jacobian value is [[2., 0.], [0., 4.]]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        target: Tensor to be differentiated.\n",
      "     |        sources: a list or nested structure of Tensors or Variables. `target`\n",
      "     |          will be differentiated against elements in `sources`.\n",
      "     |        unconnected_gradients: a value which can either hold 'none' or 'zero' and\n",
      "     |          alters the value which will be returned if the target and sources are\n",
      "     |          unconnected. The possible values and effects are detailed in\n",
      "     |          'UnconnectedGradients' and it defaults to 'none'.\n",
      "     |        parallel_iterations: A knob to control how many iterations are dispatched\n",
      "     |          in parallel. This knob can be used to control the total memory usage.\n",
      "     |        experimental_use_pfor: If true, vectorizes the jacobian computation. Else\n",
      "     |          falls back to a sequential while_loop. Vectorization can sometimes fail\n",
      "     |          or lead to excessive memory usage. This option can be used to disable\n",
      "     |          vectorization in such cases.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A list or nested structure of Tensors (or None), one for each element in\n",
      "     |        `sources`. Returned structure is the same as the structure of `sources`.\n",
      "     |        Note if any gradient is sparse (IndexedSlices), jacobian function\n",
      "     |        currently makes it dense and returns a Tensor instead. This may change in\n",
      "     |        the future.\n",
      "     |      \n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        RuntimeError: If called on a non-persistent tape with eager execution\n",
      "     |          enabled and without enabling experimental_use_pfor.\n",
      "     |        ValueError: If vectorization of jacobian computation fails.\n",
      "     |  \n",
      "     |  reset(self)\n",
      "     |      Clears all information stored in this tape.\n",
      "     |      \n",
      "     |      Equivalent to exiting and reentering the tape context manager with a new\n",
      "     |      tape. For example, the two following code blocks are equivalent:\n",
      "     |      \n",
      "     |      ```\n",
      "     |      with tf.GradientTape() as t:\n",
      "     |        loss = loss_fn()\n",
      "     |      with tf.GradientTape() as t:\n",
      "     |        loss += other_loss_fn()\n",
      "     |      t.gradient(loss, ...)  # Only differentiates other_loss_fn, not loss_fn\n",
      "     |      \n",
      "     |      \n",
      "     |      # The following is equivalent to the above\n",
      "     |      with tf.GradientTape() as t:\n",
      "     |        loss = loss_fn()\n",
      "     |        t.reset()\n",
      "     |        loss += other_loss_fn()\n",
      "     |      t.gradient(loss, ...)  # Only differentiates other_loss_fn, not loss_fn\n",
      "     |      ```\n",
      "     |      \n",
      "     |      This is useful if you don't want to exit the context manager for the tape,\n",
      "     |      or can't because the desired reset point is inside a control flow construct:\n",
      "     |      \n",
      "     |      ```\n",
      "     |      with tf.GradientTape() as t:\n",
      "     |        loss = ...\n",
      "     |        if loss > k:\n",
      "     |          t.reset()\n",
      "     |      ```\n",
      "     |  \n",
      "     |  stop_recording(self)\n",
      "     |      Temporarily stops recording operations on this tape.\n",
      "     |      \n",
      "     |      Operations executed while this context manager is active will not be\n",
      "     |      recorded on the tape. This is useful for reducing the memory used by tracing\n",
      "     |      all computations.\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      ```\n",
      "     |        with tf.GradientTape(persistent=True) as t:\n",
      "     |          loss = compute_loss(model)\n",
      "     |          with t.stop_recording():\n",
      "     |            # The gradient computation below is not traced, saving memory.\n",
      "     |            grads = t.gradient(loss, model.variables)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Yields:\n",
      "     |        None\n",
      "     |      Raises:\n",
      "     |        RuntimeError: if the tape is not currently recording.\n",
      "     |  \n",
      "     |  watch(self, tensor)\n",
      "     |      Ensures that `tensor` is being traced by this tape.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        tensor: a Tensor or list of Tensors.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: if it encounters something that is not a tensor.\n",
      "     |  \n",
      "     |  watched_variables(self)\n",
      "     |      Returns variables watched by this tape in order of construction.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Graph(builtins.object)\n",
      "     |  A TensorFlow computation, represented as a dataflow graph.\n",
      "     |  \n",
      "     |  A `Graph` contains a set of\n",
      "     |  `tf.Operation` objects,\n",
      "     |  which represent units of computation; and\n",
      "     |  `tf.Tensor` objects, which represent\n",
      "     |  the units of data that flow between operations.\n",
      "     |  \n",
      "     |  A default `Graph` is always registered, and accessible by calling\n",
      "     |  `tf.compat.v1.get_default_graph`.\n",
      "     |  To add an operation to the default graph, simply call one of the functions\n",
      "     |  that defines a new `Operation`:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  c = tf.constant(4.0)\n",
      "     |  assert c.graph is tf.compat.v1.get_default_graph()\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Another typical usage involves the\n",
      "     |  `tf.Graph.as_default`\n",
      "     |  context manager, which overrides the current default graph for the\n",
      "     |  lifetime of the context:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  g = tf.Graph()\n",
      "     |  with g.as_default():\n",
      "     |    # Define operations and tensors in `g`.\n",
      "     |    c = tf.constant(30.0)\n",
      "     |    assert c.graph is g\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Important note: This class *is not* thread-safe for graph construction. All\n",
      "     |  operations should be created from a single thread, or external\n",
      "     |  synchronization must be provided. Unless otherwise specified, all methods\n",
      "     |  are not thread-safe.\n",
      "     |  \n",
      "     |  A `Graph` instance supports an arbitrary number of \"collections\"\n",
      "     |  that are identified by name. For convenience when building a large\n",
      "     |  graph, collections can store groups of related objects: for\n",
      "     |  example, the `tf.Variable` uses a collection (named\n",
      "     |  `tf.GraphKeys.GLOBAL_VARIABLES`) for\n",
      "     |  all variables that are created during the construction of a graph. The caller\n",
      "     |  may define additional collections by specifying a new name.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self)\n",
      "     |      Creates a new, empty Graph.\n",
      "     |  \n",
      "     |  add_to_collection(self, name, value)\n",
      "     |      Stores `value` in the collection with the given `name`.\n",
      "     |      \n",
      "     |      Note that collections are not sets, so it is possible to add a value to\n",
      "     |      a collection several times.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: The key for the collection. The `GraphKeys` class contains many\n",
      "     |          standard names for collections.\n",
      "     |        value: The value to add to the collection.\n",
      "     |  \n",
      "     |  add_to_collections(self, names, value)\n",
      "     |      Stores `value` in the collections given by `names`.\n",
      "     |      \n",
      "     |      Note that collections are not sets, so it is possible to add a value to\n",
      "     |      a collection several times. This function makes sure that duplicates in\n",
      "     |      `names` are ignored, but it will not check for pre-existing membership of\n",
      "     |      `value` in any of the collections in `names`.\n",
      "     |      \n",
      "     |      `names` can be any iterable, but if `names` is a string, it is treated as a\n",
      "     |      single collection name.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        names: The keys for the collections to add to. The `GraphKeys` class\n",
      "     |          contains many standard names for collections.\n",
      "     |        value: The value to add to the collections.\n",
      "     |  \n",
      "     |  as_default(self)\n",
      "     |      Returns a context manager that makes this `Graph` the default graph.\n",
      "     |      \n",
      "     |      This method should be used if you want to create multiple graphs\n",
      "     |      in the same process. For convenience, a global default graph is\n",
      "     |      provided, and all ops will be added to this graph if you do not\n",
      "     |      create a new graph explicitly.\n",
      "     |      \n",
      "     |      Use this method with the `with` keyword to specify that ops created within\n",
      "     |      the scope of a block should be added to this graph. In this case, once\n",
      "     |      the scope of the `with` is exited, the previous default graph is set again\n",
      "     |      as default. There is a stack, so it's ok to have multiple nested levels\n",
      "     |      of `as_default` calls.\n",
      "     |      \n",
      "     |      The default graph is a property of the current thread. If you\n",
      "     |      create a new thread, and wish to use the default graph in that\n",
      "     |      thread, you must explicitly add a `with g.as_default():` in that\n",
      "     |      thread's function.\n",
      "     |      \n",
      "     |      The following code examples are equivalent:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      # 1. Using Graph.as_default():\n",
      "     |      g = tf.Graph()\n",
      "     |      with g.as_default():\n",
      "     |        c = tf.constant(5.0)\n",
      "     |        assert c.graph is g\n",
      "     |      \n",
      "     |      # 2. Constructing and making default:\n",
      "     |      with tf.Graph().as_default() as g:\n",
      "     |        c = tf.constant(5.0)\n",
      "     |        assert c.graph is g\n",
      "     |      ```\n",
      "     |      \n",
      "     |      If eager execution is enabled ops created under this context manager will be\n",
      "     |      added to the graph instead of executed eagerly.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A context manager for using this graph as the default graph.\n",
      "     |  \n",
      "     |  as_graph_def(self, from_version=None, add_shapes=False)\n",
      "     |      Returns a serialized `GraphDef` representation of this graph.\n",
      "     |      \n",
      "     |      The serialized `GraphDef` can be imported into another `Graph`\n",
      "     |      (using `tf.import_graph_def`) or used with the\n",
      "     |      [C++ Session API](../../api_docs/cc/index.md).\n",
      "     |      \n",
      "     |      This method is thread-safe.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        from_version: Optional.  If this is set, returns a `GraphDef` containing\n",
      "     |          only the nodes that were added to this graph since its `version`\n",
      "     |          property had the given value.\n",
      "     |        add_shapes: If true, adds an \"_output_shapes\" list attr to each node with\n",
      "     |          the inferred shapes of each of its outputs.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A\n",
      "     |        [`GraphDef`](https://www.tensorflow.org/code/tensorflow/core/framework/graph.proto)\n",
      "     |        protocol buffer.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If the `graph_def` would be too large.\n",
      "     |  \n",
      "     |  as_graph_element(self, obj, allow_tensor=True, allow_operation=True)\n",
      "     |      Returns the object referred to by `obj`, as an `Operation` or `Tensor`.\n",
      "     |      \n",
      "     |      This function validates that `obj` represents an element of this\n",
      "     |      graph, and gives an informative error message if it is not.\n",
      "     |      \n",
      "     |      This function is the canonical way to get/validate an object of\n",
      "     |      one of the allowed types from an external argument reference in the\n",
      "     |      Session API.\n",
      "     |      \n",
      "     |      This method may be called concurrently from multiple threads.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        obj: A `Tensor`, an `Operation`, or the name of a tensor or operation. Can\n",
      "     |          also be any object with an `_as_graph_element()` method that returns a\n",
      "     |          value of one of these types. Note: `_as_graph_element` will be called\n",
      "     |          inside the graph's lock and so may not modify the graph.\n",
      "     |        allow_tensor: If true, `obj` may refer to a `Tensor`.\n",
      "     |        allow_operation: If true, `obj` may refer to an `Operation`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The `Tensor` or `Operation` in the Graph corresponding to `obj`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If `obj` is not a type we support attempting to convert\n",
      "     |          to types.\n",
      "     |        ValueError: If `obj` is of an appropriate type but invalid. For\n",
      "     |          example, an invalid string.\n",
      "     |        KeyError: If `obj` is not an object in the graph.\n",
      "     |  \n",
      "     |  clear_collection(self, name)\n",
      "     |      Clears all values in a collection.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: The key for the collection. The `GraphKeys` class contains many\n",
      "     |          standard names for collections.\n",
      "     |  \n",
      "     |  colocate_with(self, op, ignore_existing=False)\n",
      "     |      Returns a context manager that specifies an op to colocate with.\n",
      "     |      \n",
      "     |      Note: this function is not for public use, only for internal libraries.\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      a = tf.Variable([1.0])\n",
      "     |      with g.colocate_with(a):\n",
      "     |        b = tf.constant(1.0)\n",
      "     |        c = tf.add(a, b)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      `b` and `c` will always be colocated with `a`, no matter where `a`\n",
      "     |      is eventually placed.\n",
      "     |      \n",
      "     |      **NOTE** Using a colocation scope resets any existing device constraints.\n",
      "     |      \n",
      "     |      If `op` is `None` then `ignore_existing` must be `True` and the new\n",
      "     |      scope resets all colocation and device constraints.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        op: The op to colocate all created ops with, or `None`.\n",
      "     |        ignore_existing: If true, only applies colocation of this op within the\n",
      "     |          context, rather than applying all colocation properties on the stack.\n",
      "     |          If `op` is `None`, this value must be `True`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: if op is None but ignore_existing is False.\n",
      "     |      \n",
      "     |      Yields:\n",
      "     |        A context manager that specifies the op with which to colocate\n",
      "     |        newly created ops.\n",
      "     |  \n",
      "     |  container(self, container_name)\n",
      "     |      Returns a context manager that specifies the resource container to use.\n",
      "     |      \n",
      "     |      Stateful operations, such as variables and queues, can maintain their\n",
      "     |      states on devices so that they can be shared by multiple processes.\n",
      "     |      A resource container is a string name under which these stateful\n",
      "     |      operations are tracked. These resources can be released or cleared\n",
      "     |      with `tf.Session.reset()`.\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      with g.container('experiment0'):\n",
      "     |        # All stateful Operations constructed in this context will be placed\n",
      "     |        # in resource container \"experiment0\".\n",
      "     |        v1 = tf.Variable([1.0])\n",
      "     |        v2 = tf.Variable([2.0])\n",
      "     |        with g.container(\"experiment1\"):\n",
      "     |          # All stateful Operations constructed in this context will be\n",
      "     |          # placed in resource container \"experiment1\".\n",
      "     |          v3 = tf.Variable([3.0])\n",
      "     |          q1 = tf.queue.FIFOQueue(10, tf.float32)\n",
      "     |        # All stateful Operations constructed in this context will be\n",
      "     |        # be created in the \"experiment0\".\n",
      "     |        v4 = tf.Variable([4.0])\n",
      "     |        q1 = tf.queue.FIFOQueue(20, tf.float32)\n",
      "     |        with g.container(\"\"):\n",
      "     |          # All stateful Operations constructed in this context will be\n",
      "     |          # be placed in the default resource container.\n",
      "     |          v5 = tf.Variable([5.0])\n",
      "     |          q3 = tf.queue.FIFOQueue(30, tf.float32)\n",
      "     |      \n",
      "     |      # Resets container \"experiment0\", after which the state of v1, v2, v4, q1\n",
      "     |      # will become undefined (such as uninitialized).\n",
      "     |      tf.Session.reset(target, [\"experiment0\"])\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        container_name: container name string.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A context manager for defining resource containers for stateful ops,\n",
      "     |          yields the container name.\n",
      "     |  \n",
      "     |  control_dependencies(self, control_inputs)\n",
      "     |      Returns a context manager that specifies control dependencies.\n",
      "     |      \n",
      "     |      Use with the `with` keyword to specify that all operations constructed\n",
      "     |      within the context should have control dependencies on\n",
      "     |      `control_inputs`. For example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      with g.control_dependencies([a, b, c]):\n",
      "     |        # `d` and `e` will only run after `a`, `b`, and `c` have executed.\n",
      "     |        d = ...\n",
      "     |        e = ...\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Multiple calls to `control_dependencies()` can be nested, and in\n",
      "     |      that case a new `Operation` will have control dependencies on the union\n",
      "     |      of `control_inputs` from all active contexts.\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      with g.control_dependencies([a, b]):\n",
      "     |        # Ops constructed here run after `a` and `b`.\n",
      "     |        with g.control_dependencies([c, d]):\n",
      "     |          # Ops constructed here run after `a`, `b`, `c`, and `d`.\n",
      "     |      ```\n",
      "     |      \n",
      "     |      You can pass None to clear the control dependencies:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      with g.control_dependencies([a, b]):\n",
      "     |        # Ops constructed here run after `a` and `b`.\n",
      "     |        with g.control_dependencies(None):\n",
      "     |          # Ops constructed here run normally, not waiting for either `a` or `b`.\n",
      "     |          with g.control_dependencies([c, d]):\n",
      "     |            # Ops constructed here run after `c` and `d`, also not waiting\n",
      "     |            # for either `a` or `b`.\n",
      "     |      ```\n",
      "     |      \n",
      "     |      *N.B.* The control dependencies context applies *only* to ops that\n",
      "     |      are constructed within the context. Merely using an op or tensor\n",
      "     |      in the context does not add a control dependency. The following\n",
      "     |      example illustrates this point:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      # WRONG\n",
      "     |      def my_func(pred, tensor):\n",
      "     |        t = tf.matmul(tensor, tensor)\n",
      "     |        with tf.control_dependencies([pred]):\n",
      "     |          # The matmul op is created outside the context, so no control\n",
      "     |          # dependency will be added.\n",
      "     |          return t\n",
      "     |      \n",
      "     |      # RIGHT\n",
      "     |      def my_func(pred, tensor):\n",
      "     |        with tf.control_dependencies([pred]):\n",
      "     |          # The matmul op is created in the context, so a control dependency\n",
      "     |          # will be added.\n",
      "     |          return tf.matmul(tensor, tensor)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Also note that though execution of ops created under this scope will trigger\n",
      "     |      execution of the dependencies, the ops created under this scope might still\n",
      "     |      be pruned from a normal tensorflow graph. For example, in the following\n",
      "     |      snippet of code the dependencies are never executed:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |        loss = model.loss()\n",
      "     |        with tf.control_dependencies(dependencies):\n",
      "     |          loss = loss + tf.constant(1)  # note: dependencies ignored in the\n",
      "     |                                        # backward pass\n",
      "     |        return tf.gradients(loss, model.variables)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      This is because evaluating the gradient graph does not require evaluating\n",
      "     |      the constant(1) op created in the forward pass.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        control_inputs: A list of `Operation` or `Tensor` objects which must be\n",
      "     |          executed or computed before running the operations defined in the\n",
      "     |          context.  Can also be `None` to clear the control dependencies.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |       A context manager that specifies control dependencies for all\n",
      "     |       operations constructed within the context.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If `control_inputs` is not a list of `Operation` or\n",
      "     |          `Tensor` objects.\n",
      "     |  \n",
      "     |  create_op(self, op_type, inputs, dtypes=None, input_types=None, name=None, attrs=None, op_def=None, compute_shapes=True, compute_device=True)\n",
      "     |      Creates an `Operation` in this graph. (deprecated arguments)\n",
      "     |      \n",
      "     |      Warning: SOME ARGUMENTS ARE DEPRECATED: `(compute_shapes)`. They will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Shapes are always computed; don't use the compute_shapes as it has no effect.\n",
      "     |      \n",
      "     |      This is a low-level interface for creating an `Operation`. Most\n",
      "     |      programs will not call this method directly, and instead use the\n",
      "     |      Python op constructors, such as `tf.constant()`, which add ops to\n",
      "     |      the default graph.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        op_type: The `Operation` type to create. This corresponds to the\n",
      "     |          `OpDef.name` field for the proto that defines the operation.\n",
      "     |        inputs: A list of `Tensor` objects that will be inputs to the `Operation`.\n",
      "     |        dtypes: (Optional) A list of `DType` objects that will be the types of the\n",
      "     |          tensors that the operation produces.\n",
      "     |        input_types: (Optional.) A list of `DType`s that will be the types of the\n",
      "     |          tensors that the operation consumes. By default, uses the base `DType`\n",
      "     |          of each input in `inputs`. Operations that expect reference-typed inputs\n",
      "     |          must specify `input_types` explicitly.\n",
      "     |        name: (Optional.) A string name for the operation. If not specified, a\n",
      "     |          name is generated based on `op_type`.\n",
      "     |        attrs: (Optional.) A dictionary where the key is the attribute name (a\n",
      "     |          string) and the value is the respective `attr` attribute of the\n",
      "     |          `NodeDef` proto that will represent the operation (an `AttrValue`\n",
      "     |          proto).\n",
      "     |        op_def: (Optional.) The `OpDef` proto that describes the `op_type` that\n",
      "     |          the operation will have.\n",
      "     |        compute_shapes: (Optional.) Deprecated. Has no effect (shapes are always\n",
      "     |          computed).\n",
      "     |        compute_device: (Optional.) If True, device functions will be executed to\n",
      "     |          compute the device property of the Operation.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: if any of the inputs is not a `Tensor`.\n",
      "     |        ValueError: if colocation conflicts with existing device assignment.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An `Operation` object.\n",
      "     |  \n",
      "     |  device(self, device_name_or_function)\n",
      "     |      Returns a context manager that specifies the default device to use.\n",
      "     |      \n",
      "     |      The `device_name_or_function` argument may either be a device name\n",
      "     |      string, a device function, or None:\n",
      "     |      \n",
      "     |      * If it is a device name string, all operations constructed in\n",
      "     |        this context will be assigned to the device with that name, unless\n",
      "     |        overridden by a nested `device()` context.\n",
      "     |      * If it is a function, it will be treated as a function from\n",
      "     |        Operation objects to device name strings, and invoked each time\n",
      "     |        a new Operation is created. The Operation will be assigned to\n",
      "     |        the device with the returned name.\n",
      "     |      * If it is None, all `device()` invocations from the enclosing context\n",
      "     |        will be ignored.\n",
      "     |      \n",
      "     |      For information about the valid syntax of device name strings, see\n",
      "     |      the documentation in\n",
      "     |      [`DeviceNameUtils`](https://www.tensorflow.org/code/tensorflow/core/util/device_name_utils.h).\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      with g.device('/device:GPU:0'):\n",
      "     |        # All operations constructed in this context will be placed\n",
      "     |        # on GPU 0.\n",
      "     |        with g.device(None):\n",
      "     |          # All operations constructed in this context will have no\n",
      "     |          # assigned device.\n",
      "     |      \n",
      "     |      # Defines a function from `Operation` to device string.\n",
      "     |      def matmul_on_gpu(n):\n",
      "     |        if n.type == \"MatMul\":\n",
      "     |          return \"/device:GPU:0\"\n",
      "     |        else:\n",
      "     |          return \"/cpu:0\"\n",
      "     |      \n",
      "     |      with g.device(matmul_on_gpu):\n",
      "     |        # All operations of type \"MatMul\" constructed in this context\n",
      "     |        # will be placed on GPU 0; all other operations will be placed\n",
      "     |        # on CPU 0.\n",
      "     |      ```\n",
      "     |      \n",
      "     |      **N.B.** The device scope may be overridden by op wrappers or\n",
      "     |      other library code. For example, a variable assignment op\n",
      "     |      `v.assign()` must be colocated with the `tf.Variable` `v`, and\n",
      "     |      incompatible device scopes will be ignored.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        device_name_or_function: The device name or function to use in the\n",
      "     |          context.\n",
      "     |      \n",
      "     |      Yields:\n",
      "     |        A context manager that specifies the default device to use for newly\n",
      "     |        created ops.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        RuntimeError: If device scopes are not properly nested.\n",
      "     |  \n",
      "     |  finalize(self)\n",
      "     |      Finalizes this graph, making it read-only.\n",
      "     |      \n",
      "     |      After calling `g.finalize()`, no new operations can be added to\n",
      "     |      `g`.  This method is used to ensure that no operations are added\n",
      "     |      to a graph when it is shared between multiple threads, for example\n",
      "     |      when using a `tf.compat.v1.train.QueueRunner`.\n",
      "     |  \n",
      "     |  get_all_collection_keys(self)\n",
      "     |      Returns a list of collections used in this graph.\n",
      "     |  \n",
      "     |  get_collection(self, name, scope=None)\n",
      "     |      Returns a list of values in the collection with the given `name`.\n",
      "     |      \n",
      "     |      This is different from `get_collection_ref()` which always returns the\n",
      "     |      actual collection list if it exists in that it returns a new list each time\n",
      "     |      it is called.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: The key for the collection. For example, the `GraphKeys` class\n",
      "     |          contains many standard names for collections.\n",
      "     |        scope: (Optional.) A string. If supplied, the resulting list is filtered\n",
      "     |          to include only items whose `name` attribute matches `scope` using\n",
      "     |          `re.match`. Items without a `name` attribute are never returned if a\n",
      "     |          scope is supplied. The choice of `re.match` means that a `scope` without\n",
      "     |          special tokens filters by prefix.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The list of values in the collection with the given `name`, or\n",
      "     |        an empty list if no value has been added to that collection. The\n",
      "     |        list contains the values in the order under which they were\n",
      "     |        collected.\n",
      "     |  \n",
      "     |  get_collection_ref(self, name)\n",
      "     |      Returns a list of values in the collection with the given `name`.\n",
      "     |      \n",
      "     |      If the collection exists, this returns the list itself, which can\n",
      "     |      be modified in place to change the collection.  If the collection does\n",
      "     |      not exist, it is created as an empty list and the list is returned.\n",
      "     |      \n",
      "     |      This is different from `get_collection()` which always returns a copy of\n",
      "     |      the collection list if it exists and never creates an empty collection.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: The key for the collection. For example, the `GraphKeys` class\n",
      "     |          contains many standard names for collections.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The list of values in the collection with the given `name`, or an empty\n",
      "     |        list if no value has been added to that collection.\n",
      "     |  \n",
      "     |  get_name_scope(self)\n",
      "     |      Returns the current name scope.\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      with tf.name_scope('scope1'):\n",
      "     |        with tf.name_scope('scope2'):\n",
      "     |          print(tf.compat.v1.get_default_graph().get_name_scope())\n",
      "     |      ```\n",
      "     |      would print the string `scope1/scope2`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A string representing the current name scope.\n",
      "     |  \n",
      "     |  get_operation_by_name(self, name)\n",
      "     |      Returns the `Operation` with the given `name`.\n",
      "     |      \n",
      "     |      This method may be called concurrently from multiple threads.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: The name of the `Operation` to return.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The `Operation` with the given `name`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If `name` is not a string.\n",
      "     |        KeyError: If `name` does not correspond to an operation in this graph.\n",
      "     |  \n",
      "     |  get_operations(self)\n",
      "     |      Return the list of operations in the graph.\n",
      "     |      \n",
      "     |      You can modify the operations in place, but modifications\n",
      "     |      to the list such as inserts/delete have no effect on the\n",
      "     |      list of operations known to the graph.\n",
      "     |      \n",
      "     |      This method may be called concurrently from multiple threads.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A list of Operations.\n",
      "     |  \n",
      "     |  get_tensor_by_name(self, name)\n",
      "     |      Returns the `Tensor` with the given `name`.\n",
      "     |      \n",
      "     |      This method may be called concurrently from multiple threads.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: The name of the `Tensor` to return.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The `Tensor` with the given `name`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If `name` is not a string.\n",
      "     |        KeyError: If `name` does not correspond to a tensor in this graph.\n",
      "     |  \n",
      "     |  gradient_override_map(self, op_type_map)\n",
      "     |      EXPERIMENTAL: A context manager for overriding gradient functions.\n",
      "     |      \n",
      "     |      This context manager can be used to override the gradient function\n",
      "     |      that will be used for ops within the scope of the context.\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      @tf.RegisterGradient(\"CustomSquare\")\n",
      "     |      def _custom_square_grad(op, grad):\n",
      "     |        # ...\n",
      "     |      \n",
      "     |      with tf.Graph().as_default() as g:\n",
      "     |        c = tf.constant(5.0)\n",
      "     |        s_1 = tf.square(c)  # Uses the default gradient for tf.square.\n",
      "     |        with g.gradient_override_map({\"Square\": \"CustomSquare\"}):\n",
      "     |          s_2 = tf.square(s_2)  # Uses _custom_square_grad to compute the\n",
      "     |                                # gradient of s_2.\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        op_type_map: A dictionary mapping op type strings to alternative op type\n",
      "     |          strings.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A context manager that sets the alternative op type to be used for one\n",
      "     |        or more ops created in that context.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If `op_type_map` is not a dictionary mapping strings to\n",
      "     |          strings.\n",
      "     |  \n",
      "     |  is_feedable(self, tensor)\n",
      "     |      Returns `True` if and only if `tensor` is feedable.\n",
      "     |  \n",
      "     |  is_fetchable(self, tensor_or_op)\n",
      "     |      Returns `True` if and only if `tensor_or_op` is fetchable.\n",
      "     |  \n",
      "     |  name_scope(self, name)\n",
      "     |      Returns a context manager that creates hierarchical names for operations.\n",
      "     |      \n",
      "     |      A graph maintains a stack of name scopes. A `with name_scope(...):`\n",
      "     |      statement pushes a new name onto the stack for the lifetime of the context.\n",
      "     |      \n",
      "     |      The `name` argument will be interpreted as follows:\n",
      "     |      \n",
      "     |      * A string (not ending with '/') will create a new name scope, in which\n",
      "     |        `name` is appended to the prefix of all operations created in the\n",
      "     |        context. If `name` has been used before, it will be made unique by\n",
      "     |        calling `self.unique_name(name)`.\n",
      "     |      * A scope previously captured from a `with g.name_scope(...) as\n",
      "     |        scope:` statement will be treated as an \"absolute\" name scope, which\n",
      "     |        makes it possible to re-enter existing scopes.\n",
      "     |      * A value of `None` or the empty string will reset the current name scope\n",
      "     |        to the top-level (empty) name scope.\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      with tf.Graph().as_default() as g:\n",
      "     |        c = tf.constant(5.0, name=\"c\")\n",
      "     |        assert c.op.name == \"c\"\n",
      "     |        c_1 = tf.constant(6.0, name=\"c\")\n",
      "     |        assert c_1.op.name == \"c_1\"\n",
      "     |      \n",
      "     |        # Creates a scope called \"nested\"\n",
      "     |        with g.name_scope(\"nested\") as scope:\n",
      "     |          nested_c = tf.constant(10.0, name=\"c\")\n",
      "     |          assert nested_c.op.name == \"nested/c\"\n",
      "     |      \n",
      "     |          # Creates a nested scope called \"inner\".\n",
      "     |          with g.name_scope(\"inner\"):\n",
      "     |            nested_inner_c = tf.constant(20.0, name=\"c\")\n",
      "     |            assert nested_inner_c.op.name == \"nested/inner/c\"\n",
      "     |      \n",
      "     |          # Create a nested scope called \"inner_1\".\n",
      "     |          with g.name_scope(\"inner\"):\n",
      "     |            nested_inner_1_c = tf.constant(30.0, name=\"c\")\n",
      "     |            assert nested_inner_1_c.op.name == \"nested/inner_1/c\"\n",
      "     |      \n",
      "     |            # Treats `scope` as an absolute name scope, and\n",
      "     |            # switches to the \"nested/\" scope.\n",
      "     |            with g.name_scope(scope):\n",
      "     |              nested_d = tf.constant(40.0, name=\"d\")\n",
      "     |              assert nested_d.op.name == \"nested/d\"\n",
      "     |      \n",
      "     |              with g.name_scope(\"\"):\n",
      "     |                e = tf.constant(50.0, name=\"e\")\n",
      "     |                assert e.op.name == \"e\"\n",
      "     |      ```\n",
      "     |      \n",
      "     |      The name of the scope itself can be captured by `with\n",
      "     |      g.name_scope(...) as scope:`, which stores the name of the scope\n",
      "     |      in the variable `scope`. This value can be used to name an\n",
      "     |      operation that represents the overall result of executing the ops\n",
      "     |      in a scope. For example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      inputs = tf.constant(...)\n",
      "     |      with g.name_scope('my_layer') as scope:\n",
      "     |        weights = tf.Variable(..., name=\"weights\")\n",
      "     |        biases = tf.Variable(..., name=\"biases\")\n",
      "     |        affine = tf.matmul(inputs, weights) + biases\n",
      "     |        output = tf.nn.relu(affine, name=scope)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      NOTE: This constructor validates the given `name`. Valid scope\n",
      "     |      names match one of the following regular expressions:\n",
      "     |      \n",
      "     |          [A-Za-z0-9.][A-Za-z0-9_.\\-/]* (for scopes at the root)\n",
      "     |          [A-Za-z0-9_.\\-/]* (for other scopes)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the scope.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A context manager that installs `name` as a new name scope.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `name` is not a valid scope name, according to the rules\n",
      "     |          above.\n",
      "     |  \n",
      "     |  prevent_feeding(self, tensor)\n",
      "     |      Marks the given `tensor` as unfeedable in this graph.\n",
      "     |  \n",
      "     |  prevent_fetching(self, op)\n",
      "     |      Marks the given `op` as unfetchable in this graph.\n",
      "     |  \n",
      "     |  switch_to_thread_local(self)\n",
      "     |      Make device, colocation and dependencies stacks thread-local.\n",
      "     |      \n",
      "     |      Device, colocation and dependencies stacks are not thread-local be default.\n",
      "     |      If multiple threads access them, then the state is shared.  This means that\n",
      "     |      one thread may affect the behavior of another thread.\n",
      "     |      \n",
      "     |      After this method is called, the stacks become thread-local.  If multiple\n",
      "     |      threads access them, then the state is not shared.  Each thread uses its own\n",
      "     |      value; a thread doesn't affect other threads by mutating such a stack.\n",
      "     |      \n",
      "     |      The initial value for every thread's stack is set to the current value\n",
      "     |      of the stack when `switch_to_thread_local()` was first called.\n",
      "     |  \n",
      "     |  unique_name(self, name, mark_as_used=True)\n",
      "     |      Return a unique operation name for `name`.\n",
      "     |      \n",
      "     |      Note: You rarely need to call `unique_name()` directly.  Most of\n",
      "     |      the time you just need to create `with g.name_scope()` blocks to\n",
      "     |      generate structured names.\n",
      "     |      \n",
      "     |      `unique_name` is used to generate structured names, separated by\n",
      "     |      `\"/\"`, to help identify operations when debugging a graph.\n",
      "     |      Operation names are displayed in error messages reported by the\n",
      "     |      TensorFlow runtime, and in various visualization tools such as\n",
      "     |      TensorBoard.\n",
      "     |      \n",
      "     |      If `mark_as_used` is set to `True`, which is the default, a new\n",
      "     |      unique name is created and marked as in use. If it's set to `False`,\n",
      "     |      the unique name is returned without actually being marked as used.\n",
      "     |      This is useful when the caller simply wants to know what the name\n",
      "     |      to be created will be.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: The name for an operation.\n",
      "     |        mark_as_used: Whether to mark this name as being used.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A string to be passed to `create_op()` that will be used\n",
      "     |        to name the operation being created.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  building_function\n",
      "     |      Returns True iff this graph represents a function.\n",
      "     |  \n",
      "     |  collections\n",
      "     |      Returns the names of the collections known to this graph.\n",
      "     |  \n",
      "     |  finalized\n",
      "     |      True if this graph has been finalized.\n",
      "     |  \n",
      "     |  graph_def_versions\n",
      "     |      The GraphDef version information of this graph.\n",
      "     |      \n",
      "     |      For details on the meaning of each version, see\n",
      "     |      [`GraphDef`](https://www.tensorflow.org/code/tensorflow/core/framework/graph.proto).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `VersionDef`.\n",
      "     |  \n",
      "     |  seed\n",
      "     |      The graph-level random seed of this graph.\n",
      "     |  \n",
      "     |  version\n",
      "     |      Returns a version number that increases as ops are added to the graph.\n",
      "     |      \n",
      "     |      Note that this is unrelated to the\n",
      "     |      `tf.Graph.graph_def_versions`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |         An integer version that increases as ops are added to the graph.\n",
      "    \n",
      "    class GraphDef(google.protobuf.pyext._message.CMessage, google.protobuf.message.Message)\n",
      "     |  A ProtocolMessage\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      GraphDef\n",
      "     |      google.protobuf.pyext._message.CMessage\n",
      "     |      google.protobuf.message.Message\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  library\n",
      "     |      Field tensorflow.GraphDef.library\n",
      "     |  \n",
      "     |  node\n",
      "     |      Field tensorflow.GraphDef.node\n",
      "     |  \n",
      "     |  version\n",
      "     |      Field tensorflow.GraphDef.version\n",
      "     |  \n",
      "     |  versions\n",
      "     |      Field tensorflow.GraphDef.versions\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  DESCRIPTOR = <google.protobuf.pyext._message.MessageDescriptor object>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.pyext._message.CMessage:\n",
      "     |  \n",
      "     |  ByteSize(...)\n",
      "     |      Returns the size of the message in bytes.\n",
      "     |  \n",
      "     |  Clear(...)\n",
      "     |      Clears the message.\n",
      "     |  \n",
      "     |  ClearExtension(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  ClearField(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  CopyFrom(...)\n",
      "     |      Copies a protocol message into the current message.\n",
      "     |  \n",
      "     |  DiscardUnknownFields(...)\n",
      "     |      Discards the unknown fields.\n",
      "     |  \n",
      "     |  FindInitializationErrors(...)\n",
      "     |      Finds unset required fields.\n",
      "     |  \n",
      "     |  FromString(...) from google.protobuf.pyext.cpp_message.GeneratedProtocolMessageType\n",
      "     |      Creates new method instance from given serialized data.\n",
      "     |  \n",
      "     |  HasExtension(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  HasField(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  IsInitialized(...)\n",
      "     |      Checks if all required fields of a protocol message are set.\n",
      "     |  \n",
      "     |  ListFields(...)\n",
      "     |      Lists all set fields of a message.\n",
      "     |  \n",
      "     |  MergeFrom(...)\n",
      "     |      Merges a protocol message into the current message.\n",
      "     |  \n",
      "     |  MergeFromString(...)\n",
      "     |      Merges a serialized message into the current message.\n",
      "     |  \n",
      "     |  ParseFromString(...)\n",
      "     |      Parses a serialized message into the current message.\n",
      "     |  \n",
      "     |  RegisterExtension(...) from google.protobuf.pyext.cpp_message.GeneratedProtocolMessageType\n",
      "     |      Registers an extension with the current message.\n",
      "     |  \n",
      "     |  SerializePartialToString(...)\n",
      "     |      Serializes the message to a string, even if it isn't initialized.\n",
      "     |  \n",
      "     |  SerializeToString(...)\n",
      "     |      Serializes the message to a string, only for initialized messages.\n",
      "     |  \n",
      "     |  SetInParent(...)\n",
      "     |      Sets the has bit of the given field in its parent message.\n",
      "     |  \n",
      "     |  UnknownFields(...)\n",
      "     |      Parse unknown field set\n",
      "     |  \n",
      "     |  WhichOneof(...)\n",
      "     |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      Makes a deep copy of the class.\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from google.protobuf.pyext._message.MessageMeta\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  __unicode__(...)\n",
      "     |      Outputs a unicode representation of the message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google.protobuf.pyext._message.CMessage:\n",
      "     |  \n",
      "     |  Extensions\n",
      "     |      Extension dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from google.protobuf.pyext._message.CMessage:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Support the pickle protocol.\n",
      "    \n",
      "    class GraphKeys(builtins.object)\n",
      "     |  Standard names to use for graph collections.\n",
      "     |  \n",
      "     |  The standard library uses various well-known names to collect and\n",
      "     |  retrieve values associated with a graph. For example, the\n",
      "     |  `tf.Optimizer` subclasses default to optimizing the variables\n",
      "     |  collected under `tf.GraphKeys.TRAINABLE_VARIABLES` if none is\n",
      "     |  specified, but it is also possible to pass an explicit list of\n",
      "     |  variables.\n",
      "     |  \n",
      "     |  The following standard keys are defined:\n",
      "     |  \n",
      "     |  * `GLOBAL_VARIABLES`: the default collection of `Variable` objects, shared\n",
      "     |    across distributed environment (model variables are subset of these). See\n",
      "     |    `tf.compat.v1.global_variables`\n",
      "     |    for more details.\n",
      "     |    Commonly, all `TRAINABLE_VARIABLES` variables will be in `MODEL_VARIABLES`,\n",
      "     |    and all `MODEL_VARIABLES` variables will be in `GLOBAL_VARIABLES`.\n",
      "     |  * `LOCAL_VARIABLES`: the subset of `Variable` objects that are local to each\n",
      "     |    machine. Usually used for temporarily variables, like counters.\n",
      "     |    Note: use `tf.contrib.framework.local_variable` to add to this collection.\n",
      "     |  * `MODEL_VARIABLES`: the subset of `Variable` objects that are used in the\n",
      "     |    model for inference (feed forward). Note: use\n",
      "     |    `tf.contrib.framework.model_variable` to add to this collection.\n",
      "     |  * `TRAINABLE_VARIABLES`: the subset of `Variable` objects that will\n",
      "     |    be trained by an optimizer. See\n",
      "     |    `tf.compat.v1.trainable_variables`\n",
      "     |    for more details.\n",
      "     |  * `SUMMARIES`: the summary `Tensor` objects that have been created in the\n",
      "     |    graph. See\n",
      "     |    `tf.compat.v1.summary.merge_all`\n",
      "     |    for more details.\n",
      "     |  * `QUEUE_RUNNERS`: the `QueueRunner` objects that are used to\n",
      "     |    produce input for a computation. See\n",
      "     |    `tf.compat.v1.train.start_queue_runners`\n",
      "     |    for more details.\n",
      "     |  * `MOVING_AVERAGE_VARIABLES`: the subset of `Variable` objects that will also\n",
      "     |    keep moving averages.  See\n",
      "     |    `tf.compat.v1.moving_average_variables`\n",
      "     |    for more details.\n",
      "     |  * `REGULARIZATION_LOSSES`: regularization losses collected during graph\n",
      "     |    construction.\n",
      "     |  \n",
      "     |  The following standard keys are _defined_, but their collections are **not**\n",
      "     |  automatically populated as many of the others are:\n",
      "     |  \n",
      "     |  * `WEIGHTS`\n",
      "     |  * `BIASES`\n",
      "     |  * `ACTIVATIONS`\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  ACTIVATIONS = 'activations'\n",
      "     |  \n",
      "     |  ASSET_FILEPATHS = 'asset_filepaths'\n",
      "     |  \n",
      "     |  BIASES = 'biases'\n",
      "     |  \n",
      "     |  CONCATENATED_VARIABLES = 'concatenated_variables'\n",
      "     |  \n",
      "     |  COND_CONTEXT = 'cond_context'\n",
      "     |  \n",
      "     |  EVAL_STEP = 'eval_step'\n",
      "     |  \n",
      "     |  GLOBAL_STEP = 'global_step'\n",
      "     |  \n",
      "     |  GLOBAL_VARIABLES = 'variables'\n",
      "     |  \n",
      "     |  INIT_OP = 'init_op'\n",
      "     |  \n",
      "     |  LOCAL_INIT_OP = 'local_init_op'\n",
      "     |  \n",
      "     |  LOCAL_RESOURCES = 'local_resources'\n",
      "     |  \n",
      "     |  LOCAL_VARIABLES = 'local_variables'\n",
      "     |  \n",
      "     |  LOSSES = 'losses'\n",
      "     |  \n",
      "     |  METRIC_VARIABLES = 'metric_variables'\n",
      "     |  \n",
      "     |  MODEL_VARIABLES = 'model_variables'\n",
      "     |  \n",
      "     |  MOVING_AVERAGE_VARIABLES = 'moving_average_variables'\n",
      "     |  \n",
      "     |  QUEUE_RUNNERS = 'queue_runners'\n",
      "     |  \n",
      "     |  READY_FOR_LOCAL_INIT_OP = 'ready_for_local_init_op'\n",
      "     |  \n",
      "     |  READY_OP = 'ready_op'\n",
      "     |  \n",
      "     |  REGULARIZATION_LOSSES = 'regularization_losses'\n",
      "     |  \n",
      "     |  RESOURCES = 'resources'\n",
      "     |  \n",
      "     |  SAVEABLE_OBJECTS = 'saveable_objects'\n",
      "     |  \n",
      "     |  SAVERS = 'savers'\n",
      "     |  \n",
      "     |  SUMMARIES = 'summaries'\n",
      "     |  \n",
      "     |  SUMMARY_OP = 'summary_op'\n",
      "     |  \n",
      "     |  TABLE_INITIALIZERS = 'table_initializer'\n",
      "     |  \n",
      "     |  TRAINABLE_RESOURCE_VARIABLES = 'trainable_resource_variables'\n",
      "     |  \n",
      "     |  TRAINABLE_VARIABLES = 'trainable_variables'\n",
      "     |  \n",
      "     |  TRAIN_OP = 'train_op'\n",
      "     |  \n",
      "     |  UPDATE_OPS = 'update_ops'\n",
      "     |  \n",
      "     |  VARIABLES = 'variables'\n",
      "     |  \n",
      "     |  WEIGHTS = 'weights'\n",
      "     |  \n",
      "     |  WHILE_CONTEXT = 'while_context'\n",
      "    \n",
      "    class GraphOptions(google.protobuf.pyext._message.CMessage, google.protobuf.message.Message)\n",
      "     |  A ProtocolMessage\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      GraphOptions\n",
      "     |      google.protobuf.pyext._message.CMessage\n",
      "     |      google.protobuf.message.Message\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  build_cost_model\n",
      "     |      Field tensorflow.GraphOptions.build_cost_model\n",
      "     |  \n",
      "     |  build_cost_model_after\n",
      "     |      Field tensorflow.GraphOptions.build_cost_model_after\n",
      "     |  \n",
      "     |  enable_bfloat16_sendrecv\n",
      "     |      Field tensorflow.GraphOptions.enable_bfloat16_sendrecv\n",
      "     |  \n",
      "     |  enable_recv_scheduling\n",
      "     |      Field tensorflow.GraphOptions.enable_recv_scheduling\n",
      "     |  \n",
      "     |  infer_shapes\n",
      "     |      Field tensorflow.GraphOptions.infer_shapes\n",
      "     |  \n",
      "     |  optimizer_options\n",
      "     |      Field tensorflow.GraphOptions.optimizer_options\n",
      "     |  \n",
      "     |  place_pruned_graph\n",
      "     |      Field tensorflow.GraphOptions.place_pruned_graph\n",
      "     |  \n",
      "     |  rewrite_options\n",
      "     |      Field tensorflow.GraphOptions.rewrite_options\n",
      "     |  \n",
      "     |  timeline_step\n",
      "     |      Field tensorflow.GraphOptions.timeline_step\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  DESCRIPTOR = <google.protobuf.pyext._message.MessageDescriptor object>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.pyext._message.CMessage:\n",
      "     |  \n",
      "     |  ByteSize(...)\n",
      "     |      Returns the size of the message in bytes.\n",
      "     |  \n",
      "     |  Clear(...)\n",
      "     |      Clears the message.\n",
      "     |  \n",
      "     |  ClearExtension(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  ClearField(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  CopyFrom(...)\n",
      "     |      Copies a protocol message into the current message.\n",
      "     |  \n",
      "     |  DiscardUnknownFields(...)\n",
      "     |      Discards the unknown fields.\n",
      "     |  \n",
      "     |  FindInitializationErrors(...)\n",
      "     |      Finds unset required fields.\n",
      "     |  \n",
      "     |  FromString(...) from google.protobuf.pyext.cpp_message.GeneratedProtocolMessageType\n",
      "     |      Creates new method instance from given serialized data.\n",
      "     |  \n",
      "     |  HasExtension(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  HasField(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  IsInitialized(...)\n",
      "     |      Checks if all required fields of a protocol message are set.\n",
      "     |  \n",
      "     |  ListFields(...)\n",
      "     |      Lists all set fields of a message.\n",
      "     |  \n",
      "     |  MergeFrom(...)\n",
      "     |      Merges a protocol message into the current message.\n",
      "     |  \n",
      "     |  MergeFromString(...)\n",
      "     |      Merges a serialized message into the current message.\n",
      "     |  \n",
      "     |  ParseFromString(...)\n",
      "     |      Parses a serialized message into the current message.\n",
      "     |  \n",
      "     |  RegisterExtension(...) from google.protobuf.pyext.cpp_message.GeneratedProtocolMessageType\n",
      "     |      Registers an extension with the current message.\n",
      "     |  \n",
      "     |  SerializePartialToString(...)\n",
      "     |      Serializes the message to a string, even if it isn't initialized.\n",
      "     |  \n",
      "     |  SerializeToString(...)\n",
      "     |      Serializes the message to a string, only for initialized messages.\n",
      "     |  \n",
      "     |  SetInParent(...)\n",
      "     |      Sets the has bit of the given field in its parent message.\n",
      "     |  \n",
      "     |  UnknownFields(...)\n",
      "     |      Parse unknown field set\n",
      "     |  \n",
      "     |  WhichOneof(...)\n",
      "     |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      Makes a deep copy of the class.\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from google.protobuf.pyext._message.MessageMeta\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  __unicode__(...)\n",
      "     |      Outputs a unicode representation of the message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google.protobuf.pyext._message.CMessage:\n",
      "     |  \n",
      "     |  Extensions\n",
      "     |      Extension dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from google.protobuf.pyext._message.CMessage:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Support the pickle protocol.\n",
      "    \n",
      "    class HistogramProto(google.protobuf.pyext._message.CMessage, google.protobuf.message.Message)\n",
      "     |  A ProtocolMessage\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      HistogramProto\n",
      "     |      google.protobuf.pyext._message.CMessage\n",
      "     |      google.protobuf.message.Message\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  bucket\n",
      "     |      Field tensorflow.HistogramProto.bucket\n",
      "     |  \n",
      "     |  bucket_limit\n",
      "     |      Field tensorflow.HistogramProto.bucket_limit\n",
      "     |  \n",
      "     |  max\n",
      "     |      Field tensorflow.HistogramProto.max\n",
      "     |  \n",
      "     |  min\n",
      "     |      Field tensorflow.HistogramProto.min\n",
      "     |  \n",
      "     |  num\n",
      "     |      Field tensorflow.HistogramProto.num\n",
      "     |  \n",
      "     |  sum\n",
      "     |      Field tensorflow.HistogramProto.sum\n",
      "     |  \n",
      "     |  sum_squares\n",
      "     |      Field tensorflow.HistogramProto.sum_squares\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  DESCRIPTOR = <google.protobuf.pyext._message.MessageDescriptor object>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.pyext._message.CMessage:\n",
      "     |  \n",
      "     |  ByteSize(...)\n",
      "     |      Returns the size of the message in bytes.\n",
      "     |  \n",
      "     |  Clear(...)\n",
      "     |      Clears the message.\n",
      "     |  \n",
      "     |  ClearExtension(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  ClearField(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  CopyFrom(...)\n",
      "     |      Copies a protocol message into the current message.\n",
      "     |  \n",
      "     |  DiscardUnknownFields(...)\n",
      "     |      Discards the unknown fields.\n",
      "     |  \n",
      "     |  FindInitializationErrors(...)\n",
      "     |      Finds unset required fields.\n",
      "     |  \n",
      "     |  FromString(...) from google.protobuf.pyext.cpp_message.GeneratedProtocolMessageType\n",
      "     |      Creates new method instance from given serialized data.\n",
      "     |  \n",
      "     |  HasExtension(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  HasField(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  IsInitialized(...)\n",
      "     |      Checks if all required fields of a protocol message are set.\n",
      "     |  \n",
      "     |  ListFields(...)\n",
      "     |      Lists all set fields of a message.\n",
      "     |  \n",
      "     |  MergeFrom(...)\n",
      "     |      Merges a protocol message into the current message.\n",
      "     |  \n",
      "     |  MergeFromString(...)\n",
      "     |      Merges a serialized message into the current message.\n",
      "     |  \n",
      "     |  ParseFromString(...)\n",
      "     |      Parses a serialized message into the current message.\n",
      "     |  \n",
      "     |  RegisterExtension(...) from google.protobuf.pyext.cpp_message.GeneratedProtocolMessageType\n",
      "     |      Registers an extension with the current message.\n",
      "     |  \n",
      "     |  SerializePartialToString(...)\n",
      "     |      Serializes the message to a string, even if it isn't initialized.\n",
      "     |  \n",
      "     |  SerializeToString(...)\n",
      "     |      Serializes the message to a string, only for initialized messages.\n",
      "     |  \n",
      "     |  SetInParent(...)\n",
      "     |      Sets the has bit of the given field in its parent message.\n",
      "     |  \n",
      "     |  UnknownFields(...)\n",
      "     |      Parse unknown field set\n",
      "     |  \n",
      "     |  WhichOneof(...)\n",
      "     |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      Makes a deep copy of the class.\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from google.protobuf.pyext._message.MessageMeta\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  __unicode__(...)\n",
      "     |      Outputs a unicode representation of the message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google.protobuf.pyext._message.CMessage:\n",
      "     |  \n",
      "     |  Extensions\n",
      "     |      Extension dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from google.protobuf.pyext._message.CMessage:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Support the pickle protocol.\n",
      "    \n",
      "    class IdentityReader(ReaderBase)\n",
      "     |  A Reader that outputs the queued work as both the key and value.\n",
      "     |  \n",
      "     |  To use, enqueue strings in a Queue.  Read will take the front\n",
      "     |  work string and output (work, work).\n",
      "     |  \n",
      "     |  See ReaderBase for supported methods.\n",
      "     |  \n",
      "     |  @compatibility(eager)\n",
      "     |  Readers are not compatible with eager execution. Instead, please\n",
      "     |  use `tf.data` to get data into your model.\n",
      "     |  @end_compatibility\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      IdentityReader\n",
      "     |      ReaderBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, name=None)\n",
      "     |      Create a IdentityReader. (deprecated)\n",
      "     |      \n",
      "     |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.map(...)`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ReaderBase:\n",
      "     |  \n",
      "     |  num_records_produced(self, name=None)\n",
      "     |      Returns the number of records this reader has produced.\n",
      "     |      \n",
      "     |      This is the same as the number of Read executions that have\n",
      "     |      succeeded.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An int64 Tensor.\n",
      "     |  \n",
      "     |  num_work_units_completed(self, name=None)\n",
      "     |      Returns the number of work units this reader has finished processing.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An int64 Tensor.\n",
      "     |  \n",
      "     |  read(self, queue, name=None)\n",
      "     |      Returns the next record (key, value) pair produced by a reader.\n",
      "     |      \n",
      "     |      Will dequeue a work unit from queue if necessary (e.g. when the\n",
      "     |      Reader needs to start reading from a new file since it has\n",
      "     |      finished with the previous file).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        queue: A Queue or a mutable string Tensor representing a handle\n",
      "     |          to a Queue, with string work items.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A tuple of Tensors (key, value).\n",
      "     |        key: A string scalar Tensor.\n",
      "     |        value: A string scalar Tensor.\n",
      "     |  \n",
      "     |  read_up_to(self, queue, num_records, name=None)\n",
      "     |      Returns up to num_records (key, value) pairs produced by a reader.\n",
      "     |      \n",
      "     |      Will dequeue a work unit from queue if necessary (e.g., when the\n",
      "     |      Reader needs to start reading from a new file since it has\n",
      "     |      finished with the previous file).\n",
      "     |      It may return less than num_records even before the last batch.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        queue: A Queue or a mutable string Tensor representing a handle\n",
      "     |          to a Queue, with string work items.\n",
      "     |        num_records: Number of records to read.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A tuple of Tensors (keys, values).\n",
      "     |        keys: A 1-D string Tensor.\n",
      "     |        values: A 1-D string Tensor.\n",
      "     |  \n",
      "     |  reset(self, name=None)\n",
      "     |      Restore a reader to its initial clean state.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The created Operation.\n",
      "     |  \n",
      "     |  restore_state(self, state, name=None)\n",
      "     |      Restore a reader to a previously saved state.\n",
      "     |      \n",
      "     |      Not all Readers support being restored, so this can produce an\n",
      "     |      Unimplemented error.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        state: A string Tensor.\n",
      "     |          Result of a SerializeState of a Reader with matching type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The created Operation.\n",
      "     |  \n",
      "     |  serialize_state(self, name=None)\n",
      "     |      Produce a string tensor that encodes the state of a reader.\n",
      "     |      \n",
      "     |      Not all Readers support being serialized, so this can produce an\n",
      "     |      Unimplemented error.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A string Tensor.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from ReaderBase:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  reader_ref\n",
      "     |      Op that implements the reader.\n",
      "     |  \n",
      "     |  supports_serialize\n",
      "     |      Whether the Reader implementation can serialize its state.\n",
      "    \n",
      "    class IndexedSlices(tensorflow.python.framework.tensor_like._TensorLike, tensorflow.python.framework.composite_tensor.CompositeTensor)\n",
      "     |  A sparse representation of a set of tensor slices at given indices.\n",
      "     |  \n",
      "     |  This class is a simple wrapper for a pair of `Tensor` objects:\n",
      "     |  \n",
      "     |  * `values`: A `Tensor` of any dtype with shape `[D0, D1, ..., Dn]`.\n",
      "     |  * `indices`: A 1-D integer `Tensor` with shape `[D0]`.\n",
      "     |  \n",
      "     |  An `IndexedSlices` is typically used to represent a subset of a larger\n",
      "     |  tensor `dense` of shape `[LARGE0, D1, .. , DN]` where `LARGE0 >> D0`.\n",
      "     |  The values in `indices` are the indices in the first dimension of\n",
      "     |  the slices that have been extracted from the larger tensor.\n",
      "     |  \n",
      "     |  The dense tensor `dense` represented by an `IndexedSlices` `slices` has\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  dense[slices.indices[i], :, :, :, ...] = slices.values[i, :, :, :, ...]\n",
      "     |  ```\n",
      "     |  \n",
      "     |  The `IndexedSlices` class is used principally in the definition of\n",
      "     |  gradients for operations that have sparse gradients\n",
      "     |  (e.g. `tf.gather`).\n",
      "     |  \n",
      "     |  Contrast this representation with\n",
      "     |  `tf.SparseTensor`,\n",
      "     |  which uses multi-dimensional indices and scalar values.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      IndexedSlices\n",
      "     |      tensorflow.python.framework.tensor_like._TensorLike\n",
      "     |      tensorflow.python.framework.composite_tensor.CompositeTensor\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, values, indices, dense_shape=None)\n",
      "     |      Creates an `IndexedSlices`.\n",
      "     |  \n",
      "     |  __neg__(self)\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  consumers(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  dense_shape\n",
      "     |      A 1-D `Tensor` containing the shape of the corresponding dense tensor.\n",
      "     |  \n",
      "     |  device\n",
      "     |      The name of the device on which `values` will be produced, or `None`.\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      The `DType` of elements in this tensor.\n",
      "     |  \n",
      "     |  graph\n",
      "     |      The `Graph` that contains the values, indices, and shape tensors.\n",
      "     |  \n",
      "     |  indices\n",
      "     |      A 1-D `Tensor` containing the indices of the slices.\n",
      "     |  \n",
      "     |  name\n",
      "     |      The name of this `IndexedSlices`.\n",
      "     |  \n",
      "     |  op\n",
      "     |      The `Operation` that produces `values` as an output.\n",
      "     |  \n",
      "     |  values\n",
      "     |      A `Tensor` containing the values of the slices.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.framework.tensor_like._TensorLike:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class IndexedSlicesSpec(tensorflow.python.framework.type_spec.TypeSpec)\n",
      "     |  Type specification for a `tf.IndexedSlices`.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      IndexedSlicesSpec\n",
      "     |      tensorflow.python.framework.type_spec.TypeSpec\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, shape=None, dtype=tf.float32, indices_dtype=tf.int64, dense_shape_dtype=None, indices_shape=None)\n",
      "     |      Constructs a type specification for a `tf.IndexedSlices`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: The dense shape of the `IndexedSlices`, or `None` to allow any\n",
      "     |          dense shape.\n",
      "     |        dtype: `tf.DType` of values in the `IndexedSlices`.\n",
      "     |        indices_dtype: `tf.DType` of the `indices` in the `IndexedSlices`.  One\n",
      "     |          of `tf.int32` or `tf.int64`.\n",
      "     |        dense_shape_dtype: `tf.DType` of the `dense_shape` in the `IndexedSlices`.\n",
      "     |          One of `tf.int32`, `tf.int64`, or `None` (if the `IndexedSlices` has\n",
      "     |          no `dense_shape` tensor).\n",
      "     |        indices_shape: The shape of the `indices` component, which indicates\n",
      "     |          how many slices are in the `IndexedSlices`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  value_type\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tensorflow.python.framework.type_spec.TypeSpec:\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __ne__(self, other)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  is_compatible_with(self, spec_or_value)\n",
      "     |      Returns true if `spec_or_value` is compatible with this TypeSpec.\n",
      "     |  \n",
      "     |  most_specific_compatible_type(self, other)\n",
      "     |      Returns the most specific TypeSpec compatible with `self` and `other`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: A `TypeSpec`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If there is no TypeSpec that is compatible with both `self`\n",
      "     |          and `other`.\n",
      "    \n",
      "    class InteractiveSession(BaseSession)\n",
      "     |  A TensorFlow `Session` for use in interactive contexts, such as a shell.\n",
      "     |  \n",
      "     |  The only difference with a regular `Session` is that an `InteractiveSession`\n",
      "     |  installs itself as the default session on construction.\n",
      "     |  The methods `tf.Tensor.eval`\n",
      "     |  and `tf.Operation.run`\n",
      "     |  will use that session to run ops.\n",
      "     |  \n",
      "     |  This is convenient in interactive shells and [IPython\n",
      "     |  notebooks](http://ipython.org), as it avoids having to pass an explicit\n",
      "     |  `Session` object to run ops.\n",
      "     |  \n",
      "     |  For example:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  sess = tf.compat.v1.InteractiveSession()\n",
      "     |  a = tf.constant(5.0)\n",
      "     |  b = tf.constant(6.0)\n",
      "     |  c = a * b\n",
      "     |  # We can just use 'c.eval()' without passing 'sess'\n",
      "     |  print(c.eval())\n",
      "     |  sess.close()\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Note that a regular session installs itself as the default session when it\n",
      "     |  is created in a `with` statement.  The common usage in non-interactive\n",
      "     |  programs is to follow that pattern:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  a = tf.constant(5.0)\n",
      "     |  b = tf.constant(6.0)\n",
      "     |  c = a * b\n",
      "     |  with tf.compat.v1.Session():\n",
      "     |    # We can also use 'c.eval()' here.\n",
      "     |    print(c.eval())\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      InteractiveSession\n",
      "     |      BaseSession\n",
      "     |      SessionInterface\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, target='', graph=None, config=None)\n",
      "     |      Creates a new interactive TensorFlow session.\n",
      "     |      \n",
      "     |      If no `graph` argument is specified when constructing the session,\n",
      "     |      the default graph will be launched in the session. If you are\n",
      "     |      using more than one graph (created with `tf.Graph()`) in the same\n",
      "     |      process, you will have to use different sessions for each graph,\n",
      "     |      but each graph can be used in multiple sessions. In this case, it\n",
      "     |      is often clearer to pass the graph to be launched explicitly to\n",
      "     |      the session constructor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        target: (Optional.) The execution engine to connect to. Defaults to using\n",
      "     |          an in-process engine.\n",
      "     |        graph: (Optional.) The `Graph` to be launched (described above).\n",
      "     |        config: (Optional) `ConfigProto` proto used to configure the session.\n",
      "     |  \n",
      "     |  close(self)\n",
      "     |      Closes an `InteractiveSession`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from BaseSession:\n",
      "     |  \n",
      "     |  __del__(self)\n",
      "     |  \n",
      "     |  as_default(self)\n",
      "     |      Returns a context manager that makes this object the default session.\n",
      "     |      \n",
      "     |      Use with the `with` keyword to specify that calls to\n",
      "     |      `tf.Operation.run` or `tf.Tensor.eval` should be executed in\n",
      "     |      this session.\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      c = tf.constant(..)\n",
      "     |      sess = tf.compat.v1.Session()\n",
      "     |      \n",
      "     |      with sess.as_default():\n",
      "     |        assert tf.compat.v1.get_default_session() is sess\n",
      "     |        print(c.eval())\n",
      "     |      ```\n",
      "     |      \n",
      "     |      To get the current default session, use `tf.compat.v1.get_default_session`.\n",
      "     |      \n",
      "     |      *N.B.* The `as_default` context manager *does not* close the\n",
      "     |      session when you exit the context, and you must close the session\n",
      "     |      explicitly.\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      c = tf.constant(...)\n",
      "     |      sess = tf.compat.v1.Session()\n",
      "     |      with sess.as_default():\n",
      "     |        print(c.eval())\n",
      "     |      # ...\n",
      "     |      with sess.as_default():\n",
      "     |        print(c.eval())\n",
      "     |      \n",
      "     |      sess.close()\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Alternatively, you can use `with tf.compat.v1.Session():` to create a\n",
      "     |      session that is automatically closed on exiting the context,\n",
      "     |      including when an uncaught exception is raised.\n",
      "     |      \n",
      "     |      *N.B.* The default session is a property of the current thread. If you\n",
      "     |      create a new thread, and wish to use the default session in that\n",
      "     |      thread, you must explicitly add a `with sess.as_default():` in that\n",
      "     |      thread's function.\n",
      "     |      \n",
      "     |      *N.B.* Entering a `with sess.as_default():` block does not affect\n",
      "     |      the current default graph. If you are using multiple graphs, and\n",
      "     |      `sess.graph` is different from the value of\n",
      "     |      `tf.compat.v1.get_default_graph`, you must explicitly enter a\n",
      "     |      `with sess.graph.as_default():` block to make `sess.graph` the default\n",
      "     |      graph.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A context manager using this session as the default session.\n",
      "     |  \n",
      "     |  list_devices(self)\n",
      "     |      Lists available devices in this session.\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      devices = sess.list_devices()\n",
      "     |      for d in devices:\n",
      "     |        print(d.name)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Where:\n",
      "     |        Each element in the list has the following properties\n",
      "     |        name: A string with the full name of the device. ex:\n",
      "     |            `/job:worker/replica:0/task:3/device:CPU:0`\n",
      "     |        device_type: The type of the device (e.g. `CPU`, `GPU`, `TPU`.)\n",
      "     |        memory_limit: The maximum amount of memory available on the device.\n",
      "     |            Note: depending on the device, it is possible the usable memory could\n",
      "     |            be substantially less.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        tf.errors.OpError: If it encounters an error (e.g. session is in an\n",
      "     |        invalid state, or network errors occur).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A list of devices in the session.\n",
      "     |  \n",
      "     |  make_callable(self, fetches, feed_list=None, accept_options=False)\n",
      "     |      Returns a Python callable that runs a particular step.\n",
      "     |      \n",
      "     |      The returned callable will take `len(feed_list)` arguments whose types\n",
      "     |      must be compatible feed values for the respective elements of `feed_list`.\n",
      "     |      For example, if element `i` of `feed_list` is a `tf.Tensor`, the `i`th\n",
      "     |      argument to the returned callable must be a numpy ndarray (or something\n",
      "     |      convertible to an ndarray) with matching element type and shape. See\n",
      "     |      `tf.Session.run` for details of the allowable feed key and value types.\n",
      "     |      \n",
      "     |      The returned callable will have the same return type as\n",
      "     |      `tf.Session.run(fetches, ...)`. For example, if `fetches` is a `tf.Tensor`,\n",
      "     |      the callable will return a numpy ndarray; if `fetches` is a `tf.Operation`,\n",
      "     |      it will return `None`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        fetches: A value or list of values to fetch. See `tf.Session.run` for\n",
      "     |          details of the allowable fetch types.\n",
      "     |        feed_list: (Optional.) A list of `feed_dict` keys. See `tf.Session.run`\n",
      "     |          for details of the allowable feed key types.\n",
      "     |        accept_options: (Optional.) If `True`, the returned `Callable` will be\n",
      "     |          able to accept `tf.compat.v1.RunOptions` and `tf.compat.v1.RunMetadata`\n",
      "     |          as optional keyword arguments `options` and `run_metadata`,\n",
      "     |          respectively, with the same syntax and semantics as `tf.Session.run`,\n",
      "     |          which is useful for certain use cases (profiling and debugging) but will\n",
      "     |          result in measurable slowdown of the `Callable`'s\n",
      "     |          performance. Default: `False`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A function that when called will execute the step defined by\n",
      "     |        `feed_list` and `fetches` in this session.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If `fetches` or `feed_list` cannot be interpreted\n",
      "     |          as arguments to `tf.Session.run`.\n",
      "     |  \n",
      "     |  partial_run(self, handle, fetches, feed_dict=None)\n",
      "     |      Continues the execution with more feeds and fetches.\n",
      "     |      \n",
      "     |      This is EXPERIMENTAL and subject to change.\n",
      "     |      \n",
      "     |      To use partial execution, a user first calls `partial_run_setup()` and\n",
      "     |      then a sequence of `partial_run()`. `partial_run_setup` specifies the\n",
      "     |      list of feeds and fetches that will be used in the subsequent\n",
      "     |      `partial_run` calls.\n",
      "     |      \n",
      "     |      The optional `feed_dict` argument allows the caller to override\n",
      "     |      the value of tensors in the graph. See run() for more information.\n",
      "     |      \n",
      "     |      Below is a simple example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      a = array_ops.placeholder(dtypes.float32, shape=[])\n",
      "     |      b = array_ops.placeholder(dtypes.float32, shape=[])\n",
      "     |      c = array_ops.placeholder(dtypes.float32, shape=[])\n",
      "     |      r1 = math_ops.add(a, b)\n",
      "     |      r2 = math_ops.multiply(r1, c)\n",
      "     |      \n",
      "     |      h = sess.partial_run_setup([r1, r2], [a, b, c])\n",
      "     |      res = sess.partial_run(h, r1, feed_dict={a: 1, b: 2})\n",
      "     |      res = sess.partial_run(h, r2, feed_dict={c: res})\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        handle: A handle for a sequence of partial runs.\n",
      "     |        fetches: A single graph element, a list of graph elements, or a dictionary\n",
      "     |          whose values are graph elements or lists of graph elements (see\n",
      "     |          documentation for `run`).\n",
      "     |        feed_dict: A dictionary that maps graph elements to values (described\n",
      "     |          above).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        Either a single value if `fetches` is a single graph element, or\n",
      "     |        a list of values if `fetches` is a list, or a dictionary with the\n",
      "     |        same keys as `fetches` if that is a dictionary\n",
      "     |        (see documentation for `run`).\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        tf.errors.OpError: Or one of its subclasses on error.\n",
      "     |  \n",
      "     |  partial_run_setup(self, fetches, feeds=None)\n",
      "     |      Sets up a graph with feeds and fetches for partial run.\n",
      "     |      \n",
      "     |      This is EXPERIMENTAL and subject to change.\n",
      "     |      \n",
      "     |      Note that contrary to `run`, `feeds` only specifies the graph elements.\n",
      "     |      The tensors will be supplied by the subsequent `partial_run` calls.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        fetches: A single graph element, or a list of graph elements.\n",
      "     |        feeds: A single graph element, or a list of graph elements.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A handle for partial run.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        RuntimeError: If this `Session` is in an invalid state (e.g. has been\n",
      "     |          closed).\n",
      "     |        TypeError: If `fetches` or `feed_dict` keys are of an inappropriate type.\n",
      "     |        tf.errors.OpError: Or one of its subclasses if a TensorFlow error happens.\n",
      "     |  \n",
      "     |  run(self, fetches, feed_dict=None, options=None, run_metadata=None)\n",
      "     |      Runs operations and evaluates tensors in `fetches`.\n",
      "     |      \n",
      "     |      This method runs one \"step\" of TensorFlow computation, by\n",
      "     |      running the necessary graph fragment to execute every `Operation`\n",
      "     |      and evaluate every `Tensor` in `fetches`, substituting the values in\n",
      "     |      `feed_dict` for the corresponding input values.\n",
      "     |      \n",
      "     |      The `fetches` argument may be a single graph element, or an arbitrarily\n",
      "     |      nested list, tuple, namedtuple, dict, or OrderedDict containing graph\n",
      "     |      elements at its leaves.  A graph element can be one of the following types:\n",
      "     |      \n",
      "     |      * A `tf.Operation`.\n",
      "     |        The corresponding fetched value will be `None`.\n",
      "     |      * A `tf.Tensor`.\n",
      "     |        The corresponding fetched value will be a numpy ndarray containing the\n",
      "     |        value of that tensor.\n",
      "     |      * A `tf.SparseTensor`.\n",
      "     |        The corresponding fetched value will be a\n",
      "     |        `tf.compat.v1.SparseTensorValue`\n",
      "     |        containing the value of that sparse tensor.\n",
      "     |      * A `get_tensor_handle` op.  The corresponding fetched value will be a\n",
      "     |        numpy ndarray containing the handle of that tensor.\n",
      "     |      * A `string` which is the name of a tensor or operation in the graph.\n",
      "     |      \n",
      "     |      The value returned by `run()` has the same shape as the `fetches` argument,\n",
      "     |      where the leaves are replaced by the corresponding values returned by\n",
      "     |      TensorFlow.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |         a = tf.constant([10, 20])\n",
      "     |         b = tf.constant([1.0, 2.0])\n",
      "     |         # 'fetches' can be a singleton\n",
      "     |         v = session.run(a)\n",
      "     |         # v is the numpy array [10, 20]\n",
      "     |         # 'fetches' can be a list.\n",
      "     |         v = session.run([a, b])\n",
      "     |         # v is a Python list with 2 numpy arrays: the 1-D array [10, 20] and the\n",
      "     |         # 1-D array [1.0, 2.0]\n",
      "     |         # 'fetches' can be arbitrary lists, tuples, namedtuple, dicts:\n",
      "     |         MyData = collections.namedtuple('MyData', ['a', 'b'])\n",
      "     |         v = session.run({'k1': MyData(a, b), 'k2': [b, a]})\n",
      "     |         # v is a dict with\n",
      "     |         # v['k1'] is a MyData namedtuple with 'a' (the numpy array [10, 20]) and\n",
      "     |         # 'b' (the numpy array [1.0, 2.0])\n",
      "     |         # v['k2'] is a list with the numpy array [1.0, 2.0] and the numpy array\n",
      "     |         # [10, 20].\n",
      "     |      ```\n",
      "     |      \n",
      "     |      The optional `feed_dict` argument allows the caller to override\n",
      "     |      the value of tensors in the graph. Each key in `feed_dict` can be\n",
      "     |      one of the following types:\n",
      "     |      \n",
      "     |      * If the key is a `tf.Tensor`, the\n",
      "     |        value may be a Python scalar, string, list, or numpy ndarray\n",
      "     |        that can be converted to the same `dtype` as that\n",
      "     |        tensor. Additionally, if the key is a\n",
      "     |        `tf.compat.v1.placeholder`, the shape of\n",
      "     |        the value will be checked for compatibility with the placeholder.\n",
      "     |      * If the key is a\n",
      "     |        `tf.SparseTensor`,\n",
      "     |        the value should be a\n",
      "     |        `tf.compat.v1.SparseTensorValue`.\n",
      "     |      * If the key is a nested tuple of `Tensor`s or `SparseTensor`s, the value\n",
      "     |        should be a nested tuple with the same structure that maps to their\n",
      "     |        corresponding values as above.\n",
      "     |      \n",
      "     |      Each value in `feed_dict` must be convertible to a numpy array of the dtype\n",
      "     |      of the corresponding key.\n",
      "     |      \n",
      "     |      The optional `options` argument expects a [`RunOptions`] proto. The options\n",
      "     |      allow controlling the behavior of this particular step (e.g. turning tracing\n",
      "     |      on).\n",
      "     |      \n",
      "     |      The optional `run_metadata` argument expects a [`RunMetadata`] proto. When\n",
      "     |      appropriate, the non-Tensor output of this step will be collected there. For\n",
      "     |      example, when users turn on tracing in `options`, the profiled info will be\n",
      "     |      collected into this argument and passed back.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        fetches: A single graph element, a list of graph elements, or a dictionary\n",
      "     |          whose values are graph elements or lists of graph elements (described\n",
      "     |          above).\n",
      "     |        feed_dict: A dictionary that maps graph elements to values (described\n",
      "     |          above).\n",
      "     |        options: A [`RunOptions`] protocol buffer\n",
      "     |        run_metadata: A [`RunMetadata`] protocol buffer\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        Either a single value if `fetches` is a single graph element, or\n",
      "     |        a list of values if `fetches` is a list, or a dictionary with the\n",
      "     |        same keys as `fetches` if that is a dictionary (described above).\n",
      "     |        Order in which `fetches` operations are evaluated inside the call\n",
      "     |        is undefined.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        RuntimeError: If this `Session` is in an invalid state (e.g. has been\n",
      "     |          closed).\n",
      "     |        TypeError: If `fetches` or `feed_dict` keys are of an inappropriate type.\n",
      "     |        ValueError: If `fetches` or `feed_dict` keys are invalid or refer to a\n",
      "     |          `Tensor` that doesn't exist.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from BaseSession:\n",
      "     |  \n",
      "     |  graph\n",
      "     |      The graph that was launched in this session.\n",
      "     |  \n",
      "     |  graph_def\n",
      "     |      A serializable version of the underlying TensorFlow graph.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A graph_pb2.GraphDef proto containing nodes for all of the Operations in\n",
      "     |        the underlying TensorFlow graph.\n",
      "     |  \n",
      "     |  sess_str\n",
      "     |      The TensorFlow process to which this session will connect.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from SessionInterface:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class LMDBReader(ReaderBase)\n",
      "     |  A Reader that outputs the records from a LMDB file.\n",
      "     |  \n",
      "     |  See ReaderBase for supported methods.\n",
      "     |  \n",
      "     |  @compatibility(eager)\n",
      "     |  Readers are not compatible with eager execution. Instead, please\n",
      "     |  use `tf.data` to get data into your model.\n",
      "     |  @end_compatibility\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      LMDBReader\n",
      "     |      ReaderBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, name=None, options=None)\n",
      "     |      Create a LMDBReader. (deprecated)\n",
      "     |      \n",
      "     |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Queue-based input pipelines have been replaced by `tf.data`. Use `tf.contrib.data.LMDBDataset`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |        options: A LMDBRecordOptions object (optional).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ReaderBase:\n",
      "     |  \n",
      "     |  num_records_produced(self, name=None)\n",
      "     |      Returns the number of records this reader has produced.\n",
      "     |      \n",
      "     |      This is the same as the number of Read executions that have\n",
      "     |      succeeded.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An int64 Tensor.\n",
      "     |  \n",
      "     |  num_work_units_completed(self, name=None)\n",
      "     |      Returns the number of work units this reader has finished processing.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An int64 Tensor.\n",
      "     |  \n",
      "     |  read(self, queue, name=None)\n",
      "     |      Returns the next record (key, value) pair produced by a reader.\n",
      "     |      \n",
      "     |      Will dequeue a work unit from queue if necessary (e.g. when the\n",
      "     |      Reader needs to start reading from a new file since it has\n",
      "     |      finished with the previous file).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        queue: A Queue or a mutable string Tensor representing a handle\n",
      "     |          to a Queue, with string work items.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A tuple of Tensors (key, value).\n",
      "     |        key: A string scalar Tensor.\n",
      "     |        value: A string scalar Tensor.\n",
      "     |  \n",
      "     |  read_up_to(self, queue, num_records, name=None)\n",
      "     |      Returns up to num_records (key, value) pairs produced by a reader.\n",
      "     |      \n",
      "     |      Will dequeue a work unit from queue if necessary (e.g., when the\n",
      "     |      Reader needs to start reading from a new file since it has\n",
      "     |      finished with the previous file).\n",
      "     |      It may return less than num_records even before the last batch.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        queue: A Queue or a mutable string Tensor representing a handle\n",
      "     |          to a Queue, with string work items.\n",
      "     |        num_records: Number of records to read.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A tuple of Tensors (keys, values).\n",
      "     |        keys: A 1-D string Tensor.\n",
      "     |        values: A 1-D string Tensor.\n",
      "     |  \n",
      "     |  reset(self, name=None)\n",
      "     |      Restore a reader to its initial clean state.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The created Operation.\n",
      "     |  \n",
      "     |  restore_state(self, state, name=None)\n",
      "     |      Restore a reader to a previously saved state.\n",
      "     |      \n",
      "     |      Not all Readers support being restored, so this can produce an\n",
      "     |      Unimplemented error.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        state: A string Tensor.\n",
      "     |          Result of a SerializeState of a Reader with matching type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The created Operation.\n",
      "     |  \n",
      "     |  serialize_state(self, name=None)\n",
      "     |      Produce a string tensor that encodes the state of a reader.\n",
      "     |      \n",
      "     |      Not all Readers support being serialized, so this can produce an\n",
      "     |      Unimplemented error.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A string Tensor.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from ReaderBase:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  reader_ref\n",
      "     |      Op that implements the reader.\n",
      "     |  \n",
      "     |  supports_serialize\n",
      "     |      Whether the Reader implementation can serialize its state.\n",
      "    \n",
      "    class LogMessage(google.protobuf.pyext._message.CMessage, google.protobuf.message.Message)\n",
      "     |  A ProtocolMessage\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      LogMessage\n",
      "     |      google.protobuf.pyext._message.CMessage\n",
      "     |      google.protobuf.message.Message\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  level\n",
      "     |      Field tensorflow.LogMessage.level\n",
      "     |  \n",
      "     |  message\n",
      "     |      Field tensorflow.LogMessage.message\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  DEBUGGING = 10\n",
      "     |  \n",
      "     |  DESCRIPTOR = <google.protobuf.pyext._message.MessageDescriptor object>\n",
      "     |  \n",
      "     |  ERROR = 40\n",
      "     |  \n",
      "     |  FATAL = 50\n",
      "     |  \n",
      "     |  INFO = 20\n",
      "     |  \n",
      "     |  Level = <google.protobuf.internal.enum_type_wrapper.EnumTypeWrapper ob...\n",
      "     |  \n",
      "     |  UNKNOWN = 0\n",
      "     |  \n",
      "     |  WARN = 30\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.pyext._message.CMessage:\n",
      "     |  \n",
      "     |  ByteSize(...)\n",
      "     |      Returns the size of the message in bytes.\n",
      "     |  \n",
      "     |  Clear(...)\n",
      "     |      Clears the message.\n",
      "     |  \n",
      "     |  ClearExtension(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  ClearField(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  CopyFrom(...)\n",
      "     |      Copies a protocol message into the current message.\n",
      "     |  \n",
      "     |  DiscardUnknownFields(...)\n",
      "     |      Discards the unknown fields.\n",
      "     |  \n",
      "     |  FindInitializationErrors(...)\n",
      "     |      Finds unset required fields.\n",
      "     |  \n",
      "     |  FromString(...) from google.protobuf.pyext.cpp_message.GeneratedProtocolMessageType\n",
      "     |      Creates new method instance from given serialized data.\n",
      "     |  \n",
      "     |  HasExtension(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  HasField(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  IsInitialized(...)\n",
      "     |      Checks if all required fields of a protocol message are set.\n",
      "     |  \n",
      "     |  ListFields(...)\n",
      "     |      Lists all set fields of a message.\n",
      "     |  \n",
      "     |  MergeFrom(...)\n",
      "     |      Merges a protocol message into the current message.\n",
      "     |  \n",
      "     |  MergeFromString(...)\n",
      "     |      Merges a serialized message into the current message.\n",
      "     |  \n",
      "     |  ParseFromString(...)\n",
      "     |      Parses a serialized message into the current message.\n",
      "     |  \n",
      "     |  RegisterExtension(...) from google.protobuf.pyext.cpp_message.GeneratedProtocolMessageType\n",
      "     |      Registers an extension with the current message.\n",
      "     |  \n",
      "     |  SerializePartialToString(...)\n",
      "     |      Serializes the message to a string, even if it isn't initialized.\n",
      "     |  \n",
      "     |  SerializeToString(...)\n",
      "     |      Serializes the message to a string, only for initialized messages.\n",
      "     |  \n",
      "     |  SetInParent(...)\n",
      "     |      Sets the has bit of the given field in its parent message.\n",
      "     |  \n",
      "     |  UnknownFields(...)\n",
      "     |      Parse unknown field set\n",
      "     |  \n",
      "     |  WhichOneof(...)\n",
      "     |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      Makes a deep copy of the class.\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from google.protobuf.pyext._message.MessageMeta\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  __unicode__(...)\n",
      "     |      Outputs a unicode representation of the message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google.protobuf.pyext._message.CMessage:\n",
      "     |  \n",
      "     |  Extensions\n",
      "     |      Extension dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from google.protobuf.pyext._message.CMessage:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Support the pickle protocol.\n",
      "    \n",
      "    class MetaGraphDef(google.protobuf.pyext._message.CMessage, google.protobuf.message.Message)\n",
      "     |  A ProtocolMessage\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      MetaGraphDef\n",
      "     |      google.protobuf.pyext._message.CMessage\n",
      "     |      google.protobuf.message.Message\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  asset_file_def\n",
      "     |      Field tensorflow.MetaGraphDef.asset_file_def\n",
      "     |  \n",
      "     |  collection_def\n",
      "     |      Field tensorflow.MetaGraphDef.collection_def\n",
      "     |  \n",
      "     |  graph_def\n",
      "     |      Field tensorflow.MetaGraphDef.graph_def\n",
      "     |  \n",
      "     |  meta_info_def\n",
      "     |      Field tensorflow.MetaGraphDef.meta_info_def\n",
      "     |  \n",
      "     |  object_graph_def\n",
      "     |      Field tensorflow.MetaGraphDef.object_graph_def\n",
      "     |  \n",
      "     |  saver_def\n",
      "     |      Field tensorflow.MetaGraphDef.saver_def\n",
      "     |  \n",
      "     |  signature_def\n",
      "     |      Field tensorflow.MetaGraphDef.signature_def\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  CollectionDefEntry = <class 'tensorflow.core.protobuf.meta_graph_pb2.C...\n",
      "     |      A ProtocolMessage\n",
      "     |  \n",
      "     |  DESCRIPTOR = <google.protobuf.pyext._message.MessageDescriptor object>\n",
      "     |  \n",
      "     |  MetaInfoDef = <class 'tensorflow.core.protobuf.meta_graph_pb2.MetaInfo...\n",
      "     |      A ProtocolMessage\n",
      "     |  \n",
      "     |  SignatureDefEntry = <class 'tensorflow.core.protobuf.meta_graph_pb2.Si...\n",
      "     |      A ProtocolMessage\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.pyext._message.CMessage:\n",
      "     |  \n",
      "     |  ByteSize(...)\n",
      "     |      Returns the size of the message in bytes.\n",
      "     |  \n",
      "     |  Clear(...)\n",
      "     |      Clears the message.\n",
      "     |  \n",
      "     |  ClearExtension(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  ClearField(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  CopyFrom(...)\n",
      "     |      Copies a protocol message into the current message.\n",
      "     |  \n",
      "     |  DiscardUnknownFields(...)\n",
      "     |      Discards the unknown fields.\n",
      "     |  \n",
      "     |  FindInitializationErrors(...)\n",
      "     |      Finds unset required fields.\n",
      "     |  \n",
      "     |  FromString(...) from google.protobuf.pyext.cpp_message.GeneratedProtocolMessageType\n",
      "     |      Creates new method instance from given serialized data.\n",
      "     |  \n",
      "     |  HasExtension(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  HasField(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  IsInitialized(...)\n",
      "     |      Checks if all required fields of a protocol message are set.\n",
      "     |  \n",
      "     |  ListFields(...)\n",
      "     |      Lists all set fields of a message.\n",
      "     |  \n",
      "     |  MergeFrom(...)\n",
      "     |      Merges a protocol message into the current message.\n",
      "     |  \n",
      "     |  MergeFromString(...)\n",
      "     |      Merges a serialized message into the current message.\n",
      "     |  \n",
      "     |  ParseFromString(...)\n",
      "     |      Parses a serialized message into the current message.\n",
      "     |  \n",
      "     |  RegisterExtension(...) from google.protobuf.pyext.cpp_message.GeneratedProtocolMessageType\n",
      "     |      Registers an extension with the current message.\n",
      "     |  \n",
      "     |  SerializePartialToString(...)\n",
      "     |      Serializes the message to a string, even if it isn't initialized.\n",
      "     |  \n",
      "     |  SerializeToString(...)\n",
      "     |      Serializes the message to a string, only for initialized messages.\n",
      "     |  \n",
      "     |  SetInParent(...)\n",
      "     |      Sets the has bit of the given field in its parent message.\n",
      "     |  \n",
      "     |  UnknownFields(...)\n",
      "     |      Parse unknown field set\n",
      "     |  \n",
      "     |  WhichOneof(...)\n",
      "     |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      Makes a deep copy of the class.\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from google.protobuf.pyext._message.MessageMeta\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  __unicode__(...)\n",
      "     |      Outputs a unicode representation of the message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google.protobuf.pyext._message.CMessage:\n",
      "     |  \n",
      "     |  Extensions\n",
      "     |      Extension dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from google.protobuf.pyext._message.CMessage:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Support the pickle protocol.\n",
      "    \n",
      "    class Module(tensorflow.python.training.tracking.tracking.AutoTrackable)\n",
      "     |  Base neural network module class.\n",
      "     |  \n",
      "     |  A module is a named container for `tf.Variable`s, other `tf.Module`s and\n",
      "     |  functions which apply to user input. For example a dense layer in a neural\n",
      "     |  network might be implemented as a `tf.Module`:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |   class Dense(tf.Module):\n",
      "     |     def __init__(self, in_features, output_features, name=None):\n",
      "     |       super(Dense, self).__init__(name=name)\n",
      "     |       self.w = tf.Variable(\n",
      "     |           tf.random.normal([input_features, output_features]), name='w')\n",
      "     |       self.b = tf.Variable(tf.zeros([output_features]), name='b')\n",
      "     |  \n",
      "     |     def __call__(self, x):\n",
      "     |       y = tf.matmul(x, self.w) + self.b\n",
      "     |       return tf.nn.relu(y)\n",
      "     |  ```\n",
      "     |  \n",
      "     |  You can use the Dense layer as you would expect:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  d = Dense(input_features=64, output_features=10)\n",
      "     |  d(tf.ones([100, 64]))\n",
      "     |  #==> <tf.Tensor: ...>\n",
      "     |  ```\n",
      "     |  \n",
      "     |  By subclassing `tf.Module` instead of `object` any `tf.Variable` or\n",
      "     |  `tf.Module` instances assigned to object properties can be collected using\n",
      "     |  the `variables`, `trainable_variables` or `submodules` property:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  d.variables\n",
      "     |  #==> (<tf.Variable 'b:0' ...>, <tf.Variable 'w:0' ...>)\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Subclasses of `tf.Module` can also take advantage of the `_flatten` method\n",
      "     |  which can be used to implement tracking of any other types.\n",
      "     |  \n",
      "     |  All `tf.Module` classes have an associated `tf.name_scope` which can be used\n",
      "     |  to group operations in TensorBoard and create hierarchies for variable names\n",
      "     |  which can help with debugging. We suggest using the name scope when creating\n",
      "     |  nested submodules/parameters or for forward methods whose graph you might want\n",
      "     |  to inspect in TensorBoard. You can enter the name scope explicitly using\n",
      "     |  `with self.name_scope:` or you can annotate methods (apart from `__init__`)\n",
      "     |  with `@tf.Module.with_name_scope`.\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  class MLP(tf.Module):\n",
      "     |    def __init__(self, input_size, sizes, name=None):\n",
      "     |      super(MLP, self).__init__(name=name)\n",
      "     |      self.layers = []\n",
      "     |      with self.name_scope:\n",
      "     |        for size in sizes:\n",
      "     |          self.layers.append(Dense(input_size=input_size, output_size=size))\n",
      "     |          input_size = size\n",
      "     |  \n",
      "     |    @tf.Module.with_name_scope\n",
      "     |    def __call__(self, x):\n",
      "     |      for layer in self.layers:\n",
      "     |        x = layer(x)\n",
      "     |      return x\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Module\n",
      "     |      tensorflow.python.training.tracking.tracking.AutoTrackable\n",
      "     |      tensorflow.python.training.tracking.base.Trackable\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, name=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  with_name_scope(method) from builtins.type\n",
      "     |      Decorator to automatically enter the module name scope.\n",
      "     |      \n",
      "     |      ```\n",
      "     |      class MyModule(tf.Module):\n",
      "     |        @tf.Module.with_name_scope\n",
      "     |        def __call__(self, x):\n",
      "     |          if not hasattr(self, 'w'):\n",
      "     |            self.w = tf.Variable(tf.random.normal([x.shape[1], 64]))\n",
      "     |          return tf.matmul(x, self.w)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      "     |      names included the module name:\n",
      "     |      \n",
      "     |      ```\n",
      "     |      mod = MyModule()\n",
      "     |      mod(tf.ones([8, 32]))\n",
      "     |      # ==> <tf.Tensor: ...>\n",
      "     |      mod.w\n",
      "     |      # ==> <tf.Variable ...'my_module/w:0'>\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        method: The method to wrap.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The original method wrapped such that it enters the module's name scope.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  name\n",
      "     |      Returns the name of this module as passed or determined in the ctor.\n",
      "     |      \n",
      "     |      NOTE: This is not the same as the `self.name_scope.name` which includes\n",
      "     |      parent module names.\n",
      "     |  \n",
      "     |  name_scope\n",
      "     |      Returns a `tf.name_scope` instance for this class.\n",
      "     |  \n",
      "     |  submodules\n",
      "     |      Sequence of all sub-modules.\n",
      "     |      \n",
      "     |      Submodules are modules which are properties of this module, or found as\n",
      "     |      properties of modules which are properties of this module (and so on).\n",
      "     |      \n",
      "     |      ```\n",
      "     |      a = tf.Module()\n",
      "     |      b = tf.Module()\n",
      "     |      c = tf.Module()\n",
      "     |      a.b = b\n",
      "     |      b.c = c\n",
      "     |      assert list(a.submodules) == [b, c]\n",
      "     |      assert list(b.submodules) == [c]\n",
      "     |      assert list(c.submodules) == []\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A sequence of all submodules.\n",
      "     |  \n",
      "     |  trainable_variables\n",
      "     |      Sequence of variables owned by this module and it's submodules.\n",
      "     |      \n",
      "     |      Note: this method uses reflection to find variables on the current instance\n",
      "     |      and submodules. For performance reasons you may wish to cache the result\n",
      "     |      of calling this method if you don't expect the return value to change.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A sequence of variables for the current module (sorted by attribute\n",
      "     |        name) followed by variables from all submodules recursively (breadth\n",
      "     |        first).\n",
      "     |  \n",
      "     |  variables\n",
      "     |      Sequence of variables owned by this module and it's submodules.\n",
      "     |      \n",
      "     |      Note: this method uses reflection to find variables on the current instance\n",
      "     |      and submodules. For performance reasons you may wish to cache the result\n",
      "     |      of calling this method if you don't expect the return value to change.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A sequence of variables for the current module (sorted by attribute\n",
      "     |        name) followed by variables from all submodules recursively (breadth\n",
      "     |        first).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tensorflow.python.training.tracking.tracking.AutoTrackable:\n",
      "     |  \n",
      "     |  __delattr__(self, name)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |      Support self.foo = trackable syntax.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class NameAttrList(google.protobuf.pyext._message.CMessage, google.protobuf.message.Message)\n",
      "     |  A ProtocolMessage\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      NameAttrList\n",
      "     |      google.protobuf.pyext._message.CMessage\n",
      "     |      google.protobuf.message.Message\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  attr\n",
      "     |      Field tensorflow.NameAttrList.attr\n",
      "     |  \n",
      "     |  name\n",
      "     |      Field tensorflow.NameAttrList.name\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  AttrEntry = <class 'tensorflow.core.framework.attr_value_pb2.AttrEntry...\n",
      "     |      A ProtocolMessage\n",
      "     |  \n",
      "     |  DESCRIPTOR = <google.protobuf.pyext._message.MessageDescriptor object>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.pyext._message.CMessage:\n",
      "     |  \n",
      "     |  ByteSize(...)\n",
      "     |      Returns the size of the message in bytes.\n",
      "     |  \n",
      "     |  Clear(...)\n",
      "     |      Clears the message.\n",
      "     |  \n",
      "     |  ClearExtension(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  ClearField(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  CopyFrom(...)\n",
      "     |      Copies a protocol message into the current message.\n",
      "     |  \n",
      "     |  DiscardUnknownFields(...)\n",
      "     |      Discards the unknown fields.\n",
      "     |  \n",
      "     |  FindInitializationErrors(...)\n",
      "     |      Finds unset required fields.\n",
      "     |  \n",
      "     |  FromString(...) from google.protobuf.pyext.cpp_message.GeneratedProtocolMessageType\n",
      "     |      Creates new method instance from given serialized data.\n",
      "     |  \n",
      "     |  HasExtension(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  HasField(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  IsInitialized(...)\n",
      "     |      Checks if all required fields of a protocol message are set.\n",
      "     |  \n",
      "     |  ListFields(...)\n",
      "     |      Lists all set fields of a message.\n",
      "     |  \n",
      "     |  MergeFrom(...)\n",
      "     |      Merges a protocol message into the current message.\n",
      "     |  \n",
      "     |  MergeFromString(...)\n",
      "     |      Merges a serialized message into the current message.\n",
      "     |  \n",
      "     |  ParseFromString(...)\n",
      "     |      Parses a serialized message into the current message.\n",
      "     |  \n",
      "     |  RegisterExtension(...) from google.protobuf.pyext.cpp_message.GeneratedProtocolMessageType\n",
      "     |      Registers an extension with the current message.\n",
      "     |  \n",
      "     |  SerializePartialToString(...)\n",
      "     |      Serializes the message to a string, even if it isn't initialized.\n",
      "     |  \n",
      "     |  SerializeToString(...)\n",
      "     |      Serializes the message to a string, only for initialized messages.\n",
      "     |  \n",
      "     |  SetInParent(...)\n",
      "     |      Sets the has bit of the given field in its parent message.\n",
      "     |  \n",
      "     |  UnknownFields(...)\n",
      "     |      Parse unknown field set\n",
      "     |  \n",
      "     |  WhichOneof(...)\n",
      "     |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      Makes a deep copy of the class.\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from google.protobuf.pyext._message.MessageMeta\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  __unicode__(...)\n",
      "     |      Outputs a unicode representation of the message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google.protobuf.pyext._message.CMessage:\n",
      "     |  \n",
      "     |  Extensions\n",
      "     |      Extension dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from google.protobuf.pyext._message.CMessage:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Support the pickle protocol.\n",
      "    \n",
      "    class NodeDef(google.protobuf.pyext._message.CMessage, google.protobuf.message.Message)\n",
      "     |  A ProtocolMessage\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      NodeDef\n",
      "     |      google.protobuf.pyext._message.CMessage\n",
      "     |      google.protobuf.message.Message\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  attr\n",
      "     |      Field tensorflow.NodeDef.attr\n",
      "     |  \n",
      "     |  device\n",
      "     |      Field tensorflow.NodeDef.device\n",
      "     |  \n",
      "     |  experimental_debug_info\n",
      "     |      Field tensorflow.NodeDef.experimental_debug_info\n",
      "     |  \n",
      "     |  input\n",
      "     |      Field tensorflow.NodeDef.input\n",
      "     |  \n",
      "     |  name\n",
      "     |      Field tensorflow.NodeDef.name\n",
      "     |  \n",
      "     |  op\n",
      "     |      Field tensorflow.NodeDef.op\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  AttrEntry = <class 'tensorflow.core.framework.node_def_pb2.AttrEntry'>\n",
      "     |      A ProtocolMessage\n",
      "     |  \n",
      "     |  DESCRIPTOR = <google.protobuf.pyext._message.MessageDescriptor object>\n",
      "     |  \n",
      "     |  ExperimentalDebugInfo = <class 'tensorflow.core.framework.node_def_pb2...\n",
      "     |      A ProtocolMessage\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.pyext._message.CMessage:\n",
      "     |  \n",
      "     |  ByteSize(...)\n",
      "     |      Returns the size of the message in bytes.\n",
      "     |  \n",
      "     |  Clear(...)\n",
      "     |      Clears the message.\n",
      "     |  \n",
      "     |  ClearExtension(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  ClearField(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  CopyFrom(...)\n",
      "     |      Copies a protocol message into the current message.\n",
      "     |  \n",
      "     |  DiscardUnknownFields(...)\n",
      "     |      Discards the unknown fields.\n",
      "     |  \n",
      "     |  FindInitializationErrors(...)\n",
      "     |      Finds unset required fields.\n",
      "     |  \n",
      "     |  FromString(...) from google.protobuf.pyext.cpp_message.GeneratedProtocolMessageType\n",
      "     |      Creates new method instance from given serialized data.\n",
      "     |  \n",
      "     |  HasExtension(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  HasField(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  IsInitialized(...)\n",
      "     |      Checks if all required fields of a protocol message are set.\n",
      "     |  \n",
      "     |  ListFields(...)\n",
      "     |      Lists all set fields of a message.\n",
      "     |  \n",
      "     |  MergeFrom(...)\n",
      "     |      Merges a protocol message into the current message.\n",
      "     |  \n",
      "     |  MergeFromString(...)\n",
      "     |      Merges a serialized message into the current message.\n",
      "     |  \n",
      "     |  ParseFromString(...)\n",
      "     |      Parses a serialized message into the current message.\n",
      "     |  \n",
      "     |  RegisterExtension(...) from google.protobuf.pyext.cpp_message.GeneratedProtocolMessageType\n",
      "     |      Registers an extension with the current message.\n",
      "     |  \n",
      "     |  SerializePartialToString(...)\n",
      "     |      Serializes the message to a string, even if it isn't initialized.\n",
      "     |  \n",
      "     |  SerializeToString(...)\n",
      "     |      Serializes the message to a string, only for initialized messages.\n",
      "     |  \n",
      "     |  SetInParent(...)\n",
      "     |      Sets the has bit of the given field in its parent message.\n",
      "     |  \n",
      "     |  UnknownFields(...)\n",
      "     |      Parse unknown field set\n",
      "     |  \n",
      "     |  WhichOneof(...)\n",
      "     |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      Makes a deep copy of the class.\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from google.protobuf.pyext._message.MessageMeta\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  __unicode__(...)\n",
      "     |      Outputs a unicode representation of the message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google.protobuf.pyext._message.CMessage:\n",
      "     |  \n",
      "     |  Extensions\n",
      "     |      Extension dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from google.protobuf.pyext._message.CMessage:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Support the pickle protocol.\n",
      "    \n",
      "    class OpError(builtins.Exception)\n",
      "     |  A generic error that is raised when TensorFlow execution fails.\n",
      "     |  \n",
      "     |  Whenever possible, the session will raise a more specific subclass\n",
      "     |  of `OpError` from the `tf.errors` module.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      OpError\n",
      "     |      builtins.Exception\n",
      "     |      builtins.BaseException\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, node_def, op, message, error_code)\n",
      "     |      Creates a new `OpError` indicating that a particular op failed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        node_def: The `node_def_pb2.NodeDef` proto representing the op that\n",
      "     |          failed, if known; otherwise None.\n",
      "     |        op: The `ops.Operation` that failed, if known; otherwise None.\n",
      "     |        message: The message string describing the failure.\n",
      "     |        error_code: The `error_codes_pb2.Code` describing the error.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  error_code\n",
      "     |      The integer error code that describes the error.\n",
      "     |  \n",
      "     |  message\n",
      "     |      The error message that describes the error.\n",
      "     |  \n",
      "     |  node_def\n",
      "     |      The `NodeDef` proto representing the op that failed.\n",
      "     |  \n",
      "     |  op\n",
      "     |      The operation that failed, if known.\n",
      "     |      \n",
      "     |      *N.B.* If the failed op was synthesized at runtime, e.g. a `Send`\n",
      "     |      or `Recv` op, there will be no corresponding\n",
      "     |      `tf.Operation`\n",
      "     |      object.  In that case, this will return `None`, and you should\n",
      "     |      instead use the `tf.errors.OpError.node_def` to\n",
      "     |      discover information about the op.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The `Operation` that failed, or None.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.Exception:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  with_traceback(...)\n",
      "     |      Exception.with_traceback(tb) --\n",
      "     |      set self.__traceback__ to tb and return self.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __cause__\n",
      "     |      exception cause\n",
      "     |  \n",
      "     |  __context__\n",
      "     |      exception context\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  __suppress_context__\n",
      "     |  \n",
      "     |  __traceback__\n",
      "     |  \n",
      "     |  args\n",
      "    \n",
      "    class Operation(builtins.object)\n",
      "     |  Represents a graph node that performs computation on tensors.\n",
      "     |  \n",
      "     |  An `Operation` is a node in a TensorFlow `Graph` that takes zero or\n",
      "     |  more `Tensor` objects as input, and produces zero or more `Tensor`\n",
      "     |  objects as output. Objects of type `Operation` are created by\n",
      "     |  calling a Python op constructor (such as\n",
      "     |  `tf.matmul`)\n",
      "     |  or `tf.Graph.create_op`.\n",
      "     |  \n",
      "     |  For example `c = tf.matmul(a, b)` creates an `Operation` of type\n",
      "     |  \"MatMul\" that takes tensors `a` and `b` as input, and produces `c`\n",
      "     |  as output.\n",
      "     |  \n",
      "     |  After the graph has been launched in a session, an `Operation` can\n",
      "     |  be executed by passing it to\n",
      "     |  `tf.Session.run`.\n",
      "     |  `op.run()` is a shortcut for calling\n",
      "     |  `tf.compat.v1.get_default_session().run(op)`.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, node_def, g, inputs=None, output_types=None, control_inputs=None, input_types=None, original_op=None, op_def=None)\n",
      "     |      Creates an `Operation`.\n",
      "     |      \n",
      "     |      NOTE: This constructor validates the name of the `Operation` (passed\n",
      "     |      as `node_def.name`). Valid `Operation` names match the following\n",
      "     |      regular expression:\n",
      "     |      \n",
      "     |          [A-Za-z0-9.][A-Za-z0-9_.\\\\-/]*\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        node_def: `node_def_pb2.NodeDef`.  `NodeDef` for the `Operation`. Used for\n",
      "     |          attributes of `node_def_pb2.NodeDef`, typically `name`, `op`, and\n",
      "     |          `device`.  The `input` attribute is irrelevant here as it will be\n",
      "     |          computed when generating the model.\n",
      "     |        g: `Graph`. The parent graph.\n",
      "     |        inputs: list of `Tensor` objects. The inputs to this `Operation`.\n",
      "     |        output_types: list of `DType` objects.  List of the types of the `Tensors`\n",
      "     |          computed by this operation.  The length of this list indicates the\n",
      "     |          number of output endpoints of the `Operation`.\n",
      "     |        control_inputs: list of operations or tensors from which to have a control\n",
      "     |          dependency.\n",
      "     |        input_types: List of `DType` objects representing the types of the tensors\n",
      "     |          accepted by the `Operation`.  By default uses `[x.dtype.base_dtype for x\n",
      "     |          in inputs]`.  Operations that expect reference-typed inputs must specify\n",
      "     |          these explicitly.\n",
      "     |        original_op: Optional. Used to associate the new `Operation` with an\n",
      "     |          existing `Operation` (for example, a replica with the op that was\n",
      "     |          replicated).\n",
      "     |        op_def: Optional. The `op_def_pb2.OpDef` proto that describes the op type\n",
      "     |          that this `Operation` represents.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: if control inputs are not Operations or Tensors,\n",
      "     |          or if `node_def` is not a `NodeDef`,\n",
      "     |          or if `g` is not a `Graph`,\n",
      "     |          or if `inputs` are not tensors,\n",
      "     |          or if `inputs` and `input_types` are incompatible.\n",
      "     |        ValueError: if the `node_def` name is not valid.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  colocation_groups(self)\n",
      "     |      Returns the list of colocation groups of the op.\n",
      "     |  \n",
      "     |  get_attr(self, name)\n",
      "     |      Returns the value of the attr of this op with the given `name`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: The name of the attr to fetch.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The value of the attr, as a Python object.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If this op does not have an attr with the given `name`.\n",
      "     |  \n",
      "     |  run(self, feed_dict=None, session=None)\n",
      "     |      Runs this operation in a `Session`.\n",
      "     |      \n",
      "     |      Calling this method will execute all preceding operations that\n",
      "     |      produce the inputs needed for this operation.\n",
      "     |      \n",
      "     |      *N.B.* Before invoking `Operation.run()`, its graph must have been\n",
      "     |      launched in a session, and either a default session must be\n",
      "     |      available, or `session` must be specified explicitly.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        feed_dict: A dictionary that maps `Tensor` objects to feed values. See\n",
      "     |          `tf.Session.run` for a description of the valid feed values.\n",
      "     |        session: (Optional.) The `Session` to be used to run to this operation. If\n",
      "     |          none, the default session will be used.\n",
      "     |  \n",
      "     |  values(self)\n",
      "     |      DEPRECATED: Use outputs.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  control_inputs\n",
      "     |      The `Operation` objects on which this op has a control dependency.\n",
      "     |      \n",
      "     |      Before this op is executed, TensorFlow will ensure that the\n",
      "     |      operations in `self.control_inputs` have finished executing. This\n",
      "     |      mechanism can be used to run ops sequentially for performance\n",
      "     |      reasons, or to ensure that the side effects of an op are observed\n",
      "     |      in the correct order.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A list of `Operation` objects.\n",
      "     |  \n",
      "     |  device\n",
      "     |      The name of the device to which this op has been assigned, if any.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The string name of the device to which this op has been\n",
      "     |        assigned, or an empty string if it has not been assigned to a\n",
      "     |        device.\n",
      "     |  \n",
      "     |  graph\n",
      "     |      The `Graph` that contains this operation.\n",
      "     |  \n",
      "     |  inputs\n",
      "     |      The list of `Tensor` objects representing the data inputs of this op.\n",
      "     |  \n",
      "     |  name\n",
      "     |      The full name of this operation.\n",
      "     |  \n",
      "     |  node_def\n",
      "     |      Returns the `NodeDef` representation of this operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A\n",
      "     |        [`NodeDef`](https://www.tensorflow.org/code/tensorflow/core/framework/node_def.proto)\n",
      "     |        protocol buffer.\n",
      "     |  \n",
      "     |  op_def\n",
      "     |      Returns the `OpDef` proto that represents the type of this op.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An\n",
      "     |        [`OpDef`](https://www.tensorflow.org/code/tensorflow/core/framework/op_def.proto)\n",
      "     |        protocol buffer.\n",
      "     |  \n",
      "     |  outputs\n",
      "     |      The list of `Tensor` objects representing the outputs of this op.\n",
      "     |  \n",
      "     |  traceback\n",
      "     |      Returns the call stack from when this operation was constructed.\n",
      "     |  \n",
      "     |  traceback_with_start_lines\n",
      "     |      Same as traceback but includes start line of function definition.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A list of 5-tuples (filename, lineno, name, code, func_start_lineno).\n",
      "     |  \n",
      "     |  type\n",
      "     |      The type of the op (e.g. `\"MatMul\"`).\n",
      "    \n",
      "    class OptimizerOptions(google.protobuf.pyext._message.CMessage, google.protobuf.message.Message)\n",
      "     |  A ProtocolMessage\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      OptimizerOptions\n",
      "     |      google.protobuf.pyext._message.CMessage\n",
      "     |      google.protobuf.message.Message\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  do_common_subexpression_elimination\n",
      "     |      Field tensorflow.OptimizerOptions.do_common_subexpression_elimination\n",
      "     |  \n",
      "     |  do_constant_folding\n",
      "     |      Field tensorflow.OptimizerOptions.do_constant_folding\n",
      "     |  \n",
      "     |  do_function_inlining\n",
      "     |      Field tensorflow.OptimizerOptions.do_function_inlining\n",
      "     |  \n",
      "     |  global_jit_level\n",
      "     |      Field tensorflow.OptimizerOptions.global_jit_level\n",
      "     |  \n",
      "     |  max_folded_constant_in_bytes\n",
      "     |      Field tensorflow.OptimizerOptions.max_folded_constant_in_bytes\n",
      "     |  \n",
      "     |  opt_level\n",
      "     |      Field tensorflow.OptimizerOptions.opt_level\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  DEFAULT = 0\n",
      "     |  \n",
      "     |  DESCRIPTOR = <google.protobuf.pyext._message.MessageDescriptor object>\n",
      "     |  \n",
      "     |  GlobalJitLevel = <google.protobuf.internal.enum_type_wrapper.EnumTypeW...\n",
      "     |  \n",
      "     |  L0 = -1\n",
      "     |  \n",
      "     |  L1 = 0\n",
      "     |  \n",
      "     |  Level = <google.protobuf.internal.enum_type_wrapper.EnumTypeWrapper ob...\n",
      "     |  \n",
      "     |  OFF = -1\n",
      "     |  \n",
      "     |  ON_1 = 1\n",
      "     |  \n",
      "     |  ON_2 = 2\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.pyext._message.CMessage:\n",
      "     |  \n",
      "     |  ByteSize(...)\n",
      "     |      Returns the size of the message in bytes.\n",
      "     |  \n",
      "     |  Clear(...)\n",
      "     |      Clears the message.\n",
      "     |  \n",
      "     |  ClearExtension(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  ClearField(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  CopyFrom(...)\n",
      "     |      Copies a protocol message into the current message.\n",
      "     |  \n",
      "     |  DiscardUnknownFields(...)\n",
      "     |      Discards the unknown fields.\n",
      "     |  \n",
      "     |  FindInitializationErrors(...)\n",
      "     |      Finds unset required fields.\n",
      "     |  \n",
      "     |  FromString(...) from google.protobuf.pyext.cpp_message.GeneratedProtocolMessageType\n",
      "     |      Creates new method instance from given serialized data.\n",
      "     |  \n",
      "     |  HasExtension(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  HasField(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  IsInitialized(...)\n",
      "     |      Checks if all required fields of a protocol message are set.\n",
      "     |  \n",
      "     |  ListFields(...)\n",
      "     |      Lists all set fields of a message.\n",
      "     |  \n",
      "     |  MergeFrom(...)\n",
      "     |      Merges a protocol message into the current message.\n",
      "     |  \n",
      "     |  MergeFromString(...)\n",
      "     |      Merges a serialized message into the current message.\n",
      "     |  \n",
      "     |  ParseFromString(...)\n",
      "     |      Parses a serialized message into the current message.\n",
      "     |  \n",
      "     |  RegisterExtension(...) from google.protobuf.pyext.cpp_message.GeneratedProtocolMessageType\n",
      "     |      Registers an extension with the current message.\n",
      "     |  \n",
      "     |  SerializePartialToString(...)\n",
      "     |      Serializes the message to a string, even if it isn't initialized.\n",
      "     |  \n",
      "     |  SerializeToString(...)\n",
      "     |      Serializes the message to a string, only for initialized messages.\n",
      "     |  \n",
      "     |  SetInParent(...)\n",
      "     |      Sets the has bit of the given field in its parent message.\n",
      "     |  \n",
      "     |  UnknownFields(...)\n",
      "     |      Parse unknown field set\n",
      "     |  \n",
      "     |  WhichOneof(...)\n",
      "     |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      Makes a deep copy of the class.\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from google.protobuf.pyext._message.MessageMeta\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  __unicode__(...)\n",
      "     |      Outputs a unicode representation of the message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google.protobuf.pyext._message.CMessage:\n",
      "     |  \n",
      "     |  Extensions\n",
      "     |      Extension dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from google.protobuf.pyext._message.CMessage:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Support the pickle protocol.\n",
      "    \n",
      "    class OptionalSpec(tensorflow.python.framework.type_spec.TypeSpec)\n",
      "     |  Represents an optional potentially containing a structured value.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      OptionalSpec\n",
      "     |      tensorflow.python.framework.type_spec.TypeSpec\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, value_structure)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  from_value(value)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  value_type\n",
      "     |      The Python type for values that are compatible with this TypeSpec.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tensorflow.python.framework.type_spec.TypeSpec:\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __ne__(self, other)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  is_compatible_with(self, spec_or_value)\n",
      "     |      Returns true if `spec_or_value` is compatible with this TypeSpec.\n",
      "     |  \n",
      "     |  most_specific_compatible_type(self, other)\n",
      "     |      Returns the most specific TypeSpec compatible with `self` and `other`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: A `TypeSpec`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If there is no TypeSpec that is compatible with both `self`\n",
      "     |          and `other`.\n",
      "    \n",
      "    class PaddingFIFOQueue(QueueBase)\n",
      "     |  A FIFOQueue that supports batching variable-sized tensors by padding.\n",
      "     |  \n",
      "     |  A `PaddingFIFOQueue` may contain components with dynamic shape, while also\n",
      "     |  supporting `dequeue_many`.  See the constructor for more details.\n",
      "     |  \n",
      "     |  See `tf.queue.QueueBase` for a description of the methods on\n",
      "     |  this class.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      PaddingFIFOQueue\n",
      "     |      QueueBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, capacity, dtypes, shapes, names=None, shared_name=None, name='padding_fifo_queue')\n",
      "     |      Creates a queue that dequeues elements in a first-in first-out order.\n",
      "     |      \n",
      "     |      A `PaddingFIFOQueue` has bounded capacity; supports multiple concurrent\n",
      "     |      producers and consumers; and provides exactly-once delivery.\n",
      "     |      \n",
      "     |      A `PaddingFIFOQueue` holds a list of up to `capacity` elements. Each\n",
      "     |      element is a fixed-length tuple of tensors whose dtypes are\n",
      "     |      described by `dtypes`, and whose shapes are described by the `shapes`\n",
      "     |      argument.\n",
      "     |      \n",
      "     |      The `shapes` argument must be specified; each component of a queue\n",
      "     |      element must have the respective shape.  Shapes of fixed\n",
      "     |      rank but variable size are allowed by setting any shape dimension to None.\n",
      "     |      In this case, the inputs' shape may vary along the given dimension, and\n",
      "     |      `dequeue_many` will pad the given dimension with zeros up to the maximum\n",
      "     |      shape of all elements in the given batch.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        capacity: An integer. The upper bound on the number of elements\n",
      "     |          that may be stored in this queue.\n",
      "     |        dtypes:  A list of `DType` objects. The length of `dtypes` must equal\n",
      "     |          the number of tensors in each queue element.\n",
      "     |        shapes: A list of `TensorShape` objects, with the same length as\n",
      "     |          `dtypes`.  Any dimension in the `TensorShape` containing value\n",
      "     |          `None` is dynamic and allows values to be enqueued with\n",
      "     |           variable size in that dimension.\n",
      "     |        names: (Optional.) A list of string naming the components in the queue\n",
      "     |          with the same length as `dtypes`, or `None`.  If specified the dequeue\n",
      "     |          methods return a dictionary with the names as keys.\n",
      "     |        shared_name: (Optional.) If non-empty, this queue will be shared under\n",
      "     |          the given name across multiple sessions.\n",
      "     |        name: Optional name for the queue operation.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If shapes is not a list of shapes, or the lengths of dtypes\n",
      "     |          and shapes do not match, or if names is specified and the lengths of\n",
      "     |          dtypes and names do not match.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from QueueBase:\n",
      "     |  \n",
      "     |  close(self, cancel_pending_enqueues=False, name=None)\n",
      "     |      Closes this queue.\n",
      "     |      \n",
      "     |      This operation signals that no more elements will be enqueued in\n",
      "     |      the given queue. Subsequent `enqueue` and `enqueue_many`\n",
      "     |      operations will fail. Subsequent `dequeue` and `dequeue_many`\n",
      "     |      operations will continue to succeed if sufficient elements remain\n",
      "     |      in the queue. Subsequently dequeue and dequeue_many operations\n",
      "     |      that would otherwise block waiting for more elements (if close\n",
      "     |      hadn't been called) will now fail immediately.\n",
      "     |      \n",
      "     |      If `cancel_pending_enqueues` is `True`, all pending requests will also\n",
      "     |      be canceled.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        cancel_pending_enqueues: (Optional.) A boolean, defaulting to\n",
      "     |          `False` (described above).\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The operation that closes the queue.\n",
      "     |  \n",
      "     |  dequeue(self, name=None)\n",
      "     |      Dequeues one element from this queue.\n",
      "     |      \n",
      "     |      If the queue is empty when this operation executes, it will block\n",
      "     |      until there is an element to dequeue.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed, the queue is empty, and there are no pending\n",
      "     |      enqueue operations that can fulfill this request,\n",
      "     |      `tf.errors.OutOfRangeError` will be raised. If the session is\n",
      "     |      `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The tuple of tensors that was dequeued.\n",
      "     |  \n",
      "     |  dequeue_many(self, n, name=None)\n",
      "     |      Dequeues and concatenates `n` elements from this queue.\n",
      "     |      \n",
      "     |      This operation concatenates queue-element component tensors along\n",
      "     |      the 0th dimension to make a single component tensor.  All of the\n",
      "     |      components in the dequeued tuple will have size `n` in the 0th dimension.\n",
      "     |      \n",
      "     |      If the queue is closed and there are less than `n` elements left, then an\n",
      "     |      `OutOfRange` exception is raised.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed, the queue contains fewer than `n` elements, and\n",
      "     |      there are no pending enqueue operations that can fulfill this\n",
      "     |      request, `tf.errors.OutOfRangeError` will be raised. If the\n",
      "     |      session is `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        n: A scalar `Tensor` containing the number of elements to dequeue.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The list of concatenated tensors that was dequeued.\n",
      "     |  \n",
      "     |  dequeue_up_to(self, n, name=None)\n",
      "     |      Dequeues and concatenates `n` elements from this queue.\n",
      "     |      \n",
      "     |      **Note** This operation is not supported by all queues.  If a queue does not\n",
      "     |      support DequeueUpTo, then a `tf.errors.UnimplementedError` is raised.\n",
      "     |      \n",
      "     |      This operation concatenates queue-element component tensors along\n",
      "     |      the 0th dimension to make a single component tensor. If the queue\n",
      "     |      has not been closed, all of the components in the dequeued tuple\n",
      "     |      will have size `n` in the 0th dimension.\n",
      "     |      \n",
      "     |      If the queue is closed and there are more than `0` but fewer than\n",
      "     |      `n` elements remaining, then instead of raising a\n",
      "     |      `tf.errors.OutOfRangeError` like `tf.QueueBase.dequeue_many`,\n",
      "     |      less than `n` elements are returned immediately.  If the queue is\n",
      "     |      closed and there are `0` elements left in the queue, then a\n",
      "     |      `tf.errors.OutOfRangeError` is raised just like in `dequeue_many`.\n",
      "     |      Otherwise the behavior is identical to `dequeue_many`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        n: A scalar `Tensor` containing the number of elements to dequeue.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The tuple of concatenated tensors that was dequeued.\n",
      "     |  \n",
      "     |  enqueue(self, vals, name=None)\n",
      "     |      Enqueues one element to this queue.\n",
      "     |      \n",
      "     |      If the queue is full when this operation executes, it will block\n",
      "     |      until the element has been enqueued.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed before this operation runs,\n",
      "     |      `tf.errors.CancelledError` will be raised. If this operation is\n",
      "     |      blocked, and either (i) the queue is closed by a close operation\n",
      "     |      with `cancel_pending_enqueues=True`, or (ii) the session is\n",
      "     |      `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        vals: A tensor, a list or tuple of tensors, or a dictionary containing\n",
      "     |          the values to enqueue.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The operation that enqueues a new tuple of tensors to the queue.\n",
      "     |  \n",
      "     |  enqueue_many(self, vals, name=None)\n",
      "     |      Enqueues zero or more elements to this queue.\n",
      "     |      \n",
      "     |      This operation slices each component tensor along the 0th dimension to\n",
      "     |      make multiple queue elements. All of the tensors in `vals` must have the\n",
      "     |      same size in the 0th dimension.\n",
      "     |      \n",
      "     |      If the queue is full when this operation executes, it will block\n",
      "     |      until all of the elements have been enqueued.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed before this operation runs,\n",
      "     |      `tf.errors.CancelledError` will be raised. If this operation is\n",
      "     |      blocked, and either (i) the queue is closed by a close operation\n",
      "     |      with `cancel_pending_enqueues=True`, or (ii) the session is\n",
      "     |      `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        vals: A tensor, a list or tuple of tensors, or a dictionary\n",
      "     |          from which the queue elements are taken.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The operation that enqueues a batch of tuples of tensors to the queue.\n",
      "     |  \n",
      "     |  is_closed(self, name=None)\n",
      "     |      Returns true if queue is closed.\n",
      "     |      \n",
      "     |      This operation returns true if the queue is closed and false if the queue\n",
      "     |      is open.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        True if the queue is closed and false if the queue is open.\n",
      "     |  \n",
      "     |  size(self, name=None)\n",
      "     |      Compute the number of elements in this queue.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A scalar tensor containing the number of elements in this queue.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from QueueBase:\n",
      "     |  \n",
      "     |  from_list(index, queues)\n",
      "     |      Create a queue using the queue reference from `queues[index]`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        index: An integer scalar tensor that determines the input that gets\n",
      "     |          selected.\n",
      "     |        queues: A list of `QueueBase` objects.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `QueueBase` object.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: When `queues` is not a list of `QueueBase` objects,\n",
      "     |          or when the data types of `queues` are not all the same.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from QueueBase:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  dtypes\n",
      "     |      The list of dtypes for each component of a queue element.\n",
      "     |  \n",
      "     |  name\n",
      "     |      The name of the underlying queue.\n",
      "     |  \n",
      "     |  names\n",
      "     |      The list of names for each component of a queue element.\n",
      "     |  \n",
      "     |  queue_ref\n",
      "     |      The underlying queue reference.\n",
      "     |  \n",
      "     |  shapes\n",
      "     |      The list of shapes for each component of a queue element.\n",
      "    \n",
      "    class PriorityQueue(QueueBase)\n",
      "     |  A queue implementation that dequeues elements in prioritized order.\n",
      "     |  \n",
      "     |  See `tf.queue.QueueBase` for a description of the methods on\n",
      "     |  this class.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      PriorityQueue\n",
      "     |      QueueBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, capacity, types, shapes=None, names=None, shared_name=None, name='priority_queue')\n",
      "     |      Creates a queue that dequeues elements in a first-in first-out order.\n",
      "     |      \n",
      "     |      A `PriorityQueue` has bounded capacity; supports multiple concurrent\n",
      "     |      producers and consumers; and provides exactly-once delivery.\n",
      "     |      \n",
      "     |      A `PriorityQueue` holds a list of up to `capacity` elements. Each\n",
      "     |      element is a fixed-length tuple of tensors whose dtypes are\n",
      "     |      described by `types`, and whose shapes are optionally described\n",
      "     |      by the `shapes` argument.\n",
      "     |      \n",
      "     |      If the `shapes` argument is specified, each component of a queue\n",
      "     |      element must have the respective fixed shape. If it is\n",
      "     |      unspecified, different queue elements may have different shapes,\n",
      "     |      but the use of `dequeue_many` is disallowed.\n",
      "     |      \n",
      "     |      Enqueues and Dequeues to the `PriorityQueue` must include an additional\n",
      "     |      tuple entry at the beginning: the `priority`.  The priority must be\n",
      "     |      an int64 scalar (for `enqueue`) or an int64 vector (for `enqueue_many`).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        capacity: An integer. The upper bound on the number of elements\n",
      "     |          that may be stored in this queue.\n",
      "     |        types:  A list of `DType` objects. The length of `types` must equal\n",
      "     |          the number of tensors in each queue element, except the first priority\n",
      "     |          element.  The first tensor in each element is the priority,\n",
      "     |          which must be type int64.\n",
      "     |        shapes: (Optional.) A list of fully-defined `TensorShape` objects,\n",
      "     |          with the same length as `types`, or `None`.\n",
      "     |        names: (Optional.) A list of strings naming the components in the queue\n",
      "     |          with the same length as `dtypes`, or `None`.  If specified, the dequeue\n",
      "     |          methods return a dictionary with the names as keys.\n",
      "     |        shared_name: (Optional.) If non-empty, this queue will be shared under\n",
      "     |          the given name across multiple sessions.\n",
      "     |        name: Optional name for the queue operation.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from QueueBase:\n",
      "     |  \n",
      "     |  close(self, cancel_pending_enqueues=False, name=None)\n",
      "     |      Closes this queue.\n",
      "     |      \n",
      "     |      This operation signals that no more elements will be enqueued in\n",
      "     |      the given queue. Subsequent `enqueue` and `enqueue_many`\n",
      "     |      operations will fail. Subsequent `dequeue` and `dequeue_many`\n",
      "     |      operations will continue to succeed if sufficient elements remain\n",
      "     |      in the queue. Subsequently dequeue and dequeue_many operations\n",
      "     |      that would otherwise block waiting for more elements (if close\n",
      "     |      hadn't been called) will now fail immediately.\n",
      "     |      \n",
      "     |      If `cancel_pending_enqueues` is `True`, all pending requests will also\n",
      "     |      be canceled.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        cancel_pending_enqueues: (Optional.) A boolean, defaulting to\n",
      "     |          `False` (described above).\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The operation that closes the queue.\n",
      "     |  \n",
      "     |  dequeue(self, name=None)\n",
      "     |      Dequeues one element from this queue.\n",
      "     |      \n",
      "     |      If the queue is empty when this operation executes, it will block\n",
      "     |      until there is an element to dequeue.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed, the queue is empty, and there are no pending\n",
      "     |      enqueue operations that can fulfill this request,\n",
      "     |      `tf.errors.OutOfRangeError` will be raised. If the session is\n",
      "     |      `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The tuple of tensors that was dequeued.\n",
      "     |  \n",
      "     |  dequeue_many(self, n, name=None)\n",
      "     |      Dequeues and concatenates `n` elements from this queue.\n",
      "     |      \n",
      "     |      This operation concatenates queue-element component tensors along\n",
      "     |      the 0th dimension to make a single component tensor.  All of the\n",
      "     |      components in the dequeued tuple will have size `n` in the 0th dimension.\n",
      "     |      \n",
      "     |      If the queue is closed and there are less than `n` elements left, then an\n",
      "     |      `OutOfRange` exception is raised.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed, the queue contains fewer than `n` elements, and\n",
      "     |      there are no pending enqueue operations that can fulfill this\n",
      "     |      request, `tf.errors.OutOfRangeError` will be raised. If the\n",
      "     |      session is `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        n: A scalar `Tensor` containing the number of elements to dequeue.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The list of concatenated tensors that was dequeued.\n",
      "     |  \n",
      "     |  dequeue_up_to(self, n, name=None)\n",
      "     |      Dequeues and concatenates `n` elements from this queue.\n",
      "     |      \n",
      "     |      **Note** This operation is not supported by all queues.  If a queue does not\n",
      "     |      support DequeueUpTo, then a `tf.errors.UnimplementedError` is raised.\n",
      "     |      \n",
      "     |      This operation concatenates queue-element component tensors along\n",
      "     |      the 0th dimension to make a single component tensor. If the queue\n",
      "     |      has not been closed, all of the components in the dequeued tuple\n",
      "     |      will have size `n` in the 0th dimension.\n",
      "     |      \n",
      "     |      If the queue is closed and there are more than `0` but fewer than\n",
      "     |      `n` elements remaining, then instead of raising a\n",
      "     |      `tf.errors.OutOfRangeError` like `tf.QueueBase.dequeue_many`,\n",
      "     |      less than `n` elements are returned immediately.  If the queue is\n",
      "     |      closed and there are `0` elements left in the queue, then a\n",
      "     |      `tf.errors.OutOfRangeError` is raised just like in `dequeue_many`.\n",
      "     |      Otherwise the behavior is identical to `dequeue_many`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        n: A scalar `Tensor` containing the number of elements to dequeue.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The tuple of concatenated tensors that was dequeued.\n",
      "     |  \n",
      "     |  enqueue(self, vals, name=None)\n",
      "     |      Enqueues one element to this queue.\n",
      "     |      \n",
      "     |      If the queue is full when this operation executes, it will block\n",
      "     |      until the element has been enqueued.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed before this operation runs,\n",
      "     |      `tf.errors.CancelledError` will be raised. If this operation is\n",
      "     |      blocked, and either (i) the queue is closed by a close operation\n",
      "     |      with `cancel_pending_enqueues=True`, or (ii) the session is\n",
      "     |      `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        vals: A tensor, a list or tuple of tensors, or a dictionary containing\n",
      "     |          the values to enqueue.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The operation that enqueues a new tuple of tensors to the queue.\n",
      "     |  \n",
      "     |  enqueue_many(self, vals, name=None)\n",
      "     |      Enqueues zero or more elements to this queue.\n",
      "     |      \n",
      "     |      This operation slices each component tensor along the 0th dimension to\n",
      "     |      make multiple queue elements. All of the tensors in `vals` must have the\n",
      "     |      same size in the 0th dimension.\n",
      "     |      \n",
      "     |      If the queue is full when this operation executes, it will block\n",
      "     |      until all of the elements have been enqueued.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed before this operation runs,\n",
      "     |      `tf.errors.CancelledError` will be raised. If this operation is\n",
      "     |      blocked, and either (i) the queue is closed by a close operation\n",
      "     |      with `cancel_pending_enqueues=True`, or (ii) the session is\n",
      "     |      `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        vals: A tensor, a list or tuple of tensors, or a dictionary\n",
      "     |          from which the queue elements are taken.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The operation that enqueues a batch of tuples of tensors to the queue.\n",
      "     |  \n",
      "     |  is_closed(self, name=None)\n",
      "     |      Returns true if queue is closed.\n",
      "     |      \n",
      "     |      This operation returns true if the queue is closed and false if the queue\n",
      "     |      is open.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        True if the queue is closed and false if the queue is open.\n",
      "     |  \n",
      "     |  size(self, name=None)\n",
      "     |      Compute the number of elements in this queue.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A scalar tensor containing the number of elements in this queue.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from QueueBase:\n",
      "     |  \n",
      "     |  from_list(index, queues)\n",
      "     |      Create a queue using the queue reference from `queues[index]`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        index: An integer scalar tensor that determines the input that gets\n",
      "     |          selected.\n",
      "     |        queues: A list of `QueueBase` objects.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `QueueBase` object.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: When `queues` is not a list of `QueueBase` objects,\n",
      "     |          or when the data types of `queues` are not all the same.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from QueueBase:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  dtypes\n",
      "     |      The list of dtypes for each component of a queue element.\n",
      "     |  \n",
      "     |  name\n",
      "     |      The name of the underlying queue.\n",
      "     |  \n",
      "     |  names\n",
      "     |      The list of names for each component of a queue element.\n",
      "     |  \n",
      "     |  queue_ref\n",
      "     |      The underlying queue reference.\n",
      "     |  \n",
      "     |  shapes\n",
      "     |      The list of shapes for each component of a queue element.\n",
      "    \n",
      "    class QueueBase(builtins.object)\n",
      "     |  Base class for queue implementations.\n",
      "     |  \n",
      "     |  A queue is a TensorFlow data structure that stores tensors across\n",
      "     |  multiple steps, and exposes operations that enqueue and dequeue\n",
      "     |  tensors.\n",
      "     |  \n",
      "     |  Each queue element is a tuple of one or more tensors, where each\n",
      "     |  tuple component has a static dtype, and may have a static shape. The\n",
      "     |  queue implementations support versions of enqueue and dequeue that\n",
      "     |  handle single elements, versions that support enqueuing and\n",
      "     |  dequeuing a batch of elements at once.\n",
      "     |  \n",
      "     |  See `tf.queue.FIFOQueue` and\n",
      "     |  `tf.queue.RandomShuffleQueue` for concrete\n",
      "     |  implementations of this class, and instructions on how to create\n",
      "     |  them.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, dtypes, shapes, names, queue_ref)\n",
      "     |      Constructs a queue object from a queue reference.\n",
      "     |      \n",
      "     |      The two optional lists, `shapes` and `names`, must be of the same length\n",
      "     |      as `dtypes` if provided.  The values at a given index `i` indicate the\n",
      "     |      shape and name to use for the corresponding queue component in `dtypes`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        dtypes:  A list of types.  The length of dtypes must equal the number\n",
      "     |          of tensors in each element.\n",
      "     |        shapes: Constraints on the shapes of tensors in an element:\n",
      "     |          A list of shape tuples or None. This list is the same length\n",
      "     |          as dtypes.  If the shape of any tensors in the element are constrained,\n",
      "     |          all must be; shapes can be None if the shapes should not be constrained.\n",
      "     |        names: Optional list of names.  If provided, the `enqueue()` and\n",
      "     |          `dequeue()` methods will use dictionaries with these names as keys.\n",
      "     |          Must be None or a list or tuple of the same length as `dtypes`.\n",
      "     |        queue_ref: The queue reference, i.e. the output of the queue op.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If one of the arguments is invalid.\n",
      "     |  \n",
      "     |  close(self, cancel_pending_enqueues=False, name=None)\n",
      "     |      Closes this queue.\n",
      "     |      \n",
      "     |      This operation signals that no more elements will be enqueued in\n",
      "     |      the given queue. Subsequent `enqueue` and `enqueue_many`\n",
      "     |      operations will fail. Subsequent `dequeue` and `dequeue_many`\n",
      "     |      operations will continue to succeed if sufficient elements remain\n",
      "     |      in the queue. Subsequently dequeue and dequeue_many operations\n",
      "     |      that would otherwise block waiting for more elements (if close\n",
      "     |      hadn't been called) will now fail immediately.\n",
      "     |      \n",
      "     |      If `cancel_pending_enqueues` is `True`, all pending requests will also\n",
      "     |      be canceled.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        cancel_pending_enqueues: (Optional.) A boolean, defaulting to\n",
      "     |          `False` (described above).\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The operation that closes the queue.\n",
      "     |  \n",
      "     |  dequeue(self, name=None)\n",
      "     |      Dequeues one element from this queue.\n",
      "     |      \n",
      "     |      If the queue is empty when this operation executes, it will block\n",
      "     |      until there is an element to dequeue.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed, the queue is empty, and there are no pending\n",
      "     |      enqueue operations that can fulfill this request,\n",
      "     |      `tf.errors.OutOfRangeError` will be raised. If the session is\n",
      "     |      `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The tuple of tensors that was dequeued.\n",
      "     |  \n",
      "     |  dequeue_many(self, n, name=None)\n",
      "     |      Dequeues and concatenates `n` elements from this queue.\n",
      "     |      \n",
      "     |      This operation concatenates queue-element component tensors along\n",
      "     |      the 0th dimension to make a single component tensor.  All of the\n",
      "     |      components in the dequeued tuple will have size `n` in the 0th dimension.\n",
      "     |      \n",
      "     |      If the queue is closed and there are less than `n` elements left, then an\n",
      "     |      `OutOfRange` exception is raised.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed, the queue contains fewer than `n` elements, and\n",
      "     |      there are no pending enqueue operations that can fulfill this\n",
      "     |      request, `tf.errors.OutOfRangeError` will be raised. If the\n",
      "     |      session is `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        n: A scalar `Tensor` containing the number of elements to dequeue.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The list of concatenated tensors that was dequeued.\n",
      "     |  \n",
      "     |  dequeue_up_to(self, n, name=None)\n",
      "     |      Dequeues and concatenates `n` elements from this queue.\n",
      "     |      \n",
      "     |      **Note** This operation is not supported by all queues.  If a queue does not\n",
      "     |      support DequeueUpTo, then a `tf.errors.UnimplementedError` is raised.\n",
      "     |      \n",
      "     |      This operation concatenates queue-element component tensors along\n",
      "     |      the 0th dimension to make a single component tensor. If the queue\n",
      "     |      has not been closed, all of the components in the dequeued tuple\n",
      "     |      will have size `n` in the 0th dimension.\n",
      "     |      \n",
      "     |      If the queue is closed and there are more than `0` but fewer than\n",
      "     |      `n` elements remaining, then instead of raising a\n",
      "     |      `tf.errors.OutOfRangeError` like `tf.QueueBase.dequeue_many`,\n",
      "     |      less than `n` elements are returned immediately.  If the queue is\n",
      "     |      closed and there are `0` elements left in the queue, then a\n",
      "     |      `tf.errors.OutOfRangeError` is raised just like in `dequeue_many`.\n",
      "     |      Otherwise the behavior is identical to `dequeue_many`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        n: A scalar `Tensor` containing the number of elements to dequeue.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The tuple of concatenated tensors that was dequeued.\n",
      "     |  \n",
      "     |  enqueue(self, vals, name=None)\n",
      "     |      Enqueues one element to this queue.\n",
      "     |      \n",
      "     |      If the queue is full when this operation executes, it will block\n",
      "     |      until the element has been enqueued.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed before this operation runs,\n",
      "     |      `tf.errors.CancelledError` will be raised. If this operation is\n",
      "     |      blocked, and either (i) the queue is closed by a close operation\n",
      "     |      with `cancel_pending_enqueues=True`, or (ii) the session is\n",
      "     |      `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        vals: A tensor, a list or tuple of tensors, or a dictionary containing\n",
      "     |          the values to enqueue.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The operation that enqueues a new tuple of tensors to the queue.\n",
      "     |  \n",
      "     |  enqueue_many(self, vals, name=None)\n",
      "     |      Enqueues zero or more elements to this queue.\n",
      "     |      \n",
      "     |      This operation slices each component tensor along the 0th dimension to\n",
      "     |      make multiple queue elements. All of the tensors in `vals` must have the\n",
      "     |      same size in the 0th dimension.\n",
      "     |      \n",
      "     |      If the queue is full when this operation executes, it will block\n",
      "     |      until all of the elements have been enqueued.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed before this operation runs,\n",
      "     |      `tf.errors.CancelledError` will be raised. If this operation is\n",
      "     |      blocked, and either (i) the queue is closed by a close operation\n",
      "     |      with `cancel_pending_enqueues=True`, or (ii) the session is\n",
      "     |      `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        vals: A tensor, a list or tuple of tensors, or a dictionary\n",
      "     |          from which the queue elements are taken.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The operation that enqueues a batch of tuples of tensors to the queue.\n",
      "     |  \n",
      "     |  is_closed(self, name=None)\n",
      "     |      Returns true if queue is closed.\n",
      "     |      \n",
      "     |      This operation returns true if the queue is closed and false if the queue\n",
      "     |      is open.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        True if the queue is closed and false if the queue is open.\n",
      "     |  \n",
      "     |  size(self, name=None)\n",
      "     |      Compute the number of elements in this queue.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A scalar tensor containing the number of elements in this queue.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  from_list(index, queues)\n",
      "     |      Create a queue using the queue reference from `queues[index]`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        index: An integer scalar tensor that determines the input that gets\n",
      "     |          selected.\n",
      "     |        queues: A list of `QueueBase` objects.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `QueueBase` object.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: When `queues` is not a list of `QueueBase` objects,\n",
      "     |          or when the data types of `queues` are not all the same.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  dtypes\n",
      "     |      The list of dtypes for each component of a queue element.\n",
      "     |  \n",
      "     |  name\n",
      "     |      The name of the underlying queue.\n",
      "     |  \n",
      "     |  names\n",
      "     |      The list of names for each component of a queue element.\n",
      "     |  \n",
      "     |  queue_ref\n",
      "     |      The underlying queue reference.\n",
      "     |  \n",
      "     |  shapes\n",
      "     |      The list of shapes for each component of a queue element.\n",
      "    \n",
      "    class RaggedTensor(tensorflow.python.framework.composite_tensor.CompositeTensor)\n",
      "     |  Represents a ragged tensor.\n",
      "     |  \n",
      "     |  A `RaggedTensor` is a tensor with one or more *ragged dimensions*, which are\n",
      "     |  dimensions whose slices may have different lengths.  For example, the inner\n",
      "     |  (column) dimension of `rt=[[3, 1, 4, 1], [], [5, 9, 2], [6], []]` is ragged,\n",
      "     |  since the column slices (`rt[0, :]`, ..., `rt[4, :]`) have different lengths.\n",
      "     |  Dimensions whose slices all have the same length are called *uniform\n",
      "     |  dimensions*.  The outermost dimension of a `RaggedTensor` is always uniform,\n",
      "     |  since it consists of a single slice (and so there is no possibility for\n",
      "     |  differing slice lengths).\n",
      "     |  \n",
      "     |  The total number of dimensions in a `RaggedTensor` is called its *rank*,\n",
      "     |  and the number of ragged dimensions in a `RaggedTensor` is called its\n",
      "     |  *ragged-rank*.  A `RaggedTensor`'s ragged-rank is fixed at graph creation\n",
      "     |  time: it can't depend on the runtime values of `Tensor`s, and can't vary\n",
      "     |  dynamically for different session runs.\n",
      "     |  \n",
      "     |  ### Potentially Ragged Tensors\n",
      "     |  \n",
      "     |  Many ops support both `Tensor`s and `RaggedTensor`s.  The term \"potentially\n",
      "     |  ragged tensor\" may be used to refer to a tensor that might be either a\n",
      "     |  `Tensor` or a `RaggedTensor`.  The ragged-rank of a `Tensor` is zero.\n",
      "     |  \n",
      "     |  ### Documenting RaggedTensor Shapes\n",
      "     |  \n",
      "     |  When documenting the shape of a RaggedTensor, ragged dimensions can be\n",
      "     |  indicated by enclosing them in parentheses.  For example, the shape of\n",
      "     |  a 3-D `RaggedTensor` that stores the fixed-size word embedding for each\n",
      "     |  word in a sentence, for each sentence in a batch, could be written as\n",
      "     |  `[num_sentences, (num_words), embedding_size]`.  The parentheses around\n",
      "     |  `(num_words)` indicate that dimension is ragged, and that the length\n",
      "     |  of each element list in that dimension may vary for each item.\n",
      "     |  \n",
      "     |  ### Component Tensors\n",
      "     |  \n",
      "     |  Internally, a `RaggedTensor` consists of a concatenated list of values that\n",
      "     |  are partitioned into variable-length rows.  In particular, each `RaggedTensor`\n",
      "     |  consists of:\n",
      "     |  \n",
      "     |    * A `values` tensor, which concatenates the variable-length rows into a\n",
      "     |      flattened list.  For example, the `values` tensor for\n",
      "     |      `[[3, 1, 4, 1], [], [5, 9, 2], [6], []]` is `[3, 1, 4, 1, 5, 9, 2, 6]`.\n",
      "     |  \n",
      "     |    * A `row_splits` vector, which indicates how those flattened values are\n",
      "     |      divided into rows.  In particular, the values for row `rt[i]` are stored\n",
      "     |      in the slice `rt.values[rt.row_splits[i]:rt.row_splits[i+1]]`.\n",
      "     |  \n",
      "     |  Example:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  >>> print(tf.RaggedTensor.from_row_splits(\n",
      "     |  ...     values=[3, 1, 4, 1, 5, 9, 2, 6],\n",
      "     |  ...     row_splits=[0, 4, 4, 7, 8, 8]))\n",
      "     |  <tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>\n",
      "     |  ```\n",
      "     |  \n",
      "     |  ### Alternative Row-Partitioning Schemes\n",
      "     |  \n",
      "     |  In addition to `row_splits`, ragged tensors provide support for four other\n",
      "     |  row-partitioning schemes:\n",
      "     |  \n",
      "     |    * `row_lengths`: a vector with shape `[nrows]`, which specifies the length\n",
      "     |      of each row.\n",
      "     |  \n",
      "     |    * `value_rowids` and `nrows`: `value_rowids` is a vector with shape\n",
      "     |      `[nvals]`, corresponding one-to-one with `values`, which specifies\n",
      "     |      each value's row index.  In particular, the row `rt[row]` consists of the\n",
      "     |      values `rt.values[j]` where `value_rowids[j]==row`.  `nrows` is an\n",
      "     |      integer scalar that specifies the number of rows in the\n",
      "     |      `RaggedTensor`. (`nrows` is used to indicate trailing empty rows.)\n",
      "     |  \n",
      "     |    * `row_starts`: a vector with shape `[nrows]`, which specifies the start\n",
      "     |      offset of each row.  Equivalent to `row_splits[:-1]`.\n",
      "     |  \n",
      "     |    * `row_limits`: a vector with shape `[nrows]`, which specifies the stop\n",
      "     |      offset of each row.  Equivalent to `row_splits[1:]`.\n",
      "     |  \n",
      "     |  Example: The following ragged tensors are equivalent, and all represent the\n",
      "     |  nested list `[[3, 1, 4, 1], [], [5, 9, 2], [6], []]`.\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  >>> values = [3, 1, 4, 1, 5, 9, 2, 6]\n",
      "     |  >>> rt1 = RaggedTensor.from_row_splits(values, row_splits=[0, 4, 4, 7, 8, 8])\n",
      "     |  >>> rt2 = RaggedTensor.from_row_lengths(values, row_lengths=[4, 0, 3, 1, 0])\n",
      "     |  >>> rt3 = RaggedTensor.from_value_rowids(\n",
      "     |  ...     values, value_rowids=[0, 0, 0, 0, 2, 2, 2, 3], nrows=5)\n",
      "     |  >>> rt4 = RaggedTensor.from_row_starts(values, row_starts=[0, 4, 4, 7, 8])\n",
      "     |  >>> rt5 = RaggedTensor.from_row_limits(values, row_limits=[4, 4, 7, 8, 8])\n",
      "     |  ```\n",
      "     |  \n",
      "     |  ### Multiple Ragged Dimensions\n",
      "     |  \n",
      "     |  `RaggedTensor`s with multiple ragged dimensions can be defined by using\n",
      "     |  a nested `RaggedTensor` for the `values` tensor.  Each nested `RaggedTensor`\n",
      "     |  adds a single ragged dimension.\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  >>> inner_rt = RaggedTensor.from_row_splits(  # =rt1 from above\n",
      "     |  ...     values=[3, 1, 4, 1, 5, 9, 2, 6], row_splits=[0, 4, 4, 7, 8, 8])\n",
      "     |  >>> outer_rt = RaggedTensor.from_row_splits(\n",
      "     |  ...     values=inner_rt, row_splits=[0, 3, 3, 5])\n",
      "     |  >>> print outer_rt.to_list()\n",
      "     |  [[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]]\n",
      "     |  >>> print outer_rt.ragged_rank\n",
      "     |  2\n",
      "     |  ```\n",
      "     |  \n",
      "     |  The factory function `RaggedTensor.from_nested_row_splits` may be used to\n",
      "     |  construct a `RaggedTensor` with multiple ragged dimensions directly, by\n",
      "     |  providing a list of `row_splits` tensors:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  >>> RaggedTensor.from_nested_row_splits(\n",
      "     |  ...     flat_values=[3, 1, 4, 1, 5, 9, 2, 6],\n",
      "     |  ...     nested_row_splits=([0, 3, 3, 5], [0, 4, 4, 7, 8, 8])).to_list()\n",
      "     |  [[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]]\n",
      "     |  ```\n",
      "     |  \n",
      "     |  ### Uniform Inner Dimensions\n",
      "     |  \n",
      "     |  `RaggedTensor`s with uniform inner dimensions can be defined\n",
      "     |  by using a multidimensional `Tensor` for `values`.\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  >>> rt = RaggedTensor.from_row_splits(values=tf.ones([5, 3]),\n",
      "     |  ..                                    row_splits=[0, 2, 5])\n",
      "     |  >>> print rt.to_list()\n",
      "     |  [[[1, 1, 1], [1, 1, 1]],\n",
      "     |   [[1, 1, 1], [1, 1, 1], [1, 1, 1]]]\n",
      "     |   >>> print rt.shape\n",
      "     |   (2, ?, 3)\n",
      "     |  ```\n",
      "     |  \n",
      "     |  ### RaggedTensor Shape Restrictions\n",
      "     |  \n",
      "     |  The shape of a RaggedTensor is currently restricted to have the following\n",
      "     |  form:\n",
      "     |  \n",
      "     |    * A single uniform dimension\n",
      "     |    * Followed by one or more ragged dimensions\n",
      "     |    * Followed by zero or more uniform dimensions.\n",
      "     |  \n",
      "     |  This restriction follows from the fact that each nested `RaggedTensor`\n",
      "     |  replaces the uniform outermost dimension of its `values` with a uniform\n",
      "     |  dimension followed by a ragged dimension.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      RaggedTensor\n",
      "     |      tensorflow.python.framework.composite_tensor.CompositeTensor\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __abs__ = abs(x, name=None)\n",
      "     |      Computes the absolute value of a tensor.\n",
      "     |      \n",
      "     |      Given a tensor of integer or floating-point values, this operation returns a\n",
      "     |      tensor of the same type, where each element contains the absolute value of the\n",
      "     |      corresponding element in the input.\n",
      "     |      \n",
      "     |      Given a tensor `x` of complex numbers, this operation returns a tensor of type\n",
      "     |      `float32` or `float64` that is the absolute value of each element in `x`. All\n",
      "     |      elements in `x` must be complex numbers of the form \\\\(a + bj\\\\). The\n",
      "     |      absolute value is computed as \\\\( \\sqrt{a^2 + b^2}\\\\).  For example:\n",
      "     |      ```python\n",
      "     |      x = tf.constant([[-2.25 + 4.75j], [-3.25 + 5.75j]])\n",
      "     |      tf.abs(x)  # [5.25594902, 6.60492229]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor` or `SparseTensor` of type `float16`, `float32`, `float64`,\n",
      "     |          `int32`, `int64`, `complex64` or `complex128`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` or `SparseTensor` the same size, type, and sparsity as `x` with\n",
      "     |          absolute values.\n",
      "     |        Note, for `complex64` or `complex128` input, the returned `Tensor` will be\n",
      "     |          of type `float32` or `float64`, respectively.\n",
      "     |      \n",
      "     |        If `x` is a `SparseTensor`, returns\n",
      "     |        `SparseTensor(x.indices, tf.math.abs(x.values, ...), x.dense_shape)`\n",
      "     |  \n",
      "     |  __add__ = add(x, y, name=None)\n",
      "     |      Returns x + y element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `math.add` supports broadcasting. `AddN` does not. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `int16`, `int32`, `int64`, `complex64`, `complex128`, `string`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `x`.\n",
      "     |  \n",
      "     |  __and__ = logical_and(x, y, name=None)\n",
      "     |      Returns the truth value of x AND y element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `math.logical_and` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor` of type `bool`.\n",
      "     |        y: A `Tensor` of type `bool`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __bool__ = _dummy_bool(_)\n",
      "     |      Dummy method to prevent a RaggedTensor from being used as a Python bool.\n",
      "     |  \n",
      "     |  __div__ = div(x, y, name=None)\n",
      "     |      Divides x / y elementwise (using Python 2 division operator semantics). (deprecated)\n",
      "     |      \n",
      "     |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Deprecated in favor of operator or tf.math.divide.\n",
      "     |      \n",
      "     |      NOTE: Prefer using the Tensor division operator or tf.divide which obey Python\n",
      "     |      3 division operator semantics.\n",
      "     |      \n",
      "     |      This function divides `x` and `y`, forcing Python 2 semantics. That is, if `x`\n",
      "     |      and `y` are both integers then the result will be an integer. This is in\n",
      "     |      contrast to Python 3, where division with `/` is always a float while division\n",
      "     |      with `//` is always an integer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: `Tensor` numerator of real numeric type.\n",
      "     |        y: `Tensor` denominator of real numeric type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        `x / y` returns the quotient of x and y.\n",
      "     |  \n",
      "     |  __floordiv__ = floordiv(x, y, name=None)\n",
      "     |      Divides `x / y` elementwise, rounding toward the most negative integer.\n",
      "     |      \n",
      "     |      The same as `tf.compat.v1.div(x,y)` for integers, but uses\n",
      "     |      `tf.floor(tf.compat.v1.div(x,y))` for\n",
      "     |      floating point arguments so that the result is always an integer (though\n",
      "     |      possibly an integer represented as floating point).  This op is generated by\n",
      "     |      `x // y` floor division in Python 3 and in Python 2.7 with\n",
      "     |      `from __future__ import division`.\n",
      "     |      \n",
      "     |      `x` and `y` must have the same type, and the result will have the same type\n",
      "     |      as well.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: `Tensor` numerator of real numeric type.\n",
      "     |        y: `Tensor` denominator of real numeric type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        `x / y` rounded down.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If the inputs are complex.\n",
      "     |  \n",
      "     |  __ge__ = greater_equal(x, y, name=None)\n",
      "     |      Returns the truth value of (x >= y) element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `math.greater_equal` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __getitem__ = ragged_tensor_getitem(self, key)\n",
      "     |      Returns the specified piece of this RaggedTensor.\n",
      "     |      \n",
      "     |      Supports multidimensional indexing and slicing, with one restriction:\n",
      "     |      indexing into a ragged inner dimension is not allowed.  This case is\n",
      "     |      problematic because the indicated value may exist in some rows but not\n",
      "     |      others.  In such cases, it's not obvious whether we should (1) report an\n",
      "     |      IndexError; (2) use a default value; or (3) skip that value and return a\n",
      "     |      tensor with fewer rows than we started with.  Following the guiding\n",
      "     |      principles of Python (\"In the face of ambiguity, refuse the temptation to\n",
      "     |      guess\"), we simply disallow this operation.\n",
      "     |      \n",
      "     |      Any dimensions added by `array_ops.newaxis` will be ragged if the following\n",
      "     |      dimension is ragged.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        self: The RaggedTensor to slice.\n",
      "     |        key: Indicates which piece of the RaggedTensor to return, using standard\n",
      "     |          Python semantics (e.g., negative values index from the end).  `key`\n",
      "     |          may have any of the following types:\n",
      "     |      \n",
      "     |          * `int` constant\n",
      "     |          * Scalar integer `Tensor`\n",
      "     |          * `slice` containing integer constants and/or scalar integer\n",
      "     |            `Tensor`s\n",
      "     |          * `Ellipsis`\n",
      "     |          * `tf.newaxis`\n",
      "     |          * `tuple` containing any of the above (for multidimentional indexing)\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` or `RaggedTensor` object.  Values that include at least one\n",
      "     |        ragged dimension are returned as `RaggedTensor`.  Values that include no\n",
      "     |        ragged dimensions are returned as `Tensor`.  See above for examples of\n",
      "     |        expressions that return `Tensor`s vs `RaggedTensor`s.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `key` is out of bounds.\n",
      "     |        ValueError: If `key` is not supported.\n",
      "     |        TypeError: If the indices in `key` have an unsupported type.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |      \n",
      "     |        ```python\n",
      "     |        >>> # A 2-D ragged tensor with 1 ragged dimension.\n",
      "     |        >>> rt = ragged.constant([['a', 'b', 'c'], ['d', 'e'], ['f'], ['g']])\n",
      "     |        >>> rt[0].eval().tolist()       # First row (1-D `Tensor`)\n",
      "     |        ['a', 'b', 'c']\n",
      "     |        >>> rt[:3].eval().tolist()      # First three rows (2-D RaggedTensor)\n",
      "     |        [['a', 'b', 'c'], ['d', 'e'], '[f'], [g']]\n",
      "     |        >>> rt[3, 0].eval().tolist()    # 1st element of 4th row (scalar)\n",
      "     |        'g'\n",
      "     |      \n",
      "     |        >>> # A 3-D ragged tensor with 2 ragged dimensions.\n",
      "     |        >>> rt = ragged.constant([[[1, 2, 3], [4]],\n",
      "     |        ...                    [[5], [], [6]],\n",
      "     |        ...                    [[7]],\n",
      "     |        ...                    [[8, 9], [10]]])\n",
      "     |        >>> rt[1].eval().tolist()       # Second row (2-D RaggedTensor)\n",
      "     |        [[5], [], [6]]\n",
      "     |        >>> rt[3, 0].eval().tolist()    # First element of fourth row (1-D Tensor)\n",
      "     |        [8, 9]\n",
      "     |        >>> rt[:, 1:3].eval().tolist()  # Items 1-3 of each row (3-D RaggedTensor)\n",
      "     |        [[[4]], [[], [6]], [], [[10]]]\n",
      "     |        >>> rt[:, -1:].eval().tolist()  # Last item of each row (3-D RaggedTensor)\n",
      "     |        [[[4]], [[6]], [[7]], [[10]]]\n",
      "     |        ```\n",
      "     |  \n",
      "     |  __gt__ = greater(x, y, name=None)\n",
      "     |      Returns the truth value of (x > y) element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `math.greater` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __init__(self, values, row_splits, cached_row_lengths=None, cached_value_rowids=None, cached_nrows=None, internal=False)\n",
      "     |      Creates a `RaggedTensor` with a specified partitioning for `values`.\n",
      "     |      \n",
      "     |      This constructor is private -- please use one of the following ops to\n",
      "     |      build `RaggedTensor`s:\n",
      "     |      \n",
      "     |        * `tf.RaggedTensor.from_row_lengths`\n",
      "     |        * `tf.RaggedTensor.from_value_rowids`\n",
      "     |        * `tf.RaggedTensor.from_row_splits`\n",
      "     |        * `tf.RaggedTensor.from_row_starts`\n",
      "     |        * `tf.RaggedTensor.from_row_limits`\n",
      "     |        * `tf.RaggedTensor.from_nested_row_splits`\n",
      "     |        * `tf.RaggedTensor.from_nested_row_lengths`\n",
      "     |        * `tf.RaggedTensor.from_nested_value_rowids`\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        values: A potentially ragged tensor of any dtype and shape `[nvals, ...]`.\n",
      "     |        row_splits: A 1-D integer tensor with shape `[nrows+1]`.\n",
      "     |        cached_row_lengths: A 1-D integer tensor with shape `[nrows]`\n",
      "     |        cached_value_rowids: A 1-D integer tensor with shape `[nvals]`.\n",
      "     |        cached_nrows: A 1-D integer scalar tensor.\n",
      "     |        internal: True if the constructor is being called by one of the factory\n",
      "     |          methods.  If false, an exception will be raised.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If a row partitioning tensor has an inappropriate dtype.\n",
      "     |        TypeError: If exactly one row partitioning argument was not specified.\n",
      "     |        ValueError: If a row partitioning tensor has an inappropriate shape.\n",
      "     |        ValueError: If multiple partitioning arguments are specified.\n",
      "     |        ValueError: If nrows is specified but value_rowids is not None.\n",
      "     |  \n",
      "     |  __invert__ = logical_not(x, name=None)\n",
      "     |      Returns the truth value of NOT x element-wise.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor` of type `bool`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __le__ = less_equal(x, y, name=None)\n",
      "     |      Returns the truth value of (x <= y) element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `math.less_equal` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __lt__ = less(x, y, name=None)\n",
      "     |      Returns the truth value of (x < y) element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `math.less` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __mod__ = floor_mod(x, y, name=None)\n",
      "     |      Returns element-wise remainder of division. When `x < 0` xor `y < 0` is\n",
      "     |      \n",
      "     |      true, this follows Python semantics in that the result here is consistent\n",
      "     |      with a flooring divide. E.g. `floor(x / y) * y + mod(x, y) = x`.\n",
      "     |      \n",
      "     |      *NOTE*: `math.floormod` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `int32`, `int64`, `bfloat16`, `half`, `float32`, `float64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `x`.\n",
      "     |  \n",
      "     |  __mul__ = multiply(x, y, name=None)\n",
      "     |      Returns x * y element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `tf.multiply` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`, `int16`, `int32`, `int64`, `complex64`, `complex128`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `x`.\n",
      "     |  \n",
      "     |  __neg__ = neg(x, name=None)\n",
      "     |      Computes numerical negative value element-wise.\n",
      "     |      \n",
      "     |      I.e., \\\\(y = -x\\\\).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int32`, `int64`, `complex64`, `complex128`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `x`.\n",
      "     |      \n",
      "     |        If `x` is a `SparseTensor`, returns\n",
      "     |        `SparseTensor(x.indices, tf.math.negative(x.values, ...), x.dense_shape)`\n",
      "     |  \n",
      "     |  __nonzero__ = _dummy_bool(_)\n",
      "     |      Dummy method to prevent a RaggedTensor from being used as a Python bool.\n",
      "     |  \n",
      "     |  __or__ = logical_or(x, y, name=None)\n",
      "     |      Returns the truth value of x OR y element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `math.logical_or` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor` of type `bool`.\n",
      "     |        y: A `Tensor` of type `bool`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __pow__ = pow(x, y, name=None)\n",
      "     |      Computes the power of one value to another.\n",
      "     |      \n",
      "     |      Given a tensor `x` and a tensor `y`, this operation computes \\\\(x^y\\\\) for\n",
      "     |      corresponding elements in `x` and `y`. For example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      x = tf.constant([[2, 2], [3, 3]])\n",
      "     |      y = tf.constant([[8, 16], [2, 3]])\n",
      "     |      tf.pow(x, y)  # [[256, 65536], [9, 27]]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor` of type `float16`, `float32`, `float64`, `int32`, `int64`,\n",
      "     |          `complex64`, or `complex128`.\n",
      "     |        y: A `Tensor` of type `float16`, `float32`, `float64`, `int32`, `int64`,\n",
      "     |          `complex64`, or `complex128`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`.\n",
      "     |  \n",
      "     |  __radd__ = add(x, y, name=None)\n",
      "     |      Returns x + y element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `math.add` supports broadcasting. `AddN` does not. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `int16`, `int32`, `int64`, `complex64`, `complex128`, `string`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `x`.\n",
      "     |  \n",
      "     |  __rand__ = logical_and(x, y, name=None)\n",
      "     |      Returns the truth value of x AND y element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `math.logical_and` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor` of type `bool`.\n",
      "     |        y: A `Tensor` of type `bool`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __rdiv__ = div(x, y, name=None)\n",
      "     |      Divides x / y elementwise (using Python 2 division operator semantics). (deprecated)\n",
      "     |      \n",
      "     |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Deprecated in favor of operator or tf.math.divide.\n",
      "     |      \n",
      "     |      NOTE: Prefer using the Tensor division operator or tf.divide which obey Python\n",
      "     |      3 division operator semantics.\n",
      "     |      \n",
      "     |      This function divides `x` and `y`, forcing Python 2 semantics. That is, if `x`\n",
      "     |      and `y` are both integers then the result will be an integer. This is in\n",
      "     |      contrast to Python 3, where division with `/` is always a float while division\n",
      "     |      with `//` is always an integer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: `Tensor` numerator of real numeric type.\n",
      "     |        y: `Tensor` denominator of real numeric type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        `x / y` returns the quotient of x and y.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __rfloordiv__ = floordiv(x, y, name=None)\n",
      "     |      Divides `x / y` elementwise, rounding toward the most negative integer.\n",
      "     |      \n",
      "     |      The same as `tf.compat.v1.div(x,y)` for integers, but uses\n",
      "     |      `tf.floor(tf.compat.v1.div(x,y))` for\n",
      "     |      floating point arguments so that the result is always an integer (though\n",
      "     |      possibly an integer represented as floating point).  This op is generated by\n",
      "     |      `x // y` floor division in Python 3 and in Python 2.7 with\n",
      "     |      `from __future__ import division`.\n",
      "     |      \n",
      "     |      `x` and `y` must have the same type, and the result will have the same type\n",
      "     |      as well.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: `Tensor` numerator of real numeric type.\n",
      "     |        y: `Tensor` denominator of real numeric type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        `x / y` rounded down.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If the inputs are complex.\n",
      "     |  \n",
      "     |  __rmod__ = floor_mod(x, y, name=None)\n",
      "     |      Returns element-wise remainder of division. When `x < 0` xor `y < 0` is\n",
      "     |      \n",
      "     |      true, this follows Python semantics in that the result here is consistent\n",
      "     |      with a flooring divide. E.g. `floor(x / y) * y + mod(x, y) = x`.\n",
      "     |      \n",
      "     |      *NOTE*: `math.floormod` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `int32`, `int64`, `bfloat16`, `half`, `float32`, `float64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `x`.\n",
      "     |  \n",
      "     |  __rmul__ = multiply(x, y, name=None)\n",
      "     |      Returns x * y element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `tf.multiply` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`, `int16`, `int32`, `int64`, `complex64`, `complex128`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `x`.\n",
      "     |  \n",
      "     |  __ror__ = logical_or(x, y, name=None)\n",
      "     |      Returns the truth value of x OR y element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `math.logical_or` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor` of type `bool`.\n",
      "     |        y: A `Tensor` of type `bool`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __rpow__ = pow(x, y, name=None)\n",
      "     |      Computes the power of one value to another.\n",
      "     |      \n",
      "     |      Given a tensor `x` and a tensor `y`, this operation computes \\\\(x^y\\\\) for\n",
      "     |      corresponding elements in `x` and `y`. For example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      x = tf.constant([[2, 2], [3, 3]])\n",
      "     |      y = tf.constant([[8, 16], [2, 3]])\n",
      "     |      tf.pow(x, y)  # [[256, 65536], [9, 27]]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor` of type `float16`, `float32`, `float64`, `int32`, `int64`,\n",
      "     |          `complex64`, or `complex128`.\n",
      "     |        y: A `Tensor` of type `float16`, `float32`, `float64`, `int32`, `int64`,\n",
      "     |          `complex64`, or `complex128`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`.\n",
      "     |  \n",
      "     |  __rsub__ = subtract(x, y, name=None)\n",
      "     |      Returns x - y element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `Subtract` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`, `int16`, `int32`, `int64`, `complex64`, `complex128`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `x`.\n",
      "     |  \n",
      "     |  __rtruediv__ = truediv(x, y, name=None)\n",
      "     |      Divides x / y elementwise (using Python 3 division operator semantics).\n",
      "     |      \n",
      "     |      NOTE: Prefer using the Tensor operator or tf.divide which obey Python\n",
      "     |      division operator semantics.\n",
      "     |      \n",
      "     |      This function forces Python 3 division operator semantics where all integer\n",
      "     |      arguments are cast to floating types first.   This op is generated by normal\n",
      "     |      `x / y` division in Python 3 and in Python 2.7 with\n",
      "     |      `from __future__ import division`.  If you want integer division that rounds\n",
      "     |      down, use `x // y` or `tf.math.floordiv`.\n",
      "     |      \n",
      "     |      `x` and `y` must have the same numeric type.  If the inputs are floating\n",
      "     |      point, the output will have the same type.  If the inputs are integral, the\n",
      "     |      inputs are cast to `float32` for `int8` and `int16` and `float64` for `int32`\n",
      "     |      and `int64` (matching the behavior of Numpy).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: `Tensor` numerator of numeric type.\n",
      "     |        y: `Tensor` denominator of numeric type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        `x / y` evaluated in floating point.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If `x` and `y` have different dtypes.\n",
      "     |  \n",
      "     |  __rxor__ = logical_xor(x, y, name='LogicalXor')\n",
      "     |      Logical XOR function.\n",
      "     |      \n",
      "     |      x ^ y = (x | y) & ~(x & y)\n",
      "     |      \n",
      "     |      Inputs are tensor and if the tensors contains more than one element, an\n",
      "     |      element-wise logical XOR is computed.\n",
      "     |      \n",
      "     |      Usage:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      x = tf.constant([False, False, True, True], dtype = tf.bool)\n",
      "     |      y = tf.constant([False, True, False, True], dtype = tf.bool)\n",
      "     |      z = tf.logical_xor(x, y, name=\"LogicalXor\")\n",
      "     |      #  here z = [False  True  True False]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          x: A `Tensor` type bool.\n",
      "     |          y: A `Tensor` of type bool.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type bool with the same size as that of x or y.\n",
      "     |  \n",
      "     |  __sub__ = subtract(x, y, name=None)\n",
      "     |      Returns x - y element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `Subtract` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`, `int16`, `int32`, `int64`, `complex64`, `complex128`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `x`.\n",
      "     |  \n",
      "     |  __truediv__ = truediv(x, y, name=None)\n",
      "     |      Divides x / y elementwise (using Python 3 division operator semantics).\n",
      "     |      \n",
      "     |      NOTE: Prefer using the Tensor operator or tf.divide which obey Python\n",
      "     |      division operator semantics.\n",
      "     |      \n",
      "     |      This function forces Python 3 division operator semantics where all integer\n",
      "     |      arguments are cast to floating types first.   This op is generated by normal\n",
      "     |      `x / y` division in Python 3 and in Python 2.7 with\n",
      "     |      `from __future__ import division`.  If you want integer division that rounds\n",
      "     |      down, use `x // y` or `tf.math.floordiv`.\n",
      "     |      \n",
      "     |      `x` and `y` must have the same numeric type.  If the inputs are floating\n",
      "     |      point, the output will have the same type.  If the inputs are integral, the\n",
      "     |      inputs are cast to `float32` for `int8` and `int16` and `float64` for `int32`\n",
      "     |      and `int64` (matching the behavior of Numpy).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: `Tensor` numerator of numeric type.\n",
      "     |        y: `Tensor` denominator of numeric type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        `x / y` evaluated in floating point.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If `x` and `y` have different dtypes.\n",
      "     |  \n",
      "     |  __xor__ = logical_xor(x, y, name='LogicalXor')\n",
      "     |      Logical XOR function.\n",
      "     |      \n",
      "     |      x ^ y = (x | y) & ~(x & y)\n",
      "     |      \n",
      "     |      Inputs are tensor and if the tensors contains more than one element, an\n",
      "     |      element-wise logical XOR is computed.\n",
      "     |      \n",
      "     |      Usage:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      x = tf.constant([False, False, True, True], dtype = tf.bool)\n",
      "     |      y = tf.constant([False, True, False, True], dtype = tf.bool)\n",
      "     |      z = tf.logical_xor(x, y, name=\"LogicalXor\")\n",
      "     |      #  here z = [False  True  True False]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          x: A `Tensor` type bool.\n",
      "     |          y: A `Tensor` of type bool.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type bool with the same size as that of x or y.\n",
      "     |  \n",
      "     |  bounding_shape(self, axis=None, name=None, out_type=None)\n",
      "     |      Returns the tight bounding box shape for this `RaggedTensor`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        axis: An integer scalar or vector indicating which axes to return the\n",
      "     |          bounding box for.  If not specified, then the full bounding box is\n",
      "     |          returned.\n",
      "     |        name: A name prefix for the returned tensor (optional).\n",
      "     |        out_type: `dtype` for the returned tensor.  Defaults to\n",
      "     |          `self.row_splits.dtype`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An integer `Tensor` (`dtype=self.row_splits.dtype`).  If `axis` is not\n",
      "     |        specified, then `output` is a vector with\n",
      "     |        `output.shape=[self.shape.ndims]`.  If `axis` is a scalar, then the\n",
      "     |        `output` is a scalar.  If `axis` is a vector, then `output` is a vector,\n",
      "     |        where `output[i]` is the bounding size for dimension `axis[i]`.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |        ```python\n",
      "     |        >>> rt = ragged.constant([[1, 2, 3, 4], [5], [], [6, 7, 8, 9], [10]])\n",
      "     |        >>> rt.bounding_shape()\n",
      "     |        [5, 4]\n",
      "     |        ```\n",
      "     |  \n",
      "     |  consumers(self)\n",
      "     |  \n",
      "     |  nested_row_lengths(self, name=None)\n",
      "     |      Returns a tuple containing the row_lengths for all ragged dimensions.\n",
      "     |      \n",
      "     |      `rt.nested_row_lengths()` is a tuple containing the `row_lengths` tensors\n",
      "     |      for all ragged dimensions in `rt`, ordered from outermost to innermost.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name prefix for the returned tensors (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `tuple` of 1-D integer `Tensors`.  The length of the tuple is equal to\n",
      "     |        `self.ragged_rank`.\n",
      "     |  \n",
      "     |  nested_value_rowids(self, name=None)\n",
      "     |      Returns a tuple containing the value_rowids for all ragged dimensions.\n",
      "     |      \n",
      "     |      `rt.nested_value_rowids` is a tuple containing the `value_rowids` tensors\n",
      "     |      for\n",
      "     |      all ragged dimensions in `rt`, ordered from outermost to innermost.  In\n",
      "     |      particular, `rt.nested_value_rowids = (rt.value_rowids(),) + value_ids`\n",
      "     |      where:\n",
      "     |      \n",
      "     |          * `value_ids = ()` if `rt.values` is a `Tensor`.\n",
      "     |          * `value_ids = rt.values.nested_value_rowids` otherwise.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name prefix for the returned tensors (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `tuple` of 1-D integer `Tensor`s.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |      \n",
      "     |        ```python\n",
      "     |        >>> rt = ragged.constant([[[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]]])\n",
      "     |        >>> for i, ids in enumerate(rt.nested_value_rowids()):\n",
      "     |        ...   print('row ids for dimension %d: %s' % (i+1, ids))\n",
      "     |        row ids for dimension 1: [0]\n",
      "     |        row ids for dimension 2: [0, 0, 0, 2, 2]\n",
      "     |        row ids for dimension 3: [0, 0, 0, 0, 2, 2, 2, 3]\n",
      "     |        ```\n",
      "     |  \n",
      "     |  nrows(self, out_type=None, name=None)\n",
      "     |      Returns the number of rows in this ragged tensor.\n",
      "     |      \n",
      "     |      I.e., the size of the outermost dimension of the tensor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        out_type: `dtype` for the returned tensor.  Defaults to\n",
      "     |          `self.row_splits.dtype`.\n",
      "     |        name: A name prefix for the returned tensor (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A scalar `Tensor` with dtype `out_type`.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |        ```python\n",
      "     |        >>> rt = ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])\n",
      "     |        >>> rt.nrows()  # rt has 5 rows.\n",
      "     |        5\n",
      "     |        ```\n",
      "     |  \n",
      "     |  row_lengths(self, axis=1, name=None)\n",
      "     |      Returns the lengths of the rows in this ragged tensor.\n",
      "     |      \n",
      "     |      `rt.row_lengths()[i]` indicates the number of values in the\n",
      "     |      `i`th row of `rt`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        axis: An integer constant indicating the axis whose row lengths should be\n",
      "     |          returned.\n",
      "     |        name: A name prefix for the returned tensor (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A potentially ragged integer Tensor with shape `self.shape[:axis]`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `axis` is out of bounds.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |        ```python\n",
      "     |        >>> rt = ragged.constant([[[3, 1, 4], [1]], [], [[5, 9], [2]], [[6]], []])\n",
      "     |        >>> rt.row_lengths(rt)  # lengths of rows in rt\n",
      "     |        tf.Tensor([2, 0, 2, 1, 0])\n",
      "     |        >>> rt.row_lengths(axis=2)  # lengths of axis=2 rows.\n",
      "     |        <tf.RaggedTensor [[3, 1], [], [2, 1], [1], []]>\n",
      "     |        ```\n",
      "     |  \n",
      "     |  row_limits(self, name=None)\n",
      "     |      Returns the limit indices for rows in this ragged tensor.\n",
      "     |      \n",
      "     |      These indices specify where the values for each row end in\n",
      "     |      `self.values`.  `rt.row_limits(self)` is equal to `rt.row_splits[:-1]`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name prefix for the returned tensor (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A 1-D integer Tensor with shape `[nrows]`.\n",
      "     |        The returned tensor is nonnegative, and is sorted in ascending order.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |        ```python\n",
      "     |        >>> rt = ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])\n",
      "     |        >>> rt.values\n",
      "     |        tf.Tensor([3, 1, 4, 1, 5, 9, 2, 6])\n",
      "     |        >>> rt.row_limits()  # indices of row limits in rt.values\n",
      "     |        tf.Tensor([4, 4, 7, 8, 8])\n",
      "     |        ```\n",
      "     |  \n",
      "     |  row_starts(self, name=None)\n",
      "     |      Returns the start indices for rows in this ragged tensor.\n",
      "     |      \n",
      "     |      These indices specify where the values for each row begin in\n",
      "     |      `self.values`.  `rt.row_starts()` is equal to `rt.row_splits[:-1]`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name prefix for the returned tensor (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A 1-D integer Tensor with shape `[nrows]`.\n",
      "     |        The returned tensor is nonnegative, and is sorted in ascending order.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |        ```python\n",
      "     |        >>> rt = ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])\n",
      "     |        >>> rt.values\n",
      "     |        tf.Tensor([3, 1, 4, 1, 5, 9, 2, 6])\n",
      "     |        >>> rt.row_starts()  # indices of row starts in rt.values\n",
      "     |        tf.Tensor([0, 4, 4, 7, 8])\n",
      "     |        ```\n",
      "     |  \n",
      "     |  to_list(self)\n",
      "     |      Returns a nested Python `list` with the values for this `RaggedTensor`.\n",
      "     |      \n",
      "     |      Requires that `rt` was constructed in eager execution mode.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A nested Python `list`.\n",
      "     |  \n",
      "     |  to_sparse(self, name=None)\n",
      "     |      Converts this `RaggedTensor` into a `tf.SparseTensor`.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      >>> rt = ragged.constant([[1, 2, 3], [4], [], [5, 6]])\n",
      "     |      >>> rt.to_sparse().eval()\n",
      "     |      SparseTensorValue(indices=[[0, 0], [0, 1], [0, 2], [1, 0], [3, 0], [3, 1]],\n",
      "     |                        values=[1, 2, 3, 4, 5, 6],\n",
      "     |                        dense_shape=[4, 3])\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name prefix for the returned tensors (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A SparseTensor with the same values as `self`.\n",
      "     |  \n",
      "     |  to_tensor(self, default_value=None, name=None)\n",
      "     |      Converts this `RaggedTensor` into a `tf.Tensor`.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      >>> rt = ragged.constant([[9, 8, 7], [], [6, 5], [4]])\n",
      "     |      >>> print rt.to_tensor()\n",
      "     |      [[9 8 7]\n",
      "     |       [0 0 0]\n",
      "     |       [6 5 0]\n",
      "     |       [4 0 0]]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        default_value: Value to set for indices not specified in `self`. Defaults\n",
      "     |          to zero.  `default_value` must be broadcastable to\n",
      "     |          `self.shape[self.ragged_rank + 1:]`.\n",
      "     |        name: A name prefix for the returned tensors (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` with shape `ragged.bounding_shape(self)` and the\n",
      "     |        values specified by the non-empty values in `self`.  Empty values are\n",
      "     |        assigned `default_value`.\n",
      "     |  \n",
      "     |  value_rowids(self, name=None)\n",
      "     |      Returns the row indices for the `values` in this ragged tensor.\n",
      "     |      \n",
      "     |      `rt.value_rowids()` corresponds one-to-one with the outermost dimension of\n",
      "     |      `rt.values`, and specifies the row containing each value.  In particular,\n",
      "     |      the row `rt[row]` consists of the values `rt.values[j]` where\n",
      "     |      `rt.value_rowids()[j] == row`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name prefix for the returned tensor (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A 1-D integer `Tensor` with shape `self.values.shape[:1]`.\n",
      "     |        The returned tensor is nonnegative, and is sorted in ascending order.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |        ```python\n",
      "     |        >>> rt = ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])\n",
      "     |        >>> rt.values\n",
      "     |        tf.Tensor([3, 1, 4, 1, 5, 9, 2, 6])\n",
      "     |        >>> rt.value_rowids()\n",
      "     |        tf.Tensor([0, 0, 0, 0, 2, 2, 2, 3])  # corresponds 1:1 with rt.values\n",
      "     |        ```\n",
      "     |  \n",
      "     |  with_flat_values(self, new_values)\n",
      "     |      Returns a copy of `self` with `flat_values` replaced by `new_value`.\n",
      "     |      \n",
      "     |      Preserves cached row-partitioning tensors such as `self.cached_nrows` and\n",
      "     |      `self.cached_value_rowids` if they have values.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        new_values: Potentially ragged tensor that should replace\n",
      "     |        `self.flat_values`.  Must have `rank > 0`, and must have the same\n",
      "     |        number of rows as `self.flat_values`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `RaggedTensor`.\n",
      "     |        `result.rank = self.ragged_rank + new_values.rank`.\n",
      "     |        `result.ragged_rank = self.ragged_rank + new_values.ragged_rank`.\n",
      "     |  \n",
      "     |  with_row_splits_dtype(self, dtype)\n",
      "     |      Returns a copy of this RaggedTensor with the given `row_splits` dtype.\n",
      "     |      \n",
      "     |      For RaggedTensors with multiple ragged dimensions, the `row_splits` for all\n",
      "     |      nested `RaggedTensor` objects are cast to the given dtype.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        dtype: The dtype for `row_splits`.  One of `tf.int32` or `tf.int64`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A copy of this RaggedTensor, with the `row_splits` cast to the given\n",
      "     |        type.\n",
      "     |  \n",
      "     |  with_values(self, new_values)\n",
      "     |      Returns a copy of `self` with `values` replaced by `new_value`.\n",
      "     |      \n",
      "     |      Preserves cached row-partitioning tensors such as `self.cached_nrows` and\n",
      "     |      `self.cached_value_rowids` if they have values.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        new_values: Potentially ragged tensor to use as the `values` for the\n",
      "     |          returned `RaggedTensor`.  Must have `rank > 0`, and must have the same\n",
      "     |          number of rows as `self.values`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `RaggedTensor`.  `result.rank = 1 + new_values.rank`.\n",
      "     |        `result.ragged_rank = 1 + new_values.ragged_rank`\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_nested_row_lengths(flat_values, nested_row_lengths, name=None, validate=True) from abc.ABCMeta\n",
      "     |      Creates a `RaggedTensor` from a nested list of `row_lengths` tensors.\n",
      "     |      \n",
      "     |      Equivalent to:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      result = flat_values\n",
      "     |      for row_lengths in reversed(nested_row_lengths):\n",
      "     |        result = from_row_lengths(result, row_lengths)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        flat_values: A potentially ragged tensor.\n",
      "     |        nested_row_lengths: A list of 1-D integer tensors.  The `i`th tensor is\n",
      "     |          used as the `row_lengths` for the `i`th ragged dimension.\n",
      "     |        name: A name prefix for the RaggedTensor (optional).\n",
      "     |        validate: If true, then use assertions to check that the arguments form\n",
      "     |          a valid `RaggedTensor`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `RaggedTensor` (or `flat_values` if `nested_row_lengths` is empty).\n",
      "     |  \n",
      "     |  from_nested_row_splits(flat_values, nested_row_splits, name=None, validate=True) from abc.ABCMeta\n",
      "     |      Creates a `RaggedTensor` from a nested list of `row_splits` tensors.\n",
      "     |      \n",
      "     |      Equivalent to:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      result = flat_values\n",
      "     |      for row_splits in reversed(nested_row_splits):\n",
      "     |        result = from_row_splits(result, row_splits)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        flat_values: A potentially ragged tensor.\n",
      "     |        nested_row_splits: A list of 1-D integer tensors.  The `i`th tensor is\n",
      "     |          used as the `row_splits` for the `i`th ragged dimension.\n",
      "     |        name: A name prefix for the RaggedTensor (optional).\n",
      "     |        validate: If true, then use assertions to check that the arguments form a\n",
      "     |          valid `RaggedTensor`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `RaggedTensor` (or `flat_values` if `nested_row_splits` is empty).\n",
      "     |  \n",
      "     |  from_nested_value_rowids(flat_values, nested_value_rowids, nested_nrows=None, name=None, validate=True) from abc.ABCMeta\n",
      "     |      Creates a `RaggedTensor` from a nested list of `value_rowids` tensors.\n",
      "     |      \n",
      "     |      Equivalent to:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      result = flat_values\n",
      "     |      for (rowids, nrows) in reversed(zip(nested_value_rowids, nested_nrows)):\n",
      "     |        result = from_value_rowids(result, rowids, nrows)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        flat_values: A potentially ragged tensor.\n",
      "     |        nested_value_rowids: A list of 1-D integer tensors.  The `i`th tensor is\n",
      "     |          used as the `value_rowids` for the `i`th ragged dimension.\n",
      "     |        nested_nrows: A list of integer scalars.  The `i`th scalar is used as the\n",
      "     |          `nrows` for the `i`th ragged dimension.\n",
      "     |        name: A name prefix for the RaggedTensor (optional).\n",
      "     |        validate: If true, then use assertions to check that the arguments form\n",
      "     |          a valid `RaggedTensor`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `RaggedTensor` (or `flat_values` if `nested_value_rowids` is empty).\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `len(nested_values_rowids) != len(nested_nrows)`.\n",
      "     |  \n",
      "     |  from_row_lengths(values, row_lengths, name=None, validate=True) from abc.ABCMeta\n",
      "     |      Creates a `RaggedTensor` with rows partitioned by `row_lengths`.\n",
      "     |      \n",
      "     |      The returned `RaggedTensor` corresponds with the python list defined by:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      result = [[values.pop(0) for i in range(length)]\n",
      "     |                for length in row_lengths]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        values: A potentially ragged tensor with shape `[nvals, ...]`.\n",
      "     |        row_lengths: A 1-D integer tensor with shape `[nrows]`.  Must be\n",
      "     |          nonnegative.  `sum(row_lengths)` must be `nvals`.\n",
      "     |        name: A name prefix for the RaggedTensor (optional).\n",
      "     |        validate: If true, then use assertions to check that the arguments form\n",
      "     |          a valid `RaggedTensor`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `RaggedTensor`.  `result.rank = values.rank + 1`.\n",
      "     |        `result.ragged_rank = values.ragged_rank + 1`.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |        ```python\n",
      "     |        >>> print(tf.RaggedTensor.from_row_lengths(\n",
      "     |        ...     values=[3, 1, 4, 1, 5, 9, 2, 6],\n",
      "     |        ...     row_lengths=[4, 0, 3, 1, 0]))\n",
      "     |        <tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []])>\n",
      "     |        ```\n",
      "     |  \n",
      "     |  from_row_limits(values, row_limits, name=None, validate=True) from abc.ABCMeta\n",
      "     |      Creates a `RaggedTensor` with rows partitioned by `row_limits`.\n",
      "     |      \n",
      "     |      Equivalent to: `from_row_splits(values, concat([0, row_limits]))`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        values: A potentially ragged tensor with shape `[nvals, ...]`.\n",
      "     |        row_limits: A 1-D integer tensor with shape `[nrows]`.  Must be sorted in\n",
      "     |          ascending order.  If `nrows>0`, then `row_limits[-1]` must be `nvals`.\n",
      "     |        name: A name prefix for the RaggedTensor (optional).\n",
      "     |        validate: If true, then use assertions to check that the arguments form\n",
      "     |          a valid `RaggedTensor`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `RaggedTensor`.  `result.rank = values.rank + 1`.\n",
      "     |        `result.ragged_rank = values.ragged_rank + 1`.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |        ```python\n",
      "     |        >>> print(tf.RaggedTensor.from_row_limits(\n",
      "     |        ...     values=[3, 1, 4, 1, 5, 9, 2, 6],\n",
      "     |        ...     row_limits=[4, 4, 7, 8, 8]))\n",
      "     |        <tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>\n",
      "     |        ```\n",
      "     |  \n",
      "     |  from_row_splits(values, row_splits, name=None, validate=True) from abc.ABCMeta\n",
      "     |      Creates a `RaggedTensor` with rows partitioned by `row_splits`.\n",
      "     |      \n",
      "     |      The returned `RaggedTensor` corresponds with the python list defined by:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      result = [values[row_splits[i]:row_splits[i + 1]]\n",
      "     |                for i in range(len(row_splits) - 1)]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        values: A potentially ragged tensor with shape `[nvals, ...]`.\n",
      "     |        row_splits: A 1-D integer tensor with shape `[nrows+1]`.  Must not be\n",
      "     |          empty, and must be sorted in ascending order.  `row_splits[0]` must be\n",
      "     |          zero and `row_splits[-1]` must be `nvals`.\n",
      "     |        name: A name prefix for the RaggedTensor (optional).\n",
      "     |        validate: If true, then use assertions to check that the arguments form\n",
      "     |          a valid `RaggedTensor`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `RaggedTensor`.  `result.rank = values.rank + 1`.\n",
      "     |        `result.ragged_rank = values.ragged_rank + 1`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `row_splits` is an empty list.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |        ```python\n",
      "     |        >>> print(tf.RaggedTensor.from_row_splits(\n",
      "     |        ...     values=[3, 1, 4, 1, 5, 9, 2, 6],\n",
      "     |        ...     row_splits=[0, 4, 4, 7, 8, 8]))\n",
      "     |        <tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>\n",
      "     |        ```\n",
      "     |  \n",
      "     |  from_row_starts(values, row_starts, name=None, validate=True) from abc.ABCMeta\n",
      "     |      Creates a `RaggedTensor` with rows partitioned by `row_starts`.\n",
      "     |      \n",
      "     |      Equivalent to: `from_row_splits(values, concat([row_starts, nvals]))`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        values: A potentially ragged tensor with shape `[nvals, ...]`.\n",
      "     |        row_starts: A 1-D integer tensor with shape `[nrows]`.  Must be\n",
      "     |          nonnegative and sorted in ascending order.  If `nrows>0`, then\n",
      "     |          `row_starts[0]` must be zero.\n",
      "     |        name: A name prefix for the RaggedTensor (optional).\n",
      "     |        validate: If true, then use assertions to check that the arguments form\n",
      "     |          a valid `RaggedTensor`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `RaggedTensor`.  `result.rank = values.rank + 1`.\n",
      "     |        `result.ragged_rank = values.ragged_rank + 1`.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |        ```python\n",
      "     |        >>> print(tf.RaggedTensor.from_row_starts(\n",
      "     |        ...     values=[3, 1, 4, 1, 5, 9, 2, 6],\n",
      "     |        ...     row_starts=[0, 4, 4, 7, 8]))\n",
      "     |        <tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>\n",
      "     |        ```\n",
      "     |  \n",
      "     |  from_sparse(st_input, name=None, row_splits_dtype=tf.int64) from abc.ABCMeta\n",
      "     |      Converts a 2D `tf.SparseTensor` to a `RaggedTensor`.\n",
      "     |      \n",
      "     |      Each row of the `output` `RaggedTensor` will contain the explicit values\n",
      "     |      from the same row in `st_input`.  `st_input` must be ragged-right.  If not\n",
      "     |      it is not ragged-right, then an error will be generated.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      >>> st = SparseTensor(indices=[[0, 1], [0, 2], [0, 3], [1, 0], [3, 0]],\n",
      "     |      ...                   values=[1, 2, 3, 4, 5],\n",
      "     |      ...                   dense_shape=[4, 3])\n",
      "     |      >>> rt.RaggedTensor.from_sparse(st).eval().tolist()\n",
      "     |      [[1, 2, 3], [4], [], [5]]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Currently, only two-dimensional `SparseTensors` are supported.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        st_input: The sparse tensor to convert.  Must have rank 2.\n",
      "     |        name: A name prefix for the returned tensors (optional).\n",
      "     |        row_splits_dtype: `dtype` for the returned `RaggedTensor`'s `row_splits`\n",
      "     |          tensor.  One of `tf.int32` or `tf.int64`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `RaggedTensor` with the same values as `st_input`.\n",
      "     |        `output.ragged_rank = rank(st_input) - 1`.\n",
      "     |        `output.shape = [st_input.dense_shape[0], None]`.\n",
      "     |      Raises:\n",
      "     |        ValueError: If the number of dimensions in `st_input` is not known\n",
      "     |          statically, or is not two.\n",
      "     |  \n",
      "     |  from_tensor(tensor, lengths=None, padding=None, ragged_rank=1, name=None, row_splits_dtype=tf.int64) from abc.ABCMeta\n",
      "     |      Converts a `tf.Tensor` into a `RaggedTensor`.\n",
      "     |      \n",
      "     |      The set of absent/default values may be specified using a vector of lengths\n",
      "     |      or a padding value (but not both).  If `lengths` is specified, then the\n",
      "     |      output tensor will satisfy `output[row] = tensor[row][:lengths[row]]`. If\n",
      "     |      'lengths' is a list of lists or tuple of lists, those lists will be used\n",
      "     |      as nested row lengths. If `padding` is specified, then any row *suffix*\n",
      "     |      consisting entirely of `padding` will be excluded from the returned\n",
      "     |      `RaggedTensor`.  If neither `lengths` nor `padding` is specified, then the\n",
      "     |      returned `RaggedTensor` will have no absent/default values.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      >>> dt = tf.constant([[5, 7, 0], [0, 3, 0], [6, 0, 0]])\n",
      "     |      >>> tf.RaggedTensor.from_tensor(dt)\n",
      "     |      <tf.RaggedTensor [[5, 7, 0], [0, 3, 0], [6, 0, 0]]>\n",
      "     |      >>> tf.RaggedTensor.from_tensor(dt, lengths=[1, 0, 3])\n",
      "     |      <tf.RaggedTensor [[5], [], [6, 0, 0]]>\n",
      "     |      \n",
      "     |      >>> tf.RaggedTensor.from_tensor(dt, padding=0)\n",
      "     |      <tf.RaggedTensor [[5, 7], [0, 3], [6]]>\n",
      "     |      \n",
      "     |      >>> dt = tf.constant([[[5, 0], [7, 0], [0, 0]],\n",
      "     |                            [[0, 0], [3, 0], [0, 0]],\n",
      "     |                            [[6, 0], [0, 0], [0, 0]]])\n",
      "     |      >>> tf.RaggedTensor.from_tensor(dt, lengths=([2, 0, 3], [1, 1, 2, 0, 1]))\n",
      "     |      <tf.RaggedTensor [[[5], [7]], [], [[6, 0], [], [0]]]>\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        tensor: The `Tensor` to convert.  Must have rank `ragged_rank + 1` or\n",
      "     |          higher.\n",
      "     |        lengths: An optional set of row lengths, specified using a 1-D integer\n",
      "     |          `Tensor` whose length is equal to `tensor.shape[0]` (the number of rows\n",
      "     |          in `tensor`).  If specified, then `output[row]` will contain\n",
      "     |          `tensor[row][:lengths[row]]`.  Negative lengths are treated as zero. You\n",
      "     |          may optionally pass a list or tuple of lengths to this argument, which\n",
      "     |          will be used as nested row lengths to construct a ragged tensor with\n",
      "     |          multiple ragged dimensions.\n",
      "     |        padding: An optional padding value.  If specified, then any row suffix\n",
      "     |          consisting entirely of `padding` will be excluded from the returned\n",
      "     |          RaggedTensor.  `padding` is a `Tensor` with the same dtype as `tensor`\n",
      "     |          and with `shape=tensor.shape[ragged_rank + 1:]`.\n",
      "     |        ragged_rank: Integer specifying the ragged rank for the returned\n",
      "     |          `RaggedTensor`.  Must be greater than zero.\n",
      "     |        name: A name prefix for the returned tensors (optional).\n",
      "     |        row_splits_dtype: `dtype` for the returned `RaggedTensor`'s `row_splits`\n",
      "     |          tensor.  One of `tf.int32` or `tf.int64`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `RaggedTensor` with the specified `ragged_rank`.  The shape of the\n",
      "     |        returned ragged tensor is compatible with the shape of `tensor`.\n",
      "     |      Raises:\n",
      "     |        ValueError: If both `lengths` and `padding` are specified.\n",
      "     |  \n",
      "     |  from_value_rowids(values, value_rowids, nrows=None, name=None, validate=True) from abc.ABCMeta\n",
      "     |      Creates a `RaggedTensor` with rows partitioned by `value_rowids`.\n",
      "     |      \n",
      "     |      The returned `RaggedTensor` corresponds with the python list defined by:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      result = [[values[i] for i in range(len(values)) if value_rowids[i] == row]\n",
      "     |                for row in range(nrows)]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        values: A potentially ragged tensor with shape `[nvals, ...]`.\n",
      "     |        value_rowids: A 1-D integer tensor with shape `[nvals]`, which corresponds\n",
      "     |          one-to-one with `values`, and specifies each value's row index.  Must be\n",
      "     |          nonnegative, and must be sorted in ascending order.\n",
      "     |        nrows: An integer scalar specifying the number of rows.  This should be\n",
      "     |          specified if the `RaggedTensor` may containing empty training rows. Must\n",
      "     |          be greater than `value_rowids[-1]` (or zero if `value_rowids` is empty).\n",
      "     |          Defaults to `value_rowids[-1]` (or zero if `value_rowids` is empty).\n",
      "     |        name: A name prefix for the RaggedTensor (optional).\n",
      "     |        validate: If true, then use assertions to check that the arguments form\n",
      "     |          a valid `RaggedTensor`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `RaggedTensor`.  `result.rank = values.rank + 1`.\n",
      "     |        `result.ragged_rank = values.ragged_rank + 1`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `nrows` is incompatible with `value_rowids`.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |        ```python\n",
      "     |        >>> print(tf.RaggedTensor.from_value_rowids(\n",
      "     |        ...     values=[3, 1, 4, 1, 5, 9, 2, 6],\n",
      "     |        ...     value_rowids=[0, 0, 0, 0, 2, 2, 2, 3],\n",
      "     |        ...     nrows=5))\n",
      "     |        <tf.RaggedTensor [[3, 1, 4, 1], [], [5, 9, 2], [6], []]>\n",
      "     |        ```\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      The `DType` of values in this tensor.\n",
      "     |  \n",
      "     |  flat_values\n",
      "     |      The innermost `values` tensor for this ragged tensor.\n",
      "     |      \n",
      "     |      Concretely, if `rt.values` is a `Tensor`, then `rt.flat_values` is\n",
      "     |      `rt.values`; otherwise, `rt.flat_values` is `rt.values.flat_values`.\n",
      "     |      \n",
      "     |      Conceptually, `flat_values` is the tensor formed by flattening the\n",
      "     |      outermost dimension and all of the ragged dimensions into a single\n",
      "     |      dimension.\n",
      "     |      \n",
      "     |      `rt.flat_values.shape = [nvals] + rt.shape[rt.ragged_rank + 1:]`\n",
      "     |      (where `nvals` is the number of items in the flattened dimensions).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |      \n",
      "     |        ```python\n",
      "     |        >>> rt = ragged.constant([[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]])\n",
      "     |        >>> print rt.flat_values()\n",
      "     |        tf.Tensor([3, 1, 4, 1, 5, 9, 2, 6])\n",
      "     |        ```\n",
      "     |  \n",
      "     |  nested_row_splits\n",
      "     |      A tuple containing the row_splits for all ragged dimensions.\n",
      "     |      \n",
      "     |      `rt.nested_row_splits` is a tuple containing the `row_splits` tensors for\n",
      "     |      all ragged dimensions in `rt`, ordered from outermost to innermost.  In\n",
      "     |      particular, `rt.nested_row_splits = (rt.row_splits,) + value_splits` where:\n",
      "     |      \n",
      "     |          * `value_splits = ()` if `rt.values` is a `Tensor`.\n",
      "     |          * `value_splits = rt.values.nested_row_splits` otherwise.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `tuple` of 1-D integer `Tensor`s.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |      \n",
      "     |        ```python\n",
      "     |        >>> rt = ragged.constant([[[[3, 1, 4, 1], [], [5, 9, 2]], [], [[6], []]]])\n",
      "     |        >>> for i, splits in enumerate(rt.nested_row_splits()):\n",
      "     |        ...   print('Splits for dimension %d: %s' % (i+1, splits))\n",
      "     |        Splits for dimension 1: [0, 1]\n",
      "     |        Splits for dimension 2: [0, 3, 3, 5]\n",
      "     |        Splits for dimension 3: [0, 4, 4, 7, 8, 8]\n",
      "     |        ```\n",
      "     |  \n",
      "     |  ragged_rank\n",
      "     |      The number of ragged dimensions in this ragged tensor.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A Python `int` indicating the number of ragged dimensions in this ragged\n",
      "     |        tensor.  The outermost dimension is not considered ragged.\n",
      "     |  \n",
      "     |  row_splits\n",
      "     |      The row-split indices for this ragged tensor's `values`.\n",
      "     |      \n",
      "     |      `rt.row_splits` specifies where the values for each row begin and end in\n",
      "     |      `rt.values`.  In particular, the values for row `rt[i]` are stored in\n",
      "     |      the slice `rt.values[rt.row_splits[i]:rt.row_splits[i+1]]`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A 1-D integer `Tensor` with shape `[self.nrows+1]`.\n",
      "     |        The returned tensor is non-empty, and is sorted in ascending order.\n",
      "     |        `self.row_splits[0]` is zero, and `self.row_splits[-1]` is equal to\n",
      "     |        `self.values.shape[0]`.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |        ```python\n",
      "     |        >>> rt = ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])\n",
      "     |        >>> print rt.row_splits  # indices of row splits in rt.values\n",
      "     |        tf.Tensor([0, 4, 4, 7, 8, 8])\n",
      "     |        ```\n",
      "     |  \n",
      "     |  shape\n",
      "     |      The statically known shape of this ragged tensor.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `TensorShape` containing the statically known shape of this ragged\n",
      "     |        tensor.  Ragged dimensions have a size of `None`.\n",
      "     |      \n",
      "     |      Examples:\n",
      "     |      \n",
      "     |        ```python\n",
      "     |        >>> ragged.constant([[0], [1, 2]]).shape\n",
      "     |        TensorShape([Dimension(2), Dimension(None)])\n",
      "     |      \n",
      "     |        >>> ragged.constant([[[0, 1]], [[1, 2], [3, 4]]], ragged_rank=1).shape\n",
      "     |        TensorShape([Dimension(2), Dimension(None), Dimension(2)\n",
      "     |        ```\n",
      "     |  \n",
      "     |  values\n",
      "     |      The concatenated rows for this ragged tensor.\n",
      "     |      \n",
      "     |      `rt.values` is a potentially ragged tensor formed by flattening the two\n",
      "     |      outermost dimensions of `rt` into a single dimension.\n",
      "     |      \n",
      "     |      `rt.values.shape = [nvals] + rt.shape[2:]` (where `nvals` is the\n",
      "     |      number of items in the outer two dimensions of `rt`).\n",
      "     |      \n",
      "     |      `rt.ragged_rank = self.ragged_rank - 1`\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A potentially ragged tensor.\n",
      "     |      \n",
      "     |      #### Example:\n",
      "     |        ```python\n",
      "     |        >>> rt = ragged.constant([[3, 1, 4, 1], [], [5, 9, 2], [6], []])\n",
      "     |        >>> print rt.values\n",
      "     |        tf.Tensor([3, 1, 4, 1, 5, 9, 2, 6])\n",
      "     |        ```\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.framework.composite_tensor.CompositeTensor:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class RaggedTensorSpec(tensorflow.python.framework.type_spec.BatchableTypeSpec)\n",
      "     |  Type specification for a `tf.RaggedTensor`.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      RaggedTensorSpec\n",
      "     |      tensorflow.python.framework.type_spec.BatchableTypeSpec\n",
      "     |      tensorflow.python.framework.type_spec.TypeSpec\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, shape=None, dtype=tf.float32, ragged_rank=None, row_splits_dtype=tf.int64)\n",
      "     |      Constructs a type specification for a `tf.RaggedTensor`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: The shape of the RaggedTensor, or `None` to allow any shape.  If\n",
      "     |          a shape is specified, then all ragged dimensions must have size `None`.\n",
      "     |        dtype: `tf.DType` of values in the RaggedTensor.\n",
      "     |        ragged_rank: Python integer, the ragged rank of the RaggedTensor\n",
      "     |          to be described.  Defaults to `shape.ndims - 1`.\n",
      "     |        row_splits_dtype: `dtype` for the RaggedTensor's `row_splits` tensor.\n",
      "     |          One of `tf.int32` or `tf.int64`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_value(value) from abc.ABCMeta\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  value_type\n",
      "     |      The Python type for values that are compatible with this TypeSpec.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tensorflow.python.framework.type_spec.TypeSpec:\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __ne__(self, other)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  is_compatible_with(self, spec_or_value)\n",
      "     |      Returns true if `spec_or_value` is compatible with this TypeSpec.\n",
      "     |  \n",
      "     |  most_specific_compatible_type(self, other)\n",
      "     |      Returns the most specific TypeSpec compatible with `self` and `other`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: A `TypeSpec`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If there is no TypeSpec that is compatible with both `self`\n",
      "     |          and `other`.\n",
      "    \n",
      "    class RandomShuffleQueue(QueueBase)\n",
      "     |  A queue implementation that dequeues elements in a random order.\n",
      "     |  \n",
      "     |  See `tf.queue.QueueBase` for a description of the methods on\n",
      "     |  this class.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      RandomShuffleQueue\n",
      "     |      QueueBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, capacity, min_after_dequeue, dtypes, shapes=None, names=None, seed=None, shared_name=None, name='random_shuffle_queue')\n",
      "     |      Create a queue that dequeues elements in a random order.\n",
      "     |      \n",
      "     |      A `RandomShuffleQueue` has bounded capacity; supports multiple\n",
      "     |      concurrent producers and consumers; and provides exactly-once\n",
      "     |      delivery.\n",
      "     |      \n",
      "     |      A `RandomShuffleQueue` holds a list of up to `capacity`\n",
      "     |      elements. Each element is a fixed-length tuple of tensors whose\n",
      "     |      dtypes are described by `dtypes`, and whose shapes are optionally\n",
      "     |      described by the `shapes` argument.\n",
      "     |      \n",
      "     |      If the `shapes` argument is specified, each component of a queue\n",
      "     |      element must have the respective fixed shape. If it is\n",
      "     |      unspecified, different queue elements may have different shapes,\n",
      "     |      but the use of `dequeue_many` is disallowed.\n",
      "     |      \n",
      "     |      The `min_after_dequeue` argument allows the caller to specify a\n",
      "     |      minimum number of elements that will remain in the queue after a\n",
      "     |      `dequeue` or `dequeue_many` operation completes, to ensure a\n",
      "     |      minimum level of mixing of elements. This invariant is maintained\n",
      "     |      by blocking those operations until sufficient elements have been\n",
      "     |      enqueued. The `min_after_dequeue` argument is ignored after the\n",
      "     |      queue has been closed.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        capacity: An integer. The upper bound on the number of elements\n",
      "     |          that may be stored in this queue.\n",
      "     |        min_after_dequeue: An integer (described above).\n",
      "     |        dtypes:  A list of `DType` objects. The length of `dtypes` must equal\n",
      "     |          the number of tensors in each queue element.\n",
      "     |        shapes: (Optional.) A list of fully-defined `TensorShape` objects\n",
      "     |          with the same length as `dtypes`, or `None`.\n",
      "     |        names: (Optional.) A list of string naming the components in the queue\n",
      "     |          with the same length as `dtypes`, or `None`.  If specified the dequeue\n",
      "     |          methods return a dictionary with the names as keys.\n",
      "     |        seed: A Python integer. Used to create a random seed. See\n",
      "     |          `tf.compat.v1.set_random_seed`\n",
      "     |          for behavior.\n",
      "     |        shared_name: (Optional.) If non-empty, this queue will be shared under\n",
      "     |          the given name across multiple sessions.\n",
      "     |        name: Optional name for the queue operation.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from QueueBase:\n",
      "     |  \n",
      "     |  close(self, cancel_pending_enqueues=False, name=None)\n",
      "     |      Closes this queue.\n",
      "     |      \n",
      "     |      This operation signals that no more elements will be enqueued in\n",
      "     |      the given queue. Subsequent `enqueue` and `enqueue_many`\n",
      "     |      operations will fail. Subsequent `dequeue` and `dequeue_many`\n",
      "     |      operations will continue to succeed if sufficient elements remain\n",
      "     |      in the queue. Subsequently dequeue and dequeue_many operations\n",
      "     |      that would otherwise block waiting for more elements (if close\n",
      "     |      hadn't been called) will now fail immediately.\n",
      "     |      \n",
      "     |      If `cancel_pending_enqueues` is `True`, all pending requests will also\n",
      "     |      be canceled.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        cancel_pending_enqueues: (Optional.) A boolean, defaulting to\n",
      "     |          `False` (described above).\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The operation that closes the queue.\n",
      "     |  \n",
      "     |  dequeue(self, name=None)\n",
      "     |      Dequeues one element from this queue.\n",
      "     |      \n",
      "     |      If the queue is empty when this operation executes, it will block\n",
      "     |      until there is an element to dequeue.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed, the queue is empty, and there are no pending\n",
      "     |      enqueue operations that can fulfill this request,\n",
      "     |      `tf.errors.OutOfRangeError` will be raised. If the session is\n",
      "     |      `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The tuple of tensors that was dequeued.\n",
      "     |  \n",
      "     |  dequeue_many(self, n, name=None)\n",
      "     |      Dequeues and concatenates `n` elements from this queue.\n",
      "     |      \n",
      "     |      This operation concatenates queue-element component tensors along\n",
      "     |      the 0th dimension to make a single component tensor.  All of the\n",
      "     |      components in the dequeued tuple will have size `n` in the 0th dimension.\n",
      "     |      \n",
      "     |      If the queue is closed and there are less than `n` elements left, then an\n",
      "     |      `OutOfRange` exception is raised.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed, the queue contains fewer than `n` elements, and\n",
      "     |      there are no pending enqueue operations that can fulfill this\n",
      "     |      request, `tf.errors.OutOfRangeError` will be raised. If the\n",
      "     |      session is `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        n: A scalar `Tensor` containing the number of elements to dequeue.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The list of concatenated tensors that was dequeued.\n",
      "     |  \n",
      "     |  dequeue_up_to(self, n, name=None)\n",
      "     |      Dequeues and concatenates `n` elements from this queue.\n",
      "     |      \n",
      "     |      **Note** This operation is not supported by all queues.  If a queue does not\n",
      "     |      support DequeueUpTo, then a `tf.errors.UnimplementedError` is raised.\n",
      "     |      \n",
      "     |      This operation concatenates queue-element component tensors along\n",
      "     |      the 0th dimension to make a single component tensor. If the queue\n",
      "     |      has not been closed, all of the components in the dequeued tuple\n",
      "     |      will have size `n` in the 0th dimension.\n",
      "     |      \n",
      "     |      If the queue is closed and there are more than `0` but fewer than\n",
      "     |      `n` elements remaining, then instead of raising a\n",
      "     |      `tf.errors.OutOfRangeError` like `tf.QueueBase.dequeue_many`,\n",
      "     |      less than `n` elements are returned immediately.  If the queue is\n",
      "     |      closed and there are `0` elements left in the queue, then a\n",
      "     |      `tf.errors.OutOfRangeError` is raised just like in `dequeue_many`.\n",
      "     |      Otherwise the behavior is identical to `dequeue_many`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        n: A scalar `Tensor` containing the number of elements to dequeue.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The tuple of concatenated tensors that was dequeued.\n",
      "     |  \n",
      "     |  enqueue(self, vals, name=None)\n",
      "     |      Enqueues one element to this queue.\n",
      "     |      \n",
      "     |      If the queue is full when this operation executes, it will block\n",
      "     |      until the element has been enqueued.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed before this operation runs,\n",
      "     |      `tf.errors.CancelledError` will be raised. If this operation is\n",
      "     |      blocked, and either (i) the queue is closed by a close operation\n",
      "     |      with `cancel_pending_enqueues=True`, or (ii) the session is\n",
      "     |      `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        vals: A tensor, a list or tuple of tensors, or a dictionary containing\n",
      "     |          the values to enqueue.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The operation that enqueues a new tuple of tensors to the queue.\n",
      "     |  \n",
      "     |  enqueue_many(self, vals, name=None)\n",
      "     |      Enqueues zero or more elements to this queue.\n",
      "     |      \n",
      "     |      This operation slices each component tensor along the 0th dimension to\n",
      "     |      make multiple queue elements. All of the tensors in `vals` must have the\n",
      "     |      same size in the 0th dimension.\n",
      "     |      \n",
      "     |      If the queue is full when this operation executes, it will block\n",
      "     |      until all of the elements have been enqueued.\n",
      "     |      \n",
      "     |      At runtime, this operation may raise an error if the queue is\n",
      "     |      `tf.QueueBase.close` before or during its execution. If the\n",
      "     |      queue is closed before this operation runs,\n",
      "     |      `tf.errors.CancelledError` will be raised. If this operation is\n",
      "     |      blocked, and either (i) the queue is closed by a close operation\n",
      "     |      with `cancel_pending_enqueues=True`, or (ii) the session is\n",
      "     |      `tf.Session.close`,\n",
      "     |      `tf.errors.CancelledError` will be raised.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        vals: A tensor, a list or tuple of tensors, or a dictionary\n",
      "     |          from which the queue elements are taken.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The operation that enqueues a batch of tuples of tensors to the queue.\n",
      "     |  \n",
      "     |  is_closed(self, name=None)\n",
      "     |      Returns true if queue is closed.\n",
      "     |      \n",
      "     |      This operation returns true if the queue is closed and false if the queue\n",
      "     |      is open.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        True if the queue is closed and false if the queue is open.\n",
      "     |  \n",
      "     |  size(self, name=None)\n",
      "     |      Compute the number of elements in this queue.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A scalar tensor containing the number of elements in this queue.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from QueueBase:\n",
      "     |  \n",
      "     |  from_list(index, queues)\n",
      "     |      Create a queue using the queue reference from `queues[index]`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        index: An integer scalar tensor that determines the input that gets\n",
      "     |          selected.\n",
      "     |        queues: A list of `QueueBase` objects.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `QueueBase` object.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: When `queues` is not a list of `QueueBase` objects,\n",
      "     |          or when the data types of `queues` are not all the same.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from QueueBase:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  dtypes\n",
      "     |      The list of dtypes for each component of a queue element.\n",
      "     |  \n",
      "     |  name\n",
      "     |      The name of the underlying queue.\n",
      "     |  \n",
      "     |  names\n",
      "     |      The list of names for each component of a queue element.\n",
      "     |  \n",
      "     |  queue_ref\n",
      "     |      The underlying queue reference.\n",
      "     |  \n",
      "     |  shapes\n",
      "     |      The list of shapes for each component of a queue element.\n",
      "    \n",
      "    class ReaderBase(builtins.object)\n",
      "     |  Base class for different Reader types, that produce a record every step.\n",
      "     |  \n",
      "     |  Conceptually, Readers convert string 'work units' into records (key,\n",
      "     |  value pairs).  Typically the 'work units' are filenames and the\n",
      "     |  records are extracted from the contents of those files.  We want a\n",
      "     |  single record produced per step, but a work unit can correspond to\n",
      "     |  many records.\n",
      "     |  \n",
      "     |  Therefore we introduce some decoupling using a queue.  The queue\n",
      "     |  contains the work units and the Reader dequeues from the queue when\n",
      "     |  it is asked to produce a record (via Read()) but it has finished the\n",
      "     |  last work unit.\n",
      "     |  \n",
      "     |  @compatibility(eager)\n",
      "     |  Readers are not compatible with eager execution. Instead, please\n",
      "     |  use `tf.data` to get data into your model.\n",
      "     |  @end_compatibility\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, reader_ref, supports_serialize=False)\n",
      "     |      Creates a new ReaderBase.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        reader_ref: The operation that implements the reader.\n",
      "     |        supports_serialize: True if the reader implementation can\n",
      "     |          serialize its state.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        RuntimeError: If eager execution is enabled.\n",
      "     |  \n",
      "     |  num_records_produced(self, name=None)\n",
      "     |      Returns the number of records this reader has produced.\n",
      "     |      \n",
      "     |      This is the same as the number of Read executions that have\n",
      "     |      succeeded.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An int64 Tensor.\n",
      "     |  \n",
      "     |  num_work_units_completed(self, name=None)\n",
      "     |      Returns the number of work units this reader has finished processing.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An int64 Tensor.\n",
      "     |  \n",
      "     |  read(self, queue, name=None)\n",
      "     |      Returns the next record (key, value) pair produced by a reader.\n",
      "     |      \n",
      "     |      Will dequeue a work unit from queue if necessary (e.g. when the\n",
      "     |      Reader needs to start reading from a new file since it has\n",
      "     |      finished with the previous file).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        queue: A Queue or a mutable string Tensor representing a handle\n",
      "     |          to a Queue, with string work items.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A tuple of Tensors (key, value).\n",
      "     |        key: A string scalar Tensor.\n",
      "     |        value: A string scalar Tensor.\n",
      "     |  \n",
      "     |  read_up_to(self, queue, num_records, name=None)\n",
      "     |      Returns up to num_records (key, value) pairs produced by a reader.\n",
      "     |      \n",
      "     |      Will dequeue a work unit from queue if necessary (e.g., when the\n",
      "     |      Reader needs to start reading from a new file since it has\n",
      "     |      finished with the previous file).\n",
      "     |      It may return less than num_records even before the last batch.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        queue: A Queue or a mutable string Tensor representing a handle\n",
      "     |          to a Queue, with string work items.\n",
      "     |        num_records: Number of records to read.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A tuple of Tensors (keys, values).\n",
      "     |        keys: A 1-D string Tensor.\n",
      "     |        values: A 1-D string Tensor.\n",
      "     |  \n",
      "     |  reset(self, name=None)\n",
      "     |      Restore a reader to its initial clean state.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The created Operation.\n",
      "     |  \n",
      "     |  restore_state(self, state, name=None)\n",
      "     |      Restore a reader to a previously saved state.\n",
      "     |      \n",
      "     |      Not all Readers support being restored, so this can produce an\n",
      "     |      Unimplemented error.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        state: A string Tensor.\n",
      "     |          Result of a SerializeState of a Reader with matching type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The created Operation.\n",
      "     |  \n",
      "     |  serialize_state(self, name=None)\n",
      "     |      Produce a string tensor that encodes the state of a reader.\n",
      "     |      \n",
      "     |      Not all Readers support being serialized, so this can produce an\n",
      "     |      Unimplemented error.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A string Tensor.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  reader_ref\n",
      "     |      Op that implements the reader.\n",
      "     |  \n",
      "     |  supports_serialize\n",
      "     |      Whether the Reader implementation can serialize its state.\n",
      "    \n",
      "    class RegisterGradient(builtins.object)\n",
      "     |  A decorator for registering the gradient function for an op type.\n",
      "     |  \n",
      "     |  This decorator is only used when defining a new op type. For an op\n",
      "     |  with `m` inputs and `n` outputs, the gradient function is a function\n",
      "     |  that takes the original `Operation` and `n` `Tensor` objects\n",
      "     |  (representing the gradients with respect to each output of the op),\n",
      "     |  and returns `m` `Tensor` objects (representing the partial gradients\n",
      "     |  with respect to each input of the op).\n",
      "     |  \n",
      "     |  For example, assuming that operations of type `\"Sub\"` take two\n",
      "     |  inputs `x` and `y`, and return a single output `x - y`, the\n",
      "     |  following gradient function would be registered:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  @tf.RegisterGradient(\"Sub\")\n",
      "     |  def _sub_grad(unused_op, grad):\n",
      "     |    return grad, tf.negative(grad)\n",
      "     |  ```\n",
      "     |  \n",
      "     |  The decorator argument `op_type` is the string type of an\n",
      "     |  operation. This corresponds to the `OpDef.name` field for the proto\n",
      "     |  that defines the operation.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, f)\n",
      "     |      Registers the function `f` as gradient function for `op_type`.\n",
      "     |  \n",
      "     |  __init__(self, op_type)\n",
      "     |      Creates a new decorator with `op_type` as the Operation type.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        op_type: The string type of an operation. This corresponds to the\n",
      "     |          `OpDef.name` field for the proto that defines the operation.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If `op_type` is not string.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class RunMetadata(google.protobuf.pyext._message.CMessage, google.protobuf.message.Message)\n",
      "     |  A ProtocolMessage\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      RunMetadata\n",
      "     |      google.protobuf.pyext._message.CMessage\n",
      "     |      google.protobuf.message.Message\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  cost_graph\n",
      "     |      Field tensorflow.RunMetadata.cost_graph\n",
      "     |  \n",
      "     |  function_graphs\n",
      "     |      Field tensorflow.RunMetadata.function_graphs\n",
      "     |  \n",
      "     |  partition_graphs\n",
      "     |      Field tensorflow.RunMetadata.partition_graphs\n",
      "     |  \n",
      "     |  step_stats\n",
      "     |      Field tensorflow.RunMetadata.step_stats\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  DESCRIPTOR = <google.protobuf.pyext._message.MessageDescriptor object>\n",
      "     |  \n",
      "     |  FunctionGraphs = <class 'tensorflow.core.protobuf.config_pb2.FunctionG...\n",
      "     |      A ProtocolMessage\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.pyext._message.CMessage:\n",
      "     |  \n",
      "     |  ByteSize(...)\n",
      "     |      Returns the size of the message in bytes.\n",
      "     |  \n",
      "     |  Clear(...)\n",
      "     |      Clears the message.\n",
      "     |  \n",
      "     |  ClearExtension(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  ClearField(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  CopyFrom(...)\n",
      "     |      Copies a protocol message into the current message.\n",
      "     |  \n",
      "     |  DiscardUnknownFields(...)\n",
      "     |      Discards the unknown fields.\n",
      "     |  \n",
      "     |  FindInitializationErrors(...)\n",
      "     |      Finds unset required fields.\n",
      "     |  \n",
      "     |  FromString(...) from google.protobuf.pyext.cpp_message.GeneratedProtocolMessageType\n",
      "     |      Creates new method instance from given serialized data.\n",
      "     |  \n",
      "     |  HasExtension(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  HasField(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  IsInitialized(...)\n",
      "     |      Checks if all required fields of a protocol message are set.\n",
      "     |  \n",
      "     |  ListFields(...)\n",
      "     |      Lists all set fields of a message.\n",
      "     |  \n",
      "     |  MergeFrom(...)\n",
      "     |      Merges a protocol message into the current message.\n",
      "     |  \n",
      "     |  MergeFromString(...)\n",
      "     |      Merges a serialized message into the current message.\n",
      "     |  \n",
      "     |  ParseFromString(...)\n",
      "     |      Parses a serialized message into the current message.\n",
      "     |  \n",
      "     |  RegisterExtension(...) from google.protobuf.pyext.cpp_message.GeneratedProtocolMessageType\n",
      "     |      Registers an extension with the current message.\n",
      "     |  \n",
      "     |  SerializePartialToString(...)\n",
      "     |      Serializes the message to a string, even if it isn't initialized.\n",
      "     |  \n",
      "     |  SerializeToString(...)\n",
      "     |      Serializes the message to a string, only for initialized messages.\n",
      "     |  \n",
      "     |  SetInParent(...)\n",
      "     |      Sets the has bit of the given field in its parent message.\n",
      "     |  \n",
      "     |  UnknownFields(...)\n",
      "     |      Parse unknown field set\n",
      "     |  \n",
      "     |  WhichOneof(...)\n",
      "     |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      Makes a deep copy of the class.\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from google.protobuf.pyext._message.MessageMeta\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  __unicode__(...)\n",
      "     |      Outputs a unicode representation of the message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google.protobuf.pyext._message.CMessage:\n",
      "     |  \n",
      "     |  Extensions\n",
      "     |      Extension dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from google.protobuf.pyext._message.CMessage:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Support the pickle protocol.\n",
      "    \n",
      "    class RunOptions(google.protobuf.pyext._message.CMessage, google.protobuf.message.Message)\n",
      "     |  A ProtocolMessage\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      RunOptions\n",
      "     |      google.protobuf.pyext._message.CMessage\n",
      "     |      google.protobuf.message.Message\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  debug_options\n",
      "     |      Field tensorflow.RunOptions.debug_options\n",
      "     |  \n",
      "     |  experimental\n",
      "     |      Field tensorflow.RunOptions.experimental\n",
      "     |  \n",
      "     |  inter_op_thread_pool\n",
      "     |      Field tensorflow.RunOptions.inter_op_thread_pool\n",
      "     |  \n",
      "     |  output_partition_graphs\n",
      "     |      Field tensorflow.RunOptions.output_partition_graphs\n",
      "     |  \n",
      "     |  report_tensor_allocations_upon_oom\n",
      "     |      Field tensorflow.RunOptions.report_tensor_allocations_upon_oom\n",
      "     |  \n",
      "     |  timeout_in_ms\n",
      "     |      Field tensorflow.RunOptions.timeout_in_ms\n",
      "     |  \n",
      "     |  trace_level\n",
      "     |      Field tensorflow.RunOptions.trace_level\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  DESCRIPTOR = <google.protobuf.pyext._message.MessageDescriptor object>\n",
      "     |  \n",
      "     |  Experimental = <class 'tensorflow.core.protobuf.config_pb2.Experimenta...\n",
      "     |      A ProtocolMessage\n",
      "     |  \n",
      "     |  FULL_TRACE = 3\n",
      "     |  \n",
      "     |  HARDWARE_TRACE = 2\n",
      "     |  \n",
      "     |  NO_TRACE = 0\n",
      "     |  \n",
      "     |  SOFTWARE_TRACE = 1\n",
      "     |  \n",
      "     |  TraceLevel = <google.protobuf.internal.enum_type_wrapper.EnumTypeWrapp...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.pyext._message.CMessage:\n",
      "     |  \n",
      "     |  ByteSize(...)\n",
      "     |      Returns the size of the message in bytes.\n",
      "     |  \n",
      "     |  Clear(...)\n",
      "     |      Clears the message.\n",
      "     |  \n",
      "     |  ClearExtension(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  ClearField(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  CopyFrom(...)\n",
      "     |      Copies a protocol message into the current message.\n",
      "     |  \n",
      "     |  DiscardUnknownFields(...)\n",
      "     |      Discards the unknown fields.\n",
      "     |  \n",
      "     |  FindInitializationErrors(...)\n",
      "     |      Finds unset required fields.\n",
      "     |  \n",
      "     |  FromString(...) from google.protobuf.pyext.cpp_message.GeneratedProtocolMessageType\n",
      "     |      Creates new method instance from given serialized data.\n",
      "     |  \n",
      "     |  HasExtension(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  HasField(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  IsInitialized(...)\n",
      "     |      Checks if all required fields of a protocol message are set.\n",
      "     |  \n",
      "     |  ListFields(...)\n",
      "     |      Lists all set fields of a message.\n",
      "     |  \n",
      "     |  MergeFrom(...)\n",
      "     |      Merges a protocol message into the current message.\n",
      "     |  \n",
      "     |  MergeFromString(...)\n",
      "     |      Merges a serialized message into the current message.\n",
      "     |  \n",
      "     |  ParseFromString(...)\n",
      "     |      Parses a serialized message into the current message.\n",
      "     |  \n",
      "     |  RegisterExtension(...) from google.protobuf.pyext.cpp_message.GeneratedProtocolMessageType\n",
      "     |      Registers an extension with the current message.\n",
      "     |  \n",
      "     |  SerializePartialToString(...)\n",
      "     |      Serializes the message to a string, even if it isn't initialized.\n",
      "     |  \n",
      "     |  SerializeToString(...)\n",
      "     |      Serializes the message to a string, only for initialized messages.\n",
      "     |  \n",
      "     |  SetInParent(...)\n",
      "     |      Sets the has bit of the given field in its parent message.\n",
      "     |  \n",
      "     |  UnknownFields(...)\n",
      "     |      Parse unknown field set\n",
      "     |  \n",
      "     |  WhichOneof(...)\n",
      "     |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      Makes a deep copy of the class.\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from google.protobuf.pyext._message.MessageMeta\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  __unicode__(...)\n",
      "     |      Outputs a unicode representation of the message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google.protobuf.pyext._message.CMessage:\n",
      "     |  \n",
      "     |  Extensions\n",
      "     |      Extension dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from google.protobuf.pyext._message.CMessage:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Support the pickle protocol.\n",
      "    \n",
      "    class Session(BaseSession)\n",
      "     |  A class for running TensorFlow operations.\n",
      "     |  \n",
      "     |  A `Session` object encapsulates the environment in which `Operation`\n",
      "     |  objects are executed, and `Tensor` objects are evaluated. For\n",
      "     |  example:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  # Build a graph.\n",
      "     |  a = tf.constant(5.0)\n",
      "     |  b = tf.constant(6.0)\n",
      "     |  c = a * b\n",
      "     |  \n",
      "     |  # Launch the graph in a session.\n",
      "     |  sess = tf.compat.v1.Session()\n",
      "     |  \n",
      "     |  # Evaluate the tensor `c`.\n",
      "     |  print(sess.run(c))\n",
      "     |  ```\n",
      "     |  \n",
      "     |  A session may own resources, such as\n",
      "     |  `tf.Variable`, `tf.queue.QueueBase`,\n",
      "     |  and `tf.compat.v1.ReaderBase`. It is important to release\n",
      "     |  these resources when they are no longer required. To do this, either\n",
      "     |  invoke the `tf.Session.close` method on the session, or use\n",
      "     |  the session as a context manager. The following two examples are\n",
      "     |  equivalent:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  # Using the `close()` method.\n",
      "     |  sess = tf.compat.v1.Session()\n",
      "     |  sess.run(...)\n",
      "     |  sess.close()\n",
      "     |  \n",
      "     |  # Using the context manager.\n",
      "     |  with tf.compat.v1.Session() as sess:\n",
      "     |    sess.run(...)\n",
      "     |  ```\n",
      "     |  \n",
      "     |  The\n",
      "     |  [`ConfigProto`](https://www.tensorflow.org/code/tensorflow/core/protobuf/config.proto)\n",
      "     |  protocol buffer exposes various configuration options for a\n",
      "     |  session. For example, to create a session that uses soft constraints\n",
      "     |  for device placement, and log the resulting placement decisions,\n",
      "     |  create a session as follows:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  # Launch the graph in a session that allows soft device placement and\n",
      "     |  # logs the placement decisions.\n",
      "     |  sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(\n",
      "     |      allow_soft_placement=True,\n",
      "     |      log_device_placement=True))\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Session\n",
      "     |      BaseSession\n",
      "     |      SessionInterface\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __enter__(self)\n",
      "     |  \n",
      "     |  __exit__(self, exec_type, exec_value, exec_tb)\n",
      "     |  \n",
      "     |  __init__(self, target='', graph=None, config=None)\n",
      "     |      Creates a new TensorFlow session.\n",
      "     |      \n",
      "     |      If no `graph` argument is specified when constructing the session,\n",
      "     |      the default graph will be launched in the session. If you are\n",
      "     |      using more than one graph (created with `tf.Graph()`) in the same\n",
      "     |      process, you will have to use different sessions for each graph,\n",
      "     |      but each graph can be used in multiple sessions. In this case, it\n",
      "     |      is often clearer to pass the graph to be launched explicitly to\n",
      "     |      the session constructor.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        target: (Optional.) The execution engine to connect to. Defaults to using\n",
      "     |          an in-process engine. See\n",
      "     |          [Distributed TensorFlow](https://tensorflow.org/deploy/distributed) for\n",
      "     |            more examples.\n",
      "     |        graph: (Optional.) The `Graph` to be launched (described above).\n",
      "     |        config: (Optional.) A\n",
      "     |          [`ConfigProto`](https://www.tensorflow.org/code/tensorflow/core/protobuf/config.proto)\n",
      "     |            protocol buffer with configuration options for the session.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  reset(target, containers=None, config=None)\n",
      "     |      Resets resource containers on `target`, and close all connected sessions.\n",
      "     |      \n",
      "     |      A resource container is distributed across all workers in the\n",
      "     |      same cluster as `target`.  When a resource container on `target`\n",
      "     |      is reset, resources associated with that container will be cleared.\n",
      "     |      In particular, all Variables in the container will become undefined:\n",
      "     |      they lose their values and shapes.\n",
      "     |      \n",
      "     |      NOTE:\n",
      "     |      (i) reset() is currently only implemented for distributed sessions.\n",
      "     |      (ii) Any sessions on the master named by `target` will be closed.\n",
      "     |      \n",
      "     |      If no resource containers are provided, all containers are reset.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        target: The execution engine to connect to.\n",
      "     |        containers: A list of resource container name strings, or `None` if all of\n",
      "     |          all the containers are to be reset.\n",
      "     |        config: (Optional.) Protocol buffer with configuration options.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        tf.errors.OpError: Or one of its subclasses if an error occurs while\n",
      "     |          resetting containers.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from BaseSession:\n",
      "     |  \n",
      "     |  __del__(self)\n",
      "     |  \n",
      "     |  as_default(self)\n",
      "     |      Returns a context manager that makes this object the default session.\n",
      "     |      \n",
      "     |      Use with the `with` keyword to specify that calls to\n",
      "     |      `tf.Operation.run` or `tf.Tensor.eval` should be executed in\n",
      "     |      this session.\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      c = tf.constant(..)\n",
      "     |      sess = tf.compat.v1.Session()\n",
      "     |      \n",
      "     |      with sess.as_default():\n",
      "     |        assert tf.compat.v1.get_default_session() is sess\n",
      "     |        print(c.eval())\n",
      "     |      ```\n",
      "     |      \n",
      "     |      To get the current default session, use `tf.compat.v1.get_default_session`.\n",
      "     |      \n",
      "     |      *N.B.* The `as_default` context manager *does not* close the\n",
      "     |      session when you exit the context, and you must close the session\n",
      "     |      explicitly.\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      c = tf.constant(...)\n",
      "     |      sess = tf.compat.v1.Session()\n",
      "     |      with sess.as_default():\n",
      "     |        print(c.eval())\n",
      "     |      # ...\n",
      "     |      with sess.as_default():\n",
      "     |        print(c.eval())\n",
      "     |      \n",
      "     |      sess.close()\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Alternatively, you can use `with tf.compat.v1.Session():` to create a\n",
      "     |      session that is automatically closed on exiting the context,\n",
      "     |      including when an uncaught exception is raised.\n",
      "     |      \n",
      "     |      *N.B.* The default session is a property of the current thread. If you\n",
      "     |      create a new thread, and wish to use the default session in that\n",
      "     |      thread, you must explicitly add a `with sess.as_default():` in that\n",
      "     |      thread's function.\n",
      "     |      \n",
      "     |      *N.B.* Entering a `with sess.as_default():` block does not affect\n",
      "     |      the current default graph. If you are using multiple graphs, and\n",
      "     |      `sess.graph` is different from the value of\n",
      "     |      `tf.compat.v1.get_default_graph`, you must explicitly enter a\n",
      "     |      `with sess.graph.as_default():` block to make `sess.graph` the default\n",
      "     |      graph.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A context manager using this session as the default session.\n",
      "     |  \n",
      "     |  close(self)\n",
      "     |      Closes this session.\n",
      "     |      \n",
      "     |      Calling this method frees all resources associated with the session.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        tf.errors.OpError: Or one of its subclasses if an error occurs while\n",
      "     |          closing the TensorFlow session.\n",
      "     |  \n",
      "     |  list_devices(self)\n",
      "     |      Lists available devices in this session.\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      devices = sess.list_devices()\n",
      "     |      for d in devices:\n",
      "     |        print(d.name)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Where:\n",
      "     |        Each element in the list has the following properties\n",
      "     |        name: A string with the full name of the device. ex:\n",
      "     |            `/job:worker/replica:0/task:3/device:CPU:0`\n",
      "     |        device_type: The type of the device (e.g. `CPU`, `GPU`, `TPU`.)\n",
      "     |        memory_limit: The maximum amount of memory available on the device.\n",
      "     |            Note: depending on the device, it is possible the usable memory could\n",
      "     |            be substantially less.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        tf.errors.OpError: If it encounters an error (e.g. session is in an\n",
      "     |        invalid state, or network errors occur).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A list of devices in the session.\n",
      "     |  \n",
      "     |  make_callable(self, fetches, feed_list=None, accept_options=False)\n",
      "     |      Returns a Python callable that runs a particular step.\n",
      "     |      \n",
      "     |      The returned callable will take `len(feed_list)` arguments whose types\n",
      "     |      must be compatible feed values for the respective elements of `feed_list`.\n",
      "     |      For example, if element `i` of `feed_list` is a `tf.Tensor`, the `i`th\n",
      "     |      argument to the returned callable must be a numpy ndarray (or something\n",
      "     |      convertible to an ndarray) with matching element type and shape. See\n",
      "     |      `tf.Session.run` for details of the allowable feed key and value types.\n",
      "     |      \n",
      "     |      The returned callable will have the same return type as\n",
      "     |      `tf.Session.run(fetches, ...)`. For example, if `fetches` is a `tf.Tensor`,\n",
      "     |      the callable will return a numpy ndarray; if `fetches` is a `tf.Operation`,\n",
      "     |      it will return `None`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        fetches: A value or list of values to fetch. See `tf.Session.run` for\n",
      "     |          details of the allowable fetch types.\n",
      "     |        feed_list: (Optional.) A list of `feed_dict` keys. See `tf.Session.run`\n",
      "     |          for details of the allowable feed key types.\n",
      "     |        accept_options: (Optional.) If `True`, the returned `Callable` will be\n",
      "     |          able to accept `tf.compat.v1.RunOptions` and `tf.compat.v1.RunMetadata`\n",
      "     |          as optional keyword arguments `options` and `run_metadata`,\n",
      "     |          respectively, with the same syntax and semantics as `tf.Session.run`,\n",
      "     |          which is useful for certain use cases (profiling and debugging) but will\n",
      "     |          result in measurable slowdown of the `Callable`'s\n",
      "     |          performance. Default: `False`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A function that when called will execute the step defined by\n",
      "     |        `feed_list` and `fetches` in this session.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If `fetches` or `feed_list` cannot be interpreted\n",
      "     |          as arguments to `tf.Session.run`.\n",
      "     |  \n",
      "     |  partial_run(self, handle, fetches, feed_dict=None)\n",
      "     |      Continues the execution with more feeds and fetches.\n",
      "     |      \n",
      "     |      This is EXPERIMENTAL and subject to change.\n",
      "     |      \n",
      "     |      To use partial execution, a user first calls `partial_run_setup()` and\n",
      "     |      then a sequence of `partial_run()`. `partial_run_setup` specifies the\n",
      "     |      list of feeds and fetches that will be used in the subsequent\n",
      "     |      `partial_run` calls.\n",
      "     |      \n",
      "     |      The optional `feed_dict` argument allows the caller to override\n",
      "     |      the value of tensors in the graph. See run() for more information.\n",
      "     |      \n",
      "     |      Below is a simple example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      a = array_ops.placeholder(dtypes.float32, shape=[])\n",
      "     |      b = array_ops.placeholder(dtypes.float32, shape=[])\n",
      "     |      c = array_ops.placeholder(dtypes.float32, shape=[])\n",
      "     |      r1 = math_ops.add(a, b)\n",
      "     |      r2 = math_ops.multiply(r1, c)\n",
      "     |      \n",
      "     |      h = sess.partial_run_setup([r1, r2], [a, b, c])\n",
      "     |      res = sess.partial_run(h, r1, feed_dict={a: 1, b: 2})\n",
      "     |      res = sess.partial_run(h, r2, feed_dict={c: res})\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        handle: A handle for a sequence of partial runs.\n",
      "     |        fetches: A single graph element, a list of graph elements, or a dictionary\n",
      "     |          whose values are graph elements or lists of graph elements (see\n",
      "     |          documentation for `run`).\n",
      "     |        feed_dict: A dictionary that maps graph elements to values (described\n",
      "     |          above).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        Either a single value if `fetches` is a single graph element, or\n",
      "     |        a list of values if `fetches` is a list, or a dictionary with the\n",
      "     |        same keys as `fetches` if that is a dictionary\n",
      "     |        (see documentation for `run`).\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        tf.errors.OpError: Or one of its subclasses on error.\n",
      "     |  \n",
      "     |  partial_run_setup(self, fetches, feeds=None)\n",
      "     |      Sets up a graph with feeds and fetches for partial run.\n",
      "     |      \n",
      "     |      This is EXPERIMENTAL and subject to change.\n",
      "     |      \n",
      "     |      Note that contrary to `run`, `feeds` only specifies the graph elements.\n",
      "     |      The tensors will be supplied by the subsequent `partial_run` calls.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        fetches: A single graph element, or a list of graph elements.\n",
      "     |        feeds: A single graph element, or a list of graph elements.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A handle for partial run.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        RuntimeError: If this `Session` is in an invalid state (e.g. has been\n",
      "     |          closed).\n",
      "     |        TypeError: If `fetches` or `feed_dict` keys are of an inappropriate type.\n",
      "     |        tf.errors.OpError: Or one of its subclasses if a TensorFlow error happens.\n",
      "     |  \n",
      "     |  run(self, fetches, feed_dict=None, options=None, run_metadata=None)\n",
      "     |      Runs operations and evaluates tensors in `fetches`.\n",
      "     |      \n",
      "     |      This method runs one \"step\" of TensorFlow computation, by\n",
      "     |      running the necessary graph fragment to execute every `Operation`\n",
      "     |      and evaluate every `Tensor` in `fetches`, substituting the values in\n",
      "     |      `feed_dict` for the corresponding input values.\n",
      "     |      \n",
      "     |      The `fetches` argument may be a single graph element, or an arbitrarily\n",
      "     |      nested list, tuple, namedtuple, dict, or OrderedDict containing graph\n",
      "     |      elements at its leaves.  A graph element can be one of the following types:\n",
      "     |      \n",
      "     |      * A `tf.Operation`.\n",
      "     |        The corresponding fetched value will be `None`.\n",
      "     |      * A `tf.Tensor`.\n",
      "     |        The corresponding fetched value will be a numpy ndarray containing the\n",
      "     |        value of that tensor.\n",
      "     |      * A `tf.SparseTensor`.\n",
      "     |        The corresponding fetched value will be a\n",
      "     |        `tf.compat.v1.SparseTensorValue`\n",
      "     |        containing the value of that sparse tensor.\n",
      "     |      * A `get_tensor_handle` op.  The corresponding fetched value will be a\n",
      "     |        numpy ndarray containing the handle of that tensor.\n",
      "     |      * A `string` which is the name of a tensor or operation in the graph.\n",
      "     |      \n",
      "     |      The value returned by `run()` has the same shape as the `fetches` argument,\n",
      "     |      where the leaves are replaced by the corresponding values returned by\n",
      "     |      TensorFlow.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |         a = tf.constant([10, 20])\n",
      "     |         b = tf.constant([1.0, 2.0])\n",
      "     |         # 'fetches' can be a singleton\n",
      "     |         v = session.run(a)\n",
      "     |         # v is the numpy array [10, 20]\n",
      "     |         # 'fetches' can be a list.\n",
      "     |         v = session.run([a, b])\n",
      "     |         # v is a Python list with 2 numpy arrays: the 1-D array [10, 20] and the\n",
      "     |         # 1-D array [1.0, 2.0]\n",
      "     |         # 'fetches' can be arbitrary lists, tuples, namedtuple, dicts:\n",
      "     |         MyData = collections.namedtuple('MyData', ['a', 'b'])\n",
      "     |         v = session.run({'k1': MyData(a, b), 'k2': [b, a]})\n",
      "     |         # v is a dict with\n",
      "     |         # v['k1'] is a MyData namedtuple with 'a' (the numpy array [10, 20]) and\n",
      "     |         # 'b' (the numpy array [1.0, 2.0])\n",
      "     |         # v['k2'] is a list with the numpy array [1.0, 2.0] and the numpy array\n",
      "     |         # [10, 20].\n",
      "     |      ```\n",
      "     |      \n",
      "     |      The optional `feed_dict` argument allows the caller to override\n",
      "     |      the value of tensors in the graph. Each key in `feed_dict` can be\n",
      "     |      one of the following types:\n",
      "     |      \n",
      "     |      * If the key is a `tf.Tensor`, the\n",
      "     |        value may be a Python scalar, string, list, or numpy ndarray\n",
      "     |        that can be converted to the same `dtype` as that\n",
      "     |        tensor. Additionally, if the key is a\n",
      "     |        `tf.compat.v1.placeholder`, the shape of\n",
      "     |        the value will be checked for compatibility with the placeholder.\n",
      "     |      * If the key is a\n",
      "     |        `tf.SparseTensor`,\n",
      "     |        the value should be a\n",
      "     |        `tf.compat.v1.SparseTensorValue`.\n",
      "     |      * If the key is a nested tuple of `Tensor`s or `SparseTensor`s, the value\n",
      "     |        should be a nested tuple with the same structure that maps to their\n",
      "     |        corresponding values as above.\n",
      "     |      \n",
      "     |      Each value in `feed_dict` must be convertible to a numpy array of the dtype\n",
      "     |      of the corresponding key.\n",
      "     |      \n",
      "     |      The optional `options` argument expects a [`RunOptions`] proto. The options\n",
      "     |      allow controlling the behavior of this particular step (e.g. turning tracing\n",
      "     |      on).\n",
      "     |      \n",
      "     |      The optional `run_metadata` argument expects a [`RunMetadata`] proto. When\n",
      "     |      appropriate, the non-Tensor output of this step will be collected there. For\n",
      "     |      example, when users turn on tracing in `options`, the profiled info will be\n",
      "     |      collected into this argument and passed back.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        fetches: A single graph element, a list of graph elements, or a dictionary\n",
      "     |          whose values are graph elements or lists of graph elements (described\n",
      "     |          above).\n",
      "     |        feed_dict: A dictionary that maps graph elements to values (described\n",
      "     |          above).\n",
      "     |        options: A [`RunOptions`] protocol buffer\n",
      "     |        run_metadata: A [`RunMetadata`] protocol buffer\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        Either a single value if `fetches` is a single graph element, or\n",
      "     |        a list of values if `fetches` is a list, or a dictionary with the\n",
      "     |        same keys as `fetches` if that is a dictionary (described above).\n",
      "     |        Order in which `fetches` operations are evaluated inside the call\n",
      "     |        is undefined.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        RuntimeError: If this `Session` is in an invalid state (e.g. has been\n",
      "     |          closed).\n",
      "     |        TypeError: If `fetches` or `feed_dict` keys are of an inappropriate type.\n",
      "     |        ValueError: If `fetches` or `feed_dict` keys are invalid or refer to a\n",
      "     |          `Tensor` that doesn't exist.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from BaseSession:\n",
      "     |  \n",
      "     |  graph\n",
      "     |      The graph that was launched in this session.\n",
      "     |  \n",
      "     |  graph_def\n",
      "     |      A serializable version of the underlying TensorFlow graph.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A graph_pb2.GraphDef proto containing nodes for all of the Operations in\n",
      "     |        the underlying TensorFlow graph.\n",
      "     |  \n",
      "     |  sess_str\n",
      "     |      The TensorFlow process to which this session will connect.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from SessionInterface:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class SessionLog(google.protobuf.pyext._message.CMessage, google.protobuf.message.Message)\n",
      "     |  A ProtocolMessage\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SessionLog\n",
      "     |      google.protobuf.pyext._message.CMessage\n",
      "     |      google.protobuf.message.Message\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  checkpoint_path\n",
      "     |      Field tensorflow.SessionLog.checkpoint_path\n",
      "     |  \n",
      "     |  msg\n",
      "     |      Field tensorflow.SessionLog.msg\n",
      "     |  \n",
      "     |  status\n",
      "     |      Field tensorflow.SessionLog.status\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  CHECKPOINT = 3\n",
      "     |  \n",
      "     |  DESCRIPTOR = <google.protobuf.pyext._message.MessageDescriptor object>\n",
      "     |  \n",
      "     |  START = 1\n",
      "     |  \n",
      "     |  STATUS_UNSPECIFIED = 0\n",
      "     |  \n",
      "     |  STOP = 2\n",
      "     |  \n",
      "     |  SessionStatus = <google.protobuf.internal.enum_type_wrapper.EnumTypeWr...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.pyext._message.CMessage:\n",
      "     |  \n",
      "     |  ByteSize(...)\n",
      "     |      Returns the size of the message in bytes.\n",
      "     |  \n",
      "     |  Clear(...)\n",
      "     |      Clears the message.\n",
      "     |  \n",
      "     |  ClearExtension(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  ClearField(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  CopyFrom(...)\n",
      "     |      Copies a protocol message into the current message.\n",
      "     |  \n",
      "     |  DiscardUnknownFields(...)\n",
      "     |      Discards the unknown fields.\n",
      "     |  \n",
      "     |  FindInitializationErrors(...)\n",
      "     |      Finds unset required fields.\n",
      "     |  \n",
      "     |  FromString(...) from google.protobuf.pyext.cpp_message.GeneratedProtocolMessageType\n",
      "     |      Creates new method instance from given serialized data.\n",
      "     |  \n",
      "     |  HasExtension(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  HasField(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  IsInitialized(...)\n",
      "     |      Checks if all required fields of a protocol message are set.\n",
      "     |  \n",
      "     |  ListFields(...)\n",
      "     |      Lists all set fields of a message.\n",
      "     |  \n",
      "     |  MergeFrom(...)\n",
      "     |      Merges a protocol message into the current message.\n",
      "     |  \n",
      "     |  MergeFromString(...)\n",
      "     |      Merges a serialized message into the current message.\n",
      "     |  \n",
      "     |  ParseFromString(...)\n",
      "     |      Parses a serialized message into the current message.\n",
      "     |  \n",
      "     |  RegisterExtension(...) from google.protobuf.pyext.cpp_message.GeneratedProtocolMessageType\n",
      "     |      Registers an extension with the current message.\n",
      "     |  \n",
      "     |  SerializePartialToString(...)\n",
      "     |      Serializes the message to a string, even if it isn't initialized.\n",
      "     |  \n",
      "     |  SerializeToString(...)\n",
      "     |      Serializes the message to a string, only for initialized messages.\n",
      "     |  \n",
      "     |  SetInParent(...)\n",
      "     |      Sets the has bit of the given field in its parent message.\n",
      "     |  \n",
      "     |  UnknownFields(...)\n",
      "     |      Parse unknown field set\n",
      "     |  \n",
      "     |  WhichOneof(...)\n",
      "     |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      Makes a deep copy of the class.\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from google.protobuf.pyext._message.MessageMeta\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  __unicode__(...)\n",
      "     |      Outputs a unicode representation of the message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google.protobuf.pyext._message.CMessage:\n",
      "     |  \n",
      "     |  Extensions\n",
      "     |      Extension dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from google.protobuf.pyext._message.CMessage:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Support the pickle protocol.\n",
      "    \n",
      "    class SparseConditionalAccumulator(ConditionalAccumulatorBase)\n",
      "     |  A conditional accumulator for aggregating sparse gradients.\n",
      "     |  \n",
      "     |  Sparse gradients are represented by `IndexedSlices`.\n",
      "     |  \n",
      "     |  Up-to-date gradients (i.e., time step at which gradient was computed is\n",
      "     |  equal to the accumulator's time step) are added to the accumulator.\n",
      "     |  \n",
      "     |  Extraction of the average gradient is blocked until the required number of\n",
      "     |  gradients has been accumulated.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |    dtype: Datatype of the accumulated gradients.\n",
      "     |    shape: Shape of the accumulated gradients.\n",
      "     |    shared_name: Optional. If non-empty, this accumulator will be shared under\n",
      "     |      the given name across multiple sessions.\n",
      "     |    name: Optional name for the accumulator.\n",
      "     |    reduction_type: Reduction type to use when taking the gradient.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SparseConditionalAccumulator\n",
      "     |      ConditionalAccumulatorBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, dtype, shape=None, shared_name=None, name='sparse_conditional_accumulator', reduction_type='MEAN')\n",
      "     |      Creates a new ConditionalAccumulator.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        dtype: Datatype of the accumulated gradients.\n",
      "     |        shape: Shape of the accumulated gradients.\n",
      "     |        accumulator_ref: A handle to the conditional accumulator, created by sub-\n",
      "     |          classes\n",
      "     |  \n",
      "     |  apply_grad(self, grad_indices, grad_values, grad_shape=None, local_step=0, name=None)\n",
      "     |      Attempts to apply a sparse gradient to the accumulator.\n",
      "     |      \n",
      "     |      The attempt is silently dropped if the gradient is stale, i.e., `local_step`\n",
      "     |      is less than the accumulator's global time step.\n",
      "     |      \n",
      "     |      A sparse gradient is represented by its indices, values and possibly empty\n",
      "     |      or None shape. Indices must be a vector representing the locations of\n",
      "     |      non-zero entries in the tensor. Values are the non-zero slices of the\n",
      "     |      gradient, and must have the same first dimension as indices, i.e., the nnz\n",
      "     |      represented by indices and values must be consistent. Shape, if not empty or\n",
      "     |      None, must be consistent with the accumulator's shape (if also provided).\n",
      "     |      \n",
      "     |      Example:\n",
      "     |        A tensor [[0, 0], [0, 1], [2, 3]] can be represented\n",
      "     |          indices: [1,2]\n",
      "     |          values: [[0,1],[2,3]]\n",
      "     |          shape: [3, 2]\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        grad_indices: Indices of the sparse gradient to be applied.\n",
      "     |        grad_values: Values of the sparse gradient to be applied.\n",
      "     |        grad_shape: Shape of the sparse gradient to be applied.\n",
      "     |        local_step: Time step at which the gradient was computed.\n",
      "     |        name: Optional name for the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The operation that (conditionally) applies a gradient to the accumulator.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        InvalidArgumentError: If grad is of the wrong shape\n",
      "     |  \n",
      "     |  apply_indexed_slices_grad(self, grad, local_step=0, name=None)\n",
      "     |      Attempts to apply a gradient to the accumulator.\n",
      "     |      \n",
      "     |      The attempt is silently dropped if the gradient is stale, i.e., `local_step`\n",
      "     |      is less than the accumulator's global time step.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        grad: The gradient `IndexedSlices` to be applied.\n",
      "     |        local_step: Time step at which the gradient was computed.\n",
      "     |        name: Optional name for the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The operation that (conditionally) applies a gradient to the accumulator.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        InvalidArgumentError: If grad is of the wrong shape\n",
      "     |  \n",
      "     |  num_accumulated(self, name=None)\n",
      "     |      Number of gradients that have currently been aggregated in accumulator.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: Optional name for the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        Number of accumulated gradients currently in accumulator.\n",
      "     |  \n",
      "     |  set_global_step(self, new_global_step, name=None)\n",
      "     |      Sets the global time step of the accumulator.\n",
      "     |      \n",
      "     |      The operation logs a warning if we attempt to set to a time step that is\n",
      "     |      lower than the accumulator's own time step.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        new_global_step: Value of new time step. Can be a variable or a constant\n",
      "     |        name: Optional name for the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        Operation that sets the accumulator's time step.\n",
      "     |  \n",
      "     |  take_grad(self, num_required, name=None)\n",
      "     |      Attempts to extract the average gradient from the accumulator.\n",
      "     |      \n",
      "     |      The operation blocks until sufficient number of gradients have been\n",
      "     |      successfully applied to the accumulator.\n",
      "     |      \n",
      "     |      Once successful, the following actions are also triggered:\n",
      "     |      - Counter of accumulated gradients is reset to 0.\n",
      "     |      - Aggregated gradient is reset to 0 tensor.\n",
      "     |      - Accumulator's internal time step is incremented by 1.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        num_required: Number of gradients that needs to have been aggregated\n",
      "     |        name: Optional name for the operation\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A tuple of indices, values, and shape representing the average gradient.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        InvalidArgumentError: If `num_required` < 1\n",
      "     |  \n",
      "     |  take_indexed_slices_grad(self, num_required, name=None)\n",
      "     |      Attempts to extract the average gradient from the accumulator.\n",
      "     |      \n",
      "     |      The operation blocks until sufficient number of gradients have been\n",
      "     |      successfully applied to the accumulator.\n",
      "     |      \n",
      "     |      Once successful, the following actions are also triggered:\n",
      "     |      - Counter of accumulated gradients is reset to 0.\n",
      "     |      - Aggregated gradient is reset to 0 tensor.\n",
      "     |      - Accumulator's internal time step is incremented by 1.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        num_required: Number of gradients that needs to have been aggregated\n",
      "     |        name: Optional name for the operation\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An `IndexedSlices` holding the value of the average gradient.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        InvalidArgumentError: If `num_required` < 1\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from ConditionalAccumulatorBase:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  accumulator_ref\n",
      "     |      The underlying accumulator reference.\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      The datatype of the gradients accumulated by this accumulator.\n",
      "     |  \n",
      "     |  name\n",
      "     |      The name of the underlying accumulator.\n",
      "    \n",
      "    class SparseFeature(SparseFeature)\n",
      "     |  Configuration for parsing a sparse input feature from an `Example`.\n",
      "     |  \n",
      "     |  Note, preferably use `VarLenFeature` (possibly in combination with a\n",
      "     |  `SequenceExample`) in order to parse out `SparseTensor`s instead of\n",
      "     |  `SparseFeature` due to its simplicity.\n",
      "     |  \n",
      "     |  Closely mimicking the `SparseTensor` that will be obtained by parsing an\n",
      "     |  `Example` with a `SparseFeature` config, a `SparseFeature` contains a\n",
      "     |  \n",
      "     |  * `value_key`: The name of key for a `Feature` in the `Example` whose parsed\n",
      "     |    `Tensor` will be the resulting `SparseTensor.values`.\n",
      "     |  \n",
      "     |  * `index_key`: A list of names - one for each dimension in the resulting\n",
      "     |    `SparseTensor` whose `indices[i][dim]` indicating the position of\n",
      "     |    the `i`-th value in the `dim` dimension will be equal to the `i`-th value in\n",
      "     |    the Feature with key named `index_key[dim]` in the `Example`.\n",
      "     |  \n",
      "     |  * `size`: A list of ints for the resulting `SparseTensor.dense_shape`.\n",
      "     |  \n",
      "     |  For example, we can represent the following 2D `SparseTensor`\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  SparseTensor(indices=[[3, 1], [20, 0]],\n",
      "     |               values=[0.5, -1.0]\n",
      "     |               dense_shape=[100, 3])\n",
      "     |  ```\n",
      "     |  \n",
      "     |  with an `Example` input proto\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  features {\n",
      "     |    feature { key: \"val\" value { float_list { value: [ 0.5, -1.0 ] } } }\n",
      "     |    feature { key: \"ix0\" value { int64_list { value: [ 3, 20 ] } } }\n",
      "     |    feature { key: \"ix1\" value { int64_list { value: [ 1, 0 ] } } }\n",
      "     |  }\n",
      "     |  ```\n",
      "     |  \n",
      "     |  and `SparseFeature` config with 2 `index_key`s\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  SparseFeature(index_key=[\"ix0\", \"ix1\"],\n",
      "     |                value_key=\"val\",\n",
      "     |                dtype=tf.float32,\n",
      "     |                size=[100, 3])\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Fields:\n",
      "     |    index_key: A single string name or a list of string names of index features.\n",
      "     |      For each key the underlying feature's type must be `int64` and its length\n",
      "     |      must always match that of the `value_key` feature.\n",
      "     |      To represent `SparseTensor`s with a `dense_shape` of `rank` higher than 1\n",
      "     |      a list of length `rank` should be used.\n",
      "     |    value_key: Name of value feature.  The underlying feature's type must\n",
      "     |      be `dtype` and its length must always match that of all the `index_key`s'\n",
      "     |      features.\n",
      "     |    dtype: Data type of the `value_key` feature.\n",
      "     |    size: A Python int or list thereof specifying the dense shape. Should be a\n",
      "     |      list if and only if `index_key` is a list. In that case the list must be\n",
      "     |      equal to the length of `index_key`. Each for each entry `i` all values in\n",
      "     |      the `index_key`[i] feature must be in `[0, size[i])`.\n",
      "     |    already_sorted: A Python boolean to specify whether the values in\n",
      "     |      `value_key` are already sorted by their index position. If so skip\n",
      "     |      sorting. False by default (optional).\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SparseFeature\n",
      "     |      SparseFeature\n",
      "     |      builtins.tuple\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(cls, index_key, value_key, dtype, size, already_sorted=False)\n",
      "     |      Create new instance of SparseFeature(index_key, value_key, dtype, size, already_sorted)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  _tf_api_names = ('io.SparseFeature',)\n",
      "     |  \n",
      "     |  _tf_api_names_v1 = ['io.SparseFeature', 'SparseFeature']\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from SparseFeature:\n",
      "     |  \n",
      "     |  __getnewargs__(self)\n",
      "     |      Return self as a plain tuple.  Used by copy and pickle.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return a nicely formatted representation string\n",
      "     |  \n",
      "     |  _asdict(self)\n",
      "     |      Return a new OrderedDict which maps field names to their values.\n",
      "     |  \n",
      "     |  _replace(_self, **kwds)\n",
      "     |      Return a new SparseFeature object replacing specified fields with new values\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from SparseFeature:\n",
      "     |  \n",
      "     |  _make(iterable, new=<built-in method __new__ of type object at 0x9d43a0>, len=<built-in function len>) from builtins.type\n",
      "     |      Make a new SparseFeature object from a sequence or iterable\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from SparseFeature:\n",
      "     |  \n",
      "     |  index_key\n",
      "     |      Alias for field number 0\n",
      "     |  \n",
      "     |  value_key\n",
      "     |      Alias for field number 1\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      Alias for field number 2\n",
      "     |  \n",
      "     |  size\n",
      "     |      Alias for field number 3\n",
      "     |  \n",
      "     |  already_sorted\n",
      "     |      Alias for field number 4\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from SparseFeature:\n",
      "     |  \n",
      "     |  _fields = ('index_key', 'value_key', 'dtype', 'size', 'already_sorted'...\n",
      "     |  \n",
      "     |  _source = \"from builtins import property as _property, tupl..._itemget...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.tuple:\n",
      "     |  \n",
      "     |  __add__(self, value, /)\n",
      "     |      Return self+value.\n",
      "     |  \n",
      "     |  __contains__(self, key, /)\n",
      "     |      Return key in self.\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __hash__(self, /)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __mul__(self, value, /)\n",
      "     |      Return self*value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __rmul__(self, value, /)\n",
      "     |      Return value*self.\n",
      "     |  \n",
      "     |  count(...)\n",
      "     |      T.count(value) -> integer -- return number of occurrences of value\n",
      "     |  \n",
      "     |  index(...)\n",
      "     |      T.index(value, [start, [stop]]) -> integer -- return first index of value.\n",
      "     |      Raises ValueError if the value is not present.\n",
      "    \n",
      "    class SparseTensor(tensorflow.python.framework.tensor_like._TensorLike, tensorflow.python.framework.composite_tensor.CompositeTensor)\n",
      "     |  Represents a sparse tensor.\n",
      "     |  \n",
      "     |  TensorFlow represents a sparse tensor as three separate dense tensors:\n",
      "     |  `indices`, `values`, and `dense_shape`.  In Python, the three tensors are\n",
      "     |  collected into a `SparseTensor` class for ease of use.  If you have separate\n",
      "     |  `indices`, `values`, and `dense_shape` tensors, wrap them in a `SparseTensor`\n",
      "     |  object before passing to the ops below.\n",
      "     |  \n",
      "     |  Concretely, the sparse tensor `SparseTensor(indices, values, dense_shape)`\n",
      "     |  comprises the following components, where `N` and `ndims` are the number\n",
      "     |  of values and number of dimensions in the `SparseTensor`, respectively:\n",
      "     |  \n",
      "     |  * `indices`: A 2-D int64 tensor of dense_shape `[N, ndims]`, which specifies\n",
      "     |    the indices of the elements in the sparse tensor that contain nonzero\n",
      "     |    values (elements are zero-indexed). For example, `indices=[[1,3], [2,4]]`\n",
      "     |    specifies that the elements with indexes of [1,3] and [2,4] have\n",
      "     |    nonzero values.\n",
      "     |  \n",
      "     |  * `values`: A 1-D tensor of any type and dense_shape `[N]`, which supplies the\n",
      "     |    values for each element in `indices`. For example, given\n",
      "     |    `indices=[[1,3], [2,4]]`, the parameter `values=[18, 3.6]` specifies\n",
      "     |    that element [1,3] of the sparse tensor has a value of 18, and element\n",
      "     |    [2,4] of the tensor has a value of 3.6.\n",
      "     |  \n",
      "     |  * `dense_shape`: A 1-D int64 tensor of dense_shape `[ndims]`, which specifies\n",
      "     |    the dense_shape of the sparse tensor. Takes a list indicating the number of\n",
      "     |    elements in each dimension. For example, `dense_shape=[3,6]` specifies a\n",
      "     |    two-dimensional 3x6 tensor, `dense_shape=[2,3,4]` specifies a\n",
      "     |    three-dimensional 2x3x4 tensor, and `dense_shape=[9]` specifies a\n",
      "     |    one-dimensional tensor with 9 elements.\n",
      "     |  \n",
      "     |  The corresponding dense tensor satisfies:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  dense.shape = dense_shape\n",
      "     |  dense[tuple(indices[i])] = values[i]\n",
      "     |  ```\n",
      "     |  \n",
      "     |  By convention, `indices` should be sorted in row-major order (or equivalently\n",
      "     |  lexicographic order on the tuples `indices[i]`). This is not enforced when\n",
      "     |  `SparseTensor` objects are constructed, but most ops assume correct ordering.\n",
      "     |  If the ordering of sparse tensor `st` is wrong, a fixed version can be\n",
      "     |  obtained by calling `tf.sparse.reorder(st)`.\n",
      "     |  \n",
      "     |  Example: The sparse tensor\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  SparseTensor(indices=[[0, 0], [1, 2]], values=[1, 2], dense_shape=[3, 4])\n",
      "     |  ```\n",
      "     |  \n",
      "     |  represents the dense tensor\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  [[1, 0, 0, 0]\n",
      "     |   [0, 0, 2, 0]\n",
      "     |   [0, 0, 0, 0]]\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SparseTensor\n",
      "     |      tensorflow.python.framework.tensor_like._TensorLike\n",
      "     |      tensorflow.python.framework.composite_tensor.CompositeTensor\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __div__ = binary_op_wrapper_sparse(sp_x, y)\n",
      "     |      Component-wise divides a SparseTensor by a dense Tensor.\n",
      "     |      \n",
      "     |      *Limitation*: this Op only broadcasts the dense side to the sparse side, but not\n",
      "     |      the other direction.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        sp_indices: A `Tensor` of type `int64`.\n",
      "     |          2-D.  `N x R` matrix with the indices of non-empty values in a\n",
      "     |          SparseTensor, possibly not in canonical ordering.\n",
      "     |        sp_values: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.\n",
      "     |          1-D.  `N` non-empty values corresponding to `sp_indices`.\n",
      "     |        sp_shape: A `Tensor` of type `int64`.\n",
      "     |          1-D.  Shape of the input SparseTensor.\n",
      "     |        dense: A `Tensor`. Must have the same type as `sp_values`.\n",
      "     |          `R`-D.  The dense Tensor operand.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `sp_values`.\n",
      "     |  \n",
      "     |  __init__(self, indices, values, dense_shape)\n",
      "     |      Creates a `SparseTensor`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        indices: A 2-D int64 tensor of shape `[N, ndims]`.\n",
      "     |        values: A 1-D tensor of any type and shape `[N]`.\n",
      "     |        dense_shape: A 1-D int64 tensor of shape `[ndims]`.\n",
      "     |  \n",
      "     |  __mul__ = binary_op_wrapper_sparse(sp_x, y)\n",
      "     |      Component-wise multiplies a SparseTensor by a dense Tensor.\n",
      "     |      \n",
      "     |      The output locations corresponding to the implicitly zero elements in the sparse\n",
      "     |      tensor will be zero (i.e., will not take up storage space), regardless of the\n",
      "     |      contents of the dense tensor (even if it's +/-INF and that INF*0 == NaN).\n",
      "     |      \n",
      "     |      *Limitation*: this Op only broadcasts the dense side to the sparse side, but not\n",
      "     |      the other direction.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        sp_indices: A `Tensor` of type `int64`.\n",
      "     |          2-D.  `N x R` matrix with the indices of non-empty values in a\n",
      "     |          SparseTensor, possibly not in canonical ordering.\n",
      "     |        sp_values: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.\n",
      "     |          1-D.  `N` non-empty values corresponding to `sp_indices`.\n",
      "     |        sp_shape: A `Tensor` of type `int64`.\n",
      "     |          1-D.  Shape of the input SparseTensor.\n",
      "     |        dense: A `Tensor`. Must have the same type as `sp_values`.\n",
      "     |          `R`-D.  The dense Tensor operand.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `sp_values`.\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  __truediv__ = binary_op_wrapper_sparse(sp_x, y)\n",
      "     |      Internal helper function for 'sp_t / dense_t'.\n",
      "     |  \n",
      "     |  consumers(self)\n",
      "     |  \n",
      "     |  eval(self, feed_dict=None, session=None)\n",
      "     |      Evaluates this sparse tensor in a `Session`.\n",
      "     |      \n",
      "     |      Calling this method will execute all preceding operations that\n",
      "     |      produce the inputs needed for the operation that produces this\n",
      "     |      tensor.\n",
      "     |      \n",
      "     |      *N.B.* Before invoking `SparseTensor.eval()`, its graph must have been\n",
      "     |      launched in a session, and either a default session must be\n",
      "     |      available, or `session` must be specified explicitly.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        feed_dict: A dictionary that maps `Tensor` objects to feed values. See\n",
      "     |          `tf.Session.run` for a description of the valid feed values.\n",
      "     |        session: (Optional.) The `Session` to be used to evaluate this sparse\n",
      "     |          tensor. If none, the default session will be used.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `SparseTensorValue` object.\n",
      "     |  \n",
      "     |  get_shape(self)\n",
      "     |      Get the `TensorShape` representing the shape of the dense tensor.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `TensorShape` object.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_value(sparse_tensor_value) from abc.ABCMeta\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  dense_shape\n",
      "     |      A 1-D Tensor of int64 representing the shape of the dense tensor.\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      The `DType` of elements in this tensor.\n",
      "     |  \n",
      "     |  graph\n",
      "     |      The `Graph` that contains the index, value, and dense_shape tensors.\n",
      "     |  \n",
      "     |  indices\n",
      "     |      The indices of non-zero values in the represented dense tensor.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A 2-D Tensor of int64 with dense_shape `[N, ndims]`, where `N` is the\n",
      "     |          number of non-zero values in the tensor, and `ndims` is the rank.\n",
      "     |  \n",
      "     |  op\n",
      "     |      The `Operation` that produces `values` as an output.\n",
      "     |  \n",
      "     |  shape\n",
      "     |      Get the `TensorShape` representing the shape of the dense tensor.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `TensorShape` object.\n",
      "     |  \n",
      "     |  values\n",
      "     |      The non-zero values in the represented dense tensor.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A 1-D Tensor of any data type.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.framework.tensor_like._TensorLike:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class SparseTensorSpec(tensorflow.python.framework.type_spec.BatchableTypeSpec)\n",
      "     |  Type specification for a `tf.SparseTensor`.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SparseTensorSpec\n",
      "     |      tensorflow.python.framework.type_spec.BatchableTypeSpec\n",
      "     |      tensorflow.python.framework.type_spec.TypeSpec\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, shape=None, dtype=tf.float32)\n",
      "     |      Constructs a type specification for a `tf.SparseTensor`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: The dense shape of the `SparseTensor`, or `None` to allow\n",
      "     |          any dense shape.\n",
      "     |        dtype: `tf.DType` of values in the `SparseTensor`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_value(value) from abc.ABCMeta\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      The `tf.dtypes.DType` specified by this type for the SparseTensor.\n",
      "     |  \n",
      "     |  shape\n",
      "     |      The `tf.TensorShape` specified by this type for the SparseTensor.\n",
      "     |  \n",
      "     |  value_type\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tensorflow.python.framework.type_spec.TypeSpec:\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __ne__(self, other)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  is_compatible_with(self, spec_or_value)\n",
      "     |      Returns true if `spec_or_value` is compatible with this TypeSpec.\n",
      "     |  \n",
      "     |  most_specific_compatible_type(self, other)\n",
      "     |      Returns the most specific TypeSpec compatible with `self` and `other`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: A `TypeSpec`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If there is no TypeSpec that is compatible with both `self`\n",
      "     |          and `other`.\n",
      "    \n",
      "    class SparseTensorValue(builtins.tuple)\n",
      "     |  SparseTensorValue(indices, values, dense_shape)\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SparseTensorValue\n",
      "     |      builtins.tuple\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getnewargs__(self)\n",
      "     |      Return self as a plain tuple.  Used by copy and pickle.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return a nicely formatted representation string\n",
      "     |  \n",
      "     |  _asdict(self)\n",
      "     |      Return a new OrderedDict which maps field names to their values.\n",
      "     |  \n",
      "     |  _replace(_self, **kwds)\n",
      "     |      Return a new SparseTensorValue object replacing specified fields with new values\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  _make(iterable, new=<built-in method __new__ of type object at 0x9d43a0>, len=<built-in function len>) from builtins.type\n",
      "     |      Make a new SparseTensorValue object from a sequence or iterable\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(_cls, indices, values, dense_shape)\n",
      "     |      Create new instance of SparseTensorValue(indices, values, dense_shape)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  indices\n",
      "     |      Alias for field number 0\n",
      "     |  \n",
      "     |  values\n",
      "     |      Alias for field number 1\n",
      "     |  \n",
      "     |  dense_shape\n",
      "     |      Alias for field number 2\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  _fields = ('indices', 'values', 'dense_shape')\n",
      "     |  \n",
      "     |  _source = \"from builtins import property as _property, tupl..._itemget...\n",
      "     |  \n",
      "     |  _tf_api_names = ()\n",
      "     |  \n",
      "     |  _tf_api_names_v1 = ['SparseTensorValue']\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.tuple:\n",
      "     |  \n",
      "     |  __add__(self, value, /)\n",
      "     |      Return self+value.\n",
      "     |  \n",
      "     |  __contains__(self, key, /)\n",
      "     |      Return key in self.\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __hash__(self, /)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __mul__(self, value, /)\n",
      "     |      Return self*value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __rmul__(self, value, /)\n",
      "     |      Return value*self.\n",
      "     |  \n",
      "     |  count(...)\n",
      "     |      T.count(value) -> integer -- return number of occurrences of value\n",
      "     |  \n",
      "     |  index(...)\n",
      "     |      T.index(value, [start, [stop]]) -> integer -- return first index of value.\n",
      "     |      Raises ValueError if the value is not present.\n",
      "    \n",
      "    class Summary(google.protobuf.pyext._message.CMessage, google.protobuf.message.Message)\n",
      "     |  A ProtocolMessage\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Summary\n",
      "     |      google.protobuf.pyext._message.CMessage\n",
      "     |      google.protobuf.message.Message\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  value\n",
      "     |      Field tensorflow.Summary.value\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  Audio = <class 'tensorflow.core.framework.summary_pb2.Audio'>\n",
      "     |      A ProtocolMessage\n",
      "     |  \n",
      "     |  DESCRIPTOR = <google.protobuf.pyext._message.MessageDescriptor object>\n",
      "     |  \n",
      "     |  Image = <class 'tensorflow.core.framework.summary_pb2.Image'>\n",
      "     |      A ProtocolMessage\n",
      "     |  \n",
      "     |  Value = <class 'tensorflow.core.framework.summary_pb2.Value'>\n",
      "     |      A ProtocolMessage\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.pyext._message.CMessage:\n",
      "     |  \n",
      "     |  ByteSize(...)\n",
      "     |      Returns the size of the message in bytes.\n",
      "     |  \n",
      "     |  Clear(...)\n",
      "     |      Clears the message.\n",
      "     |  \n",
      "     |  ClearExtension(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  ClearField(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  CopyFrom(...)\n",
      "     |      Copies a protocol message into the current message.\n",
      "     |  \n",
      "     |  DiscardUnknownFields(...)\n",
      "     |      Discards the unknown fields.\n",
      "     |  \n",
      "     |  FindInitializationErrors(...)\n",
      "     |      Finds unset required fields.\n",
      "     |  \n",
      "     |  FromString(...) from google.protobuf.pyext.cpp_message.GeneratedProtocolMessageType\n",
      "     |      Creates new method instance from given serialized data.\n",
      "     |  \n",
      "     |  HasExtension(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  HasField(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  IsInitialized(...)\n",
      "     |      Checks if all required fields of a protocol message are set.\n",
      "     |  \n",
      "     |  ListFields(...)\n",
      "     |      Lists all set fields of a message.\n",
      "     |  \n",
      "     |  MergeFrom(...)\n",
      "     |      Merges a protocol message into the current message.\n",
      "     |  \n",
      "     |  MergeFromString(...)\n",
      "     |      Merges a serialized message into the current message.\n",
      "     |  \n",
      "     |  ParseFromString(...)\n",
      "     |      Parses a serialized message into the current message.\n",
      "     |  \n",
      "     |  RegisterExtension(...) from google.protobuf.pyext.cpp_message.GeneratedProtocolMessageType\n",
      "     |      Registers an extension with the current message.\n",
      "     |  \n",
      "     |  SerializePartialToString(...)\n",
      "     |      Serializes the message to a string, even if it isn't initialized.\n",
      "     |  \n",
      "     |  SerializeToString(...)\n",
      "     |      Serializes the message to a string, only for initialized messages.\n",
      "     |  \n",
      "     |  SetInParent(...)\n",
      "     |      Sets the has bit of the given field in its parent message.\n",
      "     |  \n",
      "     |  UnknownFields(...)\n",
      "     |      Parse unknown field set\n",
      "     |  \n",
      "     |  WhichOneof(...)\n",
      "     |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      Makes a deep copy of the class.\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from google.protobuf.pyext._message.MessageMeta\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  __unicode__(...)\n",
      "     |      Outputs a unicode representation of the message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google.protobuf.pyext._message.CMessage:\n",
      "     |  \n",
      "     |  Extensions\n",
      "     |      Extension dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from google.protobuf.pyext._message.CMessage:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Support the pickle protocol.\n",
      "    \n",
      "    class SummaryMetadata(google.protobuf.pyext._message.CMessage, google.protobuf.message.Message)\n",
      "     |  A ProtocolMessage\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SummaryMetadata\n",
      "     |      google.protobuf.pyext._message.CMessage\n",
      "     |      google.protobuf.message.Message\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  display_name\n",
      "     |      Field tensorflow.SummaryMetadata.display_name\n",
      "     |  \n",
      "     |  plugin_data\n",
      "     |      Field tensorflow.SummaryMetadata.plugin_data\n",
      "     |  \n",
      "     |  summary_description\n",
      "     |      Field tensorflow.SummaryMetadata.summary_description\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  DESCRIPTOR = <google.protobuf.pyext._message.MessageDescriptor object>\n",
      "     |  \n",
      "     |  PluginData = <class 'tensorflow.core.framework.summary_pb2.PluginData'...\n",
      "     |      A ProtocolMessage\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.pyext._message.CMessage:\n",
      "     |  \n",
      "     |  ByteSize(...)\n",
      "     |      Returns the size of the message in bytes.\n",
      "     |  \n",
      "     |  Clear(...)\n",
      "     |      Clears the message.\n",
      "     |  \n",
      "     |  ClearExtension(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  ClearField(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  CopyFrom(...)\n",
      "     |      Copies a protocol message into the current message.\n",
      "     |  \n",
      "     |  DiscardUnknownFields(...)\n",
      "     |      Discards the unknown fields.\n",
      "     |  \n",
      "     |  FindInitializationErrors(...)\n",
      "     |      Finds unset required fields.\n",
      "     |  \n",
      "     |  FromString(...) from google.protobuf.pyext.cpp_message.GeneratedProtocolMessageType\n",
      "     |      Creates new method instance from given serialized data.\n",
      "     |  \n",
      "     |  HasExtension(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  HasField(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  IsInitialized(...)\n",
      "     |      Checks if all required fields of a protocol message are set.\n",
      "     |  \n",
      "     |  ListFields(...)\n",
      "     |      Lists all set fields of a message.\n",
      "     |  \n",
      "     |  MergeFrom(...)\n",
      "     |      Merges a protocol message into the current message.\n",
      "     |  \n",
      "     |  MergeFromString(...)\n",
      "     |      Merges a serialized message into the current message.\n",
      "     |  \n",
      "     |  ParseFromString(...)\n",
      "     |      Parses a serialized message into the current message.\n",
      "     |  \n",
      "     |  RegisterExtension(...) from google.protobuf.pyext.cpp_message.GeneratedProtocolMessageType\n",
      "     |      Registers an extension with the current message.\n",
      "     |  \n",
      "     |  SerializePartialToString(...)\n",
      "     |      Serializes the message to a string, even if it isn't initialized.\n",
      "     |  \n",
      "     |  SerializeToString(...)\n",
      "     |      Serializes the message to a string, only for initialized messages.\n",
      "     |  \n",
      "     |  SetInParent(...)\n",
      "     |      Sets the has bit of the given field in its parent message.\n",
      "     |  \n",
      "     |  UnknownFields(...)\n",
      "     |      Parse unknown field set\n",
      "     |  \n",
      "     |  WhichOneof(...)\n",
      "     |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      Makes a deep copy of the class.\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from google.protobuf.pyext._message.MessageMeta\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  __unicode__(...)\n",
      "     |      Outputs a unicode representation of the message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google.protobuf.pyext._message.CMessage:\n",
      "     |  \n",
      "     |  Extensions\n",
      "     |      Extension dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from google.protobuf.pyext._message.CMessage:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Support the pickle protocol.\n",
      "    \n",
      "    class TFRecordReader(ReaderBase)\n",
      "     |  A Reader that outputs the records from a TFRecords file.\n",
      "     |  \n",
      "     |  See ReaderBase for supported methods.\n",
      "     |  \n",
      "     |  @compatibility(eager)\n",
      "     |  Readers are not compatible with eager execution. Instead, please\n",
      "     |  use `tf.data` to get data into your model.\n",
      "     |  @end_compatibility\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      TFRecordReader\n",
      "     |      ReaderBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, name=None, options=None)\n",
      "     |      Create a TFRecordReader. (deprecated)\n",
      "     |      \n",
      "     |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TFRecordDataset`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |        options: A TFRecordOptions object (optional).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ReaderBase:\n",
      "     |  \n",
      "     |  num_records_produced(self, name=None)\n",
      "     |      Returns the number of records this reader has produced.\n",
      "     |      \n",
      "     |      This is the same as the number of Read executions that have\n",
      "     |      succeeded.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An int64 Tensor.\n",
      "     |  \n",
      "     |  num_work_units_completed(self, name=None)\n",
      "     |      Returns the number of work units this reader has finished processing.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An int64 Tensor.\n",
      "     |  \n",
      "     |  read(self, queue, name=None)\n",
      "     |      Returns the next record (key, value) pair produced by a reader.\n",
      "     |      \n",
      "     |      Will dequeue a work unit from queue if necessary (e.g. when the\n",
      "     |      Reader needs to start reading from a new file since it has\n",
      "     |      finished with the previous file).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        queue: A Queue or a mutable string Tensor representing a handle\n",
      "     |          to a Queue, with string work items.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A tuple of Tensors (key, value).\n",
      "     |        key: A string scalar Tensor.\n",
      "     |        value: A string scalar Tensor.\n",
      "     |  \n",
      "     |  read_up_to(self, queue, num_records, name=None)\n",
      "     |      Returns up to num_records (key, value) pairs produced by a reader.\n",
      "     |      \n",
      "     |      Will dequeue a work unit from queue if necessary (e.g., when the\n",
      "     |      Reader needs to start reading from a new file since it has\n",
      "     |      finished with the previous file).\n",
      "     |      It may return less than num_records even before the last batch.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        queue: A Queue or a mutable string Tensor representing a handle\n",
      "     |          to a Queue, with string work items.\n",
      "     |        num_records: Number of records to read.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A tuple of Tensors (keys, values).\n",
      "     |        keys: A 1-D string Tensor.\n",
      "     |        values: A 1-D string Tensor.\n",
      "     |  \n",
      "     |  reset(self, name=None)\n",
      "     |      Restore a reader to its initial clean state.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The created Operation.\n",
      "     |  \n",
      "     |  restore_state(self, state, name=None)\n",
      "     |      Restore a reader to a previously saved state.\n",
      "     |      \n",
      "     |      Not all Readers support being restored, so this can produce an\n",
      "     |      Unimplemented error.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        state: A string Tensor.\n",
      "     |          Result of a SerializeState of a Reader with matching type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The created Operation.\n",
      "     |  \n",
      "     |  serialize_state(self, name=None)\n",
      "     |      Produce a string tensor that encodes the state of a reader.\n",
      "     |      \n",
      "     |      Not all Readers support being serialized, so this can produce an\n",
      "     |      Unimplemented error.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A string Tensor.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from ReaderBase:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  reader_ref\n",
      "     |      Op that implements the reader.\n",
      "     |  \n",
      "     |  supports_serialize\n",
      "     |      Whether the Reader implementation can serialize its state.\n",
      "    \n",
      "    class Tensor(tensorflow.python.framework.tensor_like._TensorLike)\n",
      "     |  Represents one of the outputs of an `Operation`.\n",
      "     |  \n",
      "     |  A `Tensor` is a symbolic handle to one of the outputs of an\n",
      "     |  `Operation`. It does not hold the values of that operation's output,\n",
      "     |  but instead provides a means of computing those values in a\n",
      "     |  TensorFlow `tf.compat.v1.Session`.\n",
      "     |  \n",
      "     |  This class has two primary purposes:\n",
      "     |  \n",
      "     |  1. A `Tensor` can be passed as an input to another `Operation`.\n",
      "     |     This builds a dataflow connection between operations, which\n",
      "     |     enables TensorFlow to execute an entire `Graph` that represents a\n",
      "     |     large, multi-step computation.\n",
      "     |  \n",
      "     |  2. After the graph has been launched in a session, the value of the\n",
      "     |     `Tensor` can be computed by passing it to\n",
      "     |     `tf.Session.run`.\n",
      "     |     `t.eval()` is a shortcut for calling\n",
      "     |     `tf.compat.v1.get_default_session().run(t)`.\n",
      "     |  \n",
      "     |  In the following example, `c`, `d`, and `e` are symbolic `Tensor`\n",
      "     |  objects, whereas `result` is a numpy array that stores a concrete\n",
      "     |  value:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  # Build a dataflow graph.\n",
      "     |  c = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
      "     |  d = tf.constant([[1.0, 1.0], [0.0, 1.0]])\n",
      "     |  e = tf.matmul(c, d)\n",
      "     |  \n",
      "     |  # Construct a `Session` to execute the graph.\n",
      "     |  sess = tf.compat.v1.Session()\n",
      "     |  \n",
      "     |  # Execute the graph and store the value that `e` represents in `result`.\n",
      "     |  result = sess.run(e)\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Tensor\n",
      "     |      tensorflow.python.framework.tensor_like._TensorLike\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __abs__ = abs(x, name=None)\n",
      "     |      Computes the absolute value of a tensor.\n",
      "     |      \n",
      "     |      Given a tensor of integer or floating-point values, this operation returns a\n",
      "     |      tensor of the same type, where each element contains the absolute value of the\n",
      "     |      corresponding element in the input.\n",
      "     |      \n",
      "     |      Given a tensor `x` of complex numbers, this operation returns a tensor of type\n",
      "     |      `float32` or `float64` that is the absolute value of each element in `x`. All\n",
      "     |      elements in `x` must be complex numbers of the form \\\\(a + bj\\\\). The\n",
      "     |      absolute value is computed as \\\\( \\sqrt{a^2 + b^2}\\\\).  For example:\n",
      "     |      ```python\n",
      "     |      x = tf.constant([[-2.25 + 4.75j], [-3.25 + 5.75j]])\n",
      "     |      tf.abs(x)  # [5.25594902, 6.60492229]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor` or `SparseTensor` of type `float16`, `float32`, `float64`,\n",
      "     |          `int32`, `int64`, `complex64` or `complex128`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` or `SparseTensor` the same size, type, and sparsity as `x` with\n",
      "     |          absolute values.\n",
      "     |        Note, for `complex64` or `complex128` input, the returned `Tensor` will be\n",
      "     |          of type `float32` or `float64`, respectively.\n",
      "     |      \n",
      "     |        If `x` is a `SparseTensor`, returns\n",
      "     |        `SparseTensor(x.indices, tf.math.abs(x.values, ...), x.dense_shape)`\n",
      "     |  \n",
      "     |  __add__ = binary_op_wrapper(x, y)\n",
      "     |      Dispatches to add for strings and add_v2 for all other types.\n",
      "     |  \n",
      "     |  __and__ = binary_op_wrapper(x, y)\n",
      "     |      Returns the truth value of x AND y element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `math.logical_and` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor` of type `bool`.\n",
      "     |        y: A `Tensor` of type `bool`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __array__(self)\n",
      "     |  \n",
      "     |  __bool__(self)\n",
      "     |      Dummy method to prevent a tensor from being used as a Python `bool`.\n",
      "     |      \n",
      "     |      This overload raises a `TypeError` when the user inadvertently\n",
      "     |      treats a `Tensor` as a boolean (most commonly in an `if` or `while`\n",
      "     |      statement), in code that was not converted by AutoGraph. For example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      if tf.constant(True):  # Will raise.\n",
      "     |        # ...\n",
      "     |      \n",
      "     |      if tf.constant(5) < tf.constant(7):  # Will raise.\n",
      "     |        # ...\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        `TypeError`.\n",
      "     |  \n",
      "     |  __copy__(self)\n",
      "     |  \n",
      "     |  __div__ = binary_op_wrapper(x, y)\n",
      "     |      Divide two values using Python 2 semantics.\n",
      "     |      \n",
      "     |      Used for Tensor.__div__.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: `Tensor` numerator of real numeric type.\n",
      "     |        y: `Tensor` denominator of real numeric type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        `x / y` returns the quotient of x and y.\n",
      "     |  \n",
      "     |  __eq__ = tensor_equals(self, other)\n",
      "     |      Compares two tensors element-wise for equality.\n",
      "     |  \n",
      "     |  __floordiv__ = binary_op_wrapper(x, y)\n",
      "     |      Divides `x / y` elementwise, rounding toward the most negative integer.\n",
      "     |      \n",
      "     |      The same as `tf.compat.v1.div(x,y)` for integers, but uses\n",
      "     |      `tf.floor(tf.compat.v1.div(x,y))` for\n",
      "     |      floating point arguments so that the result is always an integer (though\n",
      "     |      possibly an integer represented as floating point).  This op is generated by\n",
      "     |      `x // y` floor division in Python 3 and in Python 2.7 with\n",
      "     |      `from __future__ import division`.\n",
      "     |      \n",
      "     |      `x` and `y` must have the same type, and the result will have the same type\n",
      "     |      as well.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: `Tensor` numerator of real numeric type.\n",
      "     |        y: `Tensor` denominator of real numeric type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        `x / y` rounded down.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If the inputs are complex.\n",
      "     |  \n",
      "     |  __ge__ = greater_equal(x, y, name=None)\n",
      "     |      Returns the truth value of (x >= y) element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `math.greater_equal` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __getitem__ = _slice_helper(tensor, slice_spec, var=None)\n",
      "     |      Overload for Tensor.__getitem__.\n",
      "     |      \n",
      "     |      This operation extracts the specified region from the tensor.\n",
      "     |      The notation is similar to NumPy with the restriction that\n",
      "     |      currently only support basic indexing. That means that\n",
      "     |      using a non-scalar tensor as input is not currently allowed.\n",
      "     |      \n",
      "     |      Some useful examples:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      # Strip leading and trailing 2 elements\n",
      "     |      foo = tf.constant([1,2,3,4,5,6])\n",
      "     |      print(foo[2:-2].eval())  # => [3,4]\n",
      "     |      \n",
      "     |      # Skip every other row and reverse the order of the columns\n",
      "     |      foo = tf.constant([[1,2,3], [4,5,6], [7,8,9]])\n",
      "     |      print(foo[::2,::-1].eval())  # => [[3,2,1], [9,8,7]]\n",
      "     |      \n",
      "     |      # Use scalar tensors as indices on both dimensions\n",
      "     |      print(foo[tf.constant(0), tf.constant(2)].eval())  # => 3\n",
      "     |      \n",
      "     |      # Insert another dimension\n",
      "     |      foo = tf.constant([[1,2,3], [4,5,6], [7,8,9]])\n",
      "     |      print(foo[tf.newaxis, :, :].eval()) # => [[[1,2,3], [4,5,6], [7,8,9]]]\n",
      "     |      print(foo[:, tf.newaxis, :].eval()) # => [[[1,2,3]], [[4,5,6]], [[7,8,9]]]\n",
      "     |      print(foo[:, :, tf.newaxis].eval()) # => [[[1],[2],[3]], [[4],[5],[6]],\n",
      "     |      [[7],[8],[9]]]\n",
      "     |      \n",
      "     |      # Ellipses (3 equivalent operations)\n",
      "     |      foo = tf.constant([[1,2,3], [4,5,6], [7,8,9]])\n",
      "     |      print(foo[tf.newaxis, :, :].eval())  # => [[[1,2,3], [4,5,6], [7,8,9]]]\n",
      "     |      print(foo[tf.newaxis, ...].eval())  # => [[[1,2,3], [4,5,6], [7,8,9]]]\n",
      "     |      print(foo[tf.newaxis].eval())  # => [[[1,2,3], [4,5,6], [7,8,9]]]\n",
      "     |      \n",
      "     |      # Masks\n",
      "     |      foo = tf.constant([[1,2,3], [4,5,6], [7,8,9]])\n",
      "     |      print(foo[foo > 2].eval())  # => [3, 4, 5, 6, 7, 8, 9]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Notes:\n",
      "     |        - `tf.newaxis` is `None` as in NumPy.\n",
      "     |        - An implicit ellipsis is placed at the end of the `slice_spec`\n",
      "     |        - NumPy advanced indexing is currently not supported.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        tensor: An ops.Tensor object.\n",
      "     |        slice_spec: The arguments to Tensor.__getitem__.\n",
      "     |        var: In the case of variable slice assignment, the Variable object to slice\n",
      "     |          (i.e. tensor is the read-only view of this variable).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The appropriate slice of \"tensor\", based on \"slice_spec\".\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If a slice range is negative size.\n",
      "     |        TypeError: If the slice indices aren't int, slice, ellipsis,\n",
      "     |          tf.newaxis or scalar int32/int64 tensors.\n",
      "     |  \n",
      "     |  __gt__ = greater(x, y, name=None)\n",
      "     |      Returns the truth value of (x > y) element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `math.greater` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __init__(self, op, value_index, dtype)\n",
      "     |      Creates a new `Tensor`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        op: An `Operation`. `Operation` that computes this tensor.\n",
      "     |        value_index: An `int`. Index of the operation's endpoint that produces\n",
      "     |          this tensor.\n",
      "     |        dtype: A `DType`. Type of elements stored in this tensor.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If the op is not an `Operation`.\n",
      "     |  \n",
      "     |  __invert__ = logical_not(x, name=None)\n",
      "     |      Returns the truth value of NOT x element-wise.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor` of type `bool`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __le__ = less_equal(x, y, name=None)\n",
      "     |      Returns the truth value of (x <= y) element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `math.less_equal` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  __lt__ = less(x, y, name=None)\n",
      "     |      Returns the truth value of (x < y) element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `math.less` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __matmul__ = binary_op_wrapper(x, y)\n",
      "     |      Multiplies matrix `a` by matrix `b`, producing `a` * `b`.\n",
      "     |      \n",
      "     |      The inputs must, following any transpositions, be tensors of rank >= 2\n",
      "     |      where the inner 2 dimensions specify valid matrix multiplication arguments,\n",
      "     |      and any further outer dimensions match.\n",
      "     |      \n",
      "     |      Both matrices must be of the same type. The supported types are:\n",
      "     |      `float16`, `float32`, `float64`, `int32`, `complex64`, `complex128`.\n",
      "     |      \n",
      "     |      Either matrix can be transposed or adjointed (conjugated and transposed) on\n",
      "     |      the fly by setting one of the corresponding flag to `True`. These are `False`\n",
      "     |      by default.\n",
      "     |      \n",
      "     |      If one or both of the matrices contain a lot of zeros, a more efficient\n",
      "     |      multiplication algorithm can be used by setting the corresponding\n",
      "     |      `a_is_sparse` or `b_is_sparse` flag to `True`. These are `False` by default.\n",
      "     |      This optimization is only available for plain matrices (rank-2 tensors) with\n",
      "     |      datatypes `bfloat16` or `float32`.\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      # 2-D tensor `a`\n",
      "     |      # [[1, 2, 3],\n",
      "     |      #  [4, 5, 6]]\n",
      "     |      a = tf.constant([1, 2, 3, 4, 5, 6], shape=[2, 3])\n",
      "     |      \n",
      "     |      # 2-D tensor `b`\n",
      "     |      # [[ 7,  8],\n",
      "     |      #  [ 9, 10],\n",
      "     |      #  [11, 12]]\n",
      "     |      b = tf.constant([7, 8, 9, 10, 11, 12], shape=[3, 2])\n",
      "     |      \n",
      "     |      # `a` * `b`\n",
      "     |      # [[ 58,  64],\n",
      "     |      #  [139, 154]]\n",
      "     |      c = tf.matmul(a, b)\n",
      "     |      \n",
      "     |      \n",
      "     |      # 3-D tensor `a`\n",
      "     |      # [[[ 1,  2,  3],\n",
      "     |      #   [ 4,  5,  6]],\n",
      "     |      #  [[ 7,  8,  9],\n",
      "     |      #   [10, 11, 12]]]\n",
      "     |      a = tf.constant(np.arange(1, 13, dtype=np.int32),\n",
      "     |                      shape=[2, 2, 3])\n",
      "     |      \n",
      "     |      # 3-D tensor `b`\n",
      "     |      # [[[13, 14],\n",
      "     |      #   [15, 16],\n",
      "     |      #   [17, 18]],\n",
      "     |      #  [[19, 20],\n",
      "     |      #   [21, 22],\n",
      "     |      #   [23, 24]]]\n",
      "     |      b = tf.constant(np.arange(13, 25, dtype=np.int32),\n",
      "     |                      shape=[2, 3, 2])\n",
      "     |      \n",
      "     |      # `a` * `b`\n",
      "     |      # [[[ 94, 100],\n",
      "     |      #   [229, 244]],\n",
      "     |      #  [[508, 532],\n",
      "     |      #   [697, 730]]]\n",
      "     |      c = tf.matmul(a, b)\n",
      "     |      \n",
      "     |      # Since python >= 3.5 the @ operator is supported (see PEP 465).\n",
      "     |      # In TensorFlow, it simply calls the `tf.matmul()` function, so the\n",
      "     |      # following lines are equivalent:\n",
      "     |      d = a @ b @ [[10.], [11.]]\n",
      "     |      d = tf.matmul(tf.matmul(a, b), [[10.], [11.]])\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        a: `Tensor` of type `float16`, `float32`, `float64`, `int32`, `complex64`,\n",
      "     |          `complex128` and rank > 1.\n",
      "     |        b: `Tensor` with same type and rank as `a`.\n",
      "     |        transpose_a: If `True`, `a` is transposed before multiplication.\n",
      "     |        transpose_b: If `True`, `b` is transposed before multiplication.\n",
      "     |        adjoint_a: If `True`, `a` is conjugated and transposed before\n",
      "     |          multiplication.\n",
      "     |        adjoint_b: If `True`, `b` is conjugated and transposed before\n",
      "     |          multiplication.\n",
      "     |        a_is_sparse: If `True`, `a` is treated as a sparse matrix.\n",
      "     |        b_is_sparse: If `True`, `b` is treated as a sparse matrix.\n",
      "     |        name: Name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of the same type as `a` and `b` where each inner-most matrix is\n",
      "     |        the product of the corresponding matrices in `a` and `b`, e.g. if all\n",
      "     |        transpose or adjoint attributes are `False`:\n",
      "     |      \n",
      "     |        `output`[..., i, j] = sum_k (`a`[..., i, k] * `b`[..., k, j]),\n",
      "     |        for all indices i, j.\n",
      "     |      \n",
      "     |        Note: This is matrix product, not element-wise product.\n",
      "     |      \n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If transpose_a and adjoint_a, or transpose_b and adjoint_b\n",
      "     |          are both set to True.\n",
      "     |  \n",
      "     |  __mod__ = binary_op_wrapper(x, y)\n",
      "     |      Returns element-wise remainder of division. When `x < 0` xor `y < 0` is\n",
      "     |      \n",
      "     |      true, this follows Python semantics in that the result here is consistent\n",
      "     |      with a flooring divide. E.g. `floor(x / y) * y + mod(x, y) = x`.\n",
      "     |      \n",
      "     |      *NOTE*: `math.floormod` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `int32`, `int64`, `bfloat16`, `half`, `float32`, `float64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `x`.\n",
      "     |  \n",
      "     |  __mul__ = binary_op_wrapper(x, y)\n",
      "     |      Dispatches cwise mul for \"Dense*Dense\" and \"Dense*Sparse\".\n",
      "     |  \n",
      "     |  __ne__ = tensor_not_equals(self, other)\n",
      "     |      Compares two tensors element-wise for equality.\n",
      "     |  \n",
      "     |  __neg__ = neg(x, name=None)\n",
      "     |      Computes numerical negative value element-wise.\n",
      "     |      \n",
      "     |      I.e., \\\\(y = -x\\\\).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int32`, `int64`, `complex64`, `complex128`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `x`.\n",
      "     |      \n",
      "     |        If `x` is a `SparseTensor`, returns\n",
      "     |        `SparseTensor(x.indices, tf.math.negative(x.values, ...), x.dense_shape)`\n",
      "     |  \n",
      "     |  __nonzero__(self)\n",
      "     |      Dummy method to prevent a tensor from being used as a Python `bool`.\n",
      "     |      \n",
      "     |      This is the Python 2.x counterpart to `__bool__()` above.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        `TypeError`.\n",
      "     |  \n",
      "     |  __or__ = binary_op_wrapper(x, y)\n",
      "     |      Returns the truth value of x OR y element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `math.logical_or` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor` of type `bool`.\n",
      "     |        y: A `Tensor` of type `bool`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __pow__ = binary_op_wrapper(x, y)\n",
      "     |      Computes the power of one value to another.\n",
      "     |      \n",
      "     |      Given a tensor `x` and a tensor `y`, this operation computes \\\\(x^y\\\\) for\n",
      "     |      corresponding elements in `x` and `y`. For example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      x = tf.constant([[2, 2], [3, 3]])\n",
      "     |      y = tf.constant([[8, 16], [2, 3]])\n",
      "     |      tf.pow(x, y)  # [[256, 65536], [9, 27]]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor` of type `float16`, `float32`, `float64`, `int32`, `int64`,\n",
      "     |          `complex64`, or `complex128`.\n",
      "     |        y: A `Tensor` of type `float16`, `float32`, `float64`, `int32`, `int64`,\n",
      "     |          `complex64`, or `complex128`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`.\n",
      "     |  \n",
      "     |  __radd__ = r_binary_op_wrapper(y, x)\n",
      "     |      Dispatches to add for strings and add_v2 for all other types.\n",
      "     |  \n",
      "     |  __rand__ = r_binary_op_wrapper(y, x)\n",
      "     |      Returns the truth value of x AND y element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `math.logical_and` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor` of type `bool`.\n",
      "     |        y: A `Tensor` of type `bool`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __rdiv__ = r_binary_op_wrapper(y, x)\n",
      "     |      Divide two values using Python 2 semantics.\n",
      "     |      \n",
      "     |      Used for Tensor.__div__.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: `Tensor` numerator of real numeric type.\n",
      "     |        y: `Tensor` denominator of real numeric type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        `x / y` returns the quotient of x and y.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __rfloordiv__ = r_binary_op_wrapper(y, x)\n",
      "     |      Divides `x / y` elementwise, rounding toward the most negative integer.\n",
      "     |      \n",
      "     |      The same as `tf.compat.v1.div(x,y)` for integers, but uses\n",
      "     |      `tf.floor(tf.compat.v1.div(x,y))` for\n",
      "     |      floating point arguments so that the result is always an integer (though\n",
      "     |      possibly an integer represented as floating point).  This op is generated by\n",
      "     |      `x // y` floor division in Python 3 and in Python 2.7 with\n",
      "     |      `from __future__ import division`.\n",
      "     |      \n",
      "     |      `x` and `y` must have the same type, and the result will have the same type\n",
      "     |      as well.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: `Tensor` numerator of real numeric type.\n",
      "     |        y: `Tensor` denominator of real numeric type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        `x / y` rounded down.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If the inputs are complex.\n",
      "     |  \n",
      "     |  __rmatmul__ = r_binary_op_wrapper(y, x)\n",
      "     |      Multiplies matrix `a` by matrix `b`, producing `a` * `b`.\n",
      "     |      \n",
      "     |      The inputs must, following any transpositions, be tensors of rank >= 2\n",
      "     |      where the inner 2 dimensions specify valid matrix multiplication arguments,\n",
      "     |      and any further outer dimensions match.\n",
      "     |      \n",
      "     |      Both matrices must be of the same type. The supported types are:\n",
      "     |      `float16`, `float32`, `float64`, `int32`, `complex64`, `complex128`.\n",
      "     |      \n",
      "     |      Either matrix can be transposed or adjointed (conjugated and transposed) on\n",
      "     |      the fly by setting one of the corresponding flag to `True`. These are `False`\n",
      "     |      by default.\n",
      "     |      \n",
      "     |      If one or both of the matrices contain a lot of zeros, a more efficient\n",
      "     |      multiplication algorithm can be used by setting the corresponding\n",
      "     |      `a_is_sparse` or `b_is_sparse` flag to `True`. These are `False` by default.\n",
      "     |      This optimization is only available for plain matrices (rank-2 tensors) with\n",
      "     |      datatypes `bfloat16` or `float32`.\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      # 2-D tensor `a`\n",
      "     |      # [[1, 2, 3],\n",
      "     |      #  [4, 5, 6]]\n",
      "     |      a = tf.constant([1, 2, 3, 4, 5, 6], shape=[2, 3])\n",
      "     |      \n",
      "     |      # 2-D tensor `b`\n",
      "     |      # [[ 7,  8],\n",
      "     |      #  [ 9, 10],\n",
      "     |      #  [11, 12]]\n",
      "     |      b = tf.constant([7, 8, 9, 10, 11, 12], shape=[3, 2])\n",
      "     |      \n",
      "     |      # `a` * `b`\n",
      "     |      # [[ 58,  64],\n",
      "     |      #  [139, 154]]\n",
      "     |      c = tf.matmul(a, b)\n",
      "     |      \n",
      "     |      \n",
      "     |      # 3-D tensor `a`\n",
      "     |      # [[[ 1,  2,  3],\n",
      "     |      #   [ 4,  5,  6]],\n",
      "     |      #  [[ 7,  8,  9],\n",
      "     |      #   [10, 11, 12]]]\n",
      "     |      a = tf.constant(np.arange(1, 13, dtype=np.int32),\n",
      "     |                      shape=[2, 2, 3])\n",
      "     |      \n",
      "     |      # 3-D tensor `b`\n",
      "     |      # [[[13, 14],\n",
      "     |      #   [15, 16],\n",
      "     |      #   [17, 18]],\n",
      "     |      #  [[19, 20],\n",
      "     |      #   [21, 22],\n",
      "     |      #   [23, 24]]]\n",
      "     |      b = tf.constant(np.arange(13, 25, dtype=np.int32),\n",
      "     |                      shape=[2, 3, 2])\n",
      "     |      \n",
      "     |      # `a` * `b`\n",
      "     |      # [[[ 94, 100],\n",
      "     |      #   [229, 244]],\n",
      "     |      #  [[508, 532],\n",
      "     |      #   [697, 730]]]\n",
      "     |      c = tf.matmul(a, b)\n",
      "     |      \n",
      "     |      # Since python >= 3.5 the @ operator is supported (see PEP 465).\n",
      "     |      # In TensorFlow, it simply calls the `tf.matmul()` function, so the\n",
      "     |      # following lines are equivalent:\n",
      "     |      d = a @ b @ [[10.], [11.]]\n",
      "     |      d = tf.matmul(tf.matmul(a, b), [[10.], [11.]])\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        a: `Tensor` of type `float16`, `float32`, `float64`, `int32`, `complex64`,\n",
      "     |          `complex128` and rank > 1.\n",
      "     |        b: `Tensor` with same type and rank as `a`.\n",
      "     |        transpose_a: If `True`, `a` is transposed before multiplication.\n",
      "     |        transpose_b: If `True`, `b` is transposed before multiplication.\n",
      "     |        adjoint_a: If `True`, `a` is conjugated and transposed before\n",
      "     |          multiplication.\n",
      "     |        adjoint_b: If `True`, `b` is conjugated and transposed before\n",
      "     |          multiplication.\n",
      "     |        a_is_sparse: If `True`, `a` is treated as a sparse matrix.\n",
      "     |        b_is_sparse: If `True`, `b` is treated as a sparse matrix.\n",
      "     |        name: Name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of the same type as `a` and `b` where each inner-most matrix is\n",
      "     |        the product of the corresponding matrices in `a` and `b`, e.g. if all\n",
      "     |        transpose or adjoint attributes are `False`:\n",
      "     |      \n",
      "     |        `output`[..., i, j] = sum_k (`a`[..., i, k] * `b`[..., k, j]),\n",
      "     |        for all indices i, j.\n",
      "     |      \n",
      "     |        Note: This is matrix product, not element-wise product.\n",
      "     |      \n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If transpose_a and adjoint_a, or transpose_b and adjoint_b\n",
      "     |          are both set to True.\n",
      "     |  \n",
      "     |  __rmod__ = r_binary_op_wrapper(y, x)\n",
      "     |      Returns element-wise remainder of division. When `x < 0` xor `y < 0` is\n",
      "     |      \n",
      "     |      true, this follows Python semantics in that the result here is consistent\n",
      "     |      with a flooring divide. E.g. `floor(x / y) * y + mod(x, y) = x`.\n",
      "     |      \n",
      "     |      *NOTE*: `math.floormod` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `int32`, `int64`, `bfloat16`, `half`, `float32`, `float64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `x`.\n",
      "     |  \n",
      "     |  __rmul__ = r_binary_op_wrapper(y, x)\n",
      "     |      Dispatches cwise mul for \"Dense*Dense\" and \"Dense*Sparse\".\n",
      "     |  \n",
      "     |  __ror__ = r_binary_op_wrapper(y, x)\n",
      "     |      Returns the truth value of x OR y element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `math.logical_or` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor` of type `bool`.\n",
      "     |        y: A `Tensor` of type `bool`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __rpow__ = r_binary_op_wrapper(y, x)\n",
      "     |      Computes the power of one value to another.\n",
      "     |      \n",
      "     |      Given a tensor `x` and a tensor `y`, this operation computes \\\\(x^y\\\\) for\n",
      "     |      corresponding elements in `x` and `y`. For example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      x = tf.constant([[2, 2], [3, 3]])\n",
      "     |      y = tf.constant([[8, 16], [2, 3]])\n",
      "     |      tf.pow(x, y)  # [[256, 65536], [9, 27]]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor` of type `float16`, `float32`, `float64`, `int32`, `int64`,\n",
      "     |          `complex64`, or `complex128`.\n",
      "     |        y: A `Tensor` of type `float16`, `float32`, `float64`, `int32`, `int64`,\n",
      "     |          `complex64`, or `complex128`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`.\n",
      "     |  \n",
      "     |  __rsub__ = r_binary_op_wrapper(y, x)\n",
      "     |      Returns x - y element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `Subtract` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`, `int16`, `int32`, `int64`, `complex64`, `complex128`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `x`.\n",
      "     |  \n",
      "     |  __rtruediv__ = r_binary_op_wrapper(y, x)\n",
      "     |  \n",
      "     |  __rxor__ = r_binary_op_wrapper(y, x)\n",
      "     |      Logical XOR function.\n",
      "     |      \n",
      "     |      x ^ y = (x | y) & ~(x & y)\n",
      "     |      \n",
      "     |      Inputs are tensor and if the tensors contains more than one element, an\n",
      "     |      element-wise logical XOR is computed.\n",
      "     |      \n",
      "     |      Usage:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      x = tf.constant([False, False, True, True], dtype = tf.bool)\n",
      "     |      y = tf.constant([False, True, False, True], dtype = tf.bool)\n",
      "     |      z = tf.logical_xor(x, y, name=\"LogicalXor\")\n",
      "     |      #  here z = [False  True  True False]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          x: A `Tensor` type bool.\n",
      "     |          y: A `Tensor` of type bool.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type bool with the same size as that of x or y.\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  __sub__ = binary_op_wrapper(x, y)\n",
      "     |      Returns x - y element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `Subtract` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`, `int16`, `int32`, `int64`, `complex64`, `complex128`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `x`.\n",
      "     |  \n",
      "     |  __truediv__ = binary_op_wrapper(x, y)\n",
      "     |  \n",
      "     |  __xor__ = binary_op_wrapper(x, y)\n",
      "     |      Logical XOR function.\n",
      "     |      \n",
      "     |      x ^ y = (x | y) & ~(x & y)\n",
      "     |      \n",
      "     |      Inputs are tensor and if the tensors contains more than one element, an\n",
      "     |      element-wise logical XOR is computed.\n",
      "     |      \n",
      "     |      Usage:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      x = tf.constant([False, False, True, True], dtype = tf.bool)\n",
      "     |      y = tf.constant([False, True, False, True], dtype = tf.bool)\n",
      "     |      z = tf.logical_xor(x, y, name=\"LogicalXor\")\n",
      "     |      #  here z = [False  True  True False]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          x: A `Tensor` type bool.\n",
      "     |          y: A `Tensor` of type bool.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type bool with the same size as that of x or y.\n",
      "     |  \n",
      "     |  consumers(self)\n",
      "     |      Returns a list of `Operation`s that consume this tensor.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A list of `Operation`s.\n",
      "     |  \n",
      "     |  eval(self, feed_dict=None, session=None)\n",
      "     |      Evaluates this tensor in a `Session`.\n",
      "     |      \n",
      "     |      Calling this method will execute all preceding operations that\n",
      "     |      produce the inputs needed for the operation that produces this\n",
      "     |      tensor.\n",
      "     |      \n",
      "     |      *N.B.* Before invoking `Tensor.eval()`, its graph must have been\n",
      "     |      launched in a session, and either a default session must be\n",
      "     |      available, or `session` must be specified explicitly.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        feed_dict: A dictionary that maps `Tensor` objects to feed values. See\n",
      "     |          `tf.Session.run` for a description of the valid feed values.\n",
      "     |        session: (Optional.) The `Session` to be used to evaluate this tensor. If\n",
      "     |          none, the default session will be used.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A numpy array corresponding to the value of this tensor.\n",
      "     |  \n",
      "     |  experimental_ref(self)\n",
      "     |      Returns a hashable reference object to this Tensor.\n",
      "     |      \n",
      "     |      Warning: Experimental API that could be changed or removed.\n",
      "     |      \n",
      "     |      The primary usecase for this API is to put tensors in a set/dictionary.\n",
      "     |      We can't put tensors in a set/dictionary as `tensor.__hash__()` is no longer\n",
      "     |      available starting Tensorflow 2.0.\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      import tensorflow as tf\n",
      "     |      \n",
      "     |      x = tf.constant(5)\n",
      "     |      y = tf.constant(10)\n",
      "     |      z = tf.constant(10)\n",
      "     |      \n",
      "     |      # The followings will raise an exception starting 2.0\n",
      "     |      # TypeError: Tensor is unhashable if Tensor equality is enabled.\n",
      "     |      tensor_set = {x, y, z}\n",
      "     |      tensor_dict = {x: 'five', y: 'ten', z: 'ten'}\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Instead, we can use `tensor.experimental_ref()`.\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      tensor_set = {x.experimental_ref(),\n",
      "     |                    y.experimental_ref(),\n",
      "     |                    z.experimental_ref()}\n",
      "     |      \n",
      "     |      print(x.experimental_ref() in tensor_set)\n",
      "     |      ==> True\n",
      "     |      \n",
      "     |      tensor_dict = {x.experimental_ref(): 'five',\n",
      "     |                     y.experimental_ref(): 'ten',\n",
      "     |                     z.experimental_ref(): 'ten'}\n",
      "     |      \n",
      "     |      print(tensor_dict[y.experimental_ref()])\n",
      "     |      ==> ten\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Also, the reference object provides `.deref()` function that returns the\n",
      "     |      original Tensor.\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      x = tf.constant(5)\n",
      "     |      print(x.experimental_ref().deref())\n",
      "     |      ==> tf.Tensor(5, shape=(), dtype=int32)\n",
      "     |      ```\n",
      "     |  \n",
      "     |  get_shape(self)\n",
      "     |      Alias of Tensor.shape.\n",
      "     |  \n",
      "     |  set_shape(self, shape)\n",
      "     |      Updates the shape of this tensor.\n",
      "     |      \n",
      "     |      This method can be called multiple times, and will merge the given\n",
      "     |      `shape` with the current shape of this tensor. It can be used to\n",
      "     |      provide additional information about the shape of this tensor that\n",
      "     |      cannot be inferred from the graph alone. For example, this can be used\n",
      "     |      to provide additional information about the shapes of images:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      _, image_data = tf.compat.v1.TFRecordReader(...).read(...)\n",
      "     |      image = tf.image.decode_png(image_data, channels=3)\n",
      "     |      \n",
      "     |      # The height and width dimensions of `image` are data dependent, and\n",
      "     |      # cannot be computed without executing the op.\n",
      "     |      print(image.shape)\n",
      "     |      ==> TensorShape([Dimension(None), Dimension(None), Dimension(3)])\n",
      "     |      \n",
      "     |      # We know that each image in this dataset is 28 x 28 pixels.\n",
      "     |      image.set_shape([28, 28, 3])\n",
      "     |      print(image.shape)\n",
      "     |      ==> TensorShape([Dimension(28), Dimension(28), Dimension(3)])\n",
      "     |      ```\n",
      "     |      \n",
      "     |      NOTE: This shape is not enforced at runtime. Setting incorrect shapes can\n",
      "     |      result in inconsistencies between the statically-known graph and the runtime\n",
      "     |      value of tensors. For runtime validation of the shape, use `tf.ensure_shape`\n",
      "     |      instead.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: A `TensorShape` representing the shape of this tensor, a\n",
      "     |          `TensorShapeProto`, a list, a tuple, or None.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `shape` is not compatible with the current shape of\n",
      "     |          this tensor.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  device\n",
      "     |      The name of the device on which this tensor will be produced, or None.\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      The `DType` of elements in this tensor.\n",
      "     |  \n",
      "     |  graph\n",
      "     |      The `Graph` that contains this tensor.\n",
      "     |  \n",
      "     |  name\n",
      "     |      The string name of this tensor.\n",
      "     |  \n",
      "     |  op\n",
      "     |      The `Operation` that produces this tensor as an output.\n",
      "     |  \n",
      "     |  shape\n",
      "     |      Returns the `TensorShape` that represents the shape of this tensor.\n",
      "     |      \n",
      "     |      The shape is computed using shape inference functions that are\n",
      "     |      registered in the Op for each `Operation`.  See\n",
      "     |      `tf.TensorShape`\n",
      "     |      for more details of what a shape represents.\n",
      "     |      \n",
      "     |      The inferred shape of a tensor is used to provide shape\n",
      "     |      information without having to launch the graph in a session. This\n",
      "     |      can be used for debugging, and providing early error messages. For\n",
      "     |      example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      c = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
      "     |      \n",
      "     |      print(c.shape)\n",
      "     |      ==> TensorShape([Dimension(2), Dimension(3)])\n",
      "     |      \n",
      "     |      d = tf.constant([[1.0, 0.0], [0.0, 1.0], [1.0, 0.0], [0.0, 1.0]])\n",
      "     |      \n",
      "     |      print(d.shape)\n",
      "     |      ==> TensorShape([Dimension(4), Dimension(2)])\n",
      "     |      \n",
      "     |      # Raises a ValueError, because `c` and `d` do not have compatible\n",
      "     |      # inner dimensions.\n",
      "     |      e = tf.matmul(c, d)\n",
      "     |      \n",
      "     |      f = tf.matmul(c, d, transpose_a=True, transpose_b=True)\n",
      "     |      \n",
      "     |      print(f.shape)\n",
      "     |      ==> TensorShape([Dimension(3), Dimension(4)])\n",
      "     |      ```\n",
      "     |      \n",
      "     |      In some cases, the inferred shape may have unknown dimensions. If\n",
      "     |      the caller has additional information about the values of these\n",
      "     |      dimensions, `Tensor.set_shape()` can be used to augment the\n",
      "     |      inferred shape.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `TensorShape` representing the shape of this tensor.\n",
      "     |  \n",
      "     |  value_index\n",
      "     |      The index of this tensor in the outputs of its `Operation`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  OVERLOADABLE_OPERATORS = {'__abs__', '__add__', '__and__', '__div__', ...\n",
      "     |  \n",
      "     |  __array_priority__ = 100\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.framework.tensor_like._TensorLike:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class TensorArray(builtins.object)\n",
      "     |  Class wrapping dynamic-sized, per-time-step, write-once Tensor arrays.\n",
      "     |  \n",
      "     |  This class is meant to be used with dynamic iteration primitives such as\n",
      "     |  `while_loop` and `map_fn`.  It supports gradient back-propagation via special\n",
      "     |  \"flow\" control flow dependencies.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, dtype, size=None, dynamic_size=None, clear_after_read=None, tensor_array_name=None, handle=None, flow=None, infer_shape=True, element_shape=None, colocate_with_first_write_call=True, name=None)\n",
      "     |      Construct a new TensorArray or wrap an existing TensorArray handle.\n",
      "     |      \n",
      "     |      A note about the parameter `name`:\n",
      "     |      \n",
      "     |      The name of the `TensorArray` (even if passed in) is uniquified: each time\n",
      "     |      a new `TensorArray` is created at runtime it is assigned its own name for\n",
      "     |      the duration of the run.  This avoids name collisions if a `TensorArray`\n",
      "     |      is created within a `while_loop`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        dtype: (required) data type of the TensorArray.\n",
      "     |        size: (optional) int32 scalar `Tensor`: the size of the TensorArray.\n",
      "     |          Required if handle is not provided.\n",
      "     |        dynamic_size: (optional) Python bool: If true, writes to the TensorArray\n",
      "     |          can grow the TensorArray past its initial size.  Default: False.\n",
      "     |        clear_after_read: Boolean (optional, default: True).  If True, clear\n",
      "     |          TensorArray values after reading them.  This disables read-many\n",
      "     |          semantics, but allows early release of memory.\n",
      "     |        tensor_array_name: (optional) Python string: the name of the TensorArray.\n",
      "     |          This is used when creating the TensorArray handle.  If this value is\n",
      "     |          set, handle should be None.\n",
      "     |        handle: (optional) A `Tensor` handle to an existing TensorArray.  If this\n",
      "     |          is set, tensor_array_name should be None. Only supported in graph mode.\n",
      "     |        flow: (optional) A float `Tensor` scalar coming from an existing\n",
      "     |          `TensorArray.flow`. Only supported in graph mode.\n",
      "     |        infer_shape: (optional, default: True) If True, shape inference\n",
      "     |          is enabled.  In this case, all elements must have the same shape.\n",
      "     |        element_shape: (optional, default: None) A `TensorShape` object specifying\n",
      "     |          the shape constraints of each of the elements of the TensorArray.\n",
      "     |          Need not be fully defined.\n",
      "     |        colocate_with_first_write_call: If `True`, the TensorArray will be\n",
      "     |          colocated on the same device as the Tensor used on its first write\n",
      "     |          (write operations include `write`, `unstack`, and `split`).  If `False`,\n",
      "     |          the TensorArray will be placed on the device determined by the\n",
      "     |          device context available during its initialization.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: if both handle and tensor_array_name are provided.\n",
      "     |        TypeError: if handle is provided but is not a Tensor.\n",
      "     |  \n",
      "     |  close(self, name=None)\n",
      "     |      Close the current TensorArray.\n",
      "     |      \n",
      "     |      **NOTE** The output of this function should be used.  If it is not, a warning will be logged.  To mark the output as used, call its .mark_used() method.\n",
      "     |  \n",
      "     |  concat(self, name=None)\n",
      "     |      Return the values in the TensorArray as a concatenated `Tensor`.\n",
      "     |      \n",
      "     |      All of the values must have been written, their ranks must match, and\n",
      "     |      and their shapes must all match for all dimensions except the first.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        All the tensors in the TensorArray concatenated into one tensor.\n",
      "     |  \n",
      "     |  gather(self, indices, name=None)\n",
      "     |      Return selected values in the TensorArray as a packed `Tensor`.\n",
      "     |      \n",
      "     |      All of selected values must have been written and their shapes\n",
      "     |      must all match.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        indices: A `1-D` `Tensor` taking values in `[0, max_value)`.  If\n",
      "     |          the `TensorArray` is not dynamic, `max_value=size()`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The tensors in the `TensorArray` selected by `indices`, packed into one\n",
      "     |        tensor.\n",
      "     |  \n",
      "     |  grad(self, source, flow=None, name=None)\n",
      "     |  \n",
      "     |  identity(self)\n",
      "     |      Returns a TensorArray with the same content and properties.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A new TensorArray object with flow that ensures the control dependencies\n",
      "     |        from the contexts will become control dependencies for writes, reads, etc.\n",
      "     |        Use this object all for subsequent operations.\n",
      "     |  \n",
      "     |  read(self, index, name=None)\n",
      "     |      Read the value at location `index` in the TensorArray.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        index: 0-D.  int32 tensor with the index to read from.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The tensor at index `index`.\n",
      "     |  \n",
      "     |  scatter(self, indices, value, name=None)\n",
      "     |      Scatter the values of a `Tensor` in specific indices of a `TensorArray`.\n",
      "     |      \n",
      "     |        Args:\n",
      "     |          indices: A `1-D` `Tensor` taking values in `[0, max_value)`.  If\n",
      "     |            the `TensorArray` is not dynamic, `max_value=size()`.\n",
      "     |          value: (N+1)-D.  Tensor of type `dtype`.  The Tensor to unpack.\n",
      "     |          name: A name for the operation (optional).\n",
      "     |      \n",
      "     |        Returns:\n",
      "     |          A new TensorArray object with flow that ensures the scatter occurs.\n",
      "     |          Use this object all for subsequent operations.\n",
      "     |      \n",
      "     |        Raises:\n",
      "     |          ValueError: if the shape inference fails.\n",
      "     |        \n",
      "     |      \n",
      "     |      **NOTE** The output of this function should be used.  If it is not, a warning will be logged.  To mark the output as used, call its .mark_used() method.\n",
      "     |  \n",
      "     |  size(self, name=None)\n",
      "     |      Return the size of the TensorArray.\n",
      "     |  \n",
      "     |  split(self, value, lengths, name=None)\n",
      "     |      Split the values of a `Tensor` into the TensorArray.\n",
      "     |      \n",
      "     |        Args:\n",
      "     |          value: (N+1)-D.  Tensor of type `dtype`.  The Tensor to split.\n",
      "     |          lengths: 1-D.  int32 vector with the lengths to use when splitting\n",
      "     |            `value` along its first dimension.\n",
      "     |          name: A name for the operation (optional).\n",
      "     |      \n",
      "     |        Returns:\n",
      "     |          A new TensorArray object with flow that ensures the split occurs.\n",
      "     |          Use this object all for subsequent operations.\n",
      "     |      \n",
      "     |        Raises:\n",
      "     |          ValueError: if the shape inference fails.\n",
      "     |        \n",
      "     |      \n",
      "     |      **NOTE** The output of this function should be used.  If it is not, a warning will be logged.  To mark the output as used, call its .mark_used() method.\n",
      "     |  \n",
      "     |  stack(self, name=None)\n",
      "     |      Return the values in the TensorArray as a stacked `Tensor`.\n",
      "     |      \n",
      "     |      All of the values must have been written and their shapes must all match.\n",
      "     |      If input shapes have rank-`R`, then output shape will have rank-`(R+1)`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        All the tensors in the TensorArray stacked into one tensor.\n",
      "     |  \n",
      "     |  unstack(self, value, name=None)\n",
      "     |      Unstack the values of a `Tensor` in the TensorArray.\n",
      "     |      \n",
      "     |        If input value shapes have rank-`R`, then the output TensorArray will\n",
      "     |        contain elements whose shapes are rank-`(R-1)`.\n",
      "     |      \n",
      "     |        Args:\n",
      "     |          value: (N+1)-D.  Tensor of type `dtype`.  The Tensor to unstack.\n",
      "     |          name: A name for the operation (optional).\n",
      "     |      \n",
      "     |        Returns:\n",
      "     |          A new TensorArray object with flow that ensures the unstack occurs.\n",
      "     |          Use this object all for subsequent operations.\n",
      "     |      \n",
      "     |        Raises:\n",
      "     |          ValueError: if the shape inference fails.\n",
      "     |        \n",
      "     |      \n",
      "     |      **NOTE** The output of this function should be used.  If it is not, a warning will be logged.  To mark the output as used, call its .mark_used() method.\n",
      "     |  \n",
      "     |  write(self, index, value, name=None)\n",
      "     |      Write `value` into index `index` of the TensorArray.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        index: 0-D.  int32 scalar with the index to write to.\n",
      "     |        value: N-D.  Tensor of type `dtype`.  The Tensor to write to this index.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A new TensorArray object with flow that ensures the write occurs.\n",
      "     |        Use this object all for subsequent operations.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: if there are more writers than specified.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      The data type of this TensorArray.\n",
      "     |  \n",
      "     |  dynamic_size\n",
      "     |      Python bool; if `True` the TensorArray can grow dynamically.\n",
      "     |  \n",
      "     |  element_shape\n",
      "     |      The `tf.TensorShape` of elements in this TensorArray.\n",
      "     |  \n",
      "     |  flow\n",
      "     |      The flow `Tensor` forcing ops leading to this TensorArray state.\n",
      "     |  \n",
      "     |  handle\n",
      "     |      The reference to the TensorArray.\n",
      "    \n",
      "    class TensorArraySpec(tensorflow.python.framework.type_spec.TypeSpec)\n",
      "     |  Type specification for a `tf.TensorArray`.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      TensorArraySpec\n",
      "     |      tensorflow.python.framework.type_spec.TypeSpec\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, element_shape=None, dtype=tf.float32, dynamic_size=False, infer_shape=True)\n",
      "     |      Constructs a type specification for a `tf.TensorArray`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        element_shape: The shape of each element in the `TensorArray`.\n",
      "     |        dtype: Data type of the `TensorArray`.\n",
      "     |        dynamic_size: Whether the `TensorArray` can grow past its initial size.\n",
      "     |        infer_shape: Whether shape inference is enabled.\n",
      "     |  \n",
      "     |  is_compatible_with(self, other)\n",
      "     |      Returns true if `spec_or_value` is compatible with this TypeSpec.\n",
      "     |  \n",
      "     |  most_specific_compatible_type(self, other)\n",
      "     |      Returns the most specific TypeSpec compatible with `self` and `other`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: A `TypeSpec`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If there is no TypeSpec that is compatible with both `self`\n",
      "     |          and `other`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  from_value(value)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  value_type\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tensorflow.python.framework.type_spec.TypeSpec:\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __ne__(self, other)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "    \n",
      "    class TensorInfo(google.protobuf.pyext._message.CMessage, google.protobuf.message.Message)\n",
      "     |  A ProtocolMessage\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      TensorInfo\n",
      "     |      google.protobuf.pyext._message.CMessage\n",
      "     |      google.protobuf.message.Message\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  composite_tensor\n",
      "     |      Field tensorflow.TensorInfo.composite_tensor\n",
      "     |  \n",
      "     |  coo_sparse\n",
      "     |      Field tensorflow.TensorInfo.coo_sparse\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      Field tensorflow.TensorInfo.dtype\n",
      "     |  \n",
      "     |  name\n",
      "     |      Field tensorflow.TensorInfo.name\n",
      "     |  \n",
      "     |  tensor_shape\n",
      "     |      Field tensorflow.TensorInfo.tensor_shape\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  CompositeTensor = <class 'tensorflow.core.protobuf.meta_graph_pb2.Comp...\n",
      "     |      A ProtocolMessage\n",
      "     |  \n",
      "     |  CooSparse = <class 'tensorflow.core.protobuf.meta_graph_pb2.CooSparse'...\n",
      "     |      A ProtocolMessage\n",
      "     |  \n",
      "     |  DESCRIPTOR = <google.protobuf.pyext._message.MessageDescriptor object>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.pyext._message.CMessage:\n",
      "     |  \n",
      "     |  ByteSize(...)\n",
      "     |      Returns the size of the message in bytes.\n",
      "     |  \n",
      "     |  Clear(...)\n",
      "     |      Clears the message.\n",
      "     |  \n",
      "     |  ClearExtension(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  ClearField(...)\n",
      "     |      Clears a message field.\n",
      "     |  \n",
      "     |  CopyFrom(...)\n",
      "     |      Copies a protocol message into the current message.\n",
      "     |  \n",
      "     |  DiscardUnknownFields(...)\n",
      "     |      Discards the unknown fields.\n",
      "     |  \n",
      "     |  FindInitializationErrors(...)\n",
      "     |      Finds unset required fields.\n",
      "     |  \n",
      "     |  FromString(...) from google.protobuf.pyext.cpp_message.GeneratedProtocolMessageType\n",
      "     |      Creates new method instance from given serialized data.\n",
      "     |  \n",
      "     |  HasExtension(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  HasField(...)\n",
      "     |      Checks if a message field is set.\n",
      "     |  \n",
      "     |  IsInitialized(...)\n",
      "     |      Checks if all required fields of a protocol message are set.\n",
      "     |  \n",
      "     |  ListFields(...)\n",
      "     |      Lists all set fields of a message.\n",
      "     |  \n",
      "     |  MergeFrom(...)\n",
      "     |      Merges a protocol message into the current message.\n",
      "     |  \n",
      "     |  MergeFromString(...)\n",
      "     |      Merges a serialized message into the current message.\n",
      "     |  \n",
      "     |  ParseFromString(...)\n",
      "     |      Parses a serialized message into the current message.\n",
      "     |  \n",
      "     |  RegisterExtension(...) from google.protobuf.pyext.cpp_message.GeneratedProtocolMessageType\n",
      "     |      Registers an extension with the current message.\n",
      "     |  \n",
      "     |  SerializePartialToString(...)\n",
      "     |      Serializes the message to a string, even if it isn't initialized.\n",
      "     |  \n",
      "     |  SerializeToString(...)\n",
      "     |      Serializes the message to a string, only for initialized messages.\n",
      "     |  \n",
      "     |  SetInParent(...)\n",
      "     |      Sets the has bit of the given field in its parent message.\n",
      "     |  \n",
      "     |  UnknownFields(...)\n",
      "     |      Parse unknown field set\n",
      "     |  \n",
      "     |  WhichOneof(...)\n",
      "     |      Returns the name of the field set inside a oneof, or None if no field is set.\n",
      "     |  \n",
      "     |  __deepcopy__(...)\n",
      "     |      Makes a deep copy of the class.\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from google.protobuf.pyext._message.MessageMeta\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  __unicode__(...)\n",
      "     |      Outputs a unicode representation of the message.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from google.protobuf.pyext._message.CMessage:\n",
      "     |  \n",
      "     |  Extensions\n",
      "     |      Extension dict\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from google.protobuf.pyext._message.CMessage:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from google.protobuf.message.Message:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |      Support the pickle protocol.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |      Support the pickle protocol.\n",
      "    \n",
      "    class TensorShape(builtins.object)\n",
      "     |  Represents the shape of a `Tensor`.\n",
      "     |  \n",
      "     |  A `TensorShape` represents a possibly-partial shape specification for a\n",
      "     |  `Tensor`. It may be one of the following:\n",
      "     |  \n",
      "     |  * *Fully-known shape:* has a known number of dimensions and a known size\n",
      "     |    for each dimension. e.g. `TensorShape([16, 256])`\n",
      "     |  * *Partially-known shape:* has a known number of dimensions, and an unknown\n",
      "     |    size for one or more dimension. e.g. `TensorShape([None, 256])`\n",
      "     |  * *Unknown shape:* has an unknown number of dimensions, and an unknown\n",
      "     |    size in all dimensions. e.g. `TensorShape(None)`\n",
      "     |  \n",
      "     |  If a tensor is produced by an operation of type `\"Foo\"`, its shape\n",
      "     |  may be inferred if there is a registered shape function for\n",
      "     |  `\"Foo\"`. See [Shape\n",
      "     |  functions](https://tensorflow.org/extend/adding_an_op#shape_functions_in_c)\n",
      "     |  for details of shape functions and how to register them. Alternatively,\n",
      "     |  the shape may be set explicitly using `tf.Tensor.set_shape`.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __add__(self, other)\n",
      "     |  \n",
      "     |  __bool__(self)\n",
      "     |      Returns True if this shape contains non-zero information.\n",
      "     |  \n",
      "     |  __concat__(self, other)\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Returns True if `self` is equivalent to `other`.\n",
      "     |  \n",
      "     |  __getitem__(self, key)\n",
      "     |      Returns the value of a dimension or a shape, depending on the key.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        key: If `key` is an integer, returns the dimension at that index;\n",
      "     |          otherwise if `key` is a slice, returns a TensorShape whose dimensions\n",
      "     |          are those selected by the slice from `self`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An integer if `key` is an integer, or a `TensorShape` if `key` is a\n",
      "     |        slice.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `key` is a slice and `self` is completely unknown and\n",
      "     |          the step is set.\n",
      "     |  \n",
      "     |  __init__(self, dims)\n",
      "     |      Creates a new TensorShape with the given dimensions.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        dims: A list of Dimensions, or None if the shape is unspecified.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If dims cannot be converted to a list of dimensions.\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |      Returns `self.dims` if the rank is known, otherwise raises ValueError.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Returns the rank of this shape, or raises ValueError if unspecified.\n",
      "     |  \n",
      "     |  __ne__(self, other)\n",
      "     |      Returns True if `self` is known to be different from `other`.\n",
      "     |  \n",
      "     |  __nonzero__ = __bool__(self)\n",
      "     |  \n",
      "     |  __radd__(self, other)\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __str__(self)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  as_list(self)\n",
      "     |      Returns a list of integers or `None` for each dimension.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A list of integers or `None` for each dimension.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `self` is an unknown shape with an unknown rank.\n",
      "     |  \n",
      "     |  as_proto(self)\n",
      "     |      Returns this shape as a `TensorShapeProto`.\n",
      "     |  \n",
      "     |  assert_has_rank(self, rank)\n",
      "     |      Raises an exception if `self` is not compatible with the given `rank`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        rank: An integer.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `self` does not represent a shape with the given `rank`.\n",
      "     |  \n",
      "     |  assert_is_compatible_with(self, other)\n",
      "     |      Raises exception if `self` and `other` do not represent the same shape.\n",
      "     |      \n",
      "     |      This method can be used to assert that there exists a shape that both\n",
      "     |      `self` and `other` represent.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another TensorShape.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `self` and `other` do not represent the same shape.\n",
      "     |  \n",
      "     |  assert_is_fully_defined(self)\n",
      "     |      Raises an exception if `self` is not fully defined in every dimension.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `self` does not have a known value for every dimension.\n",
      "     |  \n",
      "     |  assert_same_rank(self, other)\n",
      "     |      Raises an exception if `self` and `other` do not have compatible ranks.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another `TensorShape`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `self` and `other` do not represent shapes with the\n",
      "     |          same rank.\n",
      "     |  \n",
      "     |  concatenate(self, other)\n",
      "     |      Returns the concatenation of the dimension in `self` and `other`.\n",
      "     |      \n",
      "     |      *N.B.* If either `self` or `other` is completely unknown,\n",
      "     |      concatenation will discard information about the other shape. In\n",
      "     |      future, we might support concatenation that preserves this\n",
      "     |      information for use with slicing.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another `TensorShape`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `TensorShape` whose dimensions are the concatenation of the\n",
      "     |        dimensions in `self` and `other`.\n",
      "     |  \n",
      "     |  is_compatible_with(self, other)\n",
      "     |      Returns True iff `self` is compatible with `other`.\n",
      "     |      \n",
      "     |      Two possibly-partially-defined shapes are compatible if there\n",
      "     |      exists a fully-defined shape that both shapes can represent. Thus,\n",
      "     |      compatibility allows the shape inference code to reason about\n",
      "     |      partially-defined shapes. For example:\n",
      "     |      \n",
      "     |      * TensorShape(None) is compatible with all shapes.\n",
      "     |      \n",
      "     |      * TensorShape([None, None]) is compatible with all two-dimensional\n",
      "     |        shapes, such as TensorShape([32, 784]), and also TensorShape(None). It is\n",
      "     |        not compatible with, for example, TensorShape([None]) or\n",
      "     |        TensorShape([None, None, None]).\n",
      "     |      \n",
      "     |      * TensorShape([32, None]) is compatible with all two-dimensional shapes\n",
      "     |        with size 32 in the 0th dimension, and also TensorShape([None, None])\n",
      "     |        and TensorShape(None). It is not compatible with, for example,\n",
      "     |        TensorShape([32]), TensorShape([32, None, 1]) or TensorShape([64, None]).\n",
      "     |      \n",
      "     |      * TensorShape([32, 784]) is compatible with itself, and also\n",
      "     |        TensorShape([32, None]), TensorShape([None, 784]), TensorShape([None,\n",
      "     |        None]) and TensorShape(None). It is not compatible with, for example,\n",
      "     |        TensorShape([32, 1, 784]) or TensorShape([None]).\n",
      "     |      \n",
      "     |      The compatibility relation is reflexive and symmetric, but not\n",
      "     |      transitive. For example, TensorShape([32, 784]) is compatible with\n",
      "     |      TensorShape(None), and TensorShape(None) is compatible with\n",
      "     |      TensorShape([4, 4]), but TensorShape([32, 784]) is not compatible with\n",
      "     |      TensorShape([4, 4]).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another TensorShape.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        True iff `self` is compatible with `other`.\n",
      "     |  \n",
      "     |  is_fully_defined(self)\n",
      "     |      Returns True iff `self` is fully defined in every dimension.\n",
      "     |  \n",
      "     |  merge_with(self, other)\n",
      "     |      Returns a `TensorShape` combining the information in `self` and `other`.\n",
      "     |      \n",
      "     |      The dimensions in `self` and `other` are merged elementwise,\n",
      "     |      according to the rules defined for `Dimension.merge_with()`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another `TensorShape`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `TensorShape` containing the combined information of `self` and\n",
      "     |        `other`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `self` and `other` are not compatible.\n",
      "     |  \n",
      "     |  most_specific_compatible_shape(self, other)\n",
      "     |      Returns the most specific TensorShape compatible with `self` and `other`.\n",
      "     |      \n",
      "     |      * TensorShape([None, 1]) is the most specific TensorShape compatible with\n",
      "     |        both TensorShape([2, 1]) and TensorShape([5, 1]). Note that\n",
      "     |        TensorShape(None) is also compatible with above mentioned TensorShapes.\n",
      "     |      \n",
      "     |      * TensorShape([1, 2, 3]) is the most specific TensorShape compatible with\n",
      "     |        both TensorShape([1, 2, 3]) and TensorShape([1, 2, 3]). There are more\n",
      "     |        less specific TensorShapes compatible with above mentioned TensorShapes,\n",
      "     |        e.g. TensorShape([1, 2, None]), TensorShape(None).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: Another `TensorShape`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `TensorShape` which is the most specific compatible shape of `self`\n",
      "     |        and `other`.\n",
      "     |  \n",
      "     |  num_elements(self)\n",
      "     |      Returns the total number of elements, or none for incomplete shapes.\n",
      "     |  \n",
      "     |  with_rank(self, rank)\n",
      "     |      Returns a shape based on `self` with the given rank.\n",
      "     |      \n",
      "     |      This method promotes a completely unknown shape to one with a\n",
      "     |      known rank.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        rank: An integer.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A shape that is at least as specific as `self` with the given rank.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `self` does not represent a shape with the given `rank`.\n",
      "     |  \n",
      "     |  with_rank_at_least(self, rank)\n",
      "     |      Returns a shape based on `self` with at least the given rank.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        rank: An integer.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A shape that is at least as specific as `self` with at least the given\n",
      "     |        rank.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `self` does not represent a shape with at least the given\n",
      "     |          `rank`.\n",
      "     |  \n",
      "     |  with_rank_at_most(self, rank)\n",
      "     |      Returns a shape based on `self` with at most the given rank.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        rank: An integer.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A shape that is at least as specific as `self` with at most the given\n",
      "     |        rank.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If `self` does not represent a shape with at most the given\n",
      "     |          `rank`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  dims\n",
      "     |      Returns a list of Dimensions, or None if the shape is unspecified.\n",
      "     |  \n",
      "     |  ndims\n",
      "     |      Deprecated accessor for `rank`.\n",
      "     |  \n",
      "     |  rank\n",
      "     |      Returns the rank of this shape, or None if it is unspecified.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "    \n",
      "    class TensorSpec(tensorflow.python.framework.type_spec.BatchableTypeSpec)\n",
      "     |  Describes a tf.Tensor.\n",
      "     |  \n",
      "     |  Metadata for describing the `tf.Tensor` objects accepted or returned\n",
      "     |  by some TensorFlow APIs.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      TensorSpec\n",
      "     |      tensorflow.python.framework.type_spec.BatchableTypeSpec\n",
      "     |      tensorflow.python.framework.type_spec.TypeSpec\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __init__(self, shape, dtype=tf.float32, name=None)\n",
      "     |      Creates a TensorSpec.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: Value convertible to `tf.TensorShape`. The shape of the tensor.\n",
      "     |        dtype: Value convertible to `tf.DType`. The type of the tensor values.\n",
      "     |        name: Optional name for the Tensor.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If shape is not convertible to a `tf.TensorShape`, or dtype is\n",
      "     |          not convertible to a `tf.DType`.\n",
      "     |  \n",
      "     |  __ne__(self, other)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  is_compatible_with(self, spec_or_tensor)\n",
      "     |      Returns True if spec_or_tensor is compatible with this TensorSpec.\n",
      "     |      \n",
      "     |      Two tensors are considered compatible if they have the same dtype\n",
      "     |      and their shapes are compatible (see `tf.TensorShape.is_compatible_with`).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        spec_or_tensor: A tf.TensorSpec or a tf.Tensor\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        True if spec_or_tensor is compatible with self.\n",
      "     |  \n",
      "     |  most_specific_compatible_type(self, other)\n",
      "     |      Returns the most specific TypeSpec compatible with `self` and `other`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: A `TypeSpec`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If there is no TypeSpec that is compatible with both `self`\n",
      "     |          and `other`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_spec(spec, name=None) from abc.ABCMeta\n",
      "     |  \n",
      "     |  from_tensor(tensor, name=None) from abc.ABCMeta\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      Returns the `dtype` of elements in the tensor.\n",
      "     |  \n",
      "     |  name\n",
      "     |      Returns the (optionally provided) name of the described tensor.\n",
      "     |  \n",
      "     |  shape\n",
      "     |      Returns the `TensorShape` that represents the shape of the tensor.\n",
      "     |  \n",
      "     |  value_type\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from tensorflow.python.framework.type_spec.TypeSpec:\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      helper for pickle\n",
      "    \n",
      "    class TextLineReader(ReaderBase)\n",
      "     |  A Reader that outputs the lines of a file delimited by newlines.\n",
      "     |  \n",
      "     |  Newlines are stripped from the output.\n",
      "     |  See ReaderBase for supported methods.\n",
      "     |  \n",
      "     |  @compatibility(eager)\n",
      "     |  Readers are not compatible with eager execution. Instead, please\n",
      "     |  use `tf.data` to get data into your model.\n",
      "     |  @end_compatibility\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      TextLineReader\n",
      "     |      ReaderBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, skip_header_lines=None, name=None)\n",
      "     |      Create a TextLineReader. (deprecated)\n",
      "     |      \n",
      "     |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TextLineDataset`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        skip_header_lines: An optional int. Defaults to 0.  Number of lines\n",
      "     |          to skip from the beginning of every file.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ReaderBase:\n",
      "     |  \n",
      "     |  num_records_produced(self, name=None)\n",
      "     |      Returns the number of records this reader has produced.\n",
      "     |      \n",
      "     |      This is the same as the number of Read executions that have\n",
      "     |      succeeded.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An int64 Tensor.\n",
      "     |  \n",
      "     |  num_work_units_completed(self, name=None)\n",
      "     |      Returns the number of work units this reader has finished processing.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An int64 Tensor.\n",
      "     |  \n",
      "     |  read(self, queue, name=None)\n",
      "     |      Returns the next record (key, value) pair produced by a reader.\n",
      "     |      \n",
      "     |      Will dequeue a work unit from queue if necessary (e.g. when the\n",
      "     |      Reader needs to start reading from a new file since it has\n",
      "     |      finished with the previous file).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        queue: A Queue or a mutable string Tensor representing a handle\n",
      "     |          to a Queue, with string work items.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A tuple of Tensors (key, value).\n",
      "     |        key: A string scalar Tensor.\n",
      "     |        value: A string scalar Tensor.\n",
      "     |  \n",
      "     |  read_up_to(self, queue, num_records, name=None)\n",
      "     |      Returns up to num_records (key, value) pairs produced by a reader.\n",
      "     |      \n",
      "     |      Will dequeue a work unit from queue if necessary (e.g., when the\n",
      "     |      Reader needs to start reading from a new file since it has\n",
      "     |      finished with the previous file).\n",
      "     |      It may return less than num_records even before the last batch.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        queue: A Queue or a mutable string Tensor representing a handle\n",
      "     |          to a Queue, with string work items.\n",
      "     |        num_records: Number of records to read.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A tuple of Tensors (keys, values).\n",
      "     |        keys: A 1-D string Tensor.\n",
      "     |        values: A 1-D string Tensor.\n",
      "     |  \n",
      "     |  reset(self, name=None)\n",
      "     |      Restore a reader to its initial clean state.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The created Operation.\n",
      "     |  \n",
      "     |  restore_state(self, state, name=None)\n",
      "     |      Restore a reader to a previously saved state.\n",
      "     |      \n",
      "     |      Not all Readers support being restored, so this can produce an\n",
      "     |      Unimplemented error.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        state: A string Tensor.\n",
      "     |          Result of a SerializeState of a Reader with matching type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The created Operation.\n",
      "     |  \n",
      "     |  serialize_state(self, name=None)\n",
      "     |      Produce a string tensor that encodes the state of a reader.\n",
      "     |      \n",
      "     |      Not all Readers support being serialized, so this can produce an\n",
      "     |      Unimplemented error.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A string Tensor.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from ReaderBase:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  reader_ref\n",
      "     |      Op that implements the reader.\n",
      "     |  \n",
      "     |  supports_serialize\n",
      "     |      Whether the Reader implementation can serialize its state.\n",
      "    \n",
      "    class TypeSpec(builtins.object)\n",
      "     |  Specifies a TensorFlow value type.\n",
      "     |  \n",
      "     |  A `tf.TypeSpec` provides metadata describing an object accepted or returned\n",
      "     |  by TensorFlow APIs.  Concrete subclasses, such as `tf.TensorSpec` and\n",
      "     |  `tf.RaggedTensorSpec`, are used to describe different value types.\n",
      "     |  \n",
      "     |  For example, `tf.function`'s `input_signature` argument accepts a list\n",
      "     |  (or nested structure) of `TypeSpec`s.\n",
      "     |  \n",
      "     |  Creating new subclasses of TypeSpec (outside of TensorFlow core) is not\n",
      "     |  currently supported.  In particular, we may make breaking changes to the\n",
      "     |  private methods and properties defined by this base class.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __ne__(self, other)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __reduce__(self)\n",
      "     |      helper for pickle\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  is_compatible_with(self, spec_or_value)\n",
      "     |      Returns true if `spec_or_value` is compatible with this TypeSpec.\n",
      "     |  \n",
      "     |  most_specific_compatible_type(self, other)\n",
      "     |      Returns the most specific TypeSpec compatible with `self` and `other`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        other: A `TypeSpec`.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If there is no TypeSpec that is compatible with both `self`\n",
      "     |          and `other`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  value_type\n",
      "     |      The Python type for values that are compatible with this TypeSpec.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset({'_component_specs', '_from_components...\n",
      "    \n",
      "    class UnconnectedGradients(enum.Enum)\n",
      "     |  Controls how gradient computation behaves when y does not depend on x.\n",
      "     |  \n",
      "     |  The gradient of y with respect to x can be zero in two different ways: there\n",
      "     |  could be no differentiable path in the graph connecting x to y (and so we can\n",
      "     |  statically prove that the gradient is zero) or it could be that runtime values\n",
      "     |  of tensors in a particular execution lead to a gradient of zero (say, if a\n",
      "     |  relu unit happens to not be activated). To allow you to distinguish between\n",
      "     |  these two cases you can choose what value gets returned for the gradient when\n",
      "     |  there is no path in the graph from x to y:\n",
      "     |  \n",
      "     |  * `NONE`: Indicates that [None] will be returned if there is no path from x\n",
      "     |    to y\n",
      "     |  * `ZERO`: Indicates that a zero tensor will be returned in the shape of x.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      UnconnectedGradients\n",
      "     |      enum.Enum\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  NONE = <UnconnectedGradients.NONE: 'none'>\n",
      "     |  \n",
      "     |  ZERO = <UnconnectedGradients.ZERO: 'zero'>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from enum.Enum:\n",
      "     |  \n",
      "     |  name\n",
      "     |      The name of the Enum member.\n",
      "     |  \n",
      "     |  value\n",
      "     |      The value of the Enum member.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from enum.EnumMeta:\n",
      "     |  \n",
      "     |  __members__\n",
      "     |      Returns a mapping of member name->value.\n",
      "     |      \n",
      "     |      This mapping lists all enum members, including aliases. Note that this\n",
      "     |      is a read-only view of the internal mapping.\n",
      "    \n",
      "    class VarLenFeature(VarLenFeature)\n",
      "     |  Configuration for parsing a variable-length input feature.\n",
      "     |  \n",
      "     |  Fields:\n",
      "     |    dtype: Data type of input.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      VarLenFeature\n",
      "     |      VarLenFeature\n",
      "     |      builtins.tuple\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  _tf_api_names = ('io.VarLenFeature',)\n",
      "     |  \n",
      "     |  _tf_api_names_v1 = ['VarLenFeature', 'io.VarLenFeature']\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from VarLenFeature:\n",
      "     |  \n",
      "     |  __getnewargs__(self)\n",
      "     |      Return self as a plain tuple.  Used by copy and pickle.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return a nicely formatted representation string\n",
      "     |  \n",
      "     |  _asdict(self)\n",
      "     |      Return a new OrderedDict which maps field names to their values.\n",
      "     |  \n",
      "     |  _replace(_self, **kwds)\n",
      "     |      Return a new VarLenFeature object replacing specified fields with new values\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from VarLenFeature:\n",
      "     |  \n",
      "     |  _make(iterable, new=<built-in method __new__ of type object at 0x9d43a0>, len=<built-in function len>) from builtins.type\n",
      "     |      Make a new VarLenFeature object from a sequence or iterable\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from VarLenFeature:\n",
      "     |  \n",
      "     |  __new__(_cls, dtype)\n",
      "     |      Create new instance of VarLenFeature(dtype,)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from VarLenFeature:\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      Alias for field number 0\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from VarLenFeature:\n",
      "     |  \n",
      "     |  _fields = ('dtype',)\n",
      "     |  \n",
      "     |  _source = \"from builtins import property as _property, tupl..._itemget...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.tuple:\n",
      "     |  \n",
      "     |  __add__(self, value, /)\n",
      "     |      Return self+value.\n",
      "     |  \n",
      "     |  __contains__(self, key, /)\n",
      "     |      Return key in self.\n",
      "     |  \n",
      "     |  __eq__(self, value, /)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __ge__(self, value, /)\n",
      "     |      Return self>=value.\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __getitem__(self, key, /)\n",
      "     |      Return self[key].\n",
      "     |  \n",
      "     |  __gt__(self, value, /)\n",
      "     |      Return self>value.\n",
      "     |  \n",
      "     |  __hash__(self, /)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __iter__(self, /)\n",
      "     |      Implement iter(self).\n",
      "     |  \n",
      "     |  __le__(self, value, /)\n",
      "     |      Return self<=value.\n",
      "     |  \n",
      "     |  __len__(self, /)\n",
      "     |      Return len(self).\n",
      "     |  \n",
      "     |  __lt__(self, value, /)\n",
      "     |      Return self<value.\n",
      "     |  \n",
      "     |  __mul__(self, value, /)\n",
      "     |      Return self*value.\n",
      "     |  \n",
      "     |  __ne__(self, value, /)\n",
      "     |      Return self!=value.\n",
      "     |  \n",
      "     |  __rmul__(self, value, /)\n",
      "     |      Return value*self.\n",
      "     |  \n",
      "     |  count(...)\n",
      "     |      T.count(value) -> integer -- return number of occurrences of value\n",
      "     |  \n",
      "     |  index(...)\n",
      "     |      T.index(value, [start, [stop]]) -> integer -- return first index of value.\n",
      "     |      Raises ValueError if the value is not present.\n",
      "    \n",
      "    Variable = class VariableV1(Variable)\n",
      "     |  See the [Variables Guide](https://tensorflow.org/guide/variables).\n",
      "     |  \n",
      "     |  A variable maintains state in the graph across calls to `run()`. You add a\n",
      "     |  variable to the graph by constructing an instance of the class `Variable`.\n",
      "     |  \n",
      "     |  The `Variable()` constructor requires an initial value for the variable,\n",
      "     |  which can be a `Tensor` of any type and shape. The initial value defines the\n",
      "     |  type and shape of the variable. After construction, the type and shape of\n",
      "     |  the variable are fixed. The value can be changed using one of the assign\n",
      "     |  methods.\n",
      "     |  \n",
      "     |  If you want to change the shape of a variable later you have to use an\n",
      "     |  `assign` Op with `validate_shape=False`.\n",
      "     |  \n",
      "     |  Just like any `Tensor`, variables created with `Variable()` can be used as\n",
      "     |  inputs for other Ops in the graph. Additionally, all the operators\n",
      "     |  overloaded for the `Tensor` class are carried over to variables, so you can\n",
      "     |  also add nodes to the graph by just doing arithmetic on variables.\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  import tensorflow as tf\n",
      "     |  \n",
      "     |  # Create a variable.\n",
      "     |  w = tf.Variable(<initial-value>, name=<optional-name>)\n",
      "     |  \n",
      "     |  # Use the variable in the graph like any Tensor.\n",
      "     |  y = tf.matmul(w, ...another variable or tensor...)\n",
      "     |  \n",
      "     |  # The overloaded operators are available too.\n",
      "     |  z = tf.sigmoid(w + y)\n",
      "     |  \n",
      "     |  # Assign a new value to the variable with `assign()` or a related method.\n",
      "     |  w.assign(w + 1.0)\n",
      "     |  w.assign_add(1.0)\n",
      "     |  ```\n",
      "     |  \n",
      "     |  When you launch the graph, variables have to be explicitly initialized before\n",
      "     |  you can run Ops that use their value. You can initialize a variable by\n",
      "     |  running its *initializer op*, restoring the variable from a save file, or\n",
      "     |  simply running an `assign` Op that assigns a value to the variable. In fact,\n",
      "     |  the variable *initializer op* is just an `assign` Op that assigns the\n",
      "     |  variable's initial value to the variable itself.\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  # Launch the graph in a session.\n",
      "     |  with tf.compat.v1.Session() as sess:\n",
      "     |      # Run the variable initializer.\n",
      "     |      sess.run(w.initializer)\n",
      "     |      # ...you now can run ops that use the value of 'w'...\n",
      "     |  ```\n",
      "     |  \n",
      "     |  The most common initialization pattern is to use the convenience function\n",
      "     |  `global_variables_initializer()` to add an Op to the graph that initializes\n",
      "     |  all the variables. You then run that Op after launching the graph.\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  # Add an Op to initialize global variables.\n",
      "     |  init_op = tf.compat.v1.global_variables_initializer()\n",
      "     |  \n",
      "     |  # Launch the graph in a session.\n",
      "     |  with tf.compat.v1.Session() as sess:\n",
      "     |      # Run the Op that initializes global variables.\n",
      "     |      sess.run(init_op)\n",
      "     |      # ...you can now run any Op that uses variable values...\n",
      "     |  ```\n",
      "     |  \n",
      "     |  If you need to create a variable with an initial value dependent on another\n",
      "     |  variable, use the other variable's `initialized_value()`. This ensures that\n",
      "     |  variables are initialized in the right order.\n",
      "     |  \n",
      "     |  All variables are automatically collected in the graph where they are\n",
      "     |  created. By default, the constructor adds the new variable to the graph\n",
      "     |  collection `GraphKeys.GLOBAL_VARIABLES`. The convenience function\n",
      "     |  `global_variables()` returns the contents of that collection.\n",
      "     |  \n",
      "     |  When building a machine learning model it is often convenient to distinguish\n",
      "     |  between variables holding the trainable model parameters and other variables\n",
      "     |  such as a `global step` variable used to count training steps. To make this\n",
      "     |  easier, the variable constructor supports a `trainable=<bool>` parameter. If\n",
      "     |  `True`, the new variable is also added to the graph collection\n",
      "     |  `GraphKeys.TRAINABLE_VARIABLES`. The convenience function\n",
      "     |  `trainable_variables()` returns the contents of this collection. The\n",
      "     |  various `Optimizer` classes use this collection as the default list of\n",
      "     |  variables to optimize.\n",
      "     |  \n",
      "     |  WARNING: tf.Variable objects by default have a non-intuitive memory model. A\n",
      "     |  Variable is represented internally as a mutable Tensor which can\n",
      "     |  non-deterministically alias other Tensors in a graph. The set of operations\n",
      "     |  which consume a Variable and can lead to aliasing is undetermined and can\n",
      "     |  change across TensorFlow versions. Avoid writing code which relies on the\n",
      "     |  value of a Variable either changing or not changing as other operations\n",
      "     |  happen. For example, using Variable objects or simple functions thereof as\n",
      "     |  predicates in a `tf.cond` is dangerous and error-prone:\n",
      "     |  \n",
      "     |  ```\n",
      "     |  v = tf.Variable(True)\n",
      "     |  tf.cond(v, lambda: v.assign(False), my_false_fn)  # Note: this is broken.\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Here, adding `use_resource=True` when constructing the variable will\n",
      "     |  fix any nondeterminism issues:\n",
      "     |  ```\n",
      "     |  v = tf.Variable(True, use_resource=True)\n",
      "     |  tf.cond(v, lambda: v.assign(False), my_false_fn)\n",
      "     |  ```\n",
      "     |  \n",
      "     |  To use the replacement for variables which does\n",
      "     |  not have these issues:\n",
      "     |  \n",
      "     |  * Add `use_resource=True` when constructing `tf.Variable`;\n",
      "     |  * Call `tf.compat.v1.get_variable_scope().set_use_resource(True)` inside a\n",
      "     |    `tf.compat.v1.variable_scope` before the `tf.compat.v1.get_variable()` call.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      VariableV1\n",
      "     |      Variable\n",
      "     |      tensorflow.python.training.tracking.base.Trackable\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, initial_value=None, trainable=None, collections=None, validate_shape=True, caching_device=None, name=None, variable_def=None, dtype=None, expected_shape=None, import_scope=None, constraint=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregation.NONE: 0>, shape=None)\n",
      "     |      Creates a new variable with value `initial_value`.\n",
      "     |      \n",
      "     |      The new variable is added to the graph collections listed in `collections`,\n",
      "     |      which defaults to `[GraphKeys.GLOBAL_VARIABLES]`.\n",
      "     |      \n",
      "     |      If `trainable` is `True` the variable is also added to the graph collection\n",
      "     |      `GraphKeys.TRAINABLE_VARIABLES`.\n",
      "     |      \n",
      "     |      This constructor creates both a `variable` Op and an `assign` Op to set the\n",
      "     |      variable to its initial value.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        initial_value: A `Tensor`, or Python object convertible to a `Tensor`,\n",
      "     |          which is the initial value for the Variable. The initial value must have\n",
      "     |          a shape specified unless `validate_shape` is set to False. Can also be a\n",
      "     |          callable with no argument that returns the initial value when called. In\n",
      "     |          that case, `dtype` must be specified. (Note that initializer functions\n",
      "     |          from init_ops.py must first be bound to a shape before being used here.)\n",
      "     |        trainable: If `True`, also adds the variable to the graph collection\n",
      "     |          `GraphKeys.TRAINABLE_VARIABLES`. This collection is used as the default\n",
      "     |          list of variables to use by the `Optimizer` classes. Defaults to `True`,\n",
      "     |          unless `synchronization` is set to `ON_READ`, in which case it defaults\n",
      "     |          to `False`.\n",
      "     |        collections: List of graph collections keys. The new variable is added to\n",
      "     |          these collections. Defaults to `[GraphKeys.GLOBAL_VARIABLES]`.\n",
      "     |        validate_shape: If `False`, allows the variable to be initialized with a\n",
      "     |          value of unknown shape. If `True`, the default, the shape of\n",
      "     |          `initial_value` must be known.\n",
      "     |        caching_device: Optional device string describing where the Variable\n",
      "     |          should be cached for reading.  Defaults to the Variable's device. If not\n",
      "     |          `None`, caches on another device.  Typical use is to cache on the device\n",
      "     |          where the Ops using the Variable reside, to deduplicate copying through\n",
      "     |          `Switch` and other conditional statements.\n",
      "     |        name: Optional name for the variable. Defaults to `'Variable'` and gets\n",
      "     |          uniquified automatically.\n",
      "     |        variable_def: `VariableDef` protocol buffer. If not `None`, recreates the\n",
      "     |          Variable object with its contents, referencing the variable's nodes in\n",
      "     |          the graph, which must already exist. The graph is not changed.\n",
      "     |          `variable_def` and the other arguments are mutually exclusive.\n",
      "     |        dtype: If set, initial_value will be converted to the given type. If\n",
      "     |          `None`, either the datatype will be kept (if `initial_value` is a\n",
      "     |          Tensor), or `convert_to_tensor` will decide.\n",
      "     |        expected_shape: A TensorShape. If set, initial_value is expected to have\n",
      "     |          this shape.\n",
      "     |        import_scope: Optional `string`. Name scope to add to the `Variable.` Only\n",
      "     |          used when initializing from protocol buffer.\n",
      "     |        constraint: An optional projection function to be applied to the variable\n",
      "     |          after being updated by an `Optimizer` (e.g. used to implement norm\n",
      "     |          constraints or value constraints for layer weights). The function must\n",
      "     |          take as input the unprojected Tensor representing the value of the\n",
      "     |          variable and return the Tensor for the projected value (which must have\n",
      "     |          the same shape). Constraints are not safe to use when doing asynchronous\n",
      "     |          distributed training.\n",
      "     |        use_resource: whether to use resource variables.\n",
      "     |        synchronization: Indicates when a distributed a variable will be\n",
      "     |          aggregated. Accepted values are constants defined in the class\n",
      "     |          `tf.VariableSynchronization`. By default the synchronization is set to\n",
      "     |          `AUTO` and the current `DistributionStrategy` chooses when to\n",
      "     |          synchronize.\n",
      "     |        aggregation: Indicates how a distributed variable will be aggregated.\n",
      "     |          Accepted values are constants defined in the class\n",
      "     |          `tf.VariableAggregation`.\n",
      "     |        shape: (optional) The shape of this variable. If None, the shape of\n",
      "     |          `initial_value` will be used. When setting this argument to\n",
      "     |          `tf.TensorShape(None)` (representing an unspecified shape), the variable\n",
      "     |          can be assigned with values of different shapes.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If both `variable_def` and initial_value are specified.\n",
      "     |        ValueError: If the initial value is not specified, or does not have a\n",
      "     |          shape and `validate_shape` is `True`.\n",
      "     |        RuntimeError: If eager execution is enabled.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  SaveSliceInfo = <class 'tensorflow.python.ops.variables.Variable.SaveS...\n",
      "     |      Information on how to save this Variable as a slice.\n",
      "     |      \n",
      "     |      Provides internal support for saving variables as slices of a larger\n",
      "     |      variable.  This API is not public and is subject to change.\n",
      "     |      \n",
      "     |      Available properties:\n",
      "     |      \n",
      "     |      * full_name\n",
      "     |      * full_shape\n",
      "     |      * var_offset\n",
      "     |      * var_shape\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from Variable:\n",
      "     |  \n",
      "     |  __abs__ = abs(x, name=None)\n",
      "     |      Computes the absolute value of a tensor.\n",
      "     |      \n",
      "     |      Given a tensor of integer or floating-point values, this operation returns a\n",
      "     |      tensor of the same type, where each element contains the absolute value of the\n",
      "     |      corresponding element in the input.\n",
      "     |      \n",
      "     |      Given a tensor `x` of complex numbers, this operation returns a tensor of type\n",
      "     |      `float32` or `float64` that is the absolute value of each element in `x`. All\n",
      "     |      elements in `x` must be complex numbers of the form \\\\(a + bj\\\\). The\n",
      "     |      absolute value is computed as \\\\( \\sqrt{a^2 + b^2}\\\\).  For example:\n",
      "     |      ```python\n",
      "     |      x = tf.constant([[-2.25 + 4.75j], [-3.25 + 5.75j]])\n",
      "     |      tf.abs(x)  # [5.25594902, 6.60492229]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor` or `SparseTensor` of type `float16`, `float32`, `float64`,\n",
      "     |          `int32`, `int64`, `complex64` or `complex128`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` or `SparseTensor` the same size, type, and sparsity as `x` with\n",
      "     |          absolute values.\n",
      "     |        Note, for `complex64` or `complex128` input, the returned `Tensor` will be\n",
      "     |          of type `float32` or `float64`, respectively.\n",
      "     |  \n",
      "     |  __add__ = binary_op_wrapper(x, y)\n",
      "     |      Dispatches to add for strings and add_v2 for all other types.\n",
      "     |  \n",
      "     |  __and__ = binary_op_wrapper(x, y)\n",
      "     |      Returns the truth value of x AND y element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `math.logical_and` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor` of type `bool`.\n",
      "     |        y: A `Tensor` of type `bool`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __div__ = binary_op_wrapper(x, y)\n",
      "     |      Divide two values using Python 2 semantics.\n",
      "     |      \n",
      "     |      Used for Tensor.__div__.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: `Tensor` numerator of real numeric type.\n",
      "     |        y: `Tensor` denominator of real numeric type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        `x / y` returns the quotient of x and y.\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Compares two variables element-wise for equality.\n",
      "     |  \n",
      "     |  __floordiv__ = binary_op_wrapper(x, y)\n",
      "     |      Divides `x / y` elementwise, rounding toward the most negative integer.\n",
      "     |      \n",
      "     |      The same as `tf.compat.v1.div(x,y)` for integers, but uses\n",
      "     |      `tf.floor(tf.compat.v1.div(x,y))` for\n",
      "     |      floating point arguments so that the result is always an integer (though\n",
      "     |      possibly an integer represented as floating point).  This op is generated by\n",
      "     |      `x // y` floor division in Python 3 and in Python 2.7 with\n",
      "     |      `from __future__ import division`.\n",
      "     |      \n",
      "     |      `x` and `y` must have the same type, and the result will have the same type\n",
      "     |      as well.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: `Tensor` numerator of real numeric type.\n",
      "     |        y: `Tensor` denominator of real numeric type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        `x / y` rounded down.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If the inputs are complex.\n",
      "     |  \n",
      "     |  __ge__ = greater_equal(x, y, name=None)\n",
      "     |      Returns the truth value of (x >= y) element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `math.greater_equal` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __getitem__ = _SliceHelperVar(var, slice_spec)\n",
      "     |      Creates a slice helper object given a variable.\n",
      "     |      \n",
      "     |      This allows creating a sub-tensor from part of the current contents\n",
      "     |      of a variable. See `tf.Tensor.__getitem__` for detailed examples\n",
      "     |      of slicing.\n",
      "     |      \n",
      "     |      This function in addition also allows assignment to a sliced range.\n",
      "     |      This is similar to `__setitem__` functionality in Python. However,\n",
      "     |      the syntax is different so that the user can capture the assignment\n",
      "     |      operation for grouping or passing to `sess.run()`.\n",
      "     |      For example,\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      import tensorflow as tf\n",
      "     |      A = tf.Variable([[1,2,3], [4,5,6], [7,8,9]], dtype=tf.float32)\n",
      "     |      with tf.compat.v1.Session() as sess:\n",
      "     |        sess.run(tf.compat.v1.global_variables_initializer())\n",
      "     |        print(sess.run(A[:2, :2]))  # => [[1,2], [4,5]]\n",
      "     |      \n",
      "     |        op = A[:2,:2].assign(22. * tf.ones((2, 2)))\n",
      "     |        print(sess.run(op))  # => [[22, 22, 3], [22, 22, 6], [7,8,9]]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Note that assignments currently do not support NumPy broadcasting\n",
      "     |      semantics.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        var: An `ops.Variable` object.\n",
      "     |        slice_spec: The arguments to `Tensor.__getitem__`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The appropriate slice of \"tensor\", based on \"slice_spec\".\n",
      "     |        As an operator. The operator also has a `assign()` method\n",
      "     |        that can be used to generate an assignment operator.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If a slice range is negative size.\n",
      "     |        TypeError: TypeError: If the slice indices aren't int, slice,\n",
      "     |          ellipsis, tf.newaxis or int32/int64 tensors.\n",
      "     |  \n",
      "     |  __gt__ = greater(x, y, name=None)\n",
      "     |      Returns the truth value of (x > y) element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `math.greater` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __hash__(self)\n",
      "     |      Return hash(self).\n",
      "     |  \n",
      "     |  __invert__ = logical_not(x, name=None)\n",
      "     |      Returns the truth value of NOT x element-wise.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor` of type `bool`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |      Dummy method to prevent iteration.\n",
      "     |      \n",
      "     |      Do not call.\n",
      "     |      \n",
      "     |      NOTE(mrry): If we register __getitem__ as an overloaded operator,\n",
      "     |      Python will valiantly attempt to iterate over the variable's Tensor from 0\n",
      "     |      to infinity.  Declaring this method prevents this unintended behavior.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: when invoked.\n",
      "     |  \n",
      "     |  __le__ = less_equal(x, y, name=None)\n",
      "     |      Returns the truth value of (x <= y) element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `math.less_equal` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __lt__ = less(x, y, name=None)\n",
      "     |      Returns the truth value of (x < y) element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `math.less` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __matmul__ = binary_op_wrapper(x, y)\n",
      "     |      Multiplies matrix `a` by matrix `b`, producing `a` * `b`.\n",
      "     |      \n",
      "     |      The inputs must, following any transpositions, be tensors of rank >= 2\n",
      "     |      where the inner 2 dimensions specify valid matrix multiplication arguments,\n",
      "     |      and any further outer dimensions match.\n",
      "     |      \n",
      "     |      Both matrices must be of the same type. The supported types are:\n",
      "     |      `float16`, `float32`, `float64`, `int32`, `complex64`, `complex128`.\n",
      "     |      \n",
      "     |      Either matrix can be transposed or adjointed (conjugated and transposed) on\n",
      "     |      the fly by setting one of the corresponding flag to `True`. These are `False`\n",
      "     |      by default.\n",
      "     |      \n",
      "     |      If one or both of the matrices contain a lot of zeros, a more efficient\n",
      "     |      multiplication algorithm can be used by setting the corresponding\n",
      "     |      `a_is_sparse` or `b_is_sparse` flag to `True`. These are `False` by default.\n",
      "     |      This optimization is only available for plain matrices (rank-2 tensors) with\n",
      "     |      datatypes `bfloat16` or `float32`.\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      # 2-D tensor `a`\n",
      "     |      # [[1, 2, 3],\n",
      "     |      #  [4, 5, 6]]\n",
      "     |      a = tf.constant([1, 2, 3, 4, 5, 6], shape=[2, 3])\n",
      "     |      \n",
      "     |      # 2-D tensor `b`\n",
      "     |      # [[ 7,  8],\n",
      "     |      #  [ 9, 10],\n",
      "     |      #  [11, 12]]\n",
      "     |      b = tf.constant([7, 8, 9, 10, 11, 12], shape=[3, 2])\n",
      "     |      \n",
      "     |      # `a` * `b`\n",
      "     |      # [[ 58,  64],\n",
      "     |      #  [139, 154]]\n",
      "     |      c = tf.matmul(a, b)\n",
      "     |      \n",
      "     |      \n",
      "     |      # 3-D tensor `a`\n",
      "     |      # [[[ 1,  2,  3],\n",
      "     |      #   [ 4,  5,  6]],\n",
      "     |      #  [[ 7,  8,  9],\n",
      "     |      #   [10, 11, 12]]]\n",
      "     |      a = tf.constant(np.arange(1, 13, dtype=np.int32),\n",
      "     |                      shape=[2, 2, 3])\n",
      "     |      \n",
      "     |      # 3-D tensor `b`\n",
      "     |      # [[[13, 14],\n",
      "     |      #   [15, 16],\n",
      "     |      #   [17, 18]],\n",
      "     |      #  [[19, 20],\n",
      "     |      #   [21, 22],\n",
      "     |      #   [23, 24]]]\n",
      "     |      b = tf.constant(np.arange(13, 25, dtype=np.int32),\n",
      "     |                      shape=[2, 3, 2])\n",
      "     |      \n",
      "     |      # `a` * `b`\n",
      "     |      # [[[ 94, 100],\n",
      "     |      #   [229, 244]],\n",
      "     |      #  [[508, 532],\n",
      "     |      #   [697, 730]]]\n",
      "     |      c = tf.matmul(a, b)\n",
      "     |      \n",
      "     |      # Since python >= 3.5 the @ operator is supported (see PEP 465).\n",
      "     |      # In TensorFlow, it simply calls the `tf.matmul()` function, so the\n",
      "     |      # following lines are equivalent:\n",
      "     |      d = a @ b @ [[10.], [11.]]\n",
      "     |      d = tf.matmul(tf.matmul(a, b), [[10.], [11.]])\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        a: `Tensor` of type `float16`, `float32`, `float64`, `int32`, `complex64`,\n",
      "     |          `complex128` and rank > 1.\n",
      "     |        b: `Tensor` with same type and rank as `a`.\n",
      "     |        transpose_a: If `True`, `a` is transposed before multiplication.\n",
      "     |        transpose_b: If `True`, `b` is transposed before multiplication.\n",
      "     |        adjoint_a: If `True`, `a` is conjugated and transposed before\n",
      "     |          multiplication.\n",
      "     |        adjoint_b: If `True`, `b` is conjugated and transposed before\n",
      "     |          multiplication.\n",
      "     |        a_is_sparse: If `True`, `a` is treated as a sparse matrix.\n",
      "     |        b_is_sparse: If `True`, `b` is treated as a sparse matrix.\n",
      "     |        name: Name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of the same type as `a` and `b` where each inner-most matrix is\n",
      "     |        the product of the corresponding matrices in `a` and `b`, e.g. if all\n",
      "     |        transpose or adjoint attributes are `False`:\n",
      "     |      \n",
      "     |        `output`[..., i, j] = sum_k (`a`[..., i, k] * `b`[..., k, j]),\n",
      "     |        for all indices i, j.\n",
      "     |      \n",
      "     |        Note: This is matrix product, not element-wise product.\n",
      "     |      \n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If transpose_a and adjoint_a, or transpose_b and adjoint_b\n",
      "     |          are both set to True.\n",
      "     |  \n",
      "     |  __mod__ = binary_op_wrapper(x, y)\n",
      "     |      Returns element-wise remainder of division. When `x < 0` xor `y < 0` is\n",
      "     |      \n",
      "     |      true, this follows Python semantics in that the result here is consistent\n",
      "     |      with a flooring divide. E.g. `floor(x / y) * y + mod(x, y) = x`.\n",
      "     |      \n",
      "     |      *NOTE*: `math.floormod` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `int32`, `int64`, `bfloat16`, `half`, `float32`, `float64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `x`.\n",
      "     |  \n",
      "     |  __mul__ = binary_op_wrapper(x, y)\n",
      "     |      Dispatches cwise mul for \"Dense*Dense\" and \"Dense*Sparse\".\n",
      "     |  \n",
      "     |  __ne__(self, other)\n",
      "     |      Compares two variables element-wise for equality.\n",
      "     |  \n",
      "     |  __neg__ = neg(x, name=None)\n",
      "     |      Computes numerical negative value element-wise.\n",
      "     |      \n",
      "     |      I.e., \\\\(y = -x\\\\).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int32`, `int64`, `complex64`, `complex128`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `x`.\n",
      "     |  \n",
      "     |  __or__ = binary_op_wrapper(x, y)\n",
      "     |      Returns the truth value of x OR y element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `math.logical_or` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor` of type `bool`.\n",
      "     |        y: A `Tensor` of type `bool`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __pow__ = binary_op_wrapper(x, y)\n",
      "     |      Computes the power of one value to another.\n",
      "     |      \n",
      "     |      Given a tensor `x` and a tensor `y`, this operation computes \\\\(x^y\\\\) for\n",
      "     |      corresponding elements in `x` and `y`. For example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      x = tf.constant([[2, 2], [3, 3]])\n",
      "     |      y = tf.constant([[8, 16], [2, 3]])\n",
      "     |      tf.pow(x, y)  # [[256, 65536], [9, 27]]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor` of type `float16`, `float32`, `float64`, `int32`, `int64`,\n",
      "     |          `complex64`, or `complex128`.\n",
      "     |        y: A `Tensor` of type `float16`, `float32`, `float64`, `int32`, `int64`,\n",
      "     |          `complex64`, or `complex128`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`.\n",
      "     |  \n",
      "     |  __radd__ = r_binary_op_wrapper(y, x)\n",
      "     |      Dispatches to add for strings and add_v2 for all other types.\n",
      "     |  \n",
      "     |  __rand__ = r_binary_op_wrapper(y, x)\n",
      "     |      Returns the truth value of x AND y element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `math.logical_and` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor` of type `bool`.\n",
      "     |        y: A `Tensor` of type `bool`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __rdiv__ = r_binary_op_wrapper(y, x)\n",
      "     |      Divide two values using Python 2 semantics.\n",
      "     |      \n",
      "     |      Used for Tensor.__div__.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: `Tensor` numerator of real numeric type.\n",
      "     |        y: `Tensor` denominator of real numeric type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        `x / y` returns the quotient of x and y.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __rfloordiv__ = r_binary_op_wrapper(y, x)\n",
      "     |      Divides `x / y` elementwise, rounding toward the most negative integer.\n",
      "     |      \n",
      "     |      The same as `tf.compat.v1.div(x,y)` for integers, but uses\n",
      "     |      `tf.floor(tf.compat.v1.div(x,y))` for\n",
      "     |      floating point arguments so that the result is always an integer (though\n",
      "     |      possibly an integer represented as floating point).  This op is generated by\n",
      "     |      `x // y` floor division in Python 3 and in Python 2.7 with\n",
      "     |      `from __future__ import division`.\n",
      "     |      \n",
      "     |      `x` and `y` must have the same type, and the result will have the same type\n",
      "     |      as well.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: `Tensor` numerator of real numeric type.\n",
      "     |        y: `Tensor` denominator of real numeric type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        `x / y` rounded down.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: If the inputs are complex.\n",
      "     |  \n",
      "     |  __rmatmul__ = r_binary_op_wrapper(y, x)\n",
      "     |      Multiplies matrix `a` by matrix `b`, producing `a` * `b`.\n",
      "     |      \n",
      "     |      The inputs must, following any transpositions, be tensors of rank >= 2\n",
      "     |      where the inner 2 dimensions specify valid matrix multiplication arguments,\n",
      "     |      and any further outer dimensions match.\n",
      "     |      \n",
      "     |      Both matrices must be of the same type. The supported types are:\n",
      "     |      `float16`, `float32`, `float64`, `int32`, `complex64`, `complex128`.\n",
      "     |      \n",
      "     |      Either matrix can be transposed or adjointed (conjugated and transposed) on\n",
      "     |      the fly by setting one of the corresponding flag to `True`. These are `False`\n",
      "     |      by default.\n",
      "     |      \n",
      "     |      If one or both of the matrices contain a lot of zeros, a more efficient\n",
      "     |      multiplication algorithm can be used by setting the corresponding\n",
      "     |      `a_is_sparse` or `b_is_sparse` flag to `True`. These are `False` by default.\n",
      "     |      This optimization is only available for plain matrices (rank-2 tensors) with\n",
      "     |      datatypes `bfloat16` or `float32`.\n",
      "     |      \n",
      "     |      For example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      # 2-D tensor `a`\n",
      "     |      # [[1, 2, 3],\n",
      "     |      #  [4, 5, 6]]\n",
      "     |      a = tf.constant([1, 2, 3, 4, 5, 6], shape=[2, 3])\n",
      "     |      \n",
      "     |      # 2-D tensor `b`\n",
      "     |      # [[ 7,  8],\n",
      "     |      #  [ 9, 10],\n",
      "     |      #  [11, 12]]\n",
      "     |      b = tf.constant([7, 8, 9, 10, 11, 12], shape=[3, 2])\n",
      "     |      \n",
      "     |      # `a` * `b`\n",
      "     |      # [[ 58,  64],\n",
      "     |      #  [139, 154]]\n",
      "     |      c = tf.matmul(a, b)\n",
      "     |      \n",
      "     |      \n",
      "     |      # 3-D tensor `a`\n",
      "     |      # [[[ 1,  2,  3],\n",
      "     |      #   [ 4,  5,  6]],\n",
      "     |      #  [[ 7,  8,  9],\n",
      "     |      #   [10, 11, 12]]]\n",
      "     |      a = tf.constant(np.arange(1, 13, dtype=np.int32),\n",
      "     |                      shape=[2, 2, 3])\n",
      "     |      \n",
      "     |      # 3-D tensor `b`\n",
      "     |      # [[[13, 14],\n",
      "     |      #   [15, 16],\n",
      "     |      #   [17, 18]],\n",
      "     |      #  [[19, 20],\n",
      "     |      #   [21, 22],\n",
      "     |      #   [23, 24]]]\n",
      "     |      b = tf.constant(np.arange(13, 25, dtype=np.int32),\n",
      "     |                      shape=[2, 3, 2])\n",
      "     |      \n",
      "     |      # `a` * `b`\n",
      "     |      # [[[ 94, 100],\n",
      "     |      #   [229, 244]],\n",
      "     |      #  [[508, 532],\n",
      "     |      #   [697, 730]]]\n",
      "     |      c = tf.matmul(a, b)\n",
      "     |      \n",
      "     |      # Since python >= 3.5 the @ operator is supported (see PEP 465).\n",
      "     |      # In TensorFlow, it simply calls the `tf.matmul()` function, so the\n",
      "     |      # following lines are equivalent:\n",
      "     |      d = a @ b @ [[10.], [11.]]\n",
      "     |      d = tf.matmul(tf.matmul(a, b), [[10.], [11.]])\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        a: `Tensor` of type `float16`, `float32`, `float64`, `int32`, `complex64`,\n",
      "     |          `complex128` and rank > 1.\n",
      "     |        b: `Tensor` with same type and rank as `a`.\n",
      "     |        transpose_a: If `True`, `a` is transposed before multiplication.\n",
      "     |        transpose_b: If `True`, `b` is transposed before multiplication.\n",
      "     |        adjoint_a: If `True`, `a` is conjugated and transposed before\n",
      "     |          multiplication.\n",
      "     |        adjoint_b: If `True`, `b` is conjugated and transposed before\n",
      "     |          multiplication.\n",
      "     |        a_is_sparse: If `True`, `a` is treated as a sparse matrix.\n",
      "     |        b_is_sparse: If `True`, `b` is treated as a sparse matrix.\n",
      "     |        name: Name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of the same type as `a` and `b` where each inner-most matrix is\n",
      "     |        the product of the corresponding matrices in `a` and `b`, e.g. if all\n",
      "     |        transpose or adjoint attributes are `False`:\n",
      "     |      \n",
      "     |        `output`[..., i, j] = sum_k (`a`[..., i, k] * `b`[..., k, j]),\n",
      "     |        for all indices i, j.\n",
      "     |      \n",
      "     |        Note: This is matrix product, not element-wise product.\n",
      "     |      \n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: If transpose_a and adjoint_a, or transpose_b and adjoint_b\n",
      "     |          are both set to True.\n",
      "     |  \n",
      "     |  __rmod__ = r_binary_op_wrapper(y, x)\n",
      "     |      Returns element-wise remainder of division. When `x < 0` xor `y < 0` is\n",
      "     |      \n",
      "     |      true, this follows Python semantics in that the result here is consistent\n",
      "     |      with a flooring divide. E.g. `floor(x / y) * y + mod(x, y) = x`.\n",
      "     |      \n",
      "     |      *NOTE*: `math.floormod` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `int32`, `int64`, `bfloat16`, `half`, `float32`, `float64`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `x`.\n",
      "     |  \n",
      "     |  __rmul__ = r_binary_op_wrapper(y, x)\n",
      "     |      Dispatches cwise mul for \"Dense*Dense\" and \"Dense*Sparse\".\n",
      "     |  \n",
      "     |  __ror__ = r_binary_op_wrapper(y, x)\n",
      "     |      Returns the truth value of x OR y element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `math.logical_or` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor` of type `bool`.\n",
      "     |        y: A `Tensor` of type `bool`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type `bool`.\n",
      "     |  \n",
      "     |  __rpow__ = r_binary_op_wrapper(y, x)\n",
      "     |      Computes the power of one value to another.\n",
      "     |      \n",
      "     |      Given a tensor `x` and a tensor `y`, this operation computes \\\\(x^y\\\\) for\n",
      "     |      corresponding elements in `x` and `y`. For example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      x = tf.constant([[2, 2], [3, 3]])\n",
      "     |      y = tf.constant([[8, 16], [2, 3]])\n",
      "     |      tf.pow(x, y)  # [[256, 65536], [9, 27]]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor` of type `float16`, `float32`, `float64`, `int32`, `int64`,\n",
      "     |          `complex64`, or `complex128`.\n",
      "     |        y: A `Tensor` of type `float16`, `float32`, `float64`, `int32`, `int64`,\n",
      "     |          `complex64`, or `complex128`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`.\n",
      "     |  \n",
      "     |  __rsub__ = r_binary_op_wrapper(y, x)\n",
      "     |      Returns x - y element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `Subtract` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`, `int16`, `int32`, `int64`, `complex64`, `complex128`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `x`.\n",
      "     |  \n",
      "     |  __rtruediv__ = r_binary_op_wrapper(y, x)\n",
      "     |  \n",
      "     |  __rxor__ = r_binary_op_wrapper(y, x)\n",
      "     |      Logical XOR function.\n",
      "     |      \n",
      "     |      x ^ y = (x | y) & ~(x & y)\n",
      "     |      \n",
      "     |      Inputs are tensor and if the tensors contains more than one element, an\n",
      "     |      element-wise logical XOR is computed.\n",
      "     |      \n",
      "     |      Usage:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      x = tf.constant([False, False, True, True], dtype = tf.bool)\n",
      "     |      y = tf.constant([False, True, False, True], dtype = tf.bool)\n",
      "     |      z = tf.logical_xor(x, y, name=\"LogicalXor\")\n",
      "     |      #  here z = [False  True  True False]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          x: A `Tensor` type bool.\n",
      "     |          y: A `Tensor` of type bool.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type bool with the same size as that of x or y.\n",
      "     |  \n",
      "     |  __sub__ = binary_op_wrapper(x, y)\n",
      "     |      Returns x - y element-wise.\n",
      "     |      \n",
      "     |      *NOTE*: `Subtract` supports broadcasting. More about broadcasting\n",
      "     |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`, `int16`, `int32`, `int64`, `complex64`, `complex128`.\n",
      "     |        y: A `Tensor`. Must have the same type as `x`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `x`.\n",
      "     |  \n",
      "     |  __truediv__ = binary_op_wrapper(x, y)\n",
      "     |  \n",
      "     |  __xor__ = binary_op_wrapper(x, y)\n",
      "     |      Logical XOR function.\n",
      "     |      \n",
      "     |      x ^ y = (x | y) & ~(x & y)\n",
      "     |      \n",
      "     |      Inputs are tensor and if the tensors contains more than one element, an\n",
      "     |      element-wise logical XOR is computed.\n",
      "     |      \n",
      "     |      Usage:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      x = tf.constant([False, False, True, True], dtype = tf.bool)\n",
      "     |      y = tf.constant([False, True, False, True], dtype = tf.bool)\n",
      "     |      z = tf.logical_xor(x, y, name=\"LogicalXor\")\n",
      "     |      #  here z = [False  True  True False]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          x: A `Tensor` type bool.\n",
      "     |          y: A `Tensor` of type bool.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` of type bool with the same size as that of x or y.\n",
      "     |  \n",
      "     |  assign(self, value, use_locking=False, name=None, read_value=True)\n",
      "     |      Assigns a new value to the variable.\n",
      "     |      \n",
      "     |      This is essentially a shortcut for `assign(self, value)`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        value: A `Tensor`. The new value for this variable.\n",
      "     |        use_locking: If `True`, use locking during the assignment.\n",
      "     |        name: The name of the operation to be created\n",
      "     |        read_value: if True, will return something which evaluates to the new\n",
      "     |          value of the variable; if False will return the assign op.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` that will hold the new value of this variable after\n",
      "     |        the assignment has completed.\n",
      "     |  \n",
      "     |  assign_add(self, delta, use_locking=False, name=None, read_value=True)\n",
      "     |      Adds a value to this variable.\n",
      "     |      \n",
      "     |       This is essentially a shortcut for `assign_add(self, delta)`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        delta: A `Tensor`. The value to add to this variable.\n",
      "     |        use_locking: If `True`, use locking during the operation.\n",
      "     |        name: The name of the operation to be created\n",
      "     |        read_value: if True, will return something which evaluates to the new\n",
      "     |          value of the variable; if False will return the assign op.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` that will hold the new value of this variable after\n",
      "     |        the addition has completed.\n",
      "     |  \n",
      "     |  assign_sub(self, delta, use_locking=False, name=None, read_value=True)\n",
      "     |      Subtracts a value from this variable.\n",
      "     |      \n",
      "     |      This is essentially a shortcut for `assign_sub(self, delta)`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        delta: A `Tensor`. The value to subtract from this variable.\n",
      "     |        use_locking: If `True`, use locking during the operation.\n",
      "     |        name: The name of the operation to be created\n",
      "     |        read_value: if True, will return something which evaluates to the new\n",
      "     |          value of the variable; if False will return the assign op.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` that will hold the new value of this variable after\n",
      "     |        the subtraction has completed.\n",
      "     |  \n",
      "     |  batch_scatter_update(self, sparse_delta, use_locking=False, name=None)\n",
      "     |      Assigns `tf.IndexedSlices` to this variable batch-wise.\n",
      "     |      \n",
      "     |      Analogous to `batch_gather`. This assumes that this variable and the\n",
      "     |      sparse_delta IndexedSlices have a series of leading dimensions that are the\n",
      "     |      same for all of them, and the updates are performed on the last dimension of\n",
      "     |      indices. In other words, the dimensions should be the following:\n",
      "     |      \n",
      "     |      `num_prefix_dims = sparse_delta.indices.ndims - 1`\n",
      "     |      `batch_dim = num_prefix_dims + 1`\n",
      "     |      `sparse_delta.updates.shape = sparse_delta.indices.shape + var.shape[\n",
      "     |           batch_dim:]`\n",
      "     |      \n",
      "     |      where\n",
      "     |      \n",
      "     |      `sparse_delta.updates.shape[:num_prefix_dims]`\n",
      "     |      `== sparse_delta.indices.shape[:num_prefix_dims]`\n",
      "     |      `== var.shape[:num_prefix_dims]`\n",
      "     |      \n",
      "     |      And the operation performed can be expressed as:\n",
      "     |      \n",
      "     |      `var[i_1, ..., i_n,\n",
      "     |           sparse_delta.indices[i_1, ..., i_n, j]] = sparse_delta.updates[\n",
      "     |              i_1, ..., i_n, j]`\n",
      "     |      \n",
      "     |      When sparse_delta.indices is a 1D tensor, this operation is equivalent to\n",
      "     |      `scatter_update`.\n",
      "     |      \n",
      "     |      To avoid this operation one can looping over the first `ndims` of the\n",
      "     |      variable and using `scatter_update` on the subtensors that result of slicing\n",
      "     |      the first dimension. This is a valid option for `ndims = 1`, but less\n",
      "     |      efficient than this implementation.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        sparse_delta: `tf.IndexedSlices` to be assigned to this variable.\n",
      "     |        use_locking: If `True`, use locking during the operation.\n",
      "     |        name: the name of the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` that will hold the new value of this variable after\n",
      "     |        the scattered assignment has completed.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: if `sparse_delta` is not an `IndexedSlices`.\n",
      "     |  \n",
      "     |  count_up_to(self, limit)\n",
      "     |      Increments this variable until it reaches `limit`. (deprecated)\n",
      "     |      \n",
      "     |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Prefer Dataset.range instead.\n",
      "     |      \n",
      "     |      When that Op is run it tries to increment the variable by `1`. If\n",
      "     |      incrementing the variable would bring it above `limit` then the Op raises\n",
      "     |      the exception `OutOfRangeError`.\n",
      "     |      \n",
      "     |      If no error is raised, the Op outputs the value of the variable before\n",
      "     |      the increment.\n",
      "     |      \n",
      "     |      This is essentially a shortcut for `count_up_to(self, limit)`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        limit: value at which incrementing the variable raises an error.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` that will hold the variable value before the increment. If no\n",
      "     |        other Op modifies this variable, the values produced will all be\n",
      "     |        distinct.\n",
      "     |  \n",
      "     |  eval(self, session=None)\n",
      "     |      In a session, computes and returns the value of this variable.\n",
      "     |      \n",
      "     |      This is not a graph construction method, it does not add ops to the graph.\n",
      "     |      \n",
      "     |      This convenience method requires a session where the graph\n",
      "     |      containing this variable has been launched. If no session is\n",
      "     |      passed, the default session is used.  See `tf.compat.v1.Session` for more\n",
      "     |      information on launching a graph and on sessions.\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      v = tf.Variable([1, 2])\n",
      "     |      init = tf.compat.v1.global_variables_initializer()\n",
      "     |      \n",
      "     |      with tf.compat.v1.Session() as sess:\n",
      "     |          sess.run(init)\n",
      "     |          # Usage passing the session explicitly.\n",
      "     |          print(v.eval(sess))\n",
      "     |          # Usage with the default session.  The 'with' block\n",
      "     |          # above makes 'sess' the default session.\n",
      "     |          print(v.eval())\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        session: The session to use to evaluate this variable. If none, the\n",
      "     |          default session is used.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A numpy `ndarray` with a copy of the value of this variable.\n",
      "     |  \n",
      "     |  experimental_ref(self)\n",
      "     |      Returns a hashable reference object to this Variable.\n",
      "     |      \n",
      "     |      Warning: Experimental API that could be changed or removed.\n",
      "     |      \n",
      "     |      The primary usecase for this API is to put variables in a set/dictionary.\n",
      "     |      We can't put variables in a set/dictionary as `variable.__hash__()` is no\n",
      "     |      longer available starting Tensorflow 2.0.\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      import tensorflow as tf\n",
      "     |      \n",
      "     |      x = tf.Variable(5)\n",
      "     |      y = tf.Variable(10)\n",
      "     |      z = tf.Variable(10)\n",
      "     |      \n",
      "     |      # The followings will raise an exception starting 2.0\n",
      "     |      # TypeError: Variable is unhashable if Variable equality is enabled.\n",
      "     |      variable_set = {x, y, z}\n",
      "     |      variable_dict = {x: 'five', y: 'ten'}\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Instead, we can use `variable.experimental_ref()`.\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      variable_set = {x.experimental_ref(),\n",
      "     |                      y.experimental_ref(),\n",
      "     |                      z.experimental_ref()}\n",
      "     |      \n",
      "     |      print(x.experimental_ref() in variable_set)\n",
      "     |      ==> True\n",
      "     |      \n",
      "     |      variable_dict = {x.experimental_ref(): 'five',\n",
      "     |                       y.experimental_ref(): 'ten',\n",
      "     |                       z.experimental_ref(): 'ten'}\n",
      "     |      \n",
      "     |      print(variable_dict[y.experimental_ref()])\n",
      "     |      ==> ten\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Also, the reference object provides `.deref()` function that returns the\n",
      "     |      original Variable.\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      x = tf.Variable(5)\n",
      "     |      print(x.experimental_ref().deref())\n",
      "     |      ==> <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=5>\n",
      "     |      ```\n",
      "     |  \n",
      "     |  gather_nd(self, indices, name=None)\n",
      "     |      Gather slices from `params` into a Tensor with shape specified by `indices`.\n",
      "     |      \n",
      "     |      See tf.gather_nd for details.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "     |          Index tensor.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `params`.\n",
      "     |  \n",
      "     |  get_shape(self)\n",
      "     |      Alias of `Variable.shape`.\n",
      "     |  \n",
      "     |  initialized_value(self)\n",
      "     |      Returns the value of the initialized variable. (deprecated)\n",
      "     |      \n",
      "     |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "     |      \n",
      "     |      You should use this instead of the variable itself to initialize another\n",
      "     |      variable with a value that depends on the value of this variable.\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      # Initialize 'v' with a random tensor.\n",
      "     |      v = tf.Variable(tf.random.truncated_normal([10, 40]))\n",
      "     |      # Use `initialized_value` to guarantee that `v` has been\n",
      "     |      # initialized before its value is used to initialize `w`.\n",
      "     |      # The random values are picked only once.\n",
      "     |      w = tf.Variable(v.initialized_value() * 2.0)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` holding the value of this variable after its initializer\n",
      "     |        has run.\n",
      "     |  \n",
      "     |  load(self, value, session=None)\n",
      "     |      Load new value into this variable. (deprecated)\n",
      "     |      \n",
      "     |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "     |      \n",
      "     |      Writes new value to variable's memory. Doesn't add ops to the graph.\n",
      "     |      \n",
      "     |      This convenience method requires a session where the graph\n",
      "     |      containing this variable has been launched. If no session is\n",
      "     |      passed, the default session is used.  See `tf.compat.v1.Session` for more\n",
      "     |      information on launching a graph and on sessions.\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      v = tf.Variable([1, 2])\n",
      "     |      init = tf.compat.v1.global_variables_initializer()\n",
      "     |      \n",
      "     |      with tf.compat.v1.Session() as sess:\n",
      "     |          sess.run(init)\n",
      "     |          # Usage passing the session explicitly.\n",
      "     |          v.load([2, 3], sess)\n",
      "     |          print(v.eval(sess)) # prints [2 3]\n",
      "     |          # Usage with the default session.  The 'with' block\n",
      "     |          # above makes 'sess' the default session.\n",
      "     |          v.load([3, 4], sess)\n",
      "     |          print(v.eval()) # prints [3 4]\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          value: New variable value\n",
      "     |          session: The session to use to evaluate this variable. If none, the\n",
      "     |            default session is used.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |          ValueError: Session is not passed and no default session\n",
      "     |  \n",
      "     |  read_value(self)\n",
      "     |      Returns the value of this variable, read in the current context.\n",
      "     |      \n",
      "     |      Can be different from value() if it's on another device, with control\n",
      "     |      dependencies, etc.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` containing the value of the variable.\n",
      "     |  \n",
      "     |  scatter_add(self, sparse_delta, use_locking=False, name=None)\n",
      "     |      Adds `tf.IndexedSlices` to this variable.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        sparse_delta: `tf.IndexedSlices` to be added to this variable.\n",
      "     |        use_locking: If `True`, use locking during the operation.\n",
      "     |        name: the name of the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` that will hold the new value of this variable after\n",
      "     |        the scattered addition has completed.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: if `sparse_delta` is not an `IndexedSlices`.\n",
      "     |  \n",
      "     |  scatter_div(self, sparse_delta, use_locking=False, name=None)\n",
      "     |      Divide this variable by `tf.IndexedSlices`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        sparse_delta: `tf.IndexedSlices` to divide this variable by.\n",
      "     |        use_locking: If `True`, use locking during the operation.\n",
      "     |        name: the name of the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` that will hold the new value of this variable after\n",
      "     |        the scattered division has completed.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: if `sparse_delta` is not an `IndexedSlices`.\n",
      "     |  \n",
      "     |  scatter_max(self, sparse_delta, use_locking=False, name=None)\n",
      "     |      Updates this variable with the max of `tf.IndexedSlices` and itself.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        sparse_delta: `tf.IndexedSlices` to use as an argument of max with this\n",
      "     |          variable.\n",
      "     |        use_locking: If `True`, use locking during the operation.\n",
      "     |        name: the name of the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` that will hold the new value of this variable after\n",
      "     |        the scattered maximization has completed.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: if `sparse_delta` is not an `IndexedSlices`.\n",
      "     |  \n",
      "     |  scatter_min(self, sparse_delta, use_locking=False, name=None)\n",
      "     |      Updates this variable with the min of `tf.IndexedSlices` and itself.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        sparse_delta: `tf.IndexedSlices` to use as an argument of min with this\n",
      "     |          variable.\n",
      "     |        use_locking: If `True`, use locking during the operation.\n",
      "     |        name: the name of the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` that will hold the new value of this variable after\n",
      "     |        the scattered minimization has completed.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: if `sparse_delta` is not an `IndexedSlices`.\n",
      "     |  \n",
      "     |  scatter_mul(self, sparse_delta, use_locking=False, name=None)\n",
      "     |      Multiply this variable by `tf.IndexedSlices`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        sparse_delta: `tf.IndexedSlices` to multiply this variable by.\n",
      "     |        use_locking: If `True`, use locking during the operation.\n",
      "     |        name: the name of the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` that will hold the new value of this variable after\n",
      "     |        the scattered multiplication has completed.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: if `sparse_delta` is not an `IndexedSlices`.\n",
      "     |  \n",
      "     |  scatter_nd_add(self, indices, updates, name=None)\n",
      "     |      Applies sparse addition to individual values or slices in a Variable.\n",
      "     |      \n",
      "     |      The Variable has rank `P` and `indices` is a `Tensor` of rank `Q`.\n",
      "     |      \n",
      "     |      `indices` must be integer tensor, containing indices into self.\n",
      "     |      It must be shape `[d_0, ..., d_{Q-2}, K]` where `0 < K <= P`.\n",
      "     |      \n",
      "     |      The innermost dimension of `indices` (with length `K`) corresponds to\n",
      "     |      indices into elements (if `K = P`) or slices (if `K < P`) along the `K`th\n",
      "     |      dimension of self.\n",
      "     |      \n",
      "     |      `updates` is `Tensor` of rank `Q-1+P-K` with shape:\n",
      "     |      \n",
      "     |      ```\n",
      "     |      [d_0, ..., d_{Q-2}, self.shape[K], ..., self.shape[P-1]].\n",
      "     |      ```\n",
      "     |      \n",
      "     |      For example, say we want to add 4 scattered elements to a rank-1 tensor to\n",
      "     |      8 elements. In Python, that update would look like this:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |          v = tf.Variable([1, 2, 3, 4, 5, 6, 7, 8])\n",
      "     |          indices = tf.constant([[4], [3], [1] ,[7]])\n",
      "     |          updates = tf.constant([9, 10, 11, 12])\n",
      "     |          add = v.scatter_nd_add(indices, updates)\n",
      "     |          with tf.compat.v1.Session() as sess:\n",
      "     |            print sess.run(add)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      The resulting update to v would look like this:\n",
      "     |      \n",
      "     |          [1, 13, 3, 14, 14, 6, 7, 20]\n",
      "     |      \n",
      "     |      See `tf.scatter_nd` for more details about how to make updates to\n",
      "     |      slices.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        indices: The indices to be used in the operation.\n",
      "     |        updates: The values to be used in the operation.\n",
      "     |        name: the name of the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` that will hold the new value of this variable after\n",
      "     |        the scattered addition has completed.\n",
      "     |  \n",
      "     |  scatter_nd_sub(self, indices, updates, name=None)\n",
      "     |      Applies sparse subtraction to individual values or slices in a Variable.\n",
      "     |      \n",
      "     |      Assuming the variable has rank `P` and `indices` is a `Tensor` of rank `Q`.\n",
      "     |      \n",
      "     |      `indices` must be integer tensor, containing indices into self.\n",
      "     |      It must be shape `[d_0, ..., d_{Q-2}, K]` where `0 < K <= P`.\n",
      "     |      \n",
      "     |      The innermost dimension of `indices` (with length `K`) corresponds to\n",
      "     |      indices into elements (if `K = P`) or slices (if `K < P`) along the `K`th\n",
      "     |      dimension of self.\n",
      "     |      \n",
      "     |      `updates` is `Tensor` of rank `Q-1+P-K` with shape:\n",
      "     |      \n",
      "     |      ```\n",
      "     |      [d_0, ..., d_{Q-2}, self.shape[K], ..., self.shape[P-1]].\n",
      "     |      ```\n",
      "     |      \n",
      "     |      For example, say we want to add 4 scattered elements to a rank-1 tensor to\n",
      "     |      8 elements. In Python, that update would look like this:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |          v = tf.Variable([1, 2, 3, 4, 5, 6, 7, 8])\n",
      "     |          indices = tf.constant([[4], [3], [1] ,[7]])\n",
      "     |          updates = tf.constant([9, 10, 11, 12])\n",
      "     |          op = v.scatter_nd_sub(indices, updates)\n",
      "     |          with tf.compat.v1.Session() as sess:\n",
      "     |            print sess.run(op)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      The resulting update to v would look like this:\n",
      "     |      \n",
      "     |          [1, -9, 3, -6, -6, 6, 7, -4]\n",
      "     |      \n",
      "     |      See `tf.scatter_nd` for more details about how to make updates to\n",
      "     |      slices.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        indices: The indices to be used in the operation.\n",
      "     |        updates: The values to be used in the operation.\n",
      "     |        name: the name of the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` that will hold the new value of this variable after\n",
      "     |        the scattered subtraction has completed.\n",
      "     |  \n",
      "     |  scatter_nd_update(self, indices, updates, name=None)\n",
      "     |      Applies sparse assignment to individual values or slices in a Variable.\n",
      "     |      \n",
      "     |      The Variable has rank `P` and `indices` is a `Tensor` of rank `Q`.\n",
      "     |      \n",
      "     |      `indices` must be integer tensor, containing indices into self.\n",
      "     |      It must be shape `[d_0, ..., d_{Q-2}, K]` where `0 < K <= P`.\n",
      "     |      \n",
      "     |      The innermost dimension of `indices` (with length `K`) corresponds to\n",
      "     |      indices into elements (if `K = P`) or slices (if `K < P`) along the `K`th\n",
      "     |      dimension of self.\n",
      "     |      \n",
      "     |      `updates` is `Tensor` of rank `Q-1+P-K` with shape:\n",
      "     |      \n",
      "     |      ```\n",
      "     |      [d_0, ..., d_{Q-2}, self.shape[K], ..., self.shape[P-1]].\n",
      "     |      ```\n",
      "     |      \n",
      "     |      For example, say we want to add 4 scattered elements to a rank-1 tensor to\n",
      "     |      8 elements. In Python, that update would look like this:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |          v = tf.Variable([1, 2, 3, 4, 5, 6, 7, 8])\n",
      "     |          indices = tf.constant([[4], [3], [1] ,[7]])\n",
      "     |          updates = tf.constant([9, 10, 11, 12])\n",
      "     |          op = v.scatter_nd_assign(indices, updates)\n",
      "     |          with tf.compat.v1.Session() as sess:\n",
      "     |            print sess.run(op)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      The resulting update to v would look like this:\n",
      "     |      \n",
      "     |          [1, 11, 3, 10, 9, 6, 7, 12]\n",
      "     |      \n",
      "     |      See `tf.scatter_nd` for more details about how to make updates to\n",
      "     |      slices.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        indices: The indices to be used in the operation.\n",
      "     |        updates: The values to be used in the operation.\n",
      "     |        name: the name of the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` that will hold the new value of this variable after\n",
      "     |        the scattered assignment has completed.\n",
      "     |  \n",
      "     |  scatter_sub(self, sparse_delta, use_locking=False, name=None)\n",
      "     |      Subtracts `tf.IndexedSlices` from this variable.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        sparse_delta: `tf.IndexedSlices` to be subtracted from this variable.\n",
      "     |        use_locking: If `True`, use locking during the operation.\n",
      "     |        name: the name of the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` that will hold the new value of this variable after\n",
      "     |        the scattered subtraction has completed.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: if `sparse_delta` is not an `IndexedSlices`.\n",
      "     |  \n",
      "     |  scatter_update(self, sparse_delta, use_locking=False, name=None)\n",
      "     |      Assigns `tf.IndexedSlices` to this variable.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        sparse_delta: `tf.IndexedSlices` to be assigned to this variable.\n",
      "     |        use_locking: If `True`, use locking during the operation.\n",
      "     |        name: the name of the operation.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` that will hold the new value of this variable after\n",
      "     |        the scattered assignment has completed.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: if `sparse_delta` is not an `IndexedSlices`.\n",
      "     |  \n",
      "     |  set_shape(self, shape)\n",
      "     |      Overrides the shape for this variable.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: the `TensorShape` representing the overridden shape.\n",
      "     |  \n",
      "     |  sparse_read(self, indices, name=None)\n",
      "     |      Gather slices from params axis axis according to indices.\n",
      "     |      \n",
      "     |      This function supports a subset of tf.gather, see tf.gather for details on\n",
      "     |      usage.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        indices: The index `Tensor`.  Must be one of the following types: `int32`,\n",
      "     |          `int64`. Must be in range `[0, params.shape[axis])`.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`. Has the same type as `params`.\n",
      "     |  \n",
      "     |  to_proto(self, export_scope=None)\n",
      "     |      Converts a `Variable` to a `VariableDef` protocol buffer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        export_scope: Optional `string`. Name scope to remove.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `VariableDef` protocol buffer, or `None` if the `Variable` is not\n",
      "     |        in the specified name scope.\n",
      "     |  \n",
      "     |  value(self)\n",
      "     |      Returns the last snapshot of this variable.\n",
      "     |      \n",
      "     |      You usually do not need to call this method as all ops that need the value\n",
      "     |      of the variable call it automatically through a `convert_to_tensor()` call.\n",
      "     |      \n",
      "     |      Returns a `Tensor` which holds the value of the variable.  You can not\n",
      "     |      assign a new value to this tensor as it is not a reference to the variable.\n",
      "     |      \n",
      "     |      To avoid copies, if the consumer of the returned value is on the same device\n",
      "     |      as the variable, this actually returns the live value of the variable, not\n",
      "     |      a copy.  Updates to the variable are seen by the consumer.  If the consumer\n",
      "     |      is on a different device it will get a copy of the variable.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor` containing the value of the variable.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from Variable:\n",
      "     |  \n",
      "     |  from_proto(variable_def, import_scope=None)\n",
      "     |      Returns a `Variable` object created from `variable_def`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Variable:\n",
      "     |  \n",
      "     |  aggregation\n",
      "     |  \n",
      "     |  constraint\n",
      "     |      Returns the constraint function associated with this variable.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The constraint function that was passed to the variable constructor.\n",
      "     |        Can be `None` if no constraint was passed.\n",
      "     |  \n",
      "     |  device\n",
      "     |      The device of this variable.\n",
      "     |  \n",
      "     |  dtype\n",
      "     |      The `DType` of this variable.\n",
      "     |  \n",
      "     |  graph\n",
      "     |      The `Graph` of this variable.\n",
      "     |  \n",
      "     |  initial_value\n",
      "     |      Returns the Tensor used as the initial value for the variable.\n",
      "     |      \n",
      "     |      Note that this is different from `initialized_value()` which runs\n",
      "     |      the op that initializes the variable before returning its value.\n",
      "     |      This method returns the tensor that is used by the op that initializes\n",
      "     |      the variable.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `Tensor`.\n",
      "     |  \n",
      "     |  initializer\n",
      "     |      The initializer operation for this variable.\n",
      "     |  \n",
      "     |  name\n",
      "     |      The name of this variable.\n",
      "     |  \n",
      "     |  op\n",
      "     |      The `Operation` of this variable.\n",
      "     |  \n",
      "     |  shape\n",
      "     |      The `TensorShape` of this variable.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A `TensorShape`.\n",
      "     |  \n",
      "     |  synchronization\n",
      "     |  \n",
      "     |  trainable\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from Variable:\n",
      "     |  \n",
      "     |  __array_priority__ = 100\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class VariableAggregation(enum.Enum)\n",
      "     |  Indicates how a distributed variable will be aggregated.\n",
      "     |  \n",
      "     |  `tf.distribute.Strategy` distributes a model by making multiple copies\n",
      "     |  (called \"replicas\") acting data-parallel on different elements of the input\n",
      "     |  batch. When performing some variable-update operation, say\n",
      "     |  `var.assign_add(x)`, in a model, we need to resolve how to combine the\n",
      "     |  different values for `x` computed in the different replicas.\n",
      "     |  \n",
      "     |  * `NONE`: This is the default, giving an error if you use a\n",
      "     |    variable-update operation with multiple replicas.\n",
      "     |  * `SUM`: Add the updates across replicas.\n",
      "     |  * `MEAN`: Take the arithmetic mean (\"average\") of the updates across replicas.\n",
      "     |  * `ONLY_FIRST_REPLICA`: This is for when every replica is performing the same\n",
      "     |    update, but we only want to perform the update once. Used, e.g., for the\n",
      "     |    global step counter.\n",
      "     |  * `ONLY_FIRST_TOWER`: Deprecated alias for `ONLY_FIRST_REPLICA`.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      VariableAggregation\n",
      "     |      enum.Enum\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  MEAN = <VariableAggregation.MEAN: 2>\n",
      "     |  \n",
      "     |  NONE = <VariableAggregation.NONE: 0>\n",
      "     |  \n",
      "     |  ONLY_FIRST_REPLICA = <VariableAggregation.ONLY_FIRST_REPLICA: 3>\n",
      "     |  \n",
      "     |  SUM = <VariableAggregation.SUM: 1>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from enum.Enum:\n",
      "     |  \n",
      "     |  name\n",
      "     |      The name of the Enum member.\n",
      "     |  \n",
      "     |  value\n",
      "     |      The value of the Enum member.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from enum.EnumMeta:\n",
      "     |  \n",
      "     |  __members__\n",
      "     |      Returns a mapping of member name->value.\n",
      "     |      \n",
      "     |      This mapping lists all enum members, including aliases. Note that this\n",
      "     |      is a read-only view of the internal mapping.\n",
      "    \n",
      "    class VariableScope(builtins.object)\n",
      "     |  Variable scope object to carry defaults to provide to `get_variable`.\n",
      "     |  \n",
      "     |  Many of the arguments we need for `get_variable` in a variable store are most\n",
      "     |  easily handled with a context. This object is used for the defaults.\n",
      "     |  \n",
      "     |  Attributes:\n",
      "     |    name: name of the current scope, used as prefix in get_variable.\n",
      "     |    initializer: default initializer passed to get_variable.\n",
      "     |    regularizer: default regularizer passed to get_variable.\n",
      "     |    reuse: Boolean, None, or tf.compat.v1.AUTO_REUSE, setting the reuse in\n",
      "     |      get_variable. When eager execution is enabled this argument is always\n",
      "     |      forced to be False.\n",
      "     |    caching_device: string, callable, or None: the caching device passed to\n",
      "     |      get_variable.\n",
      "     |    partitioner: callable or `None`: the partitioner passed to `get_variable`.\n",
      "     |    custom_getter: default custom getter passed to get_variable.\n",
      "     |    name_scope: The name passed to `tf.name_scope`.\n",
      "     |    dtype: default type passed to get_variable (defaults to DT_FLOAT).\n",
      "     |    use_resource: if False, create a normal Variable; if True create an\n",
      "     |      experimental ResourceVariable with well-defined semantics. Defaults to\n",
      "     |      False (will later change to True). When eager execution is enabled this\n",
      "     |      argument is always forced to be True.\n",
      "     |    constraint: An optional projection function to be applied to the variable\n",
      "     |      after being updated by an `Optimizer` (e.g. used to implement norm\n",
      "     |      constraints or value constraints for layer weights). The function must\n",
      "     |      take as input the unprojected Tensor representing the value of the\n",
      "     |      variable and return the Tensor for the projected value (which must have\n",
      "     |      the same shape). Constraints are not safe to use when doing asynchronous\n",
      "     |      distributed training.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, reuse, name='', initializer=None, regularizer=None, caching_device=None, partitioner=None, custom_getter=None, name_scope='', dtype=tf.float32, use_resource=None, constraint=None)\n",
      "     |      Creates a new VariableScope with the given properties.\n",
      "     |  \n",
      "     |  get_collection(self, name)\n",
      "     |      Get this scope's variables.\n",
      "     |  \n",
      "     |  get_variable(self, var_store, name, shape=None, dtype=None, initializer=None, regularizer=None, reuse=None, trainable=None, collections=None, caching_device=None, partitioner=None, validate_shape=True, use_resource=None, custom_getter=None, constraint=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregation.NONE: 0>)\n",
      "     |      Gets an existing variable with this name or create a new one.\n",
      "     |  \n",
      "     |  global_variables(self)\n",
      "     |      Get this scope's global variables.\n",
      "     |  \n",
      "     |  local_variables(self)\n",
      "     |      Get this scope's local variables.\n",
      "     |  \n",
      "     |  reuse_variables(self)\n",
      "     |      Reuse variables in this scope.\n",
      "     |  \n",
      "     |  set_caching_device(self, caching_device)\n",
      "     |      Set caching_device for this scope.\n",
      "     |  \n",
      "     |  set_custom_getter(self, custom_getter)\n",
      "     |      Set custom getter for this scope.\n",
      "     |  \n",
      "     |  set_dtype(self, dtype)\n",
      "     |      Set data type for this scope.\n",
      "     |  \n",
      "     |  set_initializer(self, initializer)\n",
      "     |      Set initializer for this scope.\n",
      "     |  \n",
      "     |  set_partitioner(self, partitioner)\n",
      "     |      Set partitioner for this scope.\n",
      "     |  \n",
      "     |  set_regularizer(self, regularizer)\n",
      "     |      Set regularizer for this scope.\n",
      "     |  \n",
      "     |  set_use_resource(self, use_resource)\n",
      "     |      Sets whether to use ResourceVariables for this scope.\n",
      "     |  \n",
      "     |  trainable_variables(self)\n",
      "     |      Get this scope's trainable variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  caching_device\n",
      "     |  \n",
      "     |  constraint\n",
      "     |  \n",
      "     |  custom_getter\n",
      "     |  \n",
      "     |  dtype\n",
      "     |  \n",
      "     |  initializer\n",
      "     |  \n",
      "     |  name\n",
      "     |  \n",
      "     |  original_name_scope\n",
      "     |  \n",
      "     |  partitioner\n",
      "     |  \n",
      "     |  regularizer\n",
      "     |  \n",
      "     |  reuse\n",
      "     |  \n",
      "     |  use_resource\n",
      "    \n",
      "    class VariableSynchronization(enum.Enum)\n",
      "     |  Indicates when a distributed variable will be synced.\n",
      "     |  \n",
      "     |  * `AUTO`: Indicates that the synchronization will be determined by the current\n",
      "     |    `DistributionStrategy` (eg. With `MirroredStrategy` this would be\n",
      "     |    `ON_WRITE`).\n",
      "     |  * `NONE`: Indicates that there will only be one copy of the variable, so\n",
      "     |    there is no need to sync.\n",
      "     |  * `ON_WRITE`: Indicates that the variable will be updated across devices\n",
      "     |    every time it is written.\n",
      "     |  * `ON_READ`: Indicates that the variable will be aggregated across devices\n",
      "     |    when it is read (eg. when checkpointing or when evaluating an op that uses\n",
      "     |    the variable).\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      VariableSynchronization\n",
      "     |      enum.Enum\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  AUTO = <VariableSynchronization.AUTO: 0>\n",
      "     |  \n",
      "     |  NONE = <VariableSynchronization.NONE: 1>\n",
      "     |  \n",
      "     |  ON_READ = <VariableSynchronization.ON_READ: 3>\n",
      "     |  \n",
      "     |  ON_WRITE = <VariableSynchronization.ON_WRITE: 2>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from enum.Enum:\n",
      "     |  \n",
      "     |  name\n",
      "     |      The name of the Enum member.\n",
      "     |  \n",
      "     |  value\n",
      "     |      The value of the Enum member.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from enum.EnumMeta:\n",
      "     |  \n",
      "     |  __members__\n",
      "     |      Returns a mapping of member name->value.\n",
      "     |      \n",
      "     |      This mapping lists all enum members, including aliases. Note that this\n",
      "     |      is a read-only view of the internal mapping.\n",
      "    \n",
      "    class WholeFileReader(ReaderBase)\n",
      "     |  A Reader that outputs the entire contents of a file as a value.\n",
      "     |  \n",
      "     |  To use, enqueue filenames in a Queue.  The output of Read will\n",
      "     |  be a filename (key) and the contents of that file (value).\n",
      "     |  \n",
      "     |  See ReaderBase for supported methods.\n",
      "     |  \n",
      "     |  @compatibility(eager)\n",
      "     |  Readers are not compatible with eager execution. Instead, please\n",
      "     |  use `tf.data` to get data into your model.\n",
      "     |  @end_compatibility\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      WholeFileReader\n",
      "     |      ReaderBase\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, name=None)\n",
      "     |      Create a WholeFileReader. (deprecated)\n",
      "     |      \n",
      "     |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.map(tf.read_file)`.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from ReaderBase:\n",
      "     |  \n",
      "     |  num_records_produced(self, name=None)\n",
      "     |      Returns the number of records this reader has produced.\n",
      "     |      \n",
      "     |      This is the same as the number of Read executions that have\n",
      "     |      succeeded.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An int64 Tensor.\n",
      "     |  \n",
      "     |  num_work_units_completed(self, name=None)\n",
      "     |      Returns the number of work units this reader has finished processing.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An int64 Tensor.\n",
      "     |  \n",
      "     |  read(self, queue, name=None)\n",
      "     |      Returns the next record (key, value) pair produced by a reader.\n",
      "     |      \n",
      "     |      Will dequeue a work unit from queue if necessary (e.g. when the\n",
      "     |      Reader needs to start reading from a new file since it has\n",
      "     |      finished with the previous file).\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        queue: A Queue or a mutable string Tensor representing a handle\n",
      "     |          to a Queue, with string work items.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A tuple of Tensors (key, value).\n",
      "     |        key: A string scalar Tensor.\n",
      "     |        value: A string scalar Tensor.\n",
      "     |  \n",
      "     |  read_up_to(self, queue, num_records, name=None)\n",
      "     |      Returns up to num_records (key, value) pairs produced by a reader.\n",
      "     |      \n",
      "     |      Will dequeue a work unit from queue if necessary (e.g., when the\n",
      "     |      Reader needs to start reading from a new file since it has\n",
      "     |      finished with the previous file).\n",
      "     |      It may return less than num_records even before the last batch.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        queue: A Queue or a mutable string Tensor representing a handle\n",
      "     |          to a Queue, with string work items.\n",
      "     |        num_records: Number of records to read.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A tuple of Tensors (keys, values).\n",
      "     |        keys: A 1-D string Tensor.\n",
      "     |        values: A 1-D string Tensor.\n",
      "     |  \n",
      "     |  reset(self, name=None)\n",
      "     |      Restore a reader to its initial clean state.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The created Operation.\n",
      "     |  \n",
      "     |  restore_state(self, state, name=None)\n",
      "     |      Restore a reader to a previously saved state.\n",
      "     |      \n",
      "     |      Not all Readers support being restored, so this can produce an\n",
      "     |      Unimplemented error.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        state: A string Tensor.\n",
      "     |          Result of a SerializeState of a Reader with matching type.\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The created Operation.\n",
      "     |  \n",
      "     |  serialize_state(self, name=None)\n",
      "     |      Produce a string tensor that encodes the state of a reader.\n",
      "     |      \n",
      "     |      Not all Readers support being serialized, so this can produce an\n",
      "     |      Unimplemented error.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: A name for the operation (optional).\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A string Tensor.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from ReaderBase:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  reader_ref\n",
      "     |      Op that implements the reader.\n",
      "     |  \n",
      "     |  supports_serialize\n",
      "     |      Whether the Reader implementation can serialize its state.\n",
      "    \n",
      "    constant_initializer = class Constant(Initializer)\n",
      "     |  Initializer that generates tensors with constant values.\n",
      "     |  \n",
      "     |  The resulting tensor is populated with values of type `dtype`, as\n",
      "     |  specified by arguments `value` following the desired `shape` of the\n",
      "     |  new tensor (see examples below).\n",
      "     |  \n",
      "     |  The argument `value` can be a constant value, or a list of values of type\n",
      "     |  `dtype`. If `value` is a list, then the length of the list must be less\n",
      "     |  than or equal to the number of elements implied by the desired shape of the\n",
      "     |  tensor. In the case where the total number of elements in `value` is less\n",
      "     |  than the number of elements required by the tensor shape, the last element\n",
      "     |  in `value` will be used to fill the remaining entries. If the total number of\n",
      "     |  elements in `value` is greater than the number of elements required by the\n",
      "     |  tensor shape, the initializer will raise a `ValueError`.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |    value: A Python scalar, list or tuple of values, or a N-dimensional numpy\n",
      "     |      array. All elements of the initialized variable will be set to the\n",
      "     |      corresponding value in the `value` argument.\n",
      "     |    dtype: Default data type, used if no `dtype` argument is provided when\n",
      "     |      calling the initializer.\n",
      "     |    verify_shape: Boolean that enables verification of the shape of `value`. If\n",
      "     |      `True`, the initializer will throw an error if the shape of `value` is not\n",
      "     |      compatible with the shape of the initialized tensor.\n",
      "     |  \n",
      "     |  Raises:\n",
      "     |    TypeError: If the input `value` is not one of the expected types.\n",
      "     |  \n",
      "     |  Examples:\n",
      "     |    The following example can be rewritten using a numpy.ndarray instead\n",
      "     |    of the `value` list, even reshaped, as shown in the two commented lines\n",
      "     |    below the `value` list initialization.\n",
      "     |  \n",
      "     |  ```python\n",
      "     |    >>> import numpy as np\n",
      "     |    >>> import tensorflow as tf\n",
      "     |  \n",
      "     |    >>> value = [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "     |    >>> # value = np.array(value)\n",
      "     |    >>> # value = value.reshape([2, 4])\n",
      "     |    >>> init = tf.compat.v1.constant_initializer(value)\n",
      "     |  \n",
      "     |    >>> print('fitting shape:')\n",
      "     |    >>> with tf.compat.v1.Session():\n",
      "     |    >>>   x = tf.compat.v1.get_variable('x', shape=[2, 4], initializer=init)\n",
      "     |    >>>   x.initializer.run()\n",
      "     |    >>>   print(x.eval())\n",
      "     |  \n",
      "     |    fitting shape:\n",
      "     |    [[ 0.  1.  2.  3.]\n",
      "     |     [ 4.  5.  6.  7.]]\n",
      "     |  \n",
      "     |    >>> print('larger shape:')\n",
      "     |    >>> with tf.compat.v1.Session():\n",
      "     |    >>>   x = tf.compat.v1.get_variable('x', shape=[3, 4], initializer=init)\n",
      "     |    >>>   x.initializer.run()\n",
      "     |    >>>   print(x.eval())\n",
      "     |  \n",
      "     |    larger shape:\n",
      "     |    [[ 0.  1.  2.  3.]\n",
      "     |     [ 4.  5.  6.  7.]\n",
      "     |     [ 7.  7.  7.  7.]]\n",
      "     |  \n",
      "     |    >>> print('smaller shape:')\n",
      "     |    >>> with tf.compat.v1.Session():\n",
      "     |    >>>   x = tf.compat.v1.get_variable('x', shape=[2, 3], initializer=init)\n",
      "     |  \n",
      "     |    ValueError: Too many elements provided. Needed at most 6, but received 8\n",
      "     |  \n",
      "     |    >>> print('shape verification:')\n",
      "     |    >>> init_verify = tf.compat.v1.constant_initializer(value,\n",
      "     |    verify_shape=True)\n",
      "     |    >>> with tf.compat.v1.Session():\n",
      "     |    >>>   x = tf.compat.v1.get_variable('x', shape=[3, 4],\n",
      "     |    initializer=init_verify)\n",
      "     |  \n",
      "     |    TypeError: Expected Tensor's shape: (3, 4), got (8,).\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Constant\n",
      "     |      Initializer\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, shape, dtype=None, partition_info=None, verify_shape=None)\n",
      "     |      Returns a tensor object initialized as specified by the initializer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: Shape of the tensor.\n",
      "     |        dtype: Optional dtype of the tensor. If not provided use the initializer\n",
      "     |          dtype.\n",
      "     |        partition_info: Optional information about the possible partitioning of a\n",
      "     |          tensor.\n",
      "     |  \n",
      "     |  __init__(self, value=0, dtype=tf.float32, verify_shape=False)\n",
      "     |      DEPRECATED FUNCTION ARGUMENTS (deprecated arguments)\n",
      "     |      \n",
      "     |      Warning: SOME ARGUMENTS ARE DEPRECATED: `(dtype)`. They will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "     |      \n",
      "     |      Warning: SOME ARGUMENTS ARE DEPRECATED: `(verify_shape)`. They will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Objects must now be the required shape or no shape can be specified\n",
      "     |  \n",
      "     |  get_config(self)\n",
      "     |      Returns the configuration of the initializer as a JSON-serializable dict.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A JSON-serializable Python dict.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from Initializer:\n",
      "     |  \n",
      "     |  from_config(config) from builtins.type\n",
      "     |      Instantiates an initializer from a configuration dictionary.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      initializer = RandomUniform(-1, 1)\n",
      "     |      config = initializer.get_config()\n",
      "     |      initializer = RandomUniform.from_config(config)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        config: A Python dictionary. It will typically be the output of\n",
      "     |          `get_config`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An Initializer instance.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Initializer:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    glorot_normal_initializer = class GlorotNormal(VarianceScaling)\n",
      "     |  The Glorot normal initializer, also called Xavier normal initializer.\n",
      "     |  \n",
      "     |  It draws samples from a truncated normal distribution centered on 0\n",
      "     |  with standard deviation (after truncation) given by\n",
      "     |  `stddev = sqrt(2 / (fan_in + fan_out))` where `fan_in` is the number\n",
      "     |  of input units in the weight tensor and `fan_out` is the number of\n",
      "     |  output units in the weight tensor.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |    seed: A Python integer. Used to create random seeds. See\n",
      "     |      `tf.compat.v1.set_random_seed` for behavior.\n",
      "     |    dtype: Default data type, used if no `dtype` argument is provided when\n",
      "     |      calling the initializer. Only floating point types are supported.\n",
      "     |  References:\n",
      "     |      [Glorot et al., 2010](http://proceedings.mlr.press/v9/glorot10a.html)\n",
      "     |      ([pdf](http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf))\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      GlorotNormal\n",
      "     |      VarianceScaling\n",
      "     |      Initializer\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, seed=None, dtype=tf.float32)\n",
      "     |      DEPRECATED FUNCTION ARGUMENTS\n",
      "     |      \n",
      "     |      Warning: SOME ARGUMENTS ARE DEPRECATED: `(dtype)`. They will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "     |  \n",
      "     |  get_config(self)\n",
      "     |      Returns the configuration of the initializer as a JSON-serializable dict.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A JSON-serializable Python dict.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from VarianceScaling:\n",
      "     |  \n",
      "     |  __call__(self, shape, dtype=None, partition_info=None)\n",
      "     |      Returns a tensor object initialized as specified by the initializer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: Shape of the tensor.\n",
      "     |        dtype: Optional dtype of the tensor. If not provided use the initializer\n",
      "     |          dtype.\n",
      "     |        partition_info: Optional information about the possible partitioning of a\n",
      "     |          tensor.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from Initializer:\n",
      "     |  \n",
      "     |  from_config(config) from builtins.type\n",
      "     |      Instantiates an initializer from a configuration dictionary.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      initializer = RandomUniform(-1, 1)\n",
      "     |      config = initializer.get_config()\n",
      "     |      initializer = RandomUniform.from_config(config)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        config: A Python dictionary. It will typically be the output of\n",
      "     |          `get_config`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An Initializer instance.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Initializer:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    glorot_uniform_initializer = class GlorotUniform(VarianceScaling)\n",
      "     |  The Glorot uniform initializer, also called Xavier uniform initializer.\n",
      "     |  \n",
      "     |  It draws samples from a uniform distribution within [-limit, limit]\n",
      "     |  where `limit` is `sqrt(6 / (fan_in + fan_out))`\n",
      "     |  where `fan_in` is the number of input units in the weight tensor\n",
      "     |  and `fan_out` is the number of output units in the weight tensor.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |    seed: A Python integer. Used to create random seeds. See\n",
      "     |      `tf.compat.v1.set_random_seed` for behavior.\n",
      "     |    dtype: Default data type, used if no `dtype` argument is provided when\n",
      "     |      calling the initializer. Only floating point types are supported.\n",
      "     |  References:\n",
      "     |      [Glorot et al., 2010](http://proceedings.mlr.press/v9/glorot10a.html)\n",
      "     |      ([pdf](http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf))\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      GlorotUniform\n",
      "     |      VarianceScaling\n",
      "     |      Initializer\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, seed=None, dtype=tf.float32)\n",
      "     |      DEPRECATED FUNCTION ARGUMENTS\n",
      "     |      \n",
      "     |      Warning: SOME ARGUMENTS ARE DEPRECATED: `(dtype)`. They will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "     |  \n",
      "     |  get_config(self)\n",
      "     |      Returns the configuration of the initializer as a JSON-serializable dict.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A JSON-serializable Python dict.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from VarianceScaling:\n",
      "     |  \n",
      "     |  __call__(self, shape, dtype=None, partition_info=None)\n",
      "     |      Returns a tensor object initialized as specified by the initializer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: Shape of the tensor.\n",
      "     |        dtype: Optional dtype of the tensor. If not provided use the initializer\n",
      "     |          dtype.\n",
      "     |        partition_info: Optional information about the possible partitioning of a\n",
      "     |          tensor.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from Initializer:\n",
      "     |  \n",
      "     |  from_config(config) from builtins.type\n",
      "     |      Instantiates an initializer from a configuration dictionary.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      initializer = RandomUniform(-1, 1)\n",
      "     |      config = initializer.get_config()\n",
      "     |      initializer = RandomUniform.from_config(config)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        config: A Python dictionary. It will typically be the output of\n",
      "     |          `get_config`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An Initializer instance.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Initializer:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class name_scope(builtins.object)\n",
      "     |  A context manager for use when defining a Python op.\n",
      "     |  \n",
      "     |  This context manager validates that the given `values` are from the\n",
      "     |  same graph, makes that graph the default graph, and pushes a\n",
      "     |  name scope in that graph (see\n",
      "     |  `tf.Graph.name_scope`\n",
      "     |  for more details on that).\n",
      "     |  \n",
      "     |  For example, to define a new Python op called `my_op`:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  def my_op(a, b, c, name=None):\n",
      "     |    with tf.name_scope(name, \"MyOp\", [a, b, c]) as scope:\n",
      "     |      a = tf.convert_to_tensor(a, name=\"a\")\n",
      "     |      b = tf.convert_to_tensor(b, name=\"b\")\n",
      "     |      c = tf.convert_to_tensor(c, name=\"c\")\n",
      "     |      # Define some computation that uses `a`, `b`, and `c`.\n",
      "     |      return foo_op(..., name=scope)\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __enter__(self)\n",
      "     |      Start the scope block.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        The scope name.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: if neither `name` nor `default_name` is provided\n",
      "     |          but `values` are.\n",
      "     |  \n",
      "     |  __exit__(self, type_arg, value_arg, traceback_arg)\n",
      "     |  \n",
      "     |  __init__(self, name, default_name=None, values=None)\n",
      "     |      Initialize the context manager.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name: The name argument that is passed to the op function.\n",
      "     |        default_name: The default name to use if the `name` argument is `None`.\n",
      "     |        values: The list of `Tensor` arguments that are passed to the op function.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        TypeError: if `default_name` is passed in but not a string.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  name\n",
      "    \n",
      "    ones_initializer = class Ones(Initializer)\n",
      "     |  Initializer that generates tensors initialized to 1.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Ones\n",
      "     |      Initializer\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, shape, dtype=None, partition_info=None)\n",
      "     |      Returns a tensor object initialized as specified by the initializer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: Shape of the tensor.\n",
      "     |        dtype: Optional dtype of the tensor. If not provided use the initializer\n",
      "     |          dtype.\n",
      "     |        partition_info: Optional information about the possible partitioning of a\n",
      "     |          tensor.\n",
      "     |  \n",
      "     |  __init__(self, dtype=tf.float32)\n",
      "     |      DEPRECATED FUNCTION ARGUMENTS\n",
      "     |      \n",
      "     |      Warning: SOME ARGUMENTS ARE DEPRECATED: `(dtype)`. They will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "     |  \n",
      "     |  get_config(self)\n",
      "     |      Returns the configuration of the initializer as a JSON-serializable dict.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A JSON-serializable Python dict.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from Initializer:\n",
      "     |  \n",
      "     |  from_config(config) from builtins.type\n",
      "     |      Instantiates an initializer from a configuration dictionary.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      initializer = RandomUniform(-1, 1)\n",
      "     |      config = initializer.get_config()\n",
      "     |      initializer = RandomUniform.from_config(config)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        config: A Python dictionary. It will typically be the output of\n",
      "     |          `get_config`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An Initializer instance.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Initializer:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    orthogonal_initializer = class Orthogonal(Initializer)\n",
      "     |  Initializer that generates an orthogonal matrix.\n",
      "     |  \n",
      "     |  If the shape of the tensor to initialize is two-dimensional, it is initialized\n",
      "     |  with an orthogonal matrix obtained from the QR decomposition of a matrix of\n",
      "     |  random numbers drawn from a normal distribution.\n",
      "     |  If the matrix has fewer rows than columns then the output will have orthogonal\n",
      "     |  rows. Otherwise, the output will have orthogonal columns.\n",
      "     |  \n",
      "     |  If the shape of the tensor to initialize is more than two-dimensional,\n",
      "     |  a matrix of shape `(shape[0] * ... * shape[n - 2], shape[n - 1])`\n",
      "     |  is initialized, where `n` is the length of the shape vector.\n",
      "     |  The matrix is subsequently reshaped to give a tensor of the desired shape.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |    gain: multiplicative factor to apply to the orthogonal matrix\n",
      "     |    seed: A Python integer. Used to create random seeds. See\n",
      "     |      `tf.compat.v1.set_random_seed` for behavior.\n",
      "     |    dtype: Default data type, used if no `dtype` argument is provided when\n",
      "     |      calling the initializer. Only floating point types are supported.\n",
      "     |  References:\n",
      "     |      [Saxe et al., 2014](https://openreview.net/forum?id=_wzZwKpTDF_9C)\n",
      "     |      ([pdf](https://arxiv.org/pdf/1312.6120.pdf))\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Orthogonal\n",
      "     |      Initializer\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, shape, dtype=None, partition_info=None)\n",
      "     |      Returns a tensor object initialized as specified by the initializer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: Shape of the tensor.\n",
      "     |        dtype: Optional dtype of the tensor. If not provided use the initializer\n",
      "     |          dtype.\n",
      "     |        partition_info: Optional information about the possible partitioning of a\n",
      "     |          tensor.\n",
      "     |  \n",
      "     |  __init__(self, gain=1.0, seed=None, dtype=tf.float32)\n",
      "     |      DEPRECATED FUNCTION ARGUMENTS\n",
      "     |      \n",
      "     |      Warning: SOME ARGUMENTS ARE DEPRECATED: `(dtype)`. They will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "     |  \n",
      "     |  get_config(self)\n",
      "     |      Returns the configuration of the initializer as a JSON-serializable dict.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A JSON-serializable Python dict.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from Initializer:\n",
      "     |  \n",
      "     |  from_config(config) from builtins.type\n",
      "     |      Instantiates an initializer from a configuration dictionary.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      initializer = RandomUniform(-1, 1)\n",
      "     |      config = initializer.get_config()\n",
      "     |      initializer = RandomUniform.from_config(config)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        config: A Python dictionary. It will typically be the output of\n",
      "     |          `get_config`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An Initializer instance.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Initializer:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    random_normal_initializer = class RandomNormal(Initializer)\n",
      "     |  Initializer that generates tensors with a normal distribution.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |    mean: a python scalar or a scalar tensor. Mean of the random values to\n",
      "     |      generate.\n",
      "     |    stddev: a python scalar or a scalar tensor. Standard deviation of the random\n",
      "     |      values to generate.\n",
      "     |    seed: A Python integer. Used to create random seeds. See\n",
      "     |      `tf.compat.v1.set_random_seed` for behavior.\n",
      "     |    dtype: Default data type, used if no `dtype` argument is provided when\n",
      "     |      calling the initializer. Only floating point types are supported.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      RandomNormal\n",
      "     |      Initializer\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, shape, dtype=None, partition_info=None)\n",
      "     |      Returns a tensor object initialized as specified by the initializer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: Shape of the tensor.\n",
      "     |        dtype: Optional dtype of the tensor. If not provided use the initializer\n",
      "     |          dtype.\n",
      "     |        partition_info: Optional information about the possible partitioning of a\n",
      "     |          tensor.\n",
      "     |  \n",
      "     |  __init__(self, mean=0.0, stddev=1.0, seed=None, dtype=tf.float32)\n",
      "     |      DEPRECATED FUNCTION ARGUMENTS\n",
      "     |      \n",
      "     |      Warning: SOME ARGUMENTS ARE DEPRECATED: `(dtype)`. They will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "     |  \n",
      "     |  get_config(self)\n",
      "     |      Returns the configuration of the initializer as a JSON-serializable dict.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A JSON-serializable Python dict.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from Initializer:\n",
      "     |  \n",
      "     |  from_config(config) from builtins.type\n",
      "     |      Instantiates an initializer from a configuration dictionary.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      initializer = RandomUniform(-1, 1)\n",
      "     |      config = initializer.get_config()\n",
      "     |      initializer = RandomUniform.from_config(config)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        config: A Python dictionary. It will typically be the output of\n",
      "     |          `get_config`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An Initializer instance.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Initializer:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    random_uniform_initializer = class RandomUniform(Initializer)\n",
      "     |  Initializer that generates tensors with a uniform distribution.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |    minval: A python scalar or a scalar tensor. Lower bound of the range of\n",
      "     |      random values to generate.\n",
      "     |    maxval: A python scalar or a scalar tensor. Upper bound of the range of\n",
      "     |      random values to generate.  Defaults to 1 for float types.\n",
      "     |    seed: A Python integer. Used to create random seeds. See\n",
      "     |      `tf.compat.v1.set_random_seed` for behavior.\n",
      "     |    dtype: Default data type, used if no `dtype` argument is provided when\n",
      "     |      calling the initializer.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      RandomUniform\n",
      "     |      Initializer\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, shape, dtype=None, partition_info=None)\n",
      "     |      Returns a tensor object initialized as specified by the initializer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: Shape of the tensor.\n",
      "     |        dtype: Optional dtype of the tensor. If not provided use the initializer\n",
      "     |          dtype.\n",
      "     |        partition_info: Optional information about the possible partitioning of a\n",
      "     |          tensor.\n",
      "     |  \n",
      "     |  __init__(self, minval=0, maxval=None, seed=None, dtype=tf.float32)\n",
      "     |      DEPRECATED FUNCTION ARGUMENTS\n",
      "     |      \n",
      "     |      Warning: SOME ARGUMENTS ARE DEPRECATED: `(dtype)`. They will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "     |  \n",
      "     |  get_config(self)\n",
      "     |      Returns the configuration of the initializer as a JSON-serializable dict.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A JSON-serializable Python dict.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from Initializer:\n",
      "     |  \n",
      "     |  from_config(config) from builtins.type\n",
      "     |      Instantiates an initializer from a configuration dictionary.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      initializer = RandomUniform(-1, 1)\n",
      "     |      config = initializer.get_config()\n",
      "     |      initializer = RandomUniform.from_config(config)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        config: A Python dictionary. It will typically be the output of\n",
      "     |          `get_config`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An Initializer instance.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Initializer:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    truncated_normal_initializer = class TruncatedNormal(Initializer)\n",
      "     |  Initializer that generates a truncated normal distribution.\n",
      "     |  \n",
      "     |  These values are similar to values from a `random_normal_initializer`\n",
      "     |  except that values more than two standard deviations from the mean\n",
      "     |  are discarded and re-drawn. This is the recommended initializer for\n",
      "     |  neural network weights and filters.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |    mean: a python scalar or a scalar tensor. Mean of the random values to\n",
      "     |      generate.\n",
      "     |    stddev: a python scalar or a scalar tensor. Standard deviation of the random\n",
      "     |      values to generate.\n",
      "     |    seed: A Python integer. Used to create random seeds. See\n",
      "     |      `tf.compat.v1.set_random_seed` for behavior.\n",
      "     |    dtype: Default data type, used if no `dtype` argument is provided when\n",
      "     |      calling the initializer. Only floating point types are supported.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      TruncatedNormal\n",
      "     |      Initializer\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, shape, dtype=None, partition_info=None)\n",
      "     |      Returns a tensor object initialized as specified by the initializer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: Shape of the tensor.\n",
      "     |        dtype: Optional dtype of the tensor. If not provided use the initializer\n",
      "     |          dtype.\n",
      "     |        partition_info: Optional information about the possible partitioning of a\n",
      "     |          tensor.\n",
      "     |  \n",
      "     |  __init__(self, mean=0.0, stddev=1.0, seed=None, dtype=tf.float32)\n",
      "     |      DEPRECATED FUNCTION ARGUMENTS\n",
      "     |      \n",
      "     |      Warning: SOME ARGUMENTS ARE DEPRECATED: `(dtype)`. They will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "     |  \n",
      "     |  get_config(self)\n",
      "     |      Returns the configuration of the initializer as a JSON-serializable dict.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A JSON-serializable Python dict.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from Initializer:\n",
      "     |  \n",
      "     |  from_config(config) from builtins.type\n",
      "     |      Instantiates an initializer from a configuration dictionary.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      initializer = RandomUniform(-1, 1)\n",
      "     |      config = initializer.get_config()\n",
      "     |      initializer = RandomUniform.from_config(config)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        config: A Python dictionary. It will typically be the output of\n",
      "     |          `get_config`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An Initializer instance.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Initializer:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    uniform_unit_scaling_initializer = class UniformUnitScaling(Initializer)\n",
      "     |  Initializer that generates tensors without scaling variance.\n",
      "     |  \n",
      "     |  When initializing a deep network, it is in principle advantageous to keep\n",
      "     |  the scale of the input variance constant, so it does not explode or diminish\n",
      "     |  by reaching the final layer. If the input is `x` and the operation `x * W`,\n",
      "     |  and we want to initialize `W` uniformly at random, we need to pick `W` from\n",
      "     |  \n",
      "     |      [-sqrt(3) / sqrt(dim), sqrt(3) / sqrt(dim)]\n",
      "     |  \n",
      "     |  to keep the scale intact, where `dim = W.shape[0]` (the size of the input).\n",
      "     |  A similar calculation for convolutional networks gives an analogous result\n",
      "     |  with `dim` equal to the product of the first 3 dimensions.  When\n",
      "     |  nonlinearities are present, we need to multiply this by a constant `factor`.\n",
      "     |  See (Sussillo et al., 2014) for deeper motivation, experiments\n",
      "     |  and the calculation of constants. In section 2.3 there, the constants were\n",
      "     |  numerically computed: for a linear layer it's 1.0, relu: ~1.43, tanh: ~1.15.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |    factor: Float.  A multiplicative factor by which the values will be scaled.\n",
      "     |    seed: A Python integer. Used to create random seeds. See\n",
      "     |      `tf.compat.v1.set_random_seed` for behavior.\n",
      "     |    dtype: Default data type, used if no `dtype` argument is provided when\n",
      "     |      calling the initializer. Only floating point types are supported.\n",
      "     |  References:\n",
      "     |      [Sussillo et al., 2014](https://arxiv.org/abs/1412.6558)\n",
      "     |      ([pdf](http://arxiv.org/pdf/1412.6558.pdf))\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      UniformUnitScaling\n",
      "     |      Initializer\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, shape, dtype=None, partition_info=None)\n",
      "     |      Returns a tensor object initialized as specified by the initializer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: Shape of the tensor.\n",
      "     |        dtype: Optional dtype of the tensor. If not provided use the initializer\n",
      "     |          dtype.\n",
      "     |        partition_info: Optional information about the possible partitioning of a\n",
      "     |          tensor.\n",
      "     |  \n",
      "     |  __init__(self, factor=1.0, seed=None, dtype=tf.float32)\n",
      "     |      DEPRECATED FUNCTION (deprecated arguments)\n",
      "     |      \n",
      "     |      Warning: SOME ARGUMENTS ARE DEPRECATED: `(dtype)`. They will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "     |      \n",
      "     |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n",
      "     |  \n",
      "     |  get_config(self)\n",
      "     |      Returns the configuration of the initializer as a JSON-serializable dict.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A JSON-serializable Python dict.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from Initializer:\n",
      "     |  \n",
      "     |  from_config(config) from builtins.type\n",
      "     |      Instantiates an initializer from a configuration dictionary.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      initializer = RandomUniform(-1, 1)\n",
      "     |      config = initializer.get_config()\n",
      "     |      initializer = RandomUniform.from_config(config)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        config: A Python dictionary. It will typically be the output of\n",
      "     |          `get_config`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An Initializer instance.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Initializer:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class variable_scope(builtins.object)\n",
      "     |  A context manager for defining ops that creates variables (layers).\n",
      "     |  \n",
      "     |  This context manager validates that the (optional) `values` are from the same\n",
      "     |  graph, ensures that graph is the default graph, and pushes a name scope and a\n",
      "     |  variable scope.\n",
      "     |  \n",
      "     |  If `name_or_scope` is not None, it is used as is. If `name_or_scope` is None,\n",
      "     |  then `default_name` is used.  In that case, if the same name has been\n",
      "     |  previously used in the same scope, it will be made unique by appending `_N`\n",
      "     |  to it.\n",
      "     |  \n",
      "     |  Variable scope allows you to create new variables and to share already created\n",
      "     |  ones while providing checks to not create or share by accident. For details,\n",
      "     |  see the [Variable Scope How To](https://tensorflow.org/guide/variables), here\n",
      "     |  we present only a few basic examples.\n",
      "     |  \n",
      "     |  Simple example of how to create a new variable:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  with tf.compat.v1.variable_scope(\"foo\"):\n",
      "     |      with tf.compat.v1.variable_scope(\"bar\"):\n",
      "     |          v = tf.compat.v1.get_variable(\"v\", [1])\n",
      "     |          assert v.name == \"foo/bar/v:0\"\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Simple example of how to reenter a premade variable scope safely:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  with tf.compat.v1.variable_scope(\"foo\") as vs:\n",
      "     |    pass\n",
      "     |  \n",
      "     |  # Re-enter the variable scope.\n",
      "     |  with tf.compat.v1.variable_scope(vs,\n",
      "     |                         auxiliary_name_scope=False) as vs1:\n",
      "     |    # Restore the original name_scope.\n",
      "     |    with tf.name_scope(vs1.original_name_scope):\n",
      "     |        v = tf.compat.v1.get_variable(\"v\", [1])\n",
      "     |        assert v.name == \"foo/v:0\"\n",
      "     |        c = tf.constant([1], name=\"c\")\n",
      "     |        assert c.name == \"foo/c:0\"\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Basic example of sharing a variable AUTO_REUSE:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  def foo():\n",
      "     |    with tf.compat.v1.variable_scope(\"foo\", reuse=tf.compat.v1.AUTO_REUSE):\n",
      "     |      v = tf.compat.v1.get_variable(\"v\", [1])\n",
      "     |    return v\n",
      "     |  \n",
      "     |  v1 = foo()  # Creates v.\n",
      "     |  v2 = foo()  # Gets the same, existing v.\n",
      "     |  assert v1 == v2\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Basic example of sharing a variable with reuse=True:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  with tf.compat.v1.variable_scope(\"foo\"):\n",
      "     |      v = tf.compat.v1.get_variable(\"v\", [1])\n",
      "     |  with tf.compat.v1.variable_scope(\"foo\", reuse=True):\n",
      "     |      v1 = tf.compat.v1.get_variable(\"v\", [1])\n",
      "     |  assert v1 == v\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Sharing a variable by capturing a scope and setting reuse:\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  with tf.compat.v1.variable_scope(\"foo\") as scope:\n",
      "     |      v = tf.compat.v1.get_variable(\"v\", [1])\n",
      "     |      scope.reuse_variables()\n",
      "     |      v1 = tf.compat.v1.get_variable(\"v\", [1])\n",
      "     |  assert v1 == v\n",
      "     |  ```\n",
      "     |  \n",
      "     |  To prevent accidental sharing of variables, we raise an exception when getting\n",
      "     |  an existing variable in a non-reusing scope.\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  with tf.compat.v1.variable_scope(\"foo\"):\n",
      "     |      v = tf.compat.v1.get_variable(\"v\", [1])\n",
      "     |      v1 = tf.compat.v1.get_variable(\"v\", [1])\n",
      "     |      #  Raises ValueError(\"... v already exists ...\").\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Similarly, we raise an exception when trying to get a variable that does not\n",
      "     |  exist in reuse mode.\n",
      "     |  \n",
      "     |  ```python\n",
      "     |  with tf.compat.v1.variable_scope(\"foo\", reuse=True):\n",
      "     |      v = tf.compat.v1.get_variable(\"v\", [1])\n",
      "     |      #  Raises ValueError(\"... v does not exists ...\").\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Note that the `reuse` flag is inherited: if we open a reusing scope, then all\n",
      "     |  its sub-scopes become reusing as well.\n",
      "     |  \n",
      "     |  A note about name scoping: Setting `reuse` does not impact the naming of other\n",
      "     |  ops such as mult. See related discussion on\n",
      "     |  [github#6189](https://github.com/tensorflow/tensorflow/issues/6189)\n",
      "     |  \n",
      "     |  Note that up to and including version 1.0, it was allowed (though explicitly\n",
      "     |  discouraged) to pass False to the reuse argument, yielding undocumented\n",
      "     |  behaviour slightly different from None. Starting at 1.1.0 passing None and\n",
      "     |  False as reuse has exactly the same effect.\n",
      "     |  \n",
      "     |  A note about using variable scopes in multi-threaded environment: Variable\n",
      "     |  scopes are thread local, so one thread will not see another thread's current\n",
      "     |  scope. Also, when using `default_name`, unique scopes names are also generated\n",
      "     |  only on a per thread basis. If the same name was used within a different\n",
      "     |  thread, that doesn't prevent a new thread from creating the same scope.\n",
      "     |  However, the underlying variable store is shared across threads (within the\n",
      "     |  same graph). As such, if another thread tries to create a new variable with\n",
      "     |  the same name as a variable created by a previous thread, it will fail unless\n",
      "     |  reuse is True.\n",
      "     |  \n",
      "     |  Further, each thread starts with an empty variable scope. So if you wish to\n",
      "     |  preserve name prefixes from a scope from the main thread, you should capture\n",
      "     |  the main thread's scope and re-enter it in each thread. For e.g.\n",
      "     |  \n",
      "     |  ```\n",
      "     |  main_thread_scope = variable_scope.get_variable_scope()\n",
      "     |  \n",
      "     |  # Thread's target function:\n",
      "     |  def thread_target_fn(captured_scope):\n",
      "     |    with variable_scope.variable_scope(captured_scope):\n",
      "     |      # .... regular code for this thread\n",
      "     |  \n",
      "     |  \n",
      "     |  thread = threading.Thread(target=thread_target_fn, args=(main_thread_scope,))\n",
      "     |  ```\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __enter__(self)\n",
      "     |  \n",
      "     |  __exit__(self, type_arg, value_arg, traceback_arg)\n",
      "     |  \n",
      "     |  __init__(self, name_or_scope, default_name=None, values=None, initializer=None, regularizer=None, caching_device=None, partitioner=None, custom_getter=None, reuse=None, dtype=None, use_resource=None, constraint=None, auxiliary_name_scope=True)\n",
      "     |      Initialize the context manager.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        name_or_scope: `string` or `VariableScope`: the scope to open.\n",
      "     |        default_name: The default name to use if the `name_or_scope` argument is\n",
      "     |          `None`, this name will be uniquified. If name_or_scope is provided it\n",
      "     |          won't be used and therefore it is not required and can be None.\n",
      "     |        values: The list of `Tensor` arguments that are passed to the op function.\n",
      "     |        initializer: default initializer for variables within this scope.\n",
      "     |        regularizer: default regularizer for variables within this scope.\n",
      "     |        caching_device: default caching device for variables within this scope.\n",
      "     |        partitioner: default partitioner for variables within this scope.\n",
      "     |        custom_getter: default custom getter for variables within this scope.\n",
      "     |        reuse: `True`, None, or tf.compat.v1.AUTO_REUSE; if `True`, we go into\n",
      "     |          reuse mode for this scope as well as all sub-scopes; if\n",
      "     |          tf.compat.v1.AUTO_REUSE, we create variables if they do not exist, and\n",
      "     |          return them otherwise; if None, we inherit the parent scope's reuse\n",
      "     |          flag. When eager execution is enabled, new variables are always created\n",
      "     |          unless an EagerVariableStore or template is currently active.\n",
      "     |        dtype: type of variables created in this scope (defaults to the type in\n",
      "     |          the passed scope, or inherited from parent scope).\n",
      "     |        use_resource: If False, all variables will be regular Variables. If True,\n",
      "     |          experimental ResourceVariables with well-defined semantics will be used\n",
      "     |          instead. Defaults to False (will later change to True). When eager\n",
      "     |          execution is enabled this argument is always forced to be True.\n",
      "     |        constraint: An optional projection function to be applied to the variable\n",
      "     |          after being updated by an `Optimizer` (e.g. used to implement norm\n",
      "     |          constraints or value constraints for layer weights). The function must\n",
      "     |          take as input the unprojected Tensor representing the value of the\n",
      "     |          variable and return the Tensor for the projected value (which must have\n",
      "     |          the same shape). Constraints are not safe to use when doing asynchronous\n",
      "     |          distributed training.\n",
      "     |        auxiliary_name_scope: If `True`, we create an auxiliary name scope with\n",
      "     |          the scope. If `False`, we don't create it. Note that the argument is not\n",
      "     |          inherited, and it only takes effect for once when creating. You should\n",
      "     |          only use it for re-entering a premade variable scope.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A scope that can be captured and reused.\n",
      "     |      \n",
      "     |      Raises:\n",
      "     |        ValueError: when trying to reuse within a create scope, or create within\n",
      "     |          a reuse scope.\n",
      "     |        TypeError: when the types of some arguments are not appropriate.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    variance_scaling_initializer = class VarianceScaling(Initializer)\n",
      "     |  Initializer capable of adapting its scale to the shape of weights tensors.\n",
      "     |  \n",
      "     |  With `distribution=\"truncated_normal\" or \"untruncated_normal\"`,\n",
      "     |  samples are drawn from a truncated/untruncated normal\n",
      "     |  distribution with a mean of zero and a standard deviation (after truncation,\n",
      "     |  if used) `stddev = sqrt(scale / n)`\n",
      "     |  where n is:\n",
      "     |    - number of input units in the weight tensor, if mode = \"fan_in\"\n",
      "     |    - number of output units, if mode = \"fan_out\"\n",
      "     |    - average of the numbers of input and output units, if mode = \"fan_avg\"\n",
      "     |  \n",
      "     |  With `distribution=\"uniform\"`, samples are drawn from a uniform distribution\n",
      "     |  within [-limit, limit], with `limit = sqrt(3 * scale / n)`.\n",
      "     |  \n",
      "     |  Args:\n",
      "     |    scale: Scaling factor (positive float).\n",
      "     |    mode: One of \"fan_in\", \"fan_out\", \"fan_avg\".\n",
      "     |    distribution: Random distribution to use. One of \"normal\", \"uniform\".\n",
      "     |    seed: A Python integer. Used to create random seeds. See\n",
      "     |      `tf.compat.v1.set_random_seed` for behavior.\n",
      "     |    dtype: Default data type, used if no `dtype` argument is provided when\n",
      "     |      calling the initializer. Only floating point types are supported.\n",
      "     |  \n",
      "     |  Raises:\n",
      "     |    ValueError: In case of an invalid value for the \"scale\", mode\" or\n",
      "     |      \"distribution\" arguments.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      VarianceScaling\n",
      "     |      Initializer\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, shape, dtype=None, partition_info=None)\n",
      "     |      Returns a tensor object initialized as specified by the initializer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: Shape of the tensor.\n",
      "     |        dtype: Optional dtype of the tensor. If not provided use the initializer\n",
      "     |          dtype.\n",
      "     |        partition_info: Optional information about the possible partitioning of a\n",
      "     |          tensor.\n",
      "     |  \n",
      "     |  __init__(self, scale=1.0, mode='fan_in', distribution='truncated_normal', seed=None, dtype=tf.float32)\n",
      "     |      DEPRECATED FUNCTION ARGUMENT VALUES (deprecated arguments)\n",
      "     |      \n",
      "     |      Warning: SOME ARGUMENTS ARE DEPRECATED: `(dtype)`. They will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "     |      \n",
      "     |      Warning: SOME ARGUMENT VALUES ARE DEPRECATED: `(distribution='normal')`. They will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      `normal` is a deprecated alias for `truncated_normal`\n",
      "     |  \n",
      "     |  get_config(self)\n",
      "     |      Returns the configuration of the initializer as a JSON-serializable dict.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A JSON-serializable Python dict.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from Initializer:\n",
      "     |  \n",
      "     |  from_config(config) from builtins.type\n",
      "     |      Instantiates an initializer from a configuration dictionary.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      initializer = RandomUniform(-1, 1)\n",
      "     |      config = initializer.get_config()\n",
      "     |      initializer = RandomUniform.from_config(config)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        config: A Python dictionary. It will typically be the output of\n",
      "     |          `get_config`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An Initializer instance.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Initializer:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    zeros_initializer = class Zeros(Initializer)\n",
      "     |  Initializer that generates tensors initialized to 0.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Zeros\n",
      "     |      Initializer\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, shape, dtype=None, partition_info=None)\n",
      "     |      Returns a tensor object initialized as specified by the initializer.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        shape: Shape of the tensor.\n",
      "     |        dtype: Optional dtype of the tensor. If not provided use the initializer\n",
      "     |          dtype.\n",
      "     |        partition_info: Optional information about the possible partitioning of a\n",
      "     |          tensor.\n",
      "     |  \n",
      "     |  __init__(self, dtype=tf.float32)\n",
      "     |      DEPRECATED FUNCTION ARGUMENTS\n",
      "     |      \n",
      "     |      Warning: SOME ARGUMENTS ARE DEPRECATED: `(dtype)`. They will be removed in a future version.\n",
      "     |      Instructions for updating:\n",
      "     |      Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "     |  \n",
      "     |  get_config(self)\n",
      "     |      Returns the configuration of the initializer as a JSON-serializable dict.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        A JSON-serializable Python dict.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from Initializer:\n",
      "     |  \n",
      "     |  from_config(config) from builtins.type\n",
      "     |      Instantiates an initializer from a configuration dictionary.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |      \n",
      "     |      ```python\n",
      "     |      initializer = RandomUniform(-1, 1)\n",
      "     |      config = initializer.get_config()\n",
      "     |      initializer = RandomUniform.from_config(config)\n",
      "     |      ```\n",
      "     |      \n",
      "     |      Args:\n",
      "     |        config: A Python dictionary. It will typically be the output of\n",
      "     |          `get_config`.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |        An Initializer instance.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from Initializer:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "FUNCTIONS\n",
      "    Assert(condition, data, summarize=None, name=None)\n",
      "        Asserts that the given condition is true.\n",
      "        \n",
      "        If `condition` evaluates to false, print the list of tensors in `data`.\n",
      "        `summarize` determines how many entries of the tensors to print.\n",
      "        \n",
      "        NOTE: In graph mode, to ensure that Assert executes, one usually attaches\n",
      "        a dependency:\n",
      "        \n",
      "        ```python\n",
      "        # Ensure maximum element of x is smaller or equal to 1\n",
      "        assert_op = tf.Assert(tf.less_equal(tf.reduce_max(x), 1.), [x])\n",
      "        with tf.control_dependencies([assert_op]):\n",
      "          ... code using x ...\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          condition: The condition to evaluate.\n",
      "          data: The tensors to print out when condition is false.\n",
      "          summarize: Print this many entries of each tensor.\n",
      "          name: A name for this operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          assert_op: An `Operation` that, when executed, raises a\n",
      "          `tf.errors.InvalidArgumentError` if `condition` is not true.\n",
      "          @compatibility(eager)\n",
      "          returns None\n",
      "          @end_compatibility\n",
      "        \n",
      "        Raises:\n",
      "          @compatibility(eager)\n",
      "          `tf.errors.InvalidArgumentError` if `condition` is not true\n",
      "          @end_compatibility\n",
      "        \n",
      "        \n",
      "        **NOTE** The output of this function should be used.  If it is not, a warning will be logged.  To mark the output as used, call its .mark_used() method.\n",
      "    \n",
      "    NoGradient = no_gradient(op_type)\n",
      "        Specifies that ops of type `op_type` is not differentiable.\n",
      "        \n",
      "        This function should *not* be used for operations that have a\n",
      "        well-defined gradient that is not yet implemented.\n",
      "        \n",
      "        This function is only used when defining a new op type. It may be\n",
      "        used for ops such as `tf.size()` that are not differentiable.  For\n",
      "        example:\n",
      "        \n",
      "        ```python\n",
      "        tf.no_gradient(\"Size\")\n",
      "        ```\n",
      "        \n",
      "        The gradient computed for 'op_type' will then propagate zeros.\n",
      "        \n",
      "        For ops that have a well-defined gradient but are not yet implemented,\n",
      "        no declaration should be made, and an error *must* be thrown if\n",
      "        an attempt to request its gradient is made.\n",
      "        \n",
      "        Args:\n",
      "          op_type: The string type of an operation. This corresponds to the\n",
      "            `OpDef.name` field for the proto that defines the operation.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `op_type` is not a string.\n",
      "    \n",
      "    NotDifferentiable = no_gradient(op_type)\n",
      "        Specifies that ops of type `op_type` is not differentiable.\n",
      "        \n",
      "        This function should *not* be used for operations that have a\n",
      "        well-defined gradient that is not yet implemented.\n",
      "        \n",
      "        This function is only used when defining a new op type. It may be\n",
      "        used for ops such as `tf.size()` that are not differentiable.  For\n",
      "        example:\n",
      "        \n",
      "        ```python\n",
      "        tf.no_gradient(\"Size\")\n",
      "        ```\n",
      "        \n",
      "        The gradient computed for 'op_type' will then propagate zeros.\n",
      "        \n",
      "        For ops that have a well-defined gradient but are not yet implemented,\n",
      "        no declaration should be made, and an error *must* be thrown if\n",
      "        an attempt to request its gradient is made.\n",
      "        \n",
      "        Args:\n",
      "          op_type: The string type of an operation. This corresponds to the\n",
      "            `OpDef.name` field for the proto that defines the operation.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `op_type` is not a string.\n",
      "    \n",
      "    Print(input_, data, message=None, first_n=None, summarize=None, name=None)\n",
      "        Prints a list of tensors. (deprecated)\n",
      "        \n",
      "        Warning: THIS FUNCTION IS DEPRECATED. It will be removed after 2018-08-20.\n",
      "        Instructions for updating:\n",
      "        Use tf.print instead of tf.Print. Note that tf.print returns a no-output operator that directly prints the output. Outside of defuns or eager mode, this operator will not be executed unless it is directly specified in session.run or used as a control dependency for other operators. This is only a concern in graph mode. Below is an example of how to ensure tf.print executes in graph mode:\n",
      "        \n",
      "        \n",
      "        This is an identity op (behaves like `tf.identity`) with the side effect\n",
      "        of printing `data` when evaluating.\n",
      "        \n",
      "        Note: This op prints to the standard error. It is not currently compatible\n",
      "          with jupyter notebook (printing to the notebook *server's* output, not into\n",
      "          the notebook).\n",
      "        \n",
      "        Args:\n",
      "          input_: A tensor passed through this op.\n",
      "          data: A list of tensors to print out when op is evaluated.\n",
      "          message: A string, prefix of the error message.\n",
      "          first_n: Only log `first_n` number of times. Negative numbers log always;\n",
      "            this is the default.\n",
      "          summarize: Only print this many entries of each tensor. If None, then a\n",
      "            maximum of 3 elements are printed per input tensor.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type and contents as `input_`.\n",
      "        \n",
      "              ```python\n",
      "          sess = tf.compat.v1.Session()\n",
      "          with sess.as_default():\n",
      "              tensor = tf.range(10)\n",
      "              print_op = tf.print(tensor)\n",
      "              with tf.control_dependencies([print_op]):\n",
      "                out = tf.add(tensor, tensor)\n",
      "              sess.run(out)\n",
      "              ```\n",
      "              Additionally, to use tf.print in python 2.7, users must make sure to import\n",
      "              the following:\n",
      "        \n",
      "        `from __future__ import print_function`\n",
      "    \n",
      "    abs(x, name=None)\n",
      "        Computes the absolute value of a tensor.\n",
      "        \n",
      "        Given a tensor of integer or floating-point values, this operation returns a\n",
      "        tensor of the same type, where each element contains the absolute value of the\n",
      "        corresponding element in the input.\n",
      "        \n",
      "        Given a tensor `x` of complex numbers, this operation returns a tensor of type\n",
      "        `float32` or `float64` that is the absolute value of each element in `x`. All\n",
      "        elements in `x` must be complex numbers of the form \\\\(a + bj\\\\). The\n",
      "        absolute value is computed as \\\\( \\sqrt{a^2 + b^2}\\\\).  For example:\n",
      "        ```python\n",
      "        x = tf.constant([[-2.25 + 4.75j], [-3.25 + 5.75j]])\n",
      "        tf.abs(x)  # [5.25594902, 6.60492229]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor` or `SparseTensor` of type `float16`, `float32`, `float64`,\n",
      "            `int32`, `int64`, `complex64` or `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` or `SparseTensor` the same size, type, and sparsity as `x` with\n",
      "            absolute values.\n",
      "          Note, for `complex64` or `complex128` input, the returned `Tensor` will be\n",
      "            of type `float32` or `float64`, respectively.\n",
      "        \n",
      "          If `x` is a `SparseTensor`, returns\n",
      "          `SparseTensor(x.indices, tf.math.abs(x.values, ...), x.dense_shape)`\n",
      "    \n",
      "    accumulate_n(inputs, shape=None, tensor_dtype=None, name=None)\n",
      "        Returns the element-wise sum of a list of tensors.\n",
      "        \n",
      "        Optionally, pass `shape` and `tensor_dtype` for shape and type checking,\n",
      "        otherwise, these are inferred.\n",
      "        \n",
      "        `accumulate_n` performs the same operation as `tf.math.add_n`, but\n",
      "        does not wait for all of its inputs to be ready before beginning to sum.\n",
      "        This approach can save memory if inputs are ready at different times, since\n",
      "        minimum temporary storage is proportional to the output size rather than the\n",
      "        inputs' size.\n",
      "        \n",
      "        `accumulate_n` is differentiable (but wasn't previous to TensorFlow 1.7).\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        a = tf.constant([[1, 2], [3, 4]])\n",
      "        b = tf.constant([[5, 0], [0, 6]])\n",
      "        tf.math.accumulate_n([a, b, a])  # [[7, 4], [6, 14]]\n",
      "        \n",
      "        # Explicitly pass shape and type\n",
      "        tf.math.accumulate_n([a, b, a], shape=[2, 2], tensor_dtype=tf.int32)\n",
      "                                                                       # [[7,  4],\n",
      "                                                                       #  [6, 14]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          inputs: A list of `Tensor` objects, each with same shape and type.\n",
      "          shape: Expected shape of elements of `inputs` (optional). Also controls the\n",
      "            output shape of this op, which may affect type inference in other ops. A\n",
      "            value of `None` means \"infer the input shape from the shapes in `inputs`\".\n",
      "          tensor_dtype: Expected data type of `inputs` (optional). A value of `None`\n",
      "            means \"infer the input dtype from `inputs[0]`\".\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of same shape and type as the elements of `inputs`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If `inputs` don't all have same shape and dtype or the shape\n",
      "          cannot be inferred.\n",
      "    \n",
      "    acos(x, name=None)\n",
      "        Computes acos of x element-wise.\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int32`, `int64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    acosh(x, name=None)\n",
      "        Computes inverse hyperbolic cosine of x element-wise.\n",
      "        \n",
      "        Given an input tensor, the function computes inverse hyperbolic cosine of every element.\n",
      "        Input range is `[1, inf]`. It returns `nan` if the input lies outside the range.\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([-2, -0.5, 1, 1.2, 200, 10000, float(\"inf\")])\n",
      "        tf.math.acosh(x) ==> [nan nan 0. 0.62236255 5.9914584 9.903487 inf]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    add(x, y, name=None)\n",
      "        Returns x + y element-wise.\n",
      "        \n",
      "        *NOTE*: `math.add` supports broadcasting. `AddN` does not. More about broadcasting\n",
      "        [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `int16`, `int32`, `int64`, `complex64`, `complex128`, `string`.\n",
      "          y: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    add_check_numerics_ops()\n",
      "        Connect a `tf.debugging.check_numerics` to every floating point tensor.\n",
      "        \n",
      "        `check_numerics` operations themselves are added for each `half`, `float`,\n",
      "        or `double` tensor in the current default graph. For all ops in the graph, the\n",
      "        `check_numerics` op for all of its (`half`, `float`, or `double`) inputs\n",
      "        is guaranteed to run before the `check_numerics` op on any of its outputs.\n",
      "        \n",
      "        Note: This API is not compatible with the use of `tf.cond` or\n",
      "        `tf.while_loop`, and will raise a `ValueError` if you attempt to call it\n",
      "        in such a graph.\n",
      "        \n",
      "        Returns:\n",
      "          A `group` op depending on all `check_numerics` ops added.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If the graph contains any numeric operations in a control flow\n",
      "            structure.\n",
      "          RuntimeError: If called with eager execution enabled.\n",
      "        \n",
      "        @compatibility(eager)\n",
      "        Not compatible with eager execution. To check for `Inf`s and `NaN`s under\n",
      "        eager execution, call `tfe.seterr(inf_or_nan='raise')` once before executing\n",
      "        the checked operations.\n",
      "        @end_compatibility\n",
      "    \n",
      "    add_n(inputs, name=None)\n",
      "        Adds all input tensors element-wise.\n",
      "        \n",
      "        Converts `IndexedSlices` objects into dense tensors prior to adding.\n",
      "        \n",
      "        `tf.math.add_n` performs the same operation as `tf.math.accumulate_n`, but it\n",
      "        waits for all of its inputs to be ready before beginning to sum.\n",
      "        This buffering can result in higher memory consumption when inputs are ready\n",
      "        at different times, since the minimum temporary storage required is\n",
      "        proportional to the input size rather than the output size.\n",
      "        \n",
      "        This op does not [broadcast](\n",
      "        https://docs.scipy.org/doc/numpy-1.13.0/user/basics.broadcasting.html)\n",
      "        its inputs. If you need broadcasting, use `tf.math.add` (or the `+` operator)\n",
      "        instead.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        a = tf.constant([[3, 5], [4, 8]])\n",
      "        b = tf.constant([[1, 6], [2, 9]])\n",
      "        tf.math.add_n([a, b, a])  # [[7, 16], [10, 25]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          inputs: A list of `tf.Tensor` or `tf.IndexedSlices` objects, each with same\n",
      "            shape and type.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of same shape and type as the elements of `inputs`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If `inputs` don't all have same shape and dtype or the shape\n",
      "          cannot be inferred.\n",
      "    \n",
      "    add_to_collection(name, value)\n",
      "        Wrapper for `Graph.add_to_collection()` using the default graph.\n",
      "        \n",
      "        See `tf.Graph.add_to_collection`\n",
      "        for more details.\n",
      "        \n",
      "        Args:\n",
      "          name: The key for the collection. For example, the `GraphKeys` class\n",
      "            contains many standard names for collections.\n",
      "          value: The value to add to the collection.  @compatibility(eager)\n",
      "            Collections are only supported in eager when variables are created inside\n",
      "            an EagerVariableStore (e.g. as part of a layer or template).\n",
      "            @end_compatibility\n",
      "    \n",
      "    add_to_collections(names, value)\n",
      "        Wrapper for `Graph.add_to_collections()` using the default graph.\n",
      "        \n",
      "        See `tf.Graph.add_to_collections`\n",
      "        for more details.\n",
      "        \n",
      "        Args:\n",
      "          names: The key for the collections. The `GraphKeys` class contains many\n",
      "            standard names for collections.\n",
      "          value: The value to add to the collections.  @compatibility(eager)\n",
      "            Collections are only supported in eager when variables are created inside\n",
      "            an EagerVariableStore (e.g. as part of a layer or template).\n",
      "            @end_compatibility\n",
      "    \n",
      "    all_variables()\n",
      "        Use `tf.compat.v1.global_variables` instead. (deprecated)\n",
      "        \n",
      "        Warning: THIS FUNCTION IS DEPRECATED. It will be removed after 2017-03-02.\n",
      "        Instructions for updating:\n",
      "        Please use tf.global_variables instead.\n",
      "    \n",
      "    angle(input, name=None)\n",
      "        Returns the element-wise argument of a complex (or real) tensor.\n",
      "        \n",
      "        Given a tensor `input`, this operation returns a tensor of type `float` that\n",
      "        is the argument of each element in `input` considered as a complex number.\n",
      "        \n",
      "        The elements in `input` are considered to be complex numbers of the form\n",
      "        \\\\(a + bj\\\\), where *a* is the real part and *b* is the imaginary part.\n",
      "        If `input` is real then *b* is zero by definition.\n",
      "        \n",
      "        The argument returned by this function is of the form \\\\(atan2(b, a)\\\\).\n",
      "        If `input` is real, a tensor of all zeros is returned.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```\n",
      "        input = tf.constant([-2.25 + 4.75j, 3.25 + 5.75j], dtype=tf.complex64)\n",
      "        tf.math.angle(input).numpy()\n",
      "        # ==> array([2.0131705, 1.056345 ], dtype=float32)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `float`, `double`,\n",
      "            `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `float32` or `float64`.\n",
      "    \n",
      "    arg_max(input, dimension, output_type=tf.int64, name=None)\n",
      "        Returns the index with the largest value across dimensions of a tensor.\n",
      "        \n",
      "        Note that in case of ties the identity of the return value is not guaranteed.\n",
      "        \n",
      "        Usage:\n",
      "          ```python\n",
      "          import tensorflow as tf\n",
      "          a = [1, 10, 26.9, 2.8, 166.32, 62.3]\n",
      "          b = tf.math.argmax(input = a)\n",
      "          c = tf.keras.backend.eval(b)\n",
      "          # c = 4\n",
      "          # here a[4] = 166.32 which is the largest element of a across axis 0\n",
      "          ```\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.\n",
      "          dimension: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            int32 or int64, must be in the range `[-rank(input), rank(input))`.\n",
      "            Describes which dimension of the input Tensor to reduce across. For vectors,\n",
      "            use dimension = 0.\n",
      "          output_type: An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `output_type`.\n",
      "    \n",
      "    arg_min(input, dimension, output_type=tf.int64, name=None)\n",
      "        Returns the index with the smallest value across dimensions of a tensor.\n",
      "        \n",
      "        Note that in case of ties the identity of the return value is not guaranteed.\n",
      "        \n",
      "        Usage:\n",
      "          ```python\n",
      "          import tensorflow as tf\n",
      "          a = [1, 10, 26.9, 2.8, 166.32, 62.3]\n",
      "          b = tf.math.argmin(input = a)\n",
      "          c = tf.keras.backend.eval(b)\n",
      "          # c = 0\n",
      "          # here a[0] = 1 which is the smallest element of a across axis 0\n",
      "          ```\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.\n",
      "          dimension: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            int32 or int64, must be in the range `[-rank(input), rank(input))`.\n",
      "            Describes which dimension of the input Tensor to reduce across. For vectors,\n",
      "            use dimension = 0.\n",
      "          output_type: An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `output_type`.\n",
      "    \n",
      "    argmax(input, axis=None, name=None, dimension=None, output_type=tf.int64)\n",
      "        Returns the index with the largest value across axes of a tensor. (deprecated arguments)\n",
      "        \n",
      "        Warning: SOME ARGUMENTS ARE DEPRECATED: `(dimension)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Use the `axis` argument instead\n",
      "        \n",
      "        Note that in case of ties the identity of the return value is not guaranteed.\n",
      "        \n",
      "        Usage:\n",
      "          ```python\n",
      "          import tensorflow as tf\n",
      "          a = [1, 10, 26.9, 2.8, 166.32, 62.3]\n",
      "          b = tf.math.argmax(input = a)\n",
      "          c = tf.keras.backend.eval(b)\n",
      "          # c = 4\n",
      "          # here a[4] = 166.32 which is the largest element of a across axis 0\n",
      "          ```\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.\n",
      "          axis: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            int32 or int64, must be in the range `[-rank(input), rank(input))`.\n",
      "            Describes which axis of the input Tensor to reduce across. For vectors,\n",
      "            use axis = 0.\n",
      "          output_type: An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `output_type`.\n",
      "    \n",
      "    argmin(input, axis=None, name=None, dimension=None, output_type=tf.int64)\n",
      "        Returns the index with the smallest value across axes of a tensor. (deprecated arguments)\n",
      "        \n",
      "        Warning: SOME ARGUMENTS ARE DEPRECATED: `(dimension)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Use the `axis` argument instead\n",
      "        \n",
      "        Note that in case of ties the identity of the return value is not guaranteed.\n",
      "        \n",
      "        Usage:\n",
      "          ```python\n",
      "          import tensorflow as tf\n",
      "          a = [1, 10, 26.9, 2.8, 166.32, 62.3]\n",
      "          b = tf.math.argmin(input = a)\n",
      "          c = tf.keras.backend.eval(b)\n",
      "          # c = 0\n",
      "          # here a[0] = 1 which is the smallest element of a across axis 0\n",
      "          ```\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.\n",
      "          axis: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            int32 or int64, must be in the range `[-rank(input), rank(input))`.\n",
      "            Describes which axis of the input Tensor to reduce across. For vectors,\n",
      "            use axis = 0.\n",
      "          output_type: An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `output_type`.\n",
      "    \n",
      "    argsort(values, axis=-1, direction='ASCENDING', stable=False, name=None)\n",
      "        Returns the indices of a tensor that give its sorted order along an axis.\n",
      "        \n",
      "        For a 1D tensor, `tf.gather(values, tf.argsort(values))` is equivalent to\n",
      "        `tf.sort(values)`. For higher dimensions, the output has the same shape as\n",
      "        `values`, but along the given axis, values represent the index of the sorted\n",
      "        element in that slice of the tensor at the given position.\n",
      "        \n",
      "        Usage:\n",
      "        \n",
      "        ```python\n",
      "        import tensorflow as tf\n",
      "        a = [1, 10, 26.9, 2.8, 166.32, 62.3]\n",
      "        b = tf.argsort(a,axis=-1,direction='ASCENDING',stable=False,name=None)\n",
      "        c = tf.keras.backend.eval(b)\n",
      "        # Here, c = [0 3 1 2 5 4]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          values: 1-D or higher numeric `Tensor`.\n",
      "          axis: The axis along which to sort. The default is -1, which sorts the last\n",
      "            axis.\n",
      "          direction: The direction in which to sort the values (`'ASCENDING'` or\n",
      "            `'DESCENDING'`).\n",
      "          stable: If True, equal elements in the original tensor will not be\n",
      "            re-ordered in the returned order. Unstable sort is not yet implemented,\n",
      "            but will eventually be the default for performance reasons. If you require\n",
      "            a stable order, pass `stable=True` for forwards compatibility.\n",
      "          name: Optional name for the operation.\n",
      "        \n",
      "        Returns:\n",
      "          An int32 `Tensor` with the same shape as `values`. The indices that would\n",
      "              sort each slice of the given `values` along the given `axis`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If axis is not a constant scalar, or the direction is invalid.\n",
      "    \n",
      "    as_dtype(type_value)\n",
      "        Converts the given `type_value` to a `DType`.\n",
      "        \n",
      "        Args:\n",
      "          type_value: A value that can be converted to a `tf.DType` object. This may\n",
      "            currently be a `tf.DType` object, a [`DataType`\n",
      "            enum](https://www.tensorflow.org/code/tensorflow/core/framework/types.proto),\n",
      "              a string type name, or a `numpy.dtype`.\n",
      "        \n",
      "        Returns:\n",
      "          A `DType` corresponding to `type_value`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `type_value` cannot be converted to a `DType`.\n",
      "    \n",
      "    as_string(input, precision=-1, scientific=False, shortest=False, width=-1, fill='', name=None)\n",
      "        Converts each entry in the given tensor to strings.\n",
      "        \n",
      "        Supports many numeric types and boolean.\n",
      "        \n",
      "        For Unicode, see the\n",
      "        [https://www.tensorflow.org/tutorials/representation/unicode](Working with Unicode text)\n",
      "        tutorial.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `int8`, `int16`, `int32`, `int64`, `complex64`, `complex128`, `float32`, `float64`, `bool`.\n",
      "          precision: An optional `int`. Defaults to `-1`.\n",
      "            The post-decimal precision to use for floating point numbers.\n",
      "            Only used if precision > -1.\n",
      "          scientific: An optional `bool`. Defaults to `False`.\n",
      "            Use scientific notation for floating point numbers.\n",
      "          shortest: An optional `bool`. Defaults to `False`.\n",
      "            Use shortest representation (either scientific or standard) for\n",
      "            floating point numbers.\n",
      "          width: An optional `int`. Defaults to `-1`.\n",
      "            Pad pre-decimal numbers to this width.\n",
      "            Applies to both floating point and integer numbers.\n",
      "            Only used if width > -1.\n",
      "          fill: An optional `string`. Defaults to `\"\"`.\n",
      "            The value to pad if width > -1.  If empty, pads with spaces.\n",
      "            Another typical value is '0'.  String cannot be longer than 1 character.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `string`.\n",
      "    \n",
      "    asin(x, name=None)\n",
      "        Computes the trignometric inverse sine of x element-wise.\n",
      "        \n",
      "        The `tf.math.asin` operation returns the inverse of `tf.math.sin`, such that\n",
      "        if `y = tf.math.sin(x)` then, `x = tf.math.asin(y)`.\n",
      "        \n",
      "        **Note**: The output of `tf.math.asin` will lie within the invertible range \n",
      "        of sine, i.e [-pi/2, pi/2].\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        # Note: [1.047, 0.785] ~= [(pi/3), (pi/4)]\n",
      "        x = tf.constant([1.047, 0.785])\n",
      "        y = tf.math.sin(x) # [0.8659266, 0.7068252]\n",
      "        \n",
      "        tf.math.asin(y) # [1.047, 0.785] = x\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int32`, `int64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    asinh(x, name=None)\n",
      "        Computes inverse hyperbolic sine of x element-wise.\n",
      "        \n",
      "          Given an input tensor, this function computes inverse hyperbolic sine\n",
      "          for every element in the tensor. Both input and output has a range of\n",
      "          `[-inf, inf]`.\n",
      "        \n",
      "          ```python\n",
      "          x = tf.constant([-float(\"inf\"), -2, -0.5, 1, 1.2, 200, 10000, float(\"inf\")])\n",
      "          tf.math.asinh(x) ==> [-inf -1.4436355 -0.4812118 0.8813736 1.0159732 5.991471 9.903487 inf]\n",
      "          ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    assert_equal(x, y, data=None, summarize=None, message=None, name=None)\n",
      "        Assert the condition `x == y` holds element-wise.\n",
      "        \n",
      "        This condition holds if for every pair of (possibly broadcast) elements\n",
      "        `x[i]`, `y[i]`, we have `x[i] == y[i]`.\n",
      "        If both `x` and `y` are empty, this is trivially satisfied.\n",
      "        \n",
      "        When running in graph mode, you should add a dependency on this operation\n",
      "        to ensure that it runs. Example of adding a dependency to an operation:\n",
      "        \n",
      "        ```python\n",
      "        with tf.control_dependencies([tf.compat.v1.assert_equal(x, y)]):\n",
      "          output = tf.reduce_sum(x)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x:  Numeric `Tensor`.\n",
      "          y:  Numeric `Tensor`, same dtype as and broadcastable to `x`.\n",
      "          data:  The tensors to print out if the condition is False.  Defaults to\n",
      "            error message and first few entries of `x`, `y`.\n",
      "          summarize: Print this many entries of each tensor.\n",
      "          message: A string to prefix to the default message.\n",
      "          name: A name for this operation (optional).  Defaults to \"assert_equal\".\n",
      "        \n",
      "        Returns:\n",
      "          Op that raises `InvalidArgumentError` if `x == y` is False.\n",
      "          @compatibility(eager)\n",
      "            returns None\n",
      "          @end_compatibility\n",
      "        \n",
      "        Raises:\n",
      "          InvalidArgumentError: if the check can be performed immediately and\n",
      "            `x == y` is False. The check can be performed immediately during \n",
      "            eager execution or if `x` and `y` are statically known.\n",
      "    \n",
      "    assert_greater(x, y, data=None, summarize=None, message=None, name=None)\n",
      "        Assert the condition `x > y` holds element-wise.\n",
      "        \n",
      "        This condition holds if for every pair of (possibly broadcast) elements\n",
      "        `x[i]`, `y[i]`, we have `x[i] > y[i]`.\n",
      "        If both `x` and `y` are empty, this is trivially satisfied.\n",
      "        \n",
      "        When running in graph mode, you should add a dependency on this operation\n",
      "        to ensure that it runs. Example of adding a dependency to an operation:\n",
      "        \n",
      "        ```python\n",
      "        with tf.control_dependencies([tf.compat.v1.assert_greater(x, y)]):\n",
      "          output = tf.reduce_sum(x)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x:  Numeric `Tensor`.\n",
      "          y:  Numeric `Tensor`, same dtype as and broadcastable to `x`.\n",
      "          data:  The tensors to print out if the condition is False.  Defaults to\n",
      "            error message and first few entries of `x`, `y`.\n",
      "          summarize: Print this many entries of each tensor.\n",
      "          message: A string to prefix to the default message.\n",
      "          name: A name for this operation (optional).  Defaults to \"assert_greater\".\n",
      "        \n",
      "        Returns:\n",
      "          Op that raises `InvalidArgumentError` if `x > y` is False.\n",
      "          @compatibility(eager)\n",
      "            returns None\n",
      "          @end_compatibility\n",
      "        \n",
      "        Raises:\n",
      "          InvalidArgumentError: if the check can be performed immediately and\n",
      "            `x > y` is False. The check can be performed immediately during \n",
      "            eager execution or if `x` and `y` are statically known.\n",
      "    \n",
      "    assert_greater_equal(x, y, data=None, summarize=None, message=None, name=None)\n",
      "        Assert the condition `x >= y` holds element-wise.\n",
      "        \n",
      "        This condition holds if for every pair of (possibly broadcast) elements\n",
      "        `x[i]`, `y[i]`, we have `x[i] >= y[i]`.\n",
      "        If both `x` and `y` are empty, this is trivially satisfied.\n",
      "        \n",
      "        When running in graph mode, you should add a dependency on this operation\n",
      "        to ensure that it runs. Example of adding a dependency to an operation:\n",
      "        \n",
      "        ```python\n",
      "        with tf.control_dependencies([tf.compat.v1.assert_greater_equal(x, y)]):\n",
      "          output = tf.reduce_sum(x)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x:  Numeric `Tensor`.\n",
      "          y:  Numeric `Tensor`, same dtype as and broadcastable to `x`.\n",
      "          data:  The tensors to print out if the condition is False.  Defaults to\n",
      "            error message and first few entries of `x`, `y`.\n",
      "          summarize: Print this many entries of each tensor.\n",
      "          message: A string to prefix to the default message.\n",
      "          name: A name for this operation (optional).  Defaults to \"assert_greater_equal\".\n",
      "        \n",
      "        Returns:\n",
      "          Op that raises `InvalidArgumentError` if `x >= y` is False.\n",
      "          @compatibility(eager)\n",
      "            returns None\n",
      "          @end_compatibility\n",
      "        \n",
      "        Raises:\n",
      "          InvalidArgumentError: if the check can be performed immediately and\n",
      "            `x >= y` is False. The check can be performed immediately during \n",
      "            eager execution or if `x` and `y` are statically known.\n",
      "    \n",
      "    assert_integer(x, message=None, name=None)\n",
      "        Assert that `x` is of integer dtype.\n",
      "        \n",
      "        Example of adding a dependency to an operation:\n",
      "        \n",
      "        ```python\n",
      "        with tf.control_dependencies([tf.compat.v1.assert_integer(x)]):\n",
      "          output = tf.reduce_sum(x)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: `Tensor` whose basetype is integer and is not quantized.\n",
      "          message: A string to prefix to the default message.\n",
      "          name: A name for this operation (optional).  Defaults to \"assert_integer\".\n",
      "        \n",
      "        Raises:\n",
      "          TypeError:  If `x.dtype` is anything other than non-quantized integer.\n",
      "        \n",
      "        Returns:\n",
      "          A `no_op` that does nothing.  Type can be determined statically.\n",
      "    \n",
      "    assert_less(x, y, data=None, summarize=None, message=None, name=None)\n",
      "        Assert the condition `x < y` holds element-wise.\n",
      "        \n",
      "        This condition holds if for every pair of (possibly broadcast) elements\n",
      "        `x[i]`, `y[i]`, we have `x[i] < y[i]`.\n",
      "        If both `x` and `y` are empty, this is trivially satisfied.\n",
      "        \n",
      "        When running in graph mode, you should add a dependency on this operation\n",
      "        to ensure that it runs. Example of adding a dependency to an operation:\n",
      "        \n",
      "        ```python\n",
      "        with tf.control_dependencies([tf.compat.v1.assert_less(x, y)]):\n",
      "          output = tf.reduce_sum(x)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x:  Numeric `Tensor`.\n",
      "          y:  Numeric `Tensor`, same dtype as and broadcastable to `x`.\n",
      "          data:  The tensors to print out if the condition is False.  Defaults to\n",
      "            error message and first few entries of `x`, `y`.\n",
      "          summarize: Print this many entries of each tensor.\n",
      "          message: A string to prefix to the default message.\n",
      "          name: A name for this operation (optional).  Defaults to \"assert_less\".\n",
      "        \n",
      "        Returns:\n",
      "          Op that raises `InvalidArgumentError` if `x < y` is False.\n",
      "          @compatibility(eager)\n",
      "            returns None\n",
      "          @end_compatibility\n",
      "        \n",
      "        Raises:\n",
      "          InvalidArgumentError: if the check can be performed immediately and\n",
      "            `x < y` is False. The check can be performed immediately during \n",
      "            eager execution or if `x` and `y` are statically known.\n",
      "    \n",
      "    assert_less_equal(x, y, data=None, summarize=None, message=None, name=None)\n",
      "        Assert the condition `x <= y` holds element-wise.\n",
      "        \n",
      "        This condition holds if for every pair of (possibly broadcast) elements\n",
      "        `x[i]`, `y[i]`, we have `x[i] <= y[i]`.\n",
      "        If both `x` and `y` are empty, this is trivially satisfied.\n",
      "        \n",
      "        When running in graph mode, you should add a dependency on this operation\n",
      "        to ensure that it runs. Example of adding a dependency to an operation:\n",
      "        \n",
      "        ```python\n",
      "        with tf.control_dependencies([tf.compat.v1.assert_less_equal(x, y)]):\n",
      "          output = tf.reduce_sum(x)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x:  Numeric `Tensor`.\n",
      "          y:  Numeric `Tensor`, same dtype as and broadcastable to `x`.\n",
      "          data:  The tensors to print out if the condition is False.  Defaults to\n",
      "            error message and first few entries of `x`, `y`.\n",
      "          summarize: Print this many entries of each tensor.\n",
      "          message: A string to prefix to the default message.\n",
      "          name: A name for this operation (optional).  Defaults to \"assert_less_equal\".\n",
      "        \n",
      "        Returns:\n",
      "          Op that raises `InvalidArgumentError` if `x <= y` is False.\n",
      "          @compatibility(eager)\n",
      "            returns None\n",
      "          @end_compatibility\n",
      "        \n",
      "        Raises:\n",
      "          InvalidArgumentError: if the check can be performed immediately and\n",
      "            `x <= y` is False. The check can be performed immediately during \n",
      "            eager execution or if `x` and `y` are statically known.\n",
      "    \n",
      "    assert_near(x, y, rtol=None, atol=None, data=None, summarize=None, message=None, name=None)\n",
      "        Assert the condition `x` and `y` are close element-wise.\n",
      "        \n",
      "        Example of adding a dependency to an operation:\n",
      "        \n",
      "        ```python\n",
      "        with tf.control_dependencies([tf.compat.v1.assert_near(x, y)]):\n",
      "          output = tf.reduce_sum(x)\n",
      "        ```\n",
      "        \n",
      "        This condition holds if for every pair of (possibly broadcast) elements\n",
      "        `x[i]`, `y[i]`, we have\n",
      "        \n",
      "        ```tf.abs(x[i] - y[i]) <= atol + rtol * tf.abs(y[i])```.\n",
      "        \n",
      "        If both `x` and `y` are empty, this is trivially satisfied.\n",
      "        \n",
      "        The default `atol` and `rtol` is `10 * eps`, where `eps` is the smallest\n",
      "        representable positive number such that `1 + eps != 1`.  This is about\n",
      "        `1.2e-6` in `32bit`, `2.22e-15` in `64bit`, and `0.00977` in `16bit`.\n",
      "        See `numpy.finfo`.\n",
      "        \n",
      "        Args:\n",
      "          x:  Float or complex `Tensor`.\n",
      "          y:  Float or complex `Tensor`, same `dtype` as, and broadcastable to, `x`.\n",
      "          rtol:  `Tensor`.  Same `dtype` as, and broadcastable to, `x`.\n",
      "            The relative tolerance.  Default is `10 * eps`.\n",
      "          atol:  `Tensor`.  Same `dtype` as, and broadcastable to, `x`.\n",
      "            The absolute tolerance.  Default is `10 * eps`.\n",
      "          data:  The tensors to print out if the condition is False.  Defaults to\n",
      "            error message and first few entries of `x`, `y`.\n",
      "          summarize: Print this many entries of each tensor.\n",
      "          message: A string to prefix to the default message.\n",
      "          name: A name for this operation (optional).  Defaults to \"assert_near\".\n",
      "        \n",
      "        Returns:\n",
      "          Op that raises `InvalidArgumentError` if `x` and `y` are not close enough.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Similar to `numpy.assert_allclose`, except tolerance depends on data type.\n",
      "        This is due to the fact that `TensorFlow` is often used with `32bit`, `64bit`,\n",
      "        and even `16bit` data.\n",
      "        @end_compatibility\n",
      "    \n",
      "    assert_negative(x, data=None, summarize=None, message=None, name=None)\n",
      "        Assert the condition `x < 0` holds element-wise.\n",
      "        \n",
      "        When running in graph mode, you should add a dependency on this operation\n",
      "        to ensure that it runs. Example of adding a dependency to an operation:\n",
      "        \n",
      "        ```python\n",
      "        with tf.control_dependencies([tf.debugging.assert_negative(x, y)]):\n",
      "          output = tf.reduce_sum(x)\n",
      "        ```\n",
      "        \n",
      "        Negative means, for every element `x[i]` of `x`, we have `x[i] < 0`.\n",
      "        If `x` is empty this is trivially satisfied.\n",
      "        \n",
      "        Args:\n",
      "          x:  Numeric `Tensor`.\n",
      "          data:  The tensors to print out if the condition is False.  Defaults to\n",
      "            error message and first few entries of `x`.\n",
      "          summarize: Print this many entries of each tensor.\n",
      "          message: A string to prefix to the default message.\n",
      "          name: A name for this operation (optional).  Defaults to \"assert_negative\".\n",
      "        \n",
      "        Returns:\n",
      "          Op that raises `InvalidArgumentError` if `x < 0` is False.\n",
      "          @compatibility(eager)\n",
      "            returns None\n",
      "          @end_compatibility\n",
      "        \n",
      "        Raises:\n",
      "          InvalidArgumentError: if the check can be performed immediately and\n",
      "            `x < 0` is False. The check can be performed immediately during \n",
      "            eager execution or if `x` is statically known.\n",
      "    \n",
      "    assert_non_negative(x, data=None, summarize=None, message=None, name=None)\n",
      "        Assert the condition `x >= 0` holds element-wise.\n",
      "        \n",
      "        When running in graph mode, you should add a dependency on this operation\n",
      "        to ensure that it runs. Example of adding a dependency to an operation:\n",
      "        \n",
      "        ```python\n",
      "        with tf.control_dependencies([tf.debugging.assert_non_negative(x, y)]):\n",
      "          output = tf.reduce_sum(x)\n",
      "        ```\n",
      "        \n",
      "        Non-negative means, for every element `x[i]` of `x`, we have `x[i] >= 0`.\n",
      "        If `x` is empty this is trivially satisfied.\n",
      "        \n",
      "        Args:\n",
      "          x:  Numeric `Tensor`.\n",
      "          data:  The tensors to print out if the condition is False.  Defaults to\n",
      "            error message and first few entries of `x`.\n",
      "          summarize: Print this many entries of each tensor.\n",
      "          message: A string to prefix to the default message.\n",
      "          name: A name for this operation (optional).  Defaults to \"assert_non_negative\".\n",
      "        \n",
      "        Returns:\n",
      "          Op that raises `InvalidArgumentError` if `x >= 0` is False.\n",
      "          @compatibility(eager)\n",
      "            returns None\n",
      "          @end_compatibility\n",
      "        \n",
      "        Raises:\n",
      "          InvalidArgumentError: if the check can be performed immediately and\n",
      "            `x >= 0` is False. The check can be performed immediately during \n",
      "            eager execution or if `x` is statically known.\n",
      "    \n",
      "    assert_non_positive(x, data=None, summarize=None, message=None, name=None)\n",
      "        Assert the condition `x <= 0` holds element-wise.\n",
      "        \n",
      "        When running in graph mode, you should add a dependency on this operation\n",
      "        to ensure that it runs. Example of adding a dependency to an operation:\n",
      "        \n",
      "        ```python\n",
      "        with tf.control_dependencies([tf.debugging.assert_non_positive(x, y)]):\n",
      "          output = tf.reduce_sum(x)\n",
      "        ```\n",
      "        \n",
      "        Non-positive means, for every element `x[i]` of `x`, we have `x[i] <= 0`.\n",
      "        If `x` is empty this is trivially satisfied.\n",
      "        \n",
      "        Args:\n",
      "          x:  Numeric `Tensor`.\n",
      "          data:  The tensors to print out if the condition is False.  Defaults to\n",
      "            error message and first few entries of `x`.\n",
      "          summarize: Print this many entries of each tensor.\n",
      "          message: A string to prefix to the default message.\n",
      "          name: A name for this operation (optional).  Defaults to \"assert_non_positive\".\n",
      "        \n",
      "        Returns:\n",
      "          Op that raises `InvalidArgumentError` if `x <= 0` is False.\n",
      "          @compatibility(eager)\n",
      "            returns None\n",
      "          @end_compatibility\n",
      "        \n",
      "        Raises:\n",
      "          InvalidArgumentError: if the check can be performed immediately and\n",
      "            `x <= 0` is False. The check can be performed immediately during \n",
      "            eager execution or if `x` is statically known.\n",
      "    \n",
      "    assert_none_equal(x, y, data=None, summarize=None, message=None, name=None)\n",
      "        Assert the condition `x != y` holds element-wise.\n",
      "        \n",
      "        This condition holds if for every pair of (possibly broadcast) elements\n",
      "        `x[i]`, `y[i]`, we have `x[i] != y[i]`.\n",
      "        If both `x` and `y` are empty, this is trivially satisfied.\n",
      "        \n",
      "        When running in graph mode, you should add a dependency on this operation\n",
      "        to ensure that it runs. Example of adding a dependency to an operation:\n",
      "        \n",
      "        ```python\n",
      "        with tf.control_dependencies([tf.compat.v1.assert_none_equal(x, y)]):\n",
      "          output = tf.reduce_sum(x)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x:  Numeric `Tensor`.\n",
      "          y:  Numeric `Tensor`, same dtype as and broadcastable to `x`.\n",
      "          data:  The tensors to print out if the condition is False.  Defaults to\n",
      "            error message and first few entries of `x`, `y`.\n",
      "          summarize: Print this many entries of each tensor.\n",
      "          message: A string to prefix to the default message.\n",
      "          name: A name for this operation (optional).  Defaults to \"assert_none_equal\".\n",
      "        \n",
      "        Returns:\n",
      "          Op that raises `InvalidArgumentError` if `x != y` is False.\n",
      "          @compatibility(eager)\n",
      "            returns None\n",
      "          @end_compatibility\n",
      "        \n",
      "        Raises:\n",
      "          InvalidArgumentError: if the check can be performed immediately and\n",
      "            `x != y` is False. The check can be performed immediately during \n",
      "            eager execution or if `x` and `y` are statically known.\n",
      "    \n",
      "    assert_positive(x, data=None, summarize=None, message=None, name=None)\n",
      "        Assert the condition `x > 0` holds element-wise.\n",
      "        \n",
      "        When running in graph mode, you should add a dependency on this operation\n",
      "        to ensure that it runs. Example of adding a dependency to an operation:\n",
      "        \n",
      "        ```python\n",
      "        with tf.control_dependencies([tf.debugging.assert_positive(x, y)]):\n",
      "          output = tf.reduce_sum(x)\n",
      "        ```\n",
      "        \n",
      "        Positive means, for every element `x[i]` of `x`, we have `x[i] > 0`.\n",
      "        If `x` is empty this is trivially satisfied.\n",
      "        \n",
      "        Args:\n",
      "          x:  Numeric `Tensor`.\n",
      "          data:  The tensors to print out if the condition is False.  Defaults to\n",
      "            error message and first few entries of `x`.\n",
      "          summarize: Print this many entries of each tensor.\n",
      "          message: A string to prefix to the default message.\n",
      "          name: A name for this operation (optional).  Defaults to \"assert_positive\".\n",
      "        \n",
      "        Returns:\n",
      "          Op that raises `InvalidArgumentError` if `x > 0` is False.\n",
      "          @compatibility(eager)\n",
      "            returns None\n",
      "          @end_compatibility\n",
      "        \n",
      "        Raises:\n",
      "          InvalidArgumentError: if the check can be performed immediately and\n",
      "            `x > 0` is False. The check can be performed immediately during \n",
      "            eager execution or if `x` is statically known.\n",
      "    \n",
      "    assert_proper_iterable(values)\n",
      "        Static assert that values is a \"proper\" iterable.\n",
      "        \n",
      "        `Ops` that expect iterables of `Tensor` can call this to validate input.\n",
      "        Useful since `Tensor`, `ndarray`, byte/text type are all iterables themselves.\n",
      "        \n",
      "        Args:\n",
      "          values:  Object to be checked.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError:  If `values` is not iterable or is one of\n",
      "            `Tensor`, `SparseTensor`, `np.array`, `tf.compat.bytes_or_text_types`.\n",
      "    \n",
      "    assert_rank(x, rank, data=None, summarize=None, message=None, name=None)\n",
      "        Assert `x` has rank equal to `rank`.\n",
      "        \n",
      "        Example of adding a dependency to an operation:\n",
      "        \n",
      "        ```python\n",
      "        with tf.control_dependencies([tf.compat.v1.assert_rank(x, 2)]):\n",
      "          output = tf.reduce_sum(x)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x:  Numeric `Tensor`.\n",
      "          rank:  Scalar integer `Tensor`.\n",
      "          data:  The tensors to print out if the condition is False.  Defaults to\n",
      "            error message and the shape of `x`.\n",
      "          summarize: Print this many entries of each tensor.\n",
      "          message: A string to prefix to the default message.\n",
      "          name: A name for this operation (optional).  Defaults to \"assert_rank\".\n",
      "        \n",
      "        Returns:\n",
      "          Op raising `InvalidArgumentError` unless `x` has specified rank.\n",
      "          If static checks determine `x` has correct rank, a `no_op` is returned.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError:  If static checks determine `x` has wrong rank.\n",
      "    \n",
      "    assert_rank_at_least(x, rank, data=None, summarize=None, message=None, name=None)\n",
      "        Assert `x` has rank equal to `rank` or higher.\n",
      "        \n",
      "        Example of adding a dependency to an operation:\n",
      "        \n",
      "        ```python\n",
      "        with tf.control_dependencies([tf.compat.v1.assert_rank_at_least(x, 2)]):\n",
      "          output = tf.reduce_sum(x)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x:  Numeric `Tensor`.\n",
      "          rank:  Scalar `Tensor`.\n",
      "          data:  The tensors to print out if the condition is False.  Defaults to\n",
      "            error message and first few entries of `x`.\n",
      "          summarize: Print this many entries of each tensor.\n",
      "          message: A string to prefix to the default message.\n",
      "          name: A name for this operation (optional).\n",
      "            Defaults to \"assert_rank_at_least\".\n",
      "        \n",
      "        Returns:\n",
      "          Op raising `InvalidArgumentError` unless `x` has specified rank or higher.\n",
      "          If static checks determine `x` has correct rank, a `no_op` is returned.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError:  If static checks determine `x` has wrong rank.\n",
      "    \n",
      "    assert_rank_in(x, ranks, data=None, summarize=None, message=None, name=None)\n",
      "        Assert `x` has rank in `ranks`.\n",
      "        \n",
      "        Example of adding a dependency to an operation:\n",
      "        \n",
      "        ```python\n",
      "        with tf.control_dependencies([tf.compat.v1.assert_rank_in(x, (2, 4))]):\n",
      "          output = tf.reduce_sum(x)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x:  Numeric `Tensor`.\n",
      "          ranks:  Iterable of scalar `Tensor` objects.\n",
      "          data:  The tensors to print out if the condition is False.  Defaults to\n",
      "            error message and first few entries of `x`.\n",
      "          summarize: Print this many entries of each tensor.\n",
      "          message: A string to prefix to the default message.\n",
      "          name: A name for this operation (optional).\n",
      "            Defaults to \"assert_rank_in\".\n",
      "        \n",
      "        Returns:\n",
      "          Op raising `InvalidArgumentError` unless rank of `x` is in `ranks`.\n",
      "          If static checks determine `x` has matching rank, a `no_op` is returned.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError:  If static checks determine `x` has mismatched rank.\n",
      "    \n",
      "    assert_same_float_dtype(tensors=None, dtype=None)\n",
      "        Validate and return float type based on `tensors` and `dtype`.\n",
      "        \n",
      "        For ops such as matrix multiplication, inputs and weights must be of the\n",
      "        same float type. This function validates that all `tensors` are the same type,\n",
      "        validates that type is `dtype` (if supplied), and returns the type. Type must\n",
      "        be a floating point type. If neither `tensors` nor `dtype` is supplied,\n",
      "        the function will return `dtypes.float32`.\n",
      "        \n",
      "        Args:\n",
      "          tensors: Tensors of input values. Can include `None` elements, which will be\n",
      "              ignored.\n",
      "          dtype: Expected type.\n",
      "        \n",
      "        Returns:\n",
      "          Validated type.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: if neither `tensors` nor `dtype` is supplied, or result is not\n",
      "              float, or the common type of the inputs is not a floating point type.\n",
      "    \n",
      "    assert_scalar(tensor, name=None, message=None)\n",
      "        Asserts that the given `tensor` is a scalar (i.e. zero-dimensional).\n",
      "        \n",
      "        This function raises `ValueError` unless it can be certain that the given\n",
      "        `tensor` is a scalar. `ValueError` is also raised if the shape of `tensor` is\n",
      "        unknown.\n",
      "        \n",
      "        Args:\n",
      "          tensor: A `Tensor`.\n",
      "          name:  A name for this operation. Defaults to \"assert_scalar\"\n",
      "          message: A string to prefix to the default message.\n",
      "        \n",
      "        Returns:\n",
      "          The input tensor (potentially converted to a `Tensor`).\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If the tensor is not scalar (rank 0), or if its shape is\n",
      "            unknown.\n",
      "    \n",
      "    assert_type(tensor, tf_type, message=None, name=None)\n",
      "        Statically asserts that the given `Tensor` is of the specified type.\n",
      "        \n",
      "        Args:\n",
      "          tensor: A `Tensor`.\n",
      "          tf_type: A tensorflow type (`dtypes.float32`, `tf.int64`, `dtypes.bool`,\n",
      "            etc).\n",
      "          message: A string to prefix to the default message.\n",
      "          name:  A name to give this `Op`.  Defaults to \"assert_type\"\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If the tensors data type doesn't match `tf_type`.\n",
      "        \n",
      "        Returns:\n",
      "          A `no_op` that does nothing.  Type can be determined statically.\n",
      "    \n",
      "    assert_variables_initialized(var_list=None)\n",
      "        Returns an Op to check if variables are initialized.\n",
      "        \n",
      "        NOTE: This function is obsolete and will be removed in 6 months.  Please\n",
      "        change your implementation to use `report_uninitialized_variables()`.\n",
      "        \n",
      "        When run, the returned Op will raise the exception `FailedPreconditionError`\n",
      "        if any of the variables has not yet been initialized.\n",
      "        \n",
      "        Note: This function is implemented by trying to fetch the values of the\n",
      "        variables. If one of the variables is not initialized a message may be\n",
      "        logged by the C++ runtime. This is expected.\n",
      "        \n",
      "        Args:\n",
      "          var_list: List of `Variable` objects to check. Defaults to the value of\n",
      "            `global_variables().`\n",
      "        \n",
      "        Returns:\n",
      "          An Op, or None if there are no variables.\n",
      "        \n",
      "        \n",
      "        **NOTE** The output of this function should be used.  If it is not, a warning will be logged.  To mark the output as used, call its .mark_used() method.\n",
      "    \n",
      "    assign(ref, value, validate_shape=None, use_locking=None, name=None)\n",
      "        Update `ref` by assigning `value` to it.\n",
      "        \n",
      "        This operation outputs a Tensor that holds the new value of `ref` after\n",
      "        the value has been assigned. This makes it easier to chain operations that\n",
      "        need to use the reset value.\n",
      "        \n",
      "        Args:\n",
      "          ref: A mutable `Tensor`. Should be from a `Variable` node. May be\n",
      "            uninitialized.\n",
      "          value: A `Tensor`. Must have the same shape and dtype as `ref`. The value to\n",
      "            be assigned to the variable.\n",
      "          validate_shape: An optional `bool`. Defaults to `True`. If true, the\n",
      "            operation will validate that the shape of 'value' matches the shape of the\n",
      "            Tensor being assigned to.  If false, 'ref' will take on the shape of\n",
      "            'value'.\n",
      "          use_locking: An optional `bool`. Defaults to `True`. If True, the assignment\n",
      "            will be protected by a lock; otherwise the behavior is undefined, but may\n",
      "            exhibit less contention.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` that will hold the new value of `ref` after\n",
      "            the assignment has completed.\n",
      "    \n",
      "    assign_add(ref, value, use_locking=None, name=None)\n",
      "        Update `ref` by adding `value` to it.\n",
      "        \n",
      "        This operation outputs \"ref\" after the update is done.\n",
      "        This makes it easier to chain operations that need to use the reset value.\n",
      "        Unlike `tf.math.add`, this op does not broadcast. `ref` and `value` must have\n",
      "        the same shape.\n",
      "        \n",
      "        Args:\n",
      "          ref: A mutable `Tensor`. Must be one of the following types: `float32`,\n",
      "            `float64`, `int64`, `int32`, `uint8`, `uint16`, `int16`, `int8`,\n",
      "            `complex64`, `complex128`, `qint8`, `quint8`, `qint32`, `half`. Should be\n",
      "            from a `Variable` node.\n",
      "          value: A `Tensor`. Must have the same shape and dtype as `ref`. The value to\n",
      "            be added to the variable.\n",
      "          use_locking: An optional `bool`. Defaults to `False`. If True, the addition\n",
      "            will be protected by a lock; otherwise the behavior is undefined, but may\n",
      "            exhibit less contention.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          Same as \"ref\".  Returned as a convenience for operations that want\n",
      "          to use the new value after the variable has been updated.\n",
      "    \n",
      "    assign_sub(ref, value, use_locking=None, name=None)\n",
      "        Update `ref` by subtracting `value` from it.\n",
      "        \n",
      "        This operation outputs `ref` after the update is done.\n",
      "        This makes it easier to chain operations that need to use the reset value.\n",
      "        Unlike `tf.math.subtract`, this op does not broadcast. `ref` and `value`\n",
      "        must have the same shape.\n",
      "        \n",
      "        Args:\n",
      "          ref: A mutable `Tensor`. Must be one of the following types: `float32`,\n",
      "            `float64`, `int64`, `int32`, `uint8`, `uint16`, `int16`, `int8`,\n",
      "            `complex64`, `complex128`, `qint8`, `quint8`, `qint32`, `half`. Should be\n",
      "            from a `Variable` node.\n",
      "          value: A `Tensor`. Must have the same shape and dtype as `ref`. The value to\n",
      "            be subtracted to the variable.\n",
      "          use_locking: An optional `bool`. Defaults to `False`. If True, the\n",
      "            subtraction will be protected by a lock; otherwise the behavior is\n",
      "            undefined, but may exhibit less contention.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          Same as \"ref\".  Returned as a convenience for operations that want\n",
      "          to use the new value after the variable has been updated.\n",
      "    \n",
      "    atan(x, name=None)\n",
      "        Computes the trignometric inverse tangent of x element-wise.\n",
      "        \n",
      "        The `tf.math.atan` operation returns the inverse of `tf.math.tan`, such that\n",
      "        if `y = tf.math.tan(x)` then, `x = tf.math.atan(y)`.\n",
      "        \n",
      "        **Note**: The output of `tf.math.atan` will lie within the invertible range \n",
      "        of tan, i.e (-pi/2, pi/2).\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        # Note: [1.047, 0.785] ~= [(pi/3), (pi/4)]\n",
      "        x = tf.constant([1.047, 0.785])\n",
      "        y = tf.math.tan(x) # [1.731261, 0.99920404]\n",
      "        \n",
      "        tf.math.atan(y) # [1.047, 0.785] = x\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int32`, `int64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    atan2(y, x, name=None)\n",
      "        Computes arctangent of `y/x` element-wise, respecting signs of the arguments.\n",
      "        \n",
      "        This is the angle \\( \\theta \\in [-\\pi, \\pi] \\) such that\n",
      "        \\[ x = r \\cos(\\theta) \\]\n",
      "        and\n",
      "        \\[ y = r \\sin(\\theta) \\]\n",
      "        where \\(r = \\sqrt(x^2 + y^2) \\).\n",
      "        \n",
      "        Args:\n",
      "          y: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.\n",
      "          x: A `Tensor`. Must have the same type as `y`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `y`.\n",
      "    \n",
      "    atanh(x, name=None)\n",
      "        Computes inverse hyperbolic tangent of x element-wise.\n",
      "        \n",
      "          Given an input tensor, this function computes inverse hyperbolic tangent\n",
      "          for every element in the tensor. Input range is `[-1,1]` and output range is\n",
      "          `[-inf, inf]`. If input is `-1`, output will be `-inf` and if the\n",
      "          input is `1`, output will be `inf`. Values outside the range will have\n",
      "          `nan` as output.\n",
      "        \n",
      "          ```python\n",
      "          x = tf.constant([-float(\"inf\"), -1, -0.5, 1, 0, 0.5, 10, float(\"inf\")])\n",
      "          tf.math.atanh(x) ==> [nan -inf -0.54930615 inf  0. 0.54930615 nan nan]\n",
      "          ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    batch_gather(params, indices, name=None)\n",
      "        Gather slices from params according to indices with leading batch dims. (deprecated)\n",
      "        \n",
      "        Warning: THIS FUNCTION IS DEPRECATED. It will be removed after 2017-10-25.\n",
      "        Instructions for updating:\n",
      "        `tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n",
      "    \n",
      "    batch_scatter_update(ref, indices, updates, use_locking=True, name=None)\n",
      "        Generalization of `tf.compat.v1.scatter_update` to axis different than 0. (deprecated)\n",
      "        \n",
      "        Warning: THIS FUNCTION IS DEPRECATED. It will be removed after 2018-11-29.\n",
      "        Instructions for updating:\n",
      "        Use the batch_scatter_update method of Variable instead.\n",
      "        \n",
      "        Analogous to `batch_gather`. This assumes that `ref`, `indices` and `updates`\n",
      "        have a series of leading dimensions that are the same for all of them, and the\n",
      "        updates are performed on the last dimension of indices. In other words, the\n",
      "        dimensions should be the following:\n",
      "        \n",
      "        `num_prefix_dims = indices.ndims - 1`\n",
      "        `batch_dim = num_prefix_dims + 1`\n",
      "        `updates.shape = indices.shape + var.shape[batch_dim:]`\n",
      "        \n",
      "        where\n",
      "        \n",
      "        `updates.shape[:num_prefix_dims]`\n",
      "        `== indices.shape[:num_prefix_dims]`\n",
      "        `== var.shape[:num_prefix_dims]`\n",
      "        \n",
      "        And the operation performed can be expressed as:\n",
      "        \n",
      "        `var[i_1, ..., i_n, indices[i_1, ..., i_n, j]] = updates[i_1, ..., i_n, j]`\n",
      "        \n",
      "        When indices is a 1D tensor, this operation is equivalent to\n",
      "        `tf.compat.v1.scatter_update`.\n",
      "        \n",
      "        To avoid this operation there would be 2 alternatives:\n",
      "        1) Reshaping the variable by merging the first `ndims` dimensions. However,\n",
      "           this is not possible because `tf.reshape` returns a Tensor, which we\n",
      "           cannot use `tf.compat.v1.scatter_update` on.\n",
      "        2) Looping over the first `ndims` of the variable and using\n",
      "           `tf.compat.v1.scatter_update` on the subtensors that result of slicing the\n",
      "           first\n",
      "           dimension. This is a valid option for `ndims = 1`, but less efficient than\n",
      "           this implementation.\n",
      "        \n",
      "        See also `tf.compat.v1.scatter_update` and `tf.compat.v1.scatter_nd_update`.\n",
      "        \n",
      "        Args:\n",
      "          ref: `Variable` to scatter onto.\n",
      "          indices: Tensor containing indices as described above.\n",
      "          updates: Tensor of updates to apply to `ref`.\n",
      "          use_locking: Boolean indicating whether to lock the writing operation.\n",
      "          name: Optional scope name string.\n",
      "        \n",
      "        Returns:\n",
      "          Ref to `variable` after it has been modified.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If the initial `ndims` of `ref`, `indices`, and `updates` are\n",
      "              not the same.\n",
      "    \n",
      "    batch_to_space(input, crops, block_size, name=None, block_shape=None)\n",
      "        BatchToSpace for 4-D tensors of type T.\n",
      "        \n",
      "        This is a legacy version of the more general BatchToSpaceND.\n",
      "        \n",
      "        Rearranges (permutes) data from batch into blocks of spatial data, followed by\n",
      "        cropping. This is the reverse transformation of SpaceToBatch. More specifically,\n",
      "        this op outputs a copy of the input tensor where values from the `batch`\n",
      "        dimension are moved in spatial blocks to the `height` and `width` dimensions,\n",
      "        followed by cropping along the `height` and `width` dimensions.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. 4-D tensor with shape\n",
      "            `[batch*block_size*block_size, height_pad/block_size, width_pad/block_size,\n",
      "              depth]`. Note that the batch size of the input tensor must be divisible by\n",
      "            `block_size * block_size`.\n",
      "          crops: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            2-D tensor of non-negative integers with shape `[2, 2]`. It specifies\n",
      "            how many elements to crop from the intermediate result across the spatial\n",
      "            dimensions as follows:\n",
      "        \n",
      "                crops = [[crop_top, crop_bottom], [crop_left, crop_right]]\n",
      "          block_size: An `int` that is `>= 2`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    batch_to_space_nd(input, block_shape, crops, name=None)\n",
      "        BatchToSpace for N-D tensors of type T.\n",
      "        \n",
      "        This operation reshapes the \"batch\" dimension 0 into `M + 1` dimensions of shape\n",
      "        `block_shape + [batch]`, interleaves these blocks back into the grid defined by\n",
      "        the spatial dimensions `[1, ..., M]`, to obtain a result with the same rank as\n",
      "        the input.  The spatial dimensions of this intermediate result are then\n",
      "        optionally cropped according to `crops` to produce the output.  This is the\n",
      "        reverse of SpaceToBatch.  See below for a precise description.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`.\n",
      "            N-D with shape `input_shape = [batch] + spatial_shape + remaining_shape`,\n",
      "            where spatial_shape has M dimensions.\n",
      "          block_shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            1-D with shape `[M]`, all values must be >= 1.\n",
      "          crops: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            2-D with shape `[M, 2]`, all values must be >= 0.\n",
      "              `crops[i] = [crop_start, crop_end]` specifies the amount to crop from input\n",
      "              dimension `i + 1`, which corresponds to spatial dimension `i`.  It is\n",
      "              required that\n",
      "              `crop_start[i] + crop_end[i] <= block_shape[i] * input_shape[i + 1]`.\n",
      "        \n",
      "            This operation is equivalent to the following steps:\n",
      "        \n",
      "            1. Reshape `input` to `reshaped` of shape:\n",
      "                 [block_shape[0], ..., block_shape[M-1],\n",
      "                  batch / prod(block_shape),\n",
      "                  input_shape[1], ..., input_shape[N-1]]\n",
      "        \n",
      "            2. Permute dimensions of `reshaped` to produce `permuted` of shape\n",
      "                 [batch / prod(block_shape),\n",
      "        \n",
      "                  input_shape[1], block_shape[0],\n",
      "                  ...,\n",
      "                  input_shape[M], block_shape[M-1],\n",
      "        \n",
      "                  input_shape[M+1], ..., input_shape[N-1]]\n",
      "        \n",
      "            3. Reshape `permuted` to produce `reshaped_permuted` of shape\n",
      "                 [batch / prod(block_shape),\n",
      "        \n",
      "                  input_shape[1] * block_shape[0],\n",
      "                  ...,\n",
      "                  input_shape[M] * block_shape[M-1],\n",
      "        \n",
      "                  input_shape[M+1],\n",
      "                  ...,\n",
      "                  input_shape[N-1]]\n",
      "        \n",
      "            4. Crop the start and end of dimensions `[1, ..., M]` of\n",
      "               `reshaped_permuted` according to `crops` to produce the output of shape:\n",
      "                 [batch / prod(block_shape),\n",
      "        \n",
      "                  input_shape[1] * block_shape[0] - crops[0,0] - crops[0,1],\n",
      "                  ...,\n",
      "                  input_shape[M] * block_shape[M-1] - crops[M-1,0] - crops[M-1,1],\n",
      "        \n",
      "                  input_shape[M+1], ..., input_shape[N-1]]\n",
      "        \n",
      "            Some examples:\n",
      "        \n",
      "            (1) For the following input of shape `[4, 1, 1, 1]`, `block_shape = [2, 2]`, and\n",
      "                `crops = [[0, 0], [0, 0]]`:\n",
      "        \n",
      "            ```\n",
      "            [[[[1]]], [[[2]]], [[[3]]], [[[4]]]]\n",
      "            ```\n",
      "        \n",
      "            The output tensor has shape `[1, 2, 2, 1]` and value:\n",
      "        \n",
      "            ```\n",
      "            x = [[[[1], [2]], [[3], [4]]]]\n",
      "            ```\n",
      "        \n",
      "            (2) For the following input of shape `[4, 1, 1, 3]`, `block_shape = [2, 2]`, and\n",
      "                `crops = [[0, 0], [0, 0]]`:\n",
      "        \n",
      "            ```\n",
      "            [[[[1, 2, 3]]], [[[4, 5, 6]]], [[[7, 8, 9]]], [[[10, 11, 12]]]]\n",
      "            ```\n",
      "        \n",
      "            The output tensor has shape `[1, 2, 2, 3]` and value:\n",
      "        \n",
      "            ```\n",
      "            x = [[[[1, 2, 3], [4, 5, 6]],\n",
      "                  [[7, 8, 9], [10, 11, 12]]]]\n",
      "            ```\n",
      "        \n",
      "            (3) For the following input of shape `[4, 2, 2, 1]`, `block_shape = [2, 2]`, and\n",
      "                `crops = [[0, 0], [0, 0]]`:\n",
      "        \n",
      "            ```\n",
      "            x = [[[[1], [3]], [[9], [11]]],\n",
      "                 [[[2], [4]], [[10], [12]]],\n",
      "                 [[[5], [7]], [[13], [15]]],\n",
      "                 [[[6], [8]], [[14], [16]]]]\n",
      "            ```\n",
      "        \n",
      "            The output tensor has shape `[1, 4, 4, 1]` and value:\n",
      "        \n",
      "            ```\n",
      "            x = [[[[1],   [2],  [3],  [4]],\n",
      "                 [[5],   [6],  [7],  [8]],\n",
      "                 [[9],  [10], [11],  [12]],\n",
      "                 [[13], [14], [15],  [16]]]]\n",
      "            ```\n",
      "        \n",
      "            (4) For the following input of shape `[8, 1, 3, 1]`, `block_shape = [2, 2]`, and\n",
      "                `crops = [[0, 0], [2, 0]]`:\n",
      "        \n",
      "            ```\n",
      "            x = [[[[0], [1], [3]]], [[[0], [9], [11]]],\n",
      "                 [[[0], [2], [4]]], [[[0], [10], [12]]],\n",
      "                 [[[0], [5], [7]]], [[[0], [13], [15]]],\n",
      "                 [[[0], [6], [8]]], [[[0], [14], [16]]]]\n",
      "            ```\n",
      "        \n",
      "            The output tensor has shape `[2, 2, 4, 1]` and value:\n",
      "        \n",
      "            ```\n",
      "            x = [[[[1],   [2],  [3],  [4]],\n",
      "                  [[5],   [6],  [7],  [8]]],\n",
      "                 [[[9],  [10], [11],  [12]],\n",
      "                  [[13], [14], [15],  [16]]]]\n",
      "            ```\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    betainc(a, b, x, name=None)\n",
      "        Compute the regularized incomplete beta integral \\\\(I_x(a, b)\\\\).\n",
      "        \n",
      "        The regularized incomplete beta integral is defined as:\n",
      "        \n",
      "        \n",
      "        \\\\(I_x(a, b) = \\frac{B(x; a, b)}{B(a, b)}\\\\)\n",
      "        \n",
      "        where\n",
      "        \n",
      "        \n",
      "        \\\\(B(x; a, b) = \\int_0^x t^{a-1} (1 - t)^{b-1} dt\\\\)\n",
      "        \n",
      "        \n",
      "        is the incomplete beta function and \\\\(B(a, b)\\\\) is the *complete*\n",
      "        beta function.\n",
      "        \n",
      "        Args:\n",
      "          a: A `Tensor`. Must be one of the following types: `float32`, `float64`.\n",
      "          b: A `Tensor`. Must have the same type as `a`.\n",
      "          x: A `Tensor`. Must have the same type as `a`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `a`.\n",
      "    \n",
      "    bincount = bincount_v1(arr, weights=None, minlength=None, maxlength=None, dtype=tf.int32)\n",
      "        Counts the number of occurrences of each value in an integer array.\n",
      "        \n",
      "        If `minlength` and `maxlength` are not given, returns a vector with length\n",
      "        `tf.reduce_max(arr) + 1` if `arr` is non-empty, and length 0 otherwise.\n",
      "        If `weights` are non-None, then index `i` of the output stores the sum of the\n",
      "        value in `weights` at each index where the corresponding value in `arr` is\n",
      "        `i`.\n",
      "        \n",
      "        Args:\n",
      "          arr: An int32 tensor of non-negative values.\n",
      "          weights: If non-None, must be the same shape as arr. For each value in\n",
      "            `arr`, the bin will be incremented by the corresponding weight instead of\n",
      "            1.\n",
      "          minlength: If given, ensures the output has length at least `minlength`,\n",
      "            padding with zeros at the end if necessary.\n",
      "          maxlength: If given, skips values in `arr` that are equal or greater than\n",
      "            `maxlength`, ensuring that the output has length at most `maxlength`.\n",
      "          dtype: If `weights` is None, determines the type of the output bins.\n",
      "        \n",
      "        Returns:\n",
      "          A vector with the same dtype as `weights` or the given `dtype`. The bin\n",
      "          values.\n",
      "    \n",
      "    bitcast(input, type, name=None)\n",
      "        Bitcasts a tensor from one type to another without copying data.\n",
      "        \n",
      "        Given a tensor `input`, this operation returns a tensor that has the same buffer\n",
      "        data as `input` with datatype `type`.\n",
      "        \n",
      "        If the input datatype `T` is larger than the output datatype `type` then the\n",
      "        shape changes from [...] to [..., sizeof(`T`)/sizeof(`type`)].\n",
      "        \n",
      "        If `T` is smaller than `type`, the operator requires that the rightmost\n",
      "        dimension be equal to sizeof(`type`)/sizeof(`T`). The shape then goes from\n",
      "        [..., sizeof(`type`)/sizeof(`T`)] to [...].\n",
      "        \n",
      "        tf.bitcast() and tf.cast() work differently when real dtype is casted as a complex dtype\n",
      "        (e.g. tf.complex64 or tf.complex128) as tf.cast() make imaginary part 0 while tf.bitcast()\n",
      "        gives module error.\n",
      "        For example,\n",
      "        \n",
      "        Example 1:\n",
      "        ```python\n",
      "        >>> a = [1., 2., 3.]\n",
      "        >>> equality_bitcast = tf.bitcast(a,tf.complex128)\n",
      "        tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot bitcast from float to complex128: shape [3] [Op:Bitcast]\n",
      "        >>> equality_cast = tf.cast(a,tf.complex128)\n",
      "        >>> print(equality_cast)\n",
      "        tf.Tensor([1.+0.j 2.+0.j 3.+0.j], shape=(3,), dtype=complex128)\n",
      "        ```\n",
      "        Example 2:\n",
      "        ```python\n",
      "        >>> tf.bitcast(tf.constant(0xffffffff, dtype=tf.uint32), tf.uint8)\n",
      "        <tf.Tensor: ... shape=(4,), dtype=uint8, numpy=array([255, 255, 255, 255], dtype=uint8)>\n",
      "        ```\n",
      "        Example 3:\n",
      "        ```python\n",
      "        >>> x = [1., 2., 3.]\n",
      "        >>> y = [0., 2., 3.]\n",
      "        >>> equality= tf.equal(x,y)\n",
      "        >>> equality_cast = tf.cast(equality,tf.float32)\n",
      "        >>> equality_bitcast = tf.bitcast(equality_cast,tf.uint8)\n",
      "        >>> print(equality)\n",
      "        tf.Tensor([False True True], shape=(3,), dtype=bool)\n",
      "        >>> print(equality_cast)\n",
      "        tf.Tensor([0. 1. 1.], shape=(3,), dtype=float32)\n",
      "        >>> print(equality_bitcast)\n",
      "        tf.Tensor(\n",
      "        [[ 0 0 0 0]\n",
      "         [ 0 0 128 63]\n",
      "         [ 0 0 128 63]], shape=(3, 4), dtype=uint8)\n",
      "        ```\n",
      "        \n",
      "        *NOTE*: Bitcast is implemented as a low-level cast, so machines with different\n",
      "        endian orderings will give different results.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int64`, `int32`, `uint8`, `uint16`, `uint32`, `uint64`, `int8`, `int16`, `complex64`, `complex128`, `qint8`, `quint8`, `qint16`, `quint16`, `qint32`.\n",
      "          type: A `tf.DType` from: `tf.bfloat16, tf.half, tf.float32, tf.float64, tf.int64, tf.int32, tf.uint8, tf.uint16, tf.uint32, tf.uint64, tf.int8, tf.int16, tf.complex64, tf.complex128, tf.qint8, tf.quint8, tf.qint16, tf.quint16, tf.qint32`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `type`.\n",
      "    \n",
      "    boolean_mask(tensor, mask, name='boolean_mask', axis=None)\n",
      "        Apply boolean mask to tensor.\n",
      "        \n",
      "        Numpy equivalent is `tensor[mask]`.\n",
      "        \n",
      "        ```python\n",
      "        # 1-D example\n",
      "        tensor = [0, 1, 2, 3]\n",
      "        mask = np.array([True, False, True, False])\n",
      "        boolean_mask(tensor, mask)  # [0, 2]\n",
      "        ```\n",
      "        \n",
      "        In general, `0 < dim(mask) = K <= dim(tensor)`, and `mask`'s shape must match\n",
      "        the first K dimensions of `tensor`'s shape.  We then have:\n",
      "          `boolean_mask(tensor, mask)[i, j1,...,jd] = tensor[i1,...,iK,j1,...,jd]`\n",
      "        where `(i1,...,iK)` is the ith `True` entry of `mask` (row-major order).\n",
      "        The `axis` could be used with `mask` to indicate the axis to mask from.\n",
      "        In that case, `axis + dim(mask) <= dim(tensor)` and `mask`'s shape must match\n",
      "        the first `axis + dim(mask)` dimensions of `tensor`'s shape.\n",
      "        \n",
      "        See also: `tf.ragged.boolean_mask`, which can be applied to both dense and\n",
      "        ragged tensors, and can be used if you need to preserve the masked dimensions\n",
      "        of `tensor` (rather than flattening them, as `tf.boolean_mask` does).\n",
      "        \n",
      "        Args:\n",
      "          tensor:  N-D tensor.\n",
      "          mask:  K-D boolean tensor, K <= N and K must be known statically.\n",
      "          name:  A name for this operation (optional).\n",
      "          axis:  A 0-D int Tensor representing the axis in `tensor` to mask from. By\n",
      "            default, axis is 0 which will mask from the first dimension. Otherwise K +\n",
      "            axis <= N.\n",
      "        \n",
      "        Returns:\n",
      "          (N-K+1)-dimensional tensor populated by entries in `tensor` corresponding\n",
      "          to `True` values in `mask`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError:  If shapes do not conform.\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "        ```python\n",
      "        # 2-D example\n",
      "        tensor = [[1, 2], [3, 4], [5, 6]]\n",
      "        mask = np.array([True, False, True])\n",
      "        boolean_mask(tensor, mask)  # [[1, 2], [5, 6]]\n",
      "        ```\n",
      "    \n",
      "    broadcast_dynamic_shape(shape_x, shape_y)\n",
      "        Computes the shape of a broadcast given symbolic shapes.\n",
      "        \n",
      "        When shape_x and shape_y are Tensors representing shapes (i.e. the result of\n",
      "        calling tf.shape on another Tensor) this computes a Tensor which is the shape\n",
      "        of the result of a broadcasting op applied in tensors of shapes shape_x and\n",
      "        shape_y.\n",
      "        \n",
      "        For example, if shape_x is [1, 2, 3] and shape_y is [5, 1, 3], the result is a\n",
      "        Tensor whose value is [5, 2, 3].\n",
      "        \n",
      "        This is useful when validating the result of a broadcasting operation when the\n",
      "        tensors do not have statically known shapes.\n",
      "        \n",
      "        Args:\n",
      "          shape_x: A rank 1 integer `Tensor`, representing the shape of x.\n",
      "          shape_y: A rank 1 integer `Tensor`, representing the shape of y.\n",
      "        \n",
      "        Returns:\n",
      "          A rank 1 integer `Tensor` representing the broadcasted shape.\n",
      "    \n",
      "    broadcast_static_shape(shape_x, shape_y)\n",
      "        Computes the shape of a broadcast given known shapes.\n",
      "        \n",
      "        When shape_x and shape_y are fully known TensorShapes this computes a\n",
      "        TensorShape which is the shape of the result of a broadcasting op applied in\n",
      "        tensors of shapes shape_x and shape_y.\n",
      "        \n",
      "        For example, if shape_x is [1, 2, 3] and shape_y is [5, 1, 3], the result is a\n",
      "        TensorShape whose value is [5, 2, 3].\n",
      "        \n",
      "        This is useful when validating the result of a broadcasting operation when the\n",
      "        tensors have statically known shapes.\n",
      "        \n",
      "        Args:\n",
      "          shape_x: A `TensorShape`\n",
      "          shape_y: A `TensorShape`\n",
      "        \n",
      "        Returns:\n",
      "          A `TensorShape` representing the broadcasted shape.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If the two shapes can not be broadcasted.\n",
      "    \n",
      "    broadcast_to(input, shape, name=None)\n",
      "        Broadcast an array for a compatible shape.\n",
      "        \n",
      "        Broadcasting is the process of making arrays to have compatible shapes\n",
      "        for arithmetic operations. Two shapes are compatible if for each\n",
      "        dimension pair they are either equal or one of them is one. When trying\n",
      "        to broadcast a Tensor to a shape, it starts with the trailing dimensions,\n",
      "        and works its way forward.\n",
      "        \n",
      "        For example,\n",
      "        \n",
      "        ```python\n",
      "        >>> x = tf.constant([1, 2, 3])\n",
      "        >>> y = tf.broadcast_to(x, [3, 3])\n",
      "        >>> sess.run(y)\n",
      "        array([[1, 2, 3],\n",
      "               [1, 2, 3],\n",
      "               [1, 2, 3]], dtype=int32)\n",
      "        ```\n",
      "        \n",
      "        In the above example, the input Tensor with the shape of `[1, 3]`\n",
      "        is broadcasted to output Tensor with shape of `[3, 3]`.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. A Tensor to broadcast.\n",
      "          shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            An 1-D `int` Tensor. The shape of the desired output.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    case(pred_fn_pairs, default=None, exclusive=False, strict=False, name='case')\n",
      "        Create a case operation.\n",
      "        \n",
      "        See also `tf.switch_case`.\n",
      "        \n",
      "        The `pred_fn_pairs` parameter is a dict or list of pairs of size N.\n",
      "        Each pair contains a boolean scalar tensor and a python callable that\n",
      "        creates the tensors to be returned if the boolean evaluates to True.\n",
      "        `default` is a callable generating a list of tensors. All the callables\n",
      "        in `pred_fn_pairs` as well as `default` (if provided) should return the same\n",
      "        number and types of tensors.\n",
      "        \n",
      "        If `exclusive==True`, all predicates are evaluated, and an exception is\n",
      "        thrown if more than one of the predicates evaluates to `True`.\n",
      "        If `exclusive==False`, execution stops at the first predicate which\n",
      "        evaluates to True, and the tensors generated by the corresponding function\n",
      "        are returned immediately. If none of the predicates evaluate to True, this\n",
      "        operation returns the tensors generated by `default`.\n",
      "        \n",
      "        `tf.case` supports nested structures as implemented in\n",
      "        `tf.contrib.framework.nest`. All of the callables must return the same\n",
      "        (possibly nested) value structure of lists, tuples, and/or named tuples.\n",
      "        Singleton lists and tuples form the only exceptions to this: when returned by\n",
      "        a callable, they are implicitly unpacked to single values. This\n",
      "        behavior is disabled by passing `strict=True`.\n",
      "        \n",
      "        If an unordered dictionary is used for `pred_fn_pairs`, the order of the\n",
      "        conditional tests is not guaranteed. However, the order is guaranteed to be\n",
      "        deterministic, so that variables created in conditional branches are created\n",
      "        in fixed order across runs.\n",
      "        \n",
      "        @compatibility(eager)\n",
      "        Unordered dictionaries are not supported in eager mode when `exclusive=False`.\n",
      "        Use a list of tuples instead.\n",
      "        @end_compatibility\n",
      "        \n",
      "        \n",
      "        **Example 1:**\n",
      "        \n",
      "        Pseudocode:\n",
      "        \n",
      "        ```\n",
      "        if (x < y) return 17;\n",
      "        else return 23;\n",
      "        ```\n",
      "        \n",
      "        Expressions:\n",
      "        \n",
      "        ```python\n",
      "        f1 = lambda: tf.constant(17)\n",
      "        f2 = lambda: tf.constant(23)\n",
      "        r = tf.case([(tf.less(x, y), f1)], default=f2)\n",
      "        ```\n",
      "        \n",
      "        **Example 2:**\n",
      "        \n",
      "        Pseudocode:\n",
      "        \n",
      "        ```\n",
      "        if (x < y && x > z) raise OpError(\"Only one predicate may evaluate to True\");\n",
      "        if (x < y) return 17;\n",
      "        else if (x > z) return 23;\n",
      "        else return -1;\n",
      "        ```\n",
      "        \n",
      "        Expressions:\n",
      "        \n",
      "        ```python\n",
      "        def f1(): return tf.constant(17)\n",
      "        def f2(): return tf.constant(23)\n",
      "        def f3(): return tf.constant(-1)\n",
      "        r = tf.case({tf.less(x, y): f1, tf.greater(x, z): f2},\n",
      "                 default=f3, exclusive=True)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          pred_fn_pairs: Dict or list of pairs of a boolean scalar tensor and a\n",
      "            callable which returns a list of tensors.\n",
      "          default: Optional callable that returns a list of tensors.\n",
      "          exclusive: True iff at most one predicate is allowed to evaluate to `True`.\n",
      "          strict: A boolean that enables/disables 'strict' mode; see above.\n",
      "          name: A name for this operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          The tensors returned by the first pair whose predicate evaluated to True, or\n",
      "          those returned by `default` if none does.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `pred_fn_pairs` is not a list/dictionary.\n",
      "          TypeError: If `pred_fn_pairs` is a list but does not contain 2-tuples.\n",
      "          TypeError: If `fns[i]` is not callable for any i, or `default` is not\n",
      "                     callable.\n",
      "    \n",
      "    cast(x, dtype, name=None)\n",
      "        Casts a tensor to a new type.\n",
      "        \n",
      "        The operation casts `x` (in case of `Tensor`) or `x.values`\n",
      "        (in case of `SparseTensor` or `IndexedSlices`) to `dtype`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([1.8, 2.2], dtype=tf.float32)\n",
      "        tf.dtypes.cast(x, tf.int32)  # [1, 2], dtype=tf.int32\n",
      "        ```\n",
      "        \n",
      "        The operation supports data types (for `x` and `dtype`) of\n",
      "        `uint8`, `uint16`, `uint32`, `uint64`, `int8`, `int16`, `int32`, `int64`,\n",
      "        `float16`, `float32`, `float64`, `complex64`, `complex128`, `bfloat16`.\n",
      "        In case of casting from complex types (`complex64`, `complex128`) to real\n",
      "        types, only the real part of `x` is returned. In case of casting from real\n",
      "        types to complex types (`complex64`, `complex128`), the imaginary part of the\n",
      "        returned value is set to `0`. The handling of complex types here matches the\n",
      "        behavior of numpy.\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor` or `SparseTensor` or `IndexedSlices` of numeric type. It could\n",
      "            be `uint8`, `uint16`, `uint32`, `uint64`, `int8`, `int16`, `int32`,\n",
      "            `int64`, `float16`, `float32`, `float64`, `complex64`, `complex128`,\n",
      "            `bfloat16`.\n",
      "          dtype: The destination type. The list of supported dtypes is the same as\n",
      "            `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` or `SparseTensor` or `IndexedSlices` with same shape as `x` and\n",
      "            same type as `dtype`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `x` cannot be cast to the `dtype`.\n",
      "    \n",
      "    ceil(x, name=None)\n",
      "        Returns element-wise smallest integer not less than x.\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    check_numerics(tensor, message, name=None)\n",
      "        Checks a tensor for NaN and Inf values.\n",
      "        \n",
      "        When run, reports an `InvalidArgument` error if `tensor` has any values\n",
      "        that are not a number (NaN) or infinity (Inf). Otherwise, passes `tensor` as-is.\n",
      "        \n",
      "        Args:\n",
      "          tensor: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.\n",
      "          message: A `string`. Prefix of the error message.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `tensor`.\n",
      "    \n",
      "    cholesky(input, name=None)\n",
      "        Computes the Cholesky decomposition of one or more square matrices.\n",
      "        \n",
      "        The input is a tensor of shape `[..., M, M]` whose inner-most 2 dimensions\n",
      "        form square matrices.\n",
      "        \n",
      "        The input has to be symmetric and positive definite. Only the lower-triangular\n",
      "        part of the input will be used for this operation. The upper-triangular part\n",
      "        will not be read.\n",
      "        \n",
      "        The output is a tensor of the same shape as the input\n",
      "        containing the Cholesky decompositions for all input submatrices `[..., :, :]`.\n",
      "        \n",
      "        **Note**: The gradient computation on GPU is faster for large matrices but\n",
      "        not for large batch dimensions when the submatrices are small. In this\n",
      "        case it might be faster to use the CPU.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `float64`, `float32`, `half`, `complex64`, `complex128`.\n",
      "            Shape is `[..., M, M]`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    cholesky_solve(chol, rhs, name=None)\n",
      "        Solves systems of linear eqns `A X = RHS`, given Cholesky factorizations.\n",
      "        \n",
      "        ```python\n",
      "        # Solve 10 separate 2x2 linear systems:\n",
      "        A = ... # shape 10 x 2 x 2\n",
      "        RHS = ... # shape 10 x 2 x 1\n",
      "        chol = tf.linalg.cholesky(A)  # shape 10 x 2 x 2\n",
      "        X = tf.linalg.cholesky_solve(chol, RHS)  # shape 10 x 2 x 1\n",
      "        # tf.matmul(A, X) ~ RHS\n",
      "        X[3, :, 0]  # Solution to the linear system A[3, :, :] x = RHS[3, :, 0]\n",
      "        \n",
      "        # Solve five linear systems (K = 5) for every member of the length 10 batch.\n",
      "        A = ... # shape 10 x 2 x 2\n",
      "        RHS = ... # shape 10 x 2 x 5\n",
      "        ...\n",
      "        X[3, :, 2]  # Solution to the linear system A[3, :, :] x = RHS[3, :, 2]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          chol:  A `Tensor`.  Must be `float32` or `float64`, shape is `[..., M, M]`.\n",
      "            Cholesky factorization of `A`, e.g. `chol = tf.linalg.cholesky(A)`.\n",
      "            For that reason, only the lower triangular parts (including the diagonal)\n",
      "            of the last two dimensions of `chol` are used.  The strictly upper part is\n",
      "            assumed to be zero and not accessed.\n",
      "          rhs:  A `Tensor`, same type as `chol`, shape is `[..., M, K]`.\n",
      "          name:  A name to give this `Op`.  Defaults to `cholesky_solve`.\n",
      "        \n",
      "        Returns:\n",
      "          Solution to `A x = rhs`, shape `[..., M, K]`.\n",
      "    \n",
      "    clip_by_average_norm(t, clip_norm, name=None)\n",
      "        Clips tensor values to a maximum average L2-norm. (deprecated)\n",
      "        \n",
      "        Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        clip_by_average_norm is deprecated in TensorFlow 2.0. Please use clip_by_norm(t, clip_norm * tf.cast(tf.size(t), tf.float32), name) instead.\n",
      "        \n",
      "        Given a tensor `t`, and a maximum clip value `clip_norm`, this operation\n",
      "        normalizes `t` so that its average L2-norm is less than or equal to\n",
      "        `clip_norm`. Specifically, if the average L2-norm is already less than or\n",
      "        equal to `clip_norm`, then `t` is not modified. If the average L2-norm is\n",
      "        greater than `clip_norm`, then this operation returns a tensor of the same\n",
      "        type and shape as `t` with its values set to:\n",
      "        \n",
      "        `t * clip_norm / l2norm_avg(t)`\n",
      "        \n",
      "        In this case, the average L2-norm of the output tensor is `clip_norm`.\n",
      "        \n",
      "        This operation is typically used to clip gradients before applying them with\n",
      "        an optimizer.\n",
      "        \n",
      "        Args:\n",
      "          t: A `Tensor`.\n",
      "          clip_norm: A 0-D (scalar) `Tensor` > 0. A maximum clipping value.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A clipped `Tensor`.\n",
      "    \n",
      "    clip_by_global_norm(t_list, clip_norm, use_norm=None, name=None)\n",
      "        Clips values of multiple tensors by the ratio of the sum of their norms.\n",
      "        \n",
      "        Given a tuple or list of tensors `t_list`, and a clipping ratio `clip_norm`,\n",
      "        this operation returns a list of clipped tensors `list_clipped`\n",
      "        and the global norm (`global_norm`) of all tensors in `t_list`. Optionally,\n",
      "        if you've already computed the global norm for `t_list`, you can specify\n",
      "        the global norm with `use_norm`.\n",
      "        \n",
      "        To perform the clipping, the values `t_list[i]` are set to:\n",
      "        \n",
      "            t_list[i] * clip_norm / max(global_norm, clip_norm)\n",
      "        \n",
      "        where:\n",
      "        \n",
      "            global_norm = sqrt(sum([l2norm(t)**2 for t in t_list]))\n",
      "        \n",
      "        If `clip_norm > global_norm` then the entries in `t_list` remain as they are,\n",
      "        otherwise they're all shrunk by the global ratio.\n",
      "        \n",
      "        If `global_norm == infinity` then the entries in `t_list` are all set to `NaN`\n",
      "        to signal that an error occurred.\n",
      "        \n",
      "        Any of the entries of `t_list` that are of type `None` are ignored.\n",
      "        \n",
      "        This is the correct way to perform gradient clipping (for example, see\n",
      "        [Pascanu et al., 2012](http://arxiv.org/abs/1211.5063)\n",
      "        ([pdf](http://arxiv.org/pdf/1211.5063.pdf))).\n",
      "        \n",
      "        However, it is slower than `clip_by_norm()` because all the parameters must be\n",
      "        ready before the clipping operation can be performed.\n",
      "        \n",
      "        Args:\n",
      "          t_list: A tuple or list of mixed `Tensors`, `IndexedSlices`, or None.\n",
      "          clip_norm: A 0-D (scalar) `Tensor` > 0. The clipping ratio.\n",
      "          use_norm: A 0-D (scalar) `Tensor` of type `float` (optional). The global\n",
      "            norm to use. If not provided, `global_norm()` is used to compute the norm.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          list_clipped: A list of `Tensors` of the same type as `list_t`.\n",
      "          global_norm: A 0-D (scalar) `Tensor` representing the global norm.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `t_list` is not a sequence.\n",
      "    \n",
      "    clip_by_norm(t, clip_norm, axes=None, name=None)\n",
      "        Clips tensor values to a maximum L2-norm.\n",
      "        \n",
      "        Given a tensor `t`, and a maximum clip value `clip_norm`, this operation\n",
      "        normalizes `t` so that its L2-norm is less than or equal to `clip_norm`,\n",
      "        along the dimensions given in `axes`. Specifically, in the default case\n",
      "        where all dimensions are used for calculation, if the L2-norm of `t` is\n",
      "        already less than or equal to `clip_norm`, then `t` is not modified. If\n",
      "        the L2-norm is greater than `clip_norm`, then this operation returns a\n",
      "        tensor of the same type and shape as `t` with its values set to:\n",
      "        \n",
      "        `t * clip_norm / l2norm(t)`\n",
      "        \n",
      "        In this case, the L2-norm of the output tensor is `clip_norm`.\n",
      "        \n",
      "        As another example, if `t` is a matrix and `axes == [1]`, then each row\n",
      "        of the output will have L2-norm less than or equal to `clip_norm`. If\n",
      "        `axes == [0]` instead, each column of the output will be clipped.\n",
      "        \n",
      "        This operation is typically used to clip gradients before applying them with\n",
      "        an optimizer.\n",
      "        \n",
      "        Args:\n",
      "          t: A `Tensor` or `IndexedSlices`.\n",
      "          clip_norm: A 0-D (scalar) `Tensor` > 0. A maximum clipping value.\n",
      "          axes: A 1-D (vector) `Tensor` of type int32 containing the dimensions\n",
      "            to use for computing the L2-norm. If `None` (the default), uses all\n",
      "            dimensions.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A clipped `Tensor` or `IndexedSlices`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If the clip_norm tensor is not a 0-D scalar tensor.\n",
      "          TypeError: If dtype of the input is not a floating point or\n",
      "            complex type.\n",
      "    \n",
      "    clip_by_value(t, clip_value_min, clip_value_max, name=None)\n",
      "        Clips tensor values to a specified min and max.\n",
      "        \n",
      "        Given a tensor `t`, this operation returns a tensor of the same type and\n",
      "        shape as `t` with its values clipped to `clip_value_min` and `clip_value_max`.\n",
      "        Any values less than `clip_value_min` are set to `clip_value_min`. Any values\n",
      "        greater than `clip_value_max` are set to `clip_value_max`.\n",
      "        \n",
      "        Note: `clip_value_min` needs to be smaller or equal to `clip_value_max` for\n",
      "        correct results.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        A = tf.constant([[1, 20, 13], [3, 21, 13]])\n",
      "        B = tf.clip_by_value(A, clip_value_min=0, clip_value_max=3) # [[1, 3, 3],[3, 3, 3]]\n",
      "        C = tf.clip_by_value(A, clip_value_min=0., clip_value_max=3.) # throws `TypeError`\n",
      "        as input and clip_values are of different dtype\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          t: A `Tensor` or `IndexedSlices`.\n",
      "          clip_value_min: A 0-D (scalar) `Tensor`, or a `Tensor` with the same shape\n",
      "            as `t`. The minimum value to clip by.\n",
      "          clip_value_max: A 0-D (scalar) `Tensor`, or a `Tensor` with the same shape\n",
      "            as `t`. The maximum value to clip by.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A clipped `Tensor` or `IndexedSlices`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If the clip tensors would trigger array broadcasting\n",
      "            that would make the returned tensor larger than the input.\n",
      "          TypeError: If dtype of the input is `int32` and dtype of\n",
      "          the `clip_value_min' or `clip_value_max` is `float32`\n",
      "    \n",
      "    colocate_with = _colocate_with(op, ignore_existing=False)\n",
      "        DEPRECATED FUNCTION\n",
      "        \n",
      "        Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Colocations handled automatically by placer.\n",
      "    \n",
      "    complex(real, imag, name=None)\n",
      "        Converts two real numbers to a complex number.\n",
      "        \n",
      "        Given a tensor `real` representing the real part of a complex number, and a\n",
      "        tensor `imag` representing the imaginary part of a complex number, this\n",
      "        operation returns complex numbers elementwise of the form \\\\(a + bj\\\\), where\n",
      "        *a* represents the `real` part and *b* represents the `imag` part.\n",
      "        \n",
      "        The input tensors `real` and `imag` must have the same shape.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        real = tf.constant([2.25, 3.25])\n",
      "        imag = tf.constant([4.75, 5.75])\n",
      "        tf.complex(real, imag)  # [[2.25 + 4.75j], [3.25 + 5.75j]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          real: A `Tensor`. Must be one of the following types: `float32`, `float64`.\n",
      "          imag: A `Tensor`. Must have the same type as `real`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `complex64` or `complex128`.\n",
      "        \n",
      "        Raises: \n",
      "          TypeError: Real and imag must be correct types\n",
      "    \n",
      "    concat(values, axis, name='concat')\n",
      "        Concatenates tensors along one dimension.\n",
      "        \n",
      "        Concatenates the list of tensors `values` along dimension `axis`.  If\n",
      "        `values[i].shape = [D0, D1, ... Daxis(i), ...Dn]`, the concatenated\n",
      "        result has shape\n",
      "        \n",
      "            [D0, D1, ... Raxis, ...Dn]\n",
      "        \n",
      "        where\n",
      "        \n",
      "            Raxis = sum(Daxis(i))\n",
      "        \n",
      "        That is, the data from the input tensors is joined along the `axis`\n",
      "        dimension.\n",
      "        \n",
      "        The number of dimensions of the input tensors must match, and all dimensions\n",
      "        except `axis` must be equal.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        t1 = [[1, 2, 3], [4, 5, 6]]\n",
      "        t2 = [[7, 8, 9], [10, 11, 12]]\n",
      "        tf.concat([t1, t2], 0)  # [[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]]\n",
      "        tf.concat([t1, t2], 1)  # [[1, 2, 3, 7, 8, 9], [4, 5, 6, 10, 11, 12]]\n",
      "        \n",
      "        # tensor t3 with shape [2, 3]\n",
      "        # tensor t4 with shape [2, 3]\n",
      "        tf.shape(tf.concat([t3, t4], 0))  # [4, 3]\n",
      "        tf.shape(tf.concat([t3, t4], 1))  # [2, 6]\n",
      "        ```\n",
      "        As in Python, the `axis` could also be negative numbers. Negative `axis`\n",
      "        are interpreted as counting from the end of the rank, i.e.,\n",
      "         `axis + rank(values)`-th dimension.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        t1 = [[[1, 2], [2, 3]], [[4, 4], [5, 3]]]\n",
      "        t2 = [[[7, 4], [8, 4]], [[2, 10], [15, 11]]]\n",
      "        tf.concat([t1, t2], -1)\n",
      "        ```\n",
      "        \n",
      "        would produce:\n",
      "        \n",
      "        ```python\n",
      "        [[[ 1,  2,  7,  4],\n",
      "          [ 2,  3,  8,  4]],\n",
      "        \n",
      "         [[ 4,  4,  2, 10],\n",
      "          [ 5,  3, 15, 11]]]\n",
      "        ```\n",
      "        \n",
      "        Note: If you are concatenating along a new axis consider using stack.\n",
      "        E.g.\n",
      "        \n",
      "        ```python\n",
      "        tf.concat([tf.expand_dims(t, axis) for t in tensors], axis)\n",
      "        ```\n",
      "        \n",
      "        can be rewritten as\n",
      "        \n",
      "        ```python\n",
      "        tf.stack(tensors, axis=axis)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          values: A list of `Tensor` objects or a single `Tensor`.\n",
      "          axis: 0-D `int32` `Tensor`.  Dimension along which to concatenate. Must be\n",
      "            in the range `[-rank(values), rank(values))`. As in Python, indexing for\n",
      "            axis is 0-based. Positive axis in the rage of `[0, rank(values))` refers\n",
      "            to `axis`-th dimension. And negative axis refers to `axis +\n",
      "            rank(values)`-th dimension.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` resulting from concatenation of the input tensors.\n",
      "    \n",
      "    cond(pred, true_fn=None, false_fn=None, strict=False, name=None, fn1=None, fn2=None)\n",
      "        Return `true_fn()` if the predicate `pred` is true else `false_fn()`. (deprecated arguments)\n",
      "        \n",
      "        Warning: SOME ARGUMENTS ARE DEPRECATED: `(fn1, fn2)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        fn1/fn2 are deprecated in favor of the true_fn/false_fn arguments.\n",
      "        \n",
      "        `true_fn` and `false_fn` both return lists of output tensors. `true_fn` and\n",
      "        `false_fn` must have the same non-zero number and type of outputs.\n",
      "        \n",
      "        **WARNING**: Any Tensors or Operations created outside of `true_fn` and\n",
      "        `false_fn` will be executed regardless of which branch is selected at runtime.\n",
      "        \n",
      "        Although this behavior is consistent with the dataflow model of TensorFlow,\n",
      "        it has frequently surprised users who expected a lazier semantics.\n",
      "        Consider the following simple program:\n",
      "        \n",
      "        ```python\n",
      "        z = tf.multiply(a, b)\n",
      "        result = tf.cond(x < y, lambda: tf.add(x, z), lambda: tf.square(y))\n",
      "        ```\n",
      "        \n",
      "        If `x < y`, the `tf.add` operation will be executed and `tf.square`\n",
      "        operation will not be executed. Since `z` is needed for at least one\n",
      "        branch of the `cond`, the `tf.multiply` operation is always executed,\n",
      "        unconditionally.\n",
      "        \n",
      "        Note that `cond` calls `true_fn` and `false_fn` *exactly once* (inside the\n",
      "        call to `cond`, and not at all during `Session.run()`). `cond`\n",
      "        stitches together the graph fragments created during the `true_fn` and\n",
      "        `false_fn` calls with some additional graph nodes to ensure that the right\n",
      "        branch gets executed depending on the value of `pred`.\n",
      "        \n",
      "        `tf.cond` supports nested structures as implemented in\n",
      "        `tensorflow.python.util.nest`. Both `true_fn` and `false_fn` must return the\n",
      "        same (possibly nested) value structure of lists, tuples, and/or named tuples.\n",
      "        Singleton lists and tuples form the only exceptions to this: when returned by\n",
      "        `true_fn` and/or `false_fn`, they are implicitly unpacked to single values.\n",
      "        This behavior is disabled by passing `strict=True`.\n",
      "        \n",
      "        Args:\n",
      "          pred: A scalar determining whether to return the result of `true_fn` or\n",
      "            `false_fn`.\n",
      "          true_fn: The callable to be performed if pred is true.\n",
      "          false_fn: The callable to be performed if pred is false.\n",
      "          strict: A boolean that enables/disables 'strict' mode; see above.\n",
      "          name: Optional name prefix for the returned tensors.\n",
      "        \n",
      "        Returns:\n",
      "          Tensors returned by the call to either `true_fn` or `false_fn`. If the\n",
      "          callables return a singleton list, the element is extracted from the list.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: if `true_fn` or `false_fn` is not callable.\n",
      "          ValueError: if `true_fn` and `false_fn` do not return the same number of\n",
      "            tensors, or return tensors of different types.\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant(2)\n",
      "        y = tf.constant(5)\n",
      "        def f1(): return tf.multiply(x, 17)\n",
      "        def f2(): return tf.add(y, 23)\n",
      "        r = tf.cond(tf.less(x, y), f1, f2)\n",
      "        # r is set to f1().\n",
      "        # Operations in f2 (e.g., tf.add) are not executed.\n",
      "        ```\n",
      "    \n",
      "    confusion_matrix = confusion_matrix_v1(labels, predictions, num_classes=None, dtype=tf.int32, name=None, weights=None)\n",
      "        Computes the confusion matrix from predictions and labels.\n",
      "        \n",
      "        The matrix columns represent the prediction labels and the rows represent the\n",
      "        real labels. The confusion matrix is always a 2-D array of shape `[n, n]`,\n",
      "        where `n` is the number of valid labels for a given classification task. Both\n",
      "        prediction and labels must be 1-D arrays of the same shape in order for this\n",
      "        function to work.\n",
      "        \n",
      "        If `num_classes` is `None`, then `num_classes` will be set to one plus the\n",
      "        maximum value in either predictions or labels. Class labels are expected to\n",
      "        start at 0. For example, if `num_classes` is 3, then the possible labels\n",
      "        would be `[0, 1, 2]`.\n",
      "        \n",
      "        If `weights` is not `None`, then each prediction contributes its\n",
      "        corresponding weight to the total value of the confusion matrix cell.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "          tf.math.confusion_matrix([1, 2, 4], [2, 2, 4]) ==>\n",
      "              [[0 0 0 0 0]\n",
      "               [0 0 1 0 0]\n",
      "               [0 0 1 0 0]\n",
      "               [0 0 0 0 0]\n",
      "               [0 0 0 0 1]]\n",
      "        ```\n",
      "        \n",
      "        Note that the possible labels are assumed to be `[0, 1, 2, 3, 4]`,\n",
      "        resulting in a 5x5 confusion matrix.\n",
      "        \n",
      "        Args:\n",
      "          labels: 1-D `Tensor` of real labels for the classification task.\n",
      "          predictions: 1-D `Tensor` of predictions for a given classification.\n",
      "          num_classes: The possible number of labels the classification task can have.\n",
      "            If this value is not provided, it will be calculated using both\n",
      "            predictions and labels array.\n",
      "          dtype: Data type of the confusion matrix.\n",
      "          name: Scope name.\n",
      "          weights: An optional `Tensor` whose shape matches `predictions`.\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `dtype` with shape `[n, n]` representing the confusion\n",
      "          matrix, where `n` is the number of possible labels in the classification\n",
      "          task.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If both predictions and labels are not 1-D vectors and have\n",
      "            mismatched shapes, or if `weights` is not `None` and its shape doesn't\n",
      "            match `predictions`.\n",
      "    \n",
      "    conj(x, name=None)\n",
      "        Returns the complex conjugate of a complex number.\n",
      "        \n",
      "        Given a tensor `input` of complex numbers, this operation returns a tensor of\n",
      "        complex numbers that are the complex conjugate of each element in `input`. The\n",
      "        complex numbers in `input` must be of the form \\\\(a + bj\\\\), where *a* is the\n",
      "        real part and *b* is the imaginary part.\n",
      "        \n",
      "        The complex conjugate returned by this operation is of the form \\\\(a - bj\\\\).\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "            # tensor 'input' is [-2.25 + 4.75j, 3.25 + 5.75j]\n",
      "            tf.math.conj(input) ==> [-2.25 - 4.75j, 3.25 - 5.75j]\n",
      "        \n",
      "        If `x` is real, it is returned unchanged.\n",
      "        \n",
      "        Args:\n",
      "          x: `Tensor` to conjugate.  Must have numeric or variant type.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` that is the conjugate of `x` (with the same type).\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `x` is not a numeric tensor.\n",
      "    \n",
      "    constant = constant_v1(value, dtype=None, shape=None, name='Const', verify_shape=False)\n",
      "        Creates a constant tensor.\n",
      "        \n",
      "        The resulting tensor is populated with values of type `dtype`, as\n",
      "        specified by arguments `value` and (optionally) `shape` (see examples\n",
      "        below).\n",
      "        \n",
      "        The argument `value` can be a constant value, or a list of values of type\n",
      "        `dtype`. If `value` is a list, then the length of the list must be less\n",
      "        than or equal to the number of elements implied by the `shape` argument (if\n",
      "        specified). In the case where the list length is less than the number of\n",
      "        elements specified by `shape`, the last element in the list will be used\n",
      "        to fill the remaining entries.\n",
      "        \n",
      "        The argument `shape` is optional. If present, it specifies the dimensions of\n",
      "        the resulting tensor. If not present, the shape of `value` is used.\n",
      "        \n",
      "        If the argument `dtype` is not specified, then the type is inferred from\n",
      "        the type of `value`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        # Constant 1-D Tensor populated with value list.\n",
      "        tensor = tf.constant([1, 2, 3, 4, 5, 6, 7]) => [1 2 3 4 5 6 7]\n",
      "        \n",
      "        # Constant 2-D tensor populated with scalar value -1.\n",
      "        tensor = tf.constant(-1.0, shape=[2, 3]) => [[-1. -1. -1.]\n",
      "                                                     [-1. -1. -1.]]\n",
      "        ```\n",
      "        \n",
      "        `tf.constant` differs from `tf.fill` in a few ways:\n",
      "        \n",
      "        *   `tf.constant` supports arbitrary constants, not just uniform scalar\n",
      "            Tensors like `tf.fill`.\n",
      "        *   `tf.constant` creates a `Const` node in the computation graph with the\n",
      "            exact value at graph construction time. On the other hand, `tf.fill`\n",
      "            creates an Op in the graph that is expanded at runtime.\n",
      "        *   Because `tf.constant` only embeds constant values in the graph, it does\n",
      "            not support dynamic shapes based on other runtime Tensors, whereas\n",
      "            `tf.fill` does.\n",
      "        \n",
      "        Args:\n",
      "          value:          A constant value (or list) of output type `dtype`.\n",
      "        \n",
      "          dtype:          The type of the elements of the resulting tensor.\n",
      "        \n",
      "          shape:          Optional dimensions of resulting tensor.\n",
      "        \n",
      "          name:           Optional name for the tensor.\n",
      "        \n",
      "          verify_shape:   Boolean that enables verification of a shape of values.\n",
      "        \n",
      "        Returns:\n",
      "          A Constant Tensor.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: if shape is incorrectly specified or unsupported.\n",
      "    \n",
      "    container(container_name)\n",
      "        Wrapper for `Graph.container()` using the default graph.\n",
      "        \n",
      "        Args:\n",
      "          container_name: The container string to use in the context.\n",
      "        \n",
      "        Returns:\n",
      "          A context manager that specifies the default container to use for newly\n",
      "          created stateful ops.\n",
      "    \n",
      "    control_dependencies(control_inputs)\n",
      "        Wrapper for `Graph.control_dependencies()` using the default graph.\n",
      "        \n",
      "        See `tf.Graph.control_dependencies`\n",
      "        for more details.\n",
      "        \n",
      "        When eager execution is enabled, any callable object in the `control_inputs`\n",
      "        list will be called.\n",
      "        \n",
      "        Args:\n",
      "          control_inputs: A list of `Operation` or `Tensor` objects which must be\n",
      "            executed or computed before running the operations defined in the context.\n",
      "            Can also be `None` to clear the control dependencies. If eager execution\n",
      "            is enabled, any callable object in the `control_inputs` list will be\n",
      "            called.\n",
      "        \n",
      "        Returns:\n",
      "         A context manager that specifies control dependencies for all\n",
      "         operations constructed within the context.\n",
      "    \n",
      "    control_flow_v2_enabled()\n",
      "        Returns `True` if v2 control flow is enabled.\n",
      "        \n",
      "        Note: v2 control flow is always enabled inside of tf.function.\n",
      "    \n",
      "    convert_to_tensor(value, dtype=None, name=None, preferred_dtype=None, dtype_hint=None)\n",
      "        Converts the given `value` to a `Tensor`.\n",
      "        \n",
      "        This function converts Python objects of various types to `Tensor`\n",
      "        objects. It accepts `Tensor` objects, numpy arrays, Python lists,\n",
      "        and Python scalars. For example:\n",
      "        \n",
      "        ```python\n",
      "        import numpy as np\n",
      "        \n",
      "        def my_func(arg):\n",
      "          arg = tf.convert_to_tensor(arg, dtype=tf.float32)\n",
      "          return tf.matmul(arg, arg) + arg\n",
      "        \n",
      "        # The following calls are equivalent.\n",
      "        value_1 = my_func(tf.constant([[1.0, 2.0], [3.0, 4.0]]))\n",
      "        value_2 = my_func([[1.0, 2.0], [3.0, 4.0]])\n",
      "        value_3 = my_func(np.array([[1.0, 2.0], [3.0, 4.0]], dtype=np.float32))\n",
      "        ```\n",
      "        \n",
      "        This function can be useful when composing a new operation in Python\n",
      "        (such as `my_func` in the example above). All standard Python op\n",
      "        constructors apply this function to each of their Tensor-valued\n",
      "        inputs, which allows those ops to accept numpy arrays, Python lists,\n",
      "        and scalars in addition to `Tensor` objects.\n",
      "        \n",
      "        Note: This function diverges from default Numpy behavior for `float` and\n",
      "          `string` types when `None` is present in a Python list or scalar. Rather\n",
      "          than silently converting `None` values, an error will be thrown.\n",
      "        \n",
      "        Args:\n",
      "          value: An object whose type has a registered `Tensor` conversion function.\n",
      "          dtype: Optional element type for the returned tensor. If missing, the type\n",
      "            is inferred from the type of `value`.\n",
      "          name: Optional name to use if a new `Tensor` is created.\n",
      "          preferred_dtype: Optional element type for the returned tensor, used when\n",
      "            dtype is None. In some cases, a caller may not have a dtype in mind when\n",
      "            converting to a tensor, so preferred_dtype can be used as a soft\n",
      "            preference.  If the conversion to `preferred_dtype` is not possible, this\n",
      "            argument has no effect.\n",
      "          dtype_hint: same meaning as preferred_dtype, and overrides it.\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` based on `value`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If no conversion function is registered for `value` to `dtype`.\n",
      "          RuntimeError: If a registered conversion function returns an invalid value.\n",
      "          ValueError: If the `value` is a tensor not of given `dtype` in graph mode.\n",
      "    \n",
      "    convert_to_tensor_or_indexed_slices(value, dtype=None, name=None)\n",
      "        Converts the given object to a `Tensor` or an `IndexedSlices`.\n",
      "        \n",
      "        If `value` is an `IndexedSlices` or `SparseTensor` it is returned\n",
      "        unmodified. Otherwise, it is converted to a `Tensor` using\n",
      "        `convert_to_tensor()`.\n",
      "        \n",
      "        Args:\n",
      "          value: An `IndexedSlices`, `SparseTensor`, or an object that can be consumed\n",
      "            by `convert_to_tensor()`.\n",
      "          dtype: (Optional.) The required `DType` of the returned `Tensor` or\n",
      "            `IndexedSlices`.\n",
      "          name: (Optional.) A name to use if a new `Tensor` is created.\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`, `IndexedSlices`, or `SparseTensor` based on `value`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If `dtype` does not match the element type of `value`.\n",
      "    \n",
      "    convert_to_tensor_or_sparse_tensor(value, dtype=None, name=None)\n",
      "        Converts value to a `SparseTensor` or `Tensor`.\n",
      "        \n",
      "        Args:\n",
      "          value: A `SparseTensor`, `SparseTensorValue`, or an object whose type has a\n",
      "            registered `Tensor` conversion function.\n",
      "          dtype: Optional element type for the returned tensor. If missing, the type\n",
      "            is inferred from the type of `value`.\n",
      "          name: Optional name to use if a new `Tensor` is created.\n",
      "        \n",
      "        Returns:\n",
      "          A `SparseTensor` or `Tensor` based on `value`.\n",
      "        \n",
      "        Raises:\n",
      "          RuntimeError: If result type is incompatible with `dtype`.\n",
      "    \n",
      "    cos(x, name=None)\n",
      "        Computes cos of x element-wise.\n",
      "        \n",
      "          Given an input tensor, this function computes cosine of every\n",
      "          element in the tensor. Input range is `(-inf, inf)` and\n",
      "          output range is `[-1,1]`. If input lies outside the boundary, `nan`\n",
      "          is returned.\n",
      "        \n",
      "          ```python\n",
      "          x = tf.constant([-float(\"inf\"), -9, -0.5, 1, 1.2, 200, 10000, float(\"inf\")])\n",
      "          tf.math.cos(x) ==> [nan -0.91113025 0.87758255 0.5403023 0.36235774 0.48718765 -0.95215535 nan]\n",
      "          ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    cosh(x, name=None)\n",
      "        Computes hyperbolic cosine of x element-wise.\n",
      "        \n",
      "          Given an input tensor, this function computes hyperbolic cosine of every\n",
      "          element in the tensor. Input range is `[-inf, inf]` and output range\n",
      "          is `[1, inf]`.\n",
      "        \n",
      "          ```python\n",
      "          x = tf.constant([-float(\"inf\"), -9, -0.5, 1, 1.2, 2, 10, float(\"inf\")])\n",
      "          tf.math.cosh(x) ==> [inf 4.0515420e+03 1.1276259e+00 1.5430807e+00 1.8106556e+00 3.7621956e+00 1.1013233e+04 inf]\n",
      "          ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    count_nonzero(input_tensor=None, axis=None, keepdims=None, dtype=tf.int64, name=None, reduction_indices=None, keep_dims=None, input=None)\n",
      "        Computes number of nonzero elements across dimensions of a tensor. (deprecated arguments) (deprecated arguments)\n",
      "        \n",
      "        Warning: SOME ARGUMENTS ARE DEPRECATED: `(keep_dims)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        keep_dims is deprecated, use keepdims instead\n",
      "        \n",
      "        Warning: SOME ARGUMENTS ARE DEPRECATED: `(axis)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        reduction_indices is deprecated, use axis instead\n",
      "        \n",
      "        Reduces `input_tensor` along the dimensions given in `axis`.\n",
      "        Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each\n",
      "        entry in `axis`. If `keepdims` is true, the reduced dimensions\n",
      "        are retained with length 1.\n",
      "        \n",
      "        If `axis` has no entries, all dimensions are reduced, and a\n",
      "        tensor with a single element is returned.\n",
      "        \n",
      "        **NOTE** Floating point comparison to zero is done by exact floating point\n",
      "        equality check.  Small values are **not** rounded to zero for purposes of\n",
      "        the nonzero check.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([[0, 1, 0], [1, 1, 0]])\n",
      "        tf.math.count_nonzero(x)  # 3\n",
      "        tf.math.count_nonzero(x, 0)  # [1, 2, 0]\n",
      "        tf.math.count_nonzero(x, 1)  # [1, 2]\n",
      "        tf.math.count_nonzero(x, 1, keepdims=True)  # [[1], [2]]\n",
      "        tf.math.count_nonzero(x, [0, 1])  # 3\n",
      "        ```\n",
      "        \n",
      "        **NOTE** Strings are compared against zero-length empty string `\"\"`. Any\n",
      "        string with a size greater than zero is already considered as nonzero.\n",
      "        \n",
      "        For example:\n",
      "        ```python\n",
      "        x = tf.constant([\"\", \"a\", \"  \", \"b\", \"\"])\n",
      "        tf.math.count_nonzero(x) # 3, with \"a\", \"  \", and \"b\" as nonzero strings.\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input_tensor: The tensor to reduce. Should be of numeric type, `bool`, or\n",
      "            `string`.\n",
      "          axis: The dimensions to reduce. If `None` (the default), reduces all\n",
      "            dimensions. Must be in the range `[-rank(input_tensor),\n",
      "            rank(input_tensor))`.\n",
      "          keepdims: If true, retains reduced dimensions with length 1.\n",
      "          dtype: The output dtype; defaults to `tf.int64`.\n",
      "          name: A name for the operation (optional).\n",
      "          reduction_indices: The old (deprecated) name for axis.\n",
      "          keep_dims: Deprecated alias for `keepdims`.\n",
      "          input: Overrides input_tensor. For compatibility.\n",
      "        \n",
      "        Returns:\n",
      "          The reduced tensor (number of nonzero values).\n",
      "    \n",
      "    count_up_to(ref, limit, name=None)\n",
      "        Increments 'ref' until it reaches 'limit'. (deprecated)\n",
      "        \n",
      "        Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Prefer Dataset.range instead.\n",
      "        \n",
      "        Args:\n",
      "          ref: A Variable. Must be one of the following types: `int32`, `int64`.\n",
      "            Should be from a scalar `Variable` node.\n",
      "          limit: An `int`.\n",
      "            If incrementing ref would bring it above limit, instead generates an\n",
      "            'OutOfRange' error.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `ref`.\n",
      "          A copy of the input before increment. If nothing else modifies the\n",
      "          input, the values produced will all be distinct.\n",
      "    \n",
      "    create_partitioned_variables(shape, slicing, initializer, dtype=tf.float32, trainable=True, collections=None, name=None, reuse=None)\n",
      "        Create a list of partitioned variables according to the given `slicing`. (deprecated)\n",
      "        \n",
      "        Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Use `tf.get_variable` with a partitioner set.\n",
      "        \n",
      "        Currently only one dimension of the full variable can be sliced, and the\n",
      "        full variable can be reconstructed by the concatenation of the returned\n",
      "        list along that dimension.\n",
      "        \n",
      "        Args:\n",
      "          shape: List of integers.  The shape of the full variable.\n",
      "          slicing: List of integers.  How to partition the variable.\n",
      "            Must be of the same length as `shape`.  Each value\n",
      "            indicate how many slices to create in the corresponding\n",
      "            dimension.  Presently only one of the values can be more than 1;\n",
      "            that is, the variable can only be sliced along one dimension.\n",
      "        \n",
      "            For convenience, The requested number of partitions does not have to\n",
      "            divide the corresponding dimension evenly.  If it does not, the\n",
      "            shapes of the partitions are incremented by 1 starting from partition\n",
      "            0 until all slack is absorbed.  The adjustment rules may change in the\n",
      "            future, but as you can save/restore these variables with different\n",
      "            slicing specifications this should not be a problem.\n",
      "          initializer: A `Tensor` of shape `shape` or a variable initializer\n",
      "            function.  If a function, it will be called once for each slice,\n",
      "            passing the shape and data type of the slice as parameters.  The\n",
      "            function must return a tensor with the same shape as the slice.\n",
      "          dtype: Type of the variables. Ignored if `initializer` is a `Tensor`.\n",
      "          trainable: If True also add all the variables to the graph collection\n",
      "            `GraphKeys.TRAINABLE_VARIABLES`.\n",
      "          collections: List of graph collections keys to add the variables to.\n",
      "            Defaults to `[GraphKeys.GLOBAL_VARIABLES]`.\n",
      "          name: Optional name for the full variable.  Defaults to\n",
      "            `\"PartitionedVariable\"` and gets uniquified automatically.\n",
      "          reuse: Boolean or `None`; if `True` and name is set, it would reuse\n",
      "            previously created variables. if `False` it will create new variables.\n",
      "            if `None`, it would inherit the parent scope reuse.\n",
      "        \n",
      "        Returns:\n",
      "          A list of Variables corresponding to the slicing.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If any of the arguments is malformed.\n",
      "    \n",
      "    cross(a, b, name=None)\n",
      "        Compute the pairwise cross product.\n",
      "        \n",
      "        `a` and `b` must be the same shape; they can either be simple 3-element vectors,\n",
      "        or any shape where the innermost dimension is 3. In the latter case, each pair\n",
      "        of corresponding 3-element vectors is cross-multiplied independently.\n",
      "        \n",
      "        Args:\n",
      "          a: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "            A tensor containing 3-element vectors.\n",
      "          b: A `Tensor`. Must have the same type as `a`.\n",
      "            Another tensor, of same type and shape as `a`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `a`.\n",
      "    \n",
      "    cumprod(x, axis=0, exclusive=False, reverse=False, name=None)\n",
      "        Compute the cumulative product of the tensor `x` along `axis`.\n",
      "        \n",
      "        By default, this op performs an inclusive cumprod, which means that the\n",
      "        first element of the input is identical to the first element of the output:\n",
      "        \n",
      "        ```python\n",
      "        tf.math.cumprod([a, b, c])  # [a, a * b, a * b * c]\n",
      "        ```\n",
      "        \n",
      "        By setting the `exclusive` kwarg to `True`, an exclusive cumprod is\n",
      "        performed\n",
      "        instead:\n",
      "        \n",
      "        ```python\n",
      "        tf.math.cumprod([a, b, c], exclusive=True)  # [1, a, a * b]\n",
      "        ```\n",
      "        \n",
      "        By setting the `reverse` kwarg to `True`, the cumprod is performed in the\n",
      "        opposite direction:\n",
      "        \n",
      "        ```python\n",
      "        tf.math.cumprod([a, b, c], reverse=True)  # [a * b * c, b * c, c]\n",
      "        ```\n",
      "        \n",
      "        This is more efficient than using separate `tf.reverse` ops.\n",
      "        The `reverse` and `exclusive` kwargs can also be combined:\n",
      "        \n",
      "        ```python\n",
      "        tf.math.cumprod([a, b, c], exclusive=True, reverse=True)  # [b * c, c, 1]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `float32`, `float64`,\n",
      "            `int64`, `int32`, `uint8`, `uint16`, `int16`, `int8`, `complex64`,\n",
      "            `complex128`, `qint8`, `quint8`, `qint32`, `half`.\n",
      "          axis: A `Tensor` of type `int32` (default: 0). Must be in the range\n",
      "            `[-rank(x), rank(x))`.\n",
      "          exclusive: If `True`, perform exclusive cumprod.\n",
      "          reverse: A `bool` (default: False).\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    cumsum(x, axis=0, exclusive=False, reverse=False, name=None)\n",
      "        Compute the cumulative sum of the tensor `x` along `axis`.\n",
      "        \n",
      "        By default, this op performs an inclusive cumsum, which means that the first\n",
      "        element of the input is identical to the first element of the output:\n",
      "        \n",
      "        ```python\n",
      "        tf.cumsum([a, b, c])  # [a, a + b, a + b + c]\n",
      "        ```\n",
      "        \n",
      "        By setting the `exclusive` kwarg to `True`, an exclusive cumsum is performed\n",
      "        instead:\n",
      "        \n",
      "        ```python\n",
      "        tf.cumsum([a, b, c], exclusive=True)  # [0, a, a + b]\n",
      "        ```\n",
      "        \n",
      "        By setting the `reverse` kwarg to `True`, the cumsum is performed in the\n",
      "        opposite direction:\n",
      "        \n",
      "        ```python\n",
      "        tf.cumsum([a, b, c], reverse=True)  # [a + b + c, b + c, c]\n",
      "        ```\n",
      "        \n",
      "        This is more efficient than using separate `tf.reverse` ops.\n",
      "        \n",
      "        The `reverse` and `exclusive` kwargs can also be combined:\n",
      "        \n",
      "        ```python\n",
      "        tf.cumsum([a, b, c], exclusive=True, reverse=True)  # [b + c, c, 0]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `float32`, `float64`,\n",
      "            `int64`, `int32`, `uint8`, `uint16`, `int16`, `int8`, `complex64`,\n",
      "            `complex128`, `qint8`, `quint8`, `qint32`, `half`.\n",
      "          axis: A `Tensor` of type `int32` (default: 0). Must be in the range\n",
      "            `[-rank(x), rank(x))`.\n",
      "          exclusive: If `True`, perform exclusive cumsum.\n",
      "          reverse: A `bool` (default: False).\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    custom_gradient(f)\n",
      "        Decorator to define a function with a custom gradient.\n",
      "        \n",
      "        This decorator allows fine grained control over the gradients of a sequence\n",
      "        for operations.  This may be useful for multiple reasons, including providing\n",
      "        a more efficient or numerically stable gradient for a sequence of operations.\n",
      "        \n",
      "        For example, consider the following function that commonly occurs in the\n",
      "        computation of cross entropy and log likelihoods:\n",
      "        \n",
      "        ```python\n",
      "        def log1pexp(x):\n",
      "          return tf.math.log(1 + tf.exp(x))\n",
      "        ```\n",
      "        \n",
      "        Due to numerical instability, the gradient this function evaluated at x=100 is\n",
      "        NaN.  For example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant(100.)\n",
      "        y = log1pexp(x)\n",
      "        dy = tf.gradients(y, x) # Will be NaN when evaluated.\n",
      "        ```\n",
      "        \n",
      "        The gradient expression can be analytically simplified to provide numerical\n",
      "        stability:\n",
      "        \n",
      "        ```python\n",
      "        @tf.custom_gradient\n",
      "        def log1pexp(x):\n",
      "          e = tf.exp(x)\n",
      "          def grad(dy):\n",
      "            return dy * (1 - 1 / (1 + e))\n",
      "          return tf.math.log(1 + e), grad\n",
      "        ```\n",
      "        \n",
      "        With this definition, the gradient at x=100 will be correctly evaluated as\n",
      "        1.0.\n",
      "        \n",
      "        See also `tf.RegisterGradient` which registers a gradient function for a\n",
      "        primitive TensorFlow operation. `tf.custom_gradient` on the other hand allows\n",
      "        for fine grained control over the gradient computation of a sequence of\n",
      "        operations.\n",
      "        \n",
      "        Note that if the decorated function uses `Variable`s, the enclosing variable\n",
      "        scope must be using `ResourceVariable`s.\n",
      "        \n",
      "        Args:\n",
      "          f: function `f(*x)` that returns a tuple `(y, grad_fn)` where:\n",
      "             - `x` is a sequence of `Tensor` inputs to the function.\n",
      "             - `y` is a `Tensor` or sequence of `Tensor` outputs of applying\n",
      "               TensorFlow operations in `f` to `x`.\n",
      "             - `grad_fn` is a function with the signature `g(*grad_ys)` which returns\n",
      "               a list of `Tensor`s - the derivatives of `Tensor`s in `y` with respect\n",
      "               to the `Tensor`s in `x`.  `grad_ys` is a `Tensor` or sequence of\n",
      "               `Tensor`s the same size as `y` holding the initial value gradients for\n",
      "               each `Tensor` in `y`. In a pure mathematical sense, a vector-argument\n",
      "               vector-valued function `f`'s derivatives should be its Jacobian matrix\n",
      "               `J`. Here we are expressing the Jacobian `J` as a function `grad_fn`\n",
      "               which defines how `J` will transform a vector `grad_ys` when\n",
      "               left-multiplied with it (`grad_ys * J`). This functional representation\n",
      "               of a matrix is convenient to use for chain-rule calculation\n",
      "               (in e.g. the back-propagation algorithm).\n",
      "        \n",
      "               If `f` uses `Variable`s (that are not part of the\n",
      "               inputs), i.e. through `get_variable`, then `grad_fn` should have\n",
      "               signature `g(*grad_ys, variables=None)`, where `variables` is a list of\n",
      "               the `Variable`s, and return a 2-tuple `(grad_xs, grad_vars)`, where\n",
      "               `grad_xs` is the same as above, and `grad_vars` is a `list<Tensor>`\n",
      "               with the derivatives of `Tensor`s in `y` with respect to the variables\n",
      "               (that is, grad_vars has one Tensor per variable in variables).\n",
      "        \n",
      "        Returns:\n",
      "          A function `h(x)` which returns the same value as `f(x)[0]` and whose\n",
      "          gradient (as calculated by `tf.gradients`) is determined by `f(x)[1]`.\n",
      "    \n",
      "    decode_base64(input, name=None)\n",
      "        Decode web-safe base64-encoded strings.\n",
      "        \n",
      "        Input may or may not have padding at the end. See EncodeBase64 for padding.\n",
      "        Web-safe means that input must use - and _ instead of + and /.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor` of type `string`. Base64 strings to decode.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `string`.\n",
      "    \n",
      "    decode_compressed(bytes, compression_type='', name=None)\n",
      "        Decompress strings.\n",
      "        \n",
      "        This op decompresses each element of the `bytes` input `Tensor`, which\n",
      "        is assumed to be compressed using the given `compression_type`.\n",
      "        \n",
      "        The `output` is a string `Tensor` of the same shape as `bytes`,\n",
      "        each element containing the decompressed data from the corresponding\n",
      "        element in `bytes`.\n",
      "        \n",
      "        Args:\n",
      "          bytes: A `Tensor` of type `string`.\n",
      "            A Tensor of string which is compressed.\n",
      "          compression_type: An optional `string`. Defaults to `\"\"`.\n",
      "            A scalar containing either (i) the empty string (no\n",
      "            compression), (ii) \"ZLIB\", or (iii) \"GZIP\".\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `string`.\n",
      "    \n",
      "    decode_csv(records, record_defaults, field_delim=',', use_quote_delim=True, name=None, na_value='', select_cols=None)\n",
      "        Convert CSV records to tensors. Each column maps to one tensor.\n",
      "        \n",
      "        RFC 4180 format is expected for the CSV records.\n",
      "        (https://tools.ietf.org/html/rfc4180)\n",
      "        Note that we allow leading and trailing spaces with int or float field.\n",
      "        \n",
      "        Args:\n",
      "          records: A `Tensor` of type `string`.\n",
      "            Each string is a record/row in the csv and all records should have\n",
      "            the same format.\n",
      "          record_defaults: A list of `Tensor` objects with specific types.\n",
      "            Acceptable types are `float32`, `float64`, `int32`, `int64`, `string`.\n",
      "            One tensor per column of the input record, with either a\n",
      "            scalar default value for that column or an empty vector if the column is\n",
      "            required.\n",
      "          field_delim: An optional `string`. Defaults to `\",\"`.\n",
      "            char delimiter to separate fields in a record.\n",
      "          use_quote_delim: An optional `bool`. Defaults to `True`.\n",
      "            If false, treats double quotation marks as regular\n",
      "            characters inside of the string fields (ignoring RFC 4180, Section 2,\n",
      "            Bullet 5).\n",
      "          name: A name for the operation (optional).\n",
      "          na_value: Additional string to recognize as NA/NaN.\n",
      "          select_cols: Optional sorted list of column indices to select. If specified,\n",
      "            only this subset of columns will be parsed and returned.\n",
      "        \n",
      "        Returns:\n",
      "          A list of `Tensor` objects. Has the same type as `record_defaults`.\n",
      "          Each tensor will have the same shape as records.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If any of the arguments is malformed.\n",
      "    \n",
      "    decode_json_example(json_examples, name=None)\n",
      "        Convert JSON-encoded Example records to binary protocol buffer strings.\n",
      "        \n",
      "        This op translates a tensor containing Example records, encoded using\n",
      "        the [standard JSON\n",
      "        mapping](https://developers.google.com/protocol-buffers/docs/proto3#json),\n",
      "        into a tensor containing the same records encoded as binary protocol\n",
      "        buffers. The resulting tensor can then be fed to any of the other\n",
      "        Example-parsing ops.\n",
      "        \n",
      "        Args:\n",
      "          json_examples: A `Tensor` of type `string`.\n",
      "            Each string is a JSON object serialized according to the JSON\n",
      "            mapping of the Example proto.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `string`.\n",
      "    \n",
      "    decode_raw = decode_raw_v1(input_bytes=None, out_type=None, little_endian=True, name=None, bytes=None)\n",
      "        Convert raw byte strings into tensors. (deprecated arguments)\n",
      "        \n",
      "        Warning: SOME ARGUMENTS ARE DEPRECATED: `(bytes)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        bytes is deprecated, use input_bytes instead\n",
      "        \n",
      "        Args:\n",
      "          input_bytes:\n",
      "            Each element of the input Tensor is converted to an array of bytes.\n",
      "          out_type:\n",
      "            `DType` of the output. Acceptable types are `half`, `float`, `double`,\n",
      "            `int32`, `uint16`, `uint8`, `int16`, `int8`, `int64`.\n",
      "          little_endian:\n",
      "            Whether the `input_bytes` data is in little-endian format. Data will be\n",
      "            converted into host byte order if necessary.\n",
      "          name: A name for the operation (optional).\n",
      "          bytes: Deprecated parameter. Use `input_bytes` instead.\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` object storing the decoded bytes.\n",
      "    \n",
      "    delete_session_tensor(handle, name=None)\n",
      "        Delete the tensor for the given tensor handle.\n",
      "        \n",
      "        This is EXPERIMENTAL and subject to change.\n",
      "        \n",
      "        Delete the tensor of a given tensor handle. The tensor is produced\n",
      "        in a previous run() and stored in the state of the session.\n",
      "        \n",
      "        Args:\n",
      "          handle: The string representation of a persistent tensor handle.\n",
      "          name: Optional name prefix for the return tensor.\n",
      "        \n",
      "        Returns:\n",
      "          A pair of graph elements. The first is a placeholder for feeding a\n",
      "          tensor handle and the second is a deletion operation.\n",
      "    \n",
      "    depth_to_space(input, block_size, name=None, data_format='NHWC')\n",
      "        DepthToSpace for tensors of type T.\n",
      "        \n",
      "        Rearranges data from depth into blocks of spatial data.\n",
      "        This is the reverse transformation of SpaceToDepth. More specifically,\n",
      "        this op outputs a copy of the input tensor where values from the `depth`\n",
      "        dimension are moved in spatial blocks to the `height` and `width` dimensions.\n",
      "        The attr `block_size` indicates the input block size and how the data is moved.\n",
      "        \n",
      "          * Chunks of data of size `block_size * block_size` from depth are rearranged\n",
      "            into non-overlapping blocks of size `block_size x block_size`\n",
      "          * The width the output tensor is `input_depth * block_size`, whereas the\n",
      "            height is `input_height * block_size`.\n",
      "          * The Y, X coordinates within each block of the output image are determined\n",
      "            by the high order component of the input channel index.\n",
      "          * The depth of the input tensor must be divisible by\n",
      "            `block_size * block_size`.\n",
      "        \n",
      "        The `data_format` attr specifies the layout of the input and output tensors\n",
      "        with the following options:\n",
      "          \"NHWC\": `[ batch, height, width, channels ]`\n",
      "          \"NCHW\": `[ batch, channels, height, width ]`\n",
      "          \"NCHW_VECT_C\":\n",
      "              `qint8 [ batch, channels / 4, height, width, 4 ]`\n",
      "        \n",
      "        It is useful to consider the operation as transforming a 6-D Tensor.\n",
      "        e.g. for data_format = NHWC,\n",
      "             Each element in the input tensor can be specified via 6 coordinates,\n",
      "             ordered by decreasing memory layout significance as:\n",
      "             n,iY,iX,bY,bX,oC  (where n=batch index, iX, iY means X or Y coordinates\n",
      "                                within the input image, bX, bY means coordinates\n",
      "                                within the output block, oC means output channels).\n",
      "             The output would be the input transposed to the following layout:\n",
      "             n,iY,bY,iX,bX,oC\n",
      "        \n",
      "        This operation is useful for resizing the activations between convolutions\n",
      "        (but keeping all data), e.g. instead of pooling. It is also useful for training\n",
      "        purely convolutional models.\n",
      "        \n",
      "        For example, given an input of shape `[1, 1, 1, 4]`, data_format = \"NHWC\" and\n",
      "        block_size = 2:\n",
      "        \n",
      "        ```\n",
      "        x = [[[[1, 2, 3, 4]]]]\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        This operation will output a tensor of shape `[1, 2, 2, 1]`:\n",
      "        \n",
      "        ```\n",
      "           [[[[1], [2]],\n",
      "             [[3], [4]]]]\n",
      "        ```\n",
      "        \n",
      "        Here, the input has a batch of 1 and each batch element has shape `[1, 1, 4]`,\n",
      "        the corresponding output will have 2x2 elements and will have a depth of\n",
      "        1 channel (1 = `4 / (block_size * block_size)`).\n",
      "        The output element shape is `[2, 2, 1]`.\n",
      "        \n",
      "        For an input tensor with larger depth, here of shape `[1, 1, 1, 12]`, e.g.\n",
      "        \n",
      "        ```\n",
      "        x = [[[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]]]]\n",
      "        ```\n",
      "        \n",
      "        This operation, for block size of 2, will return the following tensor of shape\n",
      "        `[1, 2, 2, 3]`\n",
      "        \n",
      "        ```\n",
      "           [[[[1, 2, 3], [4, 5, 6]],\n",
      "             [[7, 8, 9], [10, 11, 12]]]]\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        Similarly, for the following input of shape `[1 2 2 4]`, and a block size of 2:\n",
      "        \n",
      "        ```\n",
      "        x =  [[[[1, 2, 3, 4],\n",
      "               [5, 6, 7, 8]],\n",
      "              [[9, 10, 11, 12],\n",
      "               [13, 14, 15, 16]]]]\n",
      "        ```\n",
      "        \n",
      "        the operator will return the following tensor of shape `[1 4 4 1]`:\n",
      "        \n",
      "        ```\n",
      "        x = [[[ [1],   [2],  [5],  [6]],\n",
      "              [ [3],   [4],  [7],  [8]],\n",
      "              [ [9],  [10], [13],  [14]],\n",
      "              [ [11], [12], [15],  [16]]]]\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`.\n",
      "          block_size: An `int` that is `>= 2`.\n",
      "            The size of the spatial block, same as in Space2Depth.\n",
      "          data_format: An optional `string` from: `\"NHWC\", \"NCHW\", \"NCHW_VECT_C\"`. Defaults to `\"NHWC\"`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    dequantize(input, min_range, max_range, mode='MIN_COMBINED', name=None)\n",
      "        Dequantize the 'input' tensor into a float Tensor.\n",
      "        \n",
      "        [min_range, max_range] are scalar floats that specify the range for\n",
      "        the 'input' data. The 'mode' attribute controls exactly which calculations are\n",
      "        used to convert the float values to their quantized equivalents.\n",
      "        \n",
      "        In 'MIN_COMBINED' mode, each value of the tensor will undergo the following:\n",
      "        \n",
      "        ```\n",
      "        if T == qint8: in[i] += (range(T) + 1)/ 2.0\n",
      "        out[i] = min_range + (in[i]* (max_range - min_range) / range(T))\n",
      "        ```\n",
      "        here `range(T) = numeric_limits<T>::max() - numeric_limits<T>::min()`\n",
      "        \n",
      "        *MIN_COMBINED Mode Example*\n",
      "        \n",
      "        If the input comes from a QuantizedRelu6, the output type is\n",
      "        quint8 (range of 0-255) but the possible range of QuantizedRelu6 is\n",
      "        0-6.  The min_range and max_range values are therefore 0.0 and 6.0.\n",
      "        Dequantize on quint8 will take each value, cast to float, and multiply\n",
      "        by 6 / 255.\n",
      "        Note that if quantizedtype is qint8, the operation will additionally add\n",
      "        each value by 128 prior to casting.\n",
      "        \n",
      "        If the mode is 'MIN_FIRST', then this approach is used:\n",
      "        \n",
      "        ```c++\n",
      "        num_discrete_values = 1 << (# of bits in T)\n",
      "        range_adjust = num_discrete_values / (num_discrete_values - 1)\n",
      "        range = (range_max - range_min) * range_adjust\n",
      "        range_scale = range / num_discrete_values\n",
      "        const double offset_input = static_cast<double>(input) - lowest_quantized;\n",
      "        result = range_min + ((input - numeric_limits<T>::min()) * range_scale)\n",
      "        ```\n",
      "        \n",
      "        *SCALED mode Example*\n",
      "        \n",
      "        `SCALED` mode matches the quantization approach used in\n",
      "        `QuantizeAndDequantize{V2|V3}`.\n",
      "        \n",
      "        If the mode is `SCALED`, we do not use the full range of the output type,\n",
      "        choosing to elide the lowest possible value for symmetry (e.g., output range is\n",
      "        -127 to 127, not -128 to 127 for signed 8 bit quantization), so that 0.0 maps to\n",
      "        0.\n",
      "        \n",
      "        We first find the range of values in our tensor. The\n",
      "        range we use is always centered on 0, so we find m such that\n",
      "        ```c++\n",
      "          m = max(abs(input_min), abs(input_max))\n",
      "        ```\n",
      "        \n",
      "        Our input tensor range is then `[-m, m]`.\n",
      "        \n",
      "        Next, we choose our fixed-point quantization buckets, `[min_fixed, max_fixed]`.\n",
      "        If T is signed, this is\n",
      "        ```\n",
      "          num_bits = sizeof(T) * 8\n",
      "          [min_fixed, max_fixed] =\n",
      "              [-(1 << (num_bits - 1) - 1), (1 << (num_bits - 1)) - 1]\n",
      "        ```\n",
      "        \n",
      "        Otherwise, if T is unsigned, the fixed-point range is\n",
      "        ```\n",
      "          [min_fixed, max_fixed] = [0, (1 << num_bits) - 1]\n",
      "        ```\n",
      "        \n",
      "        From this we compute our scaling factor, s:\n",
      "        ```c++\n",
      "          s = (2 * m) / (max_fixed - min_fixed)\n",
      "        ```\n",
      "        \n",
      "        Now we can dequantize the elements of our tensor:\n",
      "        ```c++\n",
      "        result = input * s\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `qint8`, `quint8`, `qint32`, `qint16`, `quint16`.\n",
      "          min_range: A `Tensor` of type `float32`.\n",
      "            The minimum scalar value possibly produced for the input.\n",
      "          max_range: A `Tensor` of type `float32`.\n",
      "            The maximum scalar value possibly produced for the input.\n",
      "          mode: An optional `string` from: `\"MIN_COMBINED\", \"MIN_FIRST\", \"SCALED\"`. Defaults to `\"MIN_COMBINED\"`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `float32`.\n",
      "    \n",
      "    deserialize_many_sparse(serialized_sparse, dtype, rank=None, name=None)\n",
      "        Deserialize and concatenate `SparseTensors` from a serialized minibatch.\n",
      "        \n",
      "        The input `serialized_sparse` must be a string matrix of shape `[N x 3]` where\n",
      "        `N` is the minibatch size and the rows correspond to packed outputs of\n",
      "        `serialize_sparse`.  The ranks of the original `SparseTensor` objects\n",
      "        must all match.  When the final `SparseTensor` is created, it has rank one\n",
      "        higher than the ranks of the incoming `SparseTensor` objects (they have been\n",
      "        concatenated along a new row dimension).\n",
      "        \n",
      "        The output `SparseTensor` object's shape values for all dimensions but the\n",
      "        first are the max across the input `SparseTensor` objects' shape values\n",
      "        for the corresponding dimensions.  Its first shape value is `N`, the minibatch\n",
      "        size.\n",
      "        \n",
      "        The input `SparseTensor` objects' indices are assumed ordered in\n",
      "        standard lexicographic order.  If this is not the case, after this\n",
      "        step run `sparse.reorder` to restore index ordering.\n",
      "        \n",
      "        For example, if the serialized input is a `[2, 3]` matrix representing two\n",
      "        original `SparseTensor` objects:\n",
      "        \n",
      "            index = [ 0]\n",
      "                    [10]\n",
      "                    [20]\n",
      "            values = [1, 2, 3]\n",
      "            shape = [50]\n",
      "        \n",
      "        and\n",
      "        \n",
      "            index = [ 2]\n",
      "                    [10]\n",
      "            values = [4, 5]\n",
      "            shape = [30]\n",
      "        \n",
      "        then the final deserialized `SparseTensor` will be:\n",
      "        \n",
      "            index = [0  0]\n",
      "                    [0 10]\n",
      "                    [0 20]\n",
      "                    [1  2]\n",
      "                    [1 10]\n",
      "            values = [1, 2, 3, 4, 5]\n",
      "            shape = [2 50]\n",
      "        \n",
      "        Args:\n",
      "          serialized_sparse: 2-D `Tensor` of type `string` of shape `[N, 3]`.\n",
      "            The serialized and packed `SparseTensor` objects.\n",
      "          dtype: The `dtype` of the serialized `SparseTensor` objects.\n",
      "          rank: (optional) Python int, the rank of the `SparseTensor` objects.\n",
      "          name: A name prefix for the returned tensors (optional)\n",
      "        \n",
      "        Returns:\n",
      "          A `SparseTensor` representing the deserialized `SparseTensor`s,\n",
      "          concatenated along the `SparseTensor`s' first dimension.\n",
      "        \n",
      "          All of the serialized `SparseTensor`s must have had the same rank and type.\n",
      "    \n",
      "    device(device_name_or_function)\n",
      "        Wrapper for `Graph.device()` using the default graph.\n",
      "        \n",
      "        See `tf.Graph.device` for more details.\n",
      "        \n",
      "        Args:\n",
      "          device_name_or_function: The device name or function to use in the context.\n",
      "        \n",
      "        Returns:\n",
      "          A context manager that specifies the default device to use for newly\n",
      "          created ops.\n",
      "        \n",
      "        Raises:\n",
      "          RuntimeError: If eager execution is enabled and a function is passed in.\n",
      "    \n",
      "    diag(diagonal, name=None)\n",
      "        Returns a diagonal tensor with a given diagonal values.\n",
      "        \n",
      "        Given a `diagonal`, this operation returns a tensor with the `diagonal` and\n",
      "        everything else padded with zeros. The diagonal is computed as follows:\n",
      "        \n",
      "        Assume `diagonal` has dimensions [D1,..., Dk], then the output is a tensor of\n",
      "        rank 2k with dimensions [D1,..., Dk, D1,..., Dk] where:\n",
      "        \n",
      "        `output[i1,..., ik, i1,..., ik] = diagonal[i1, ..., ik]` and 0 everywhere else.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```\n",
      "        # 'diagonal' is [1, 2, 3, 4]\n",
      "        tf.diag(diagonal) ==> [[1, 0, 0, 0]\n",
      "                               [0, 2, 0, 0]\n",
      "                               [0, 0, 3, 0]\n",
      "                               [0, 0, 0, 4]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          diagonal: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int32`, `int64`, `complex64`, `complex128`.\n",
      "            Rank k tensor where k is at most 1.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `diagonal`.\n",
      "    \n",
      "    diag_part(input, name=None)\n",
      "        Returns the diagonal part of the tensor.\n",
      "        \n",
      "        This operation returns a tensor with the `diagonal` part\n",
      "        of the `input`. The `diagonal` part is computed as follows:\n",
      "        \n",
      "        Assume `input` has dimensions `[D1,..., Dk, D1,..., Dk]`, then the output is a\n",
      "        tensor of rank `k` with dimensions `[D1,..., Dk]` where:\n",
      "        \n",
      "        `diagonal[i1,..., ik] = input[i1, ..., ik, i1,..., ik]`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```\n",
      "        # 'input' is [[1, 0, 0, 0]\n",
      "                      [0, 2, 0, 0]\n",
      "                      [0, 0, 3, 0]\n",
      "                      [0, 0, 0, 4]]\n",
      "        \n",
      "        tf.diag_part(input) ==> [1, 2, 3, 4]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int32`, `int64`, `complex64`, `complex128`.\n",
      "            Rank k tensor where k is even and not zero.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    digamma(x, name=None)\n",
      "        Computes Psi, the derivative of Lgamma (the log of the absolute value of\n",
      "        \n",
      "        `Gamma(x)`), element-wise.\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    dimension_at_index(shape, index)\n",
      "        Compatibility utility required to allow for both V1 and V2 behavior in TF.\n",
      "        \n",
      "        Until the release of TF 2.0, we need the legacy behavior of `TensorShape` to\n",
      "        coexist with the new behavior. This utility is a bridge between the two.\n",
      "        \n",
      "        If you want to retrieve the Dimension instance corresponding to a certain\n",
      "        index in a TensorShape instance, use this utility, like this:\n",
      "        \n",
      "        ```\n",
      "        # If you had this in your V1 code:\n",
      "        dim = tensor_shape[i]\n",
      "        \n",
      "        # Use `dimension_at_index` as direct replacement compatible with both V1 & V2:\n",
      "        dim = dimension_at_index(tensor_shape, i)\n",
      "        \n",
      "        # Another possibility would be this, but WARNING: it only works if the\n",
      "        # tensor_shape instance has a defined rank.\n",
      "        dim = tensor_shape.dims[i]  # `dims` may be None if the rank is undefined!\n",
      "        \n",
      "        # In native V2 code, we recommend instead being more explicit:\n",
      "        if tensor_shape.rank is None:\n",
      "          dim = Dimension(None)\n",
      "        else:\n",
      "          dim = tensor_shape.dims[i]\n",
      "        \n",
      "        # Being more explicit will save you from the following trap (present in V1):\n",
      "        # you might do in-place modifications to `dim` and expect them to be reflected\n",
      "        # in `tensor_shape[i]`, but they would not be (as the Dimension object was\n",
      "        # instantiated on the fly.\n",
      "        ```\n",
      "        \n",
      "        Arguments:\n",
      "          shape: A TensorShape instance.\n",
      "          index: An integer index.\n",
      "        \n",
      "        Returns:\n",
      "          A dimension object.\n",
      "    \n",
      "    dimension_value(dimension)\n",
      "        Compatibility utility required to allow for both V1 and V2 behavior in TF.\n",
      "        \n",
      "        Until the release of TF 2.0, we need the legacy behavior of `TensorShape` to\n",
      "        coexist with the new behavior. This utility is a bridge between the two.\n",
      "        \n",
      "        When accessing the value of a TensorShape dimension,\n",
      "        use this utility, like this:\n",
      "        \n",
      "        ```\n",
      "        # If you had this in your V1 code:\n",
      "        value = tensor_shape[i].value\n",
      "        \n",
      "        # Use `dimension_value` as direct replacement compatible with both V1 & V2:\n",
      "        value = dimension_value(tensor_shape[i])\n",
      "        \n",
      "        # This would be the V2 equivalent:\n",
      "        value = tensor_shape[i]  # Warning: this will return the dim value in V2!\n",
      "        ```\n",
      "        \n",
      "        Arguments:\n",
      "          dimension: Either a `Dimension` instance, an integer, or None.\n",
      "        \n",
      "        Returns:\n",
      "          A plain value, i.e. an integer or None.\n",
      "    \n",
      "    disable_control_flow_v2()\n",
      "        Opts out of control flow v2.\n",
      "        \n",
      "        Note: v2 control flow is always enabled inside of tf.function. Calling this\n",
      "        function has no effect in that case.\n",
      "        \n",
      "        If your code needs tf.disable_control_flow_v2() to be called to work\n",
      "        properly please file a bug.\n",
      "    \n",
      "    disable_eager_execution()\n",
      "        Disables eager execution.\n",
      "        \n",
      "        This function can only be called before any Graphs, Ops, or Tensors have been\n",
      "        created. It can be used at the beginning of the program for complex migration\n",
      "        projects from TensorFlow 1.x to 2.x.\n",
      "    \n",
      "    disable_resource_variables()\n",
      "        Opts out of resource variables. (deprecated)\n",
      "        \n",
      "        Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        non-resource variables are not supported in the long term\n",
      "        \n",
      "        If your code needs tf.disable_resource_variables() to be called to work\n",
      "        properly please file a bug.\n",
      "    \n",
      "    disable_tensor_equality()\n",
      "        Compare Tensors by their id and be hashable.\n",
      "        \n",
      "        This is a legacy behaviour of TensorFlow and is highly discouraged.\n",
      "    \n",
      "    disable_v2_behavior()\n",
      "        Disables TensorFlow 2.x behaviors.\n",
      "        \n",
      "        This function can be called at the beginning of the program (before `Tensors`,\n",
      "        `Graphs` or other structures have been created, and before devices have been\n",
      "        initialized. It switches all global behaviors that are different between\n",
      "        TensorFlow 1.x and 2.x to behave as intended for 1.x.\n",
      "        \n",
      "        User can call this function to disable 2.x behavior during complex migrations.\n",
      "    \n",
      "    disable_v2_tensorshape()\n",
      "        Disables the V2 TensorShape behavior and reverts to V1 behavior.\n",
      "        \n",
      "        See docstring for `enable_v2_tensorshape` for details about the new behavior.\n",
      "    \n",
      "    div(x, y, name=None)\n",
      "        Divides x / y elementwise (using Python 2 division operator semantics). (deprecated)\n",
      "        \n",
      "        Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Deprecated in favor of operator or tf.math.divide.\n",
      "        \n",
      "        NOTE: Prefer using the Tensor division operator or tf.divide which obey Python\n",
      "        3 division operator semantics.\n",
      "        \n",
      "        This function divides `x` and `y`, forcing Python 2 semantics. That is, if `x`\n",
      "        and `y` are both integers then the result will be an integer. This is in\n",
      "        contrast to Python 3, where division with `/` is always a float while division\n",
      "        with `//` is always an integer.\n",
      "        \n",
      "        Args:\n",
      "          x: `Tensor` numerator of real numeric type.\n",
      "          y: `Tensor` denominator of real numeric type.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          `x / y` returns the quotient of x and y.\n",
      "    \n",
      "    div_no_nan(x, y, name=None)\n",
      "        Computes an unsafe divide which returns 0 if the y is zero.\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `float32`, `float64`.\n",
      "          y: A `Tensor` whose dtype is compatible with `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          The element-wise value of the x divided by y.\n",
      "    \n",
      "    divide(x, y, name=None)\n",
      "        Computes Python style division of `x` by `y`.\n",
      "    \n",
      "    dynamic_partition(data, partitions, num_partitions, name=None)\n",
      "        Partitions `data` into `num_partitions` tensors using indices from `partitions`.\n",
      "        \n",
      "        For each index tuple `js` of size `partitions.ndim`, the slice `data[js, ...]`\n",
      "        becomes part of `outputs[partitions[js]]`.  The slices with `partitions[js] = i`\n",
      "        are placed in `outputs[i]` in lexicographic order of `js`, and the first\n",
      "        dimension of `outputs[i]` is the number of entries in `partitions` equal to `i`.\n",
      "        In detail,\n",
      "        \n",
      "        ```python\n",
      "            outputs[i].shape = [sum(partitions == i)] + data.shape[partitions.ndim:]\n",
      "        \n",
      "            outputs[i] = pack([data[js, ...] for js if partitions[js] == i])\n",
      "        ```\n",
      "        \n",
      "        `data.shape` must start with `partitions.shape`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "            # Scalar partitions.\n",
      "            partitions = 1\n",
      "            num_partitions = 2\n",
      "            data = [10, 20]\n",
      "            outputs[0] = []  # Empty with shape [0, 2]\n",
      "            outputs[1] = [[10, 20]]\n",
      "        \n",
      "            # Vector partitions.\n",
      "            partitions = [0, 0, 1, 1, 0]\n",
      "            num_partitions = 2\n",
      "            data = [10, 20, 30, 40, 50]\n",
      "            outputs[0] = [10, 20, 50]\n",
      "            outputs[1] = [30, 40]\n",
      "        ```\n",
      "        \n",
      "        See `dynamic_stitch` for an example on how to merge partitions back.\n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        <img style=\"width:100%\" src=\"https://www.tensorflow.org/images/DynamicPartition.png\" alt>\n",
      "        </div>\n",
      "        \n",
      "        Args:\n",
      "          data: A `Tensor`.\n",
      "          partitions: A `Tensor` of type `int32`.\n",
      "            Any shape.  Indices in the range `[0, num_partitions)`.\n",
      "          num_partitions: An `int` that is `>= 1`.\n",
      "            The number of partitions to output.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A list of `num_partitions` `Tensor` objects with the same type as `data`.\n",
      "    \n",
      "    dynamic_stitch(indices, data, name=None)\n",
      "        Interleave the values from the `data` tensors into a single tensor.\n",
      "        \n",
      "        Builds a merged tensor such that\n",
      "        \n",
      "        ```python\n",
      "            merged[indices[m][i, ..., j], ...] = data[m][i, ..., j, ...]\n",
      "        ```\n",
      "        \n",
      "        For example, if each `indices[m]` is scalar or vector, we have\n",
      "        \n",
      "        ```python\n",
      "            # Scalar indices:\n",
      "            merged[indices[m], ...] = data[m][...]\n",
      "        \n",
      "            # Vector indices:\n",
      "            merged[indices[m][i], ...] = data[m][i, ...]\n",
      "        ```\n",
      "        \n",
      "        Each `data[i].shape` must start with the corresponding `indices[i].shape`,\n",
      "        and the rest of `data[i].shape` must be constant w.r.t. `i`.  That is, we\n",
      "        must have `data[i].shape = indices[i].shape + constant`.  In terms of this\n",
      "        `constant`, the output shape is\n",
      "        \n",
      "            merged.shape = [max(indices)] + constant\n",
      "        \n",
      "        Values are merged in order, so if an index appears in both `indices[m][i]` and\n",
      "        `indices[n][j]` for `(m,i) < (n,j)` the slice `data[n][j]` will appear in the\n",
      "        merged result. If you do not need this guarantee, ParallelDynamicStitch might\n",
      "        perform better on some devices.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "            indices[0] = 6\n",
      "            indices[1] = [4, 1]\n",
      "            indices[2] = [[5, 2], [0, 3]]\n",
      "            data[0] = [61, 62]\n",
      "            data[1] = [[41, 42], [11, 12]]\n",
      "            data[2] = [[[51, 52], [21, 22]], [[1, 2], [31, 32]]]\n",
      "            merged = [[1, 2], [11, 12], [21, 22], [31, 32], [41, 42],\n",
      "                      [51, 52], [61, 62]]\n",
      "        ```\n",
      "        \n",
      "        This method can be used to merge partitions created by `dynamic_partition`\n",
      "        as illustrated on the following example:\n",
      "        \n",
      "        ```python\n",
      "            # Apply function (increments x_i) on elements for which a certain condition\n",
      "            # apply (x_i != -1 in this example).\n",
      "            x=tf.constant([0.1, -1., 5.2, 4.3, -1., 7.4])\n",
      "            condition_mask=tf.not_equal(x,tf.constant(-1.))\n",
      "            partitioned_data = tf.dynamic_partition(\n",
      "                x, tf.cast(condition_mask, tf.int32) , 2)\n",
      "            partitioned_data[1] = partitioned_data[1] + 1.0\n",
      "            condition_indices = tf.dynamic_partition(\n",
      "                tf.range(tf.shape(x)[0]), tf.cast(condition_mask, tf.int32) , 2)\n",
      "            x = tf.dynamic_stitch(condition_indices, partitioned_data)\n",
      "            # Here x=[1.1, -1., 6.2, 5.3, -1, 8.4], the -1. values remain\n",
      "            # unchanged.\n",
      "        ```\n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        <img style=\"width:100%\" src=\"https://www.tensorflow.org/images/DynamicStitch.png\" alt>\n",
      "        </div>\n",
      "        \n",
      "        Args:\n",
      "          indices: A list of at least 1 `Tensor` objects with type `int32`.\n",
      "          data: A list with the same length as `indices` of `Tensor` objects with the same type.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `data`.\n",
      "    \n",
      "    edit_distance(hypothesis, truth, normalize=True, name='edit_distance')\n",
      "        Computes the Levenshtein distance between sequences.\n",
      "        \n",
      "        This operation takes variable-length sequences (`hypothesis` and `truth`),\n",
      "        each provided as a `SparseTensor`, and computes the Levenshtein distance.\n",
      "        You can normalize the edit distance by length of `truth` by setting\n",
      "        `normalize` to true.\n",
      "        \n",
      "        For example, given the following input:\n",
      "        \n",
      "        ```python\n",
      "        # 'hypothesis' is a tensor of shape `[2, 1]` with variable-length values:\n",
      "        #   (0,0) = [\"a\"]\n",
      "        #   (1,0) = [\"b\"]\n",
      "        hypothesis = tf.SparseTensor(\n",
      "            [[0, 0, 0],\n",
      "             [1, 0, 0]],\n",
      "            [\"a\", \"b\"],\n",
      "            (2, 1, 1))\n",
      "        \n",
      "        # 'truth' is a tensor of shape `[2, 2]` with variable-length values:\n",
      "        #   (0,0) = []\n",
      "        #   (0,1) = [\"a\"]\n",
      "        #   (1,0) = [\"b\", \"c\"]\n",
      "        #   (1,1) = [\"a\"]\n",
      "        truth = tf.SparseTensor(\n",
      "            [[0, 1, 0],\n",
      "             [1, 0, 0],\n",
      "             [1, 0, 1],\n",
      "             [1, 1, 0]],\n",
      "            [\"a\", \"b\", \"c\", \"a\"],\n",
      "            (2, 2, 2))\n",
      "        \n",
      "        normalize = True\n",
      "        ```\n",
      "        \n",
      "        This operation would return the following:\n",
      "        \n",
      "        ```python\n",
      "        # 'output' is a tensor of shape `[2, 2]` with edit distances normalized\n",
      "        # by 'truth' lengths.\n",
      "        output ==> [[inf, 1.0],  # (0,0): no truth, (0,1): no hypothesis\n",
      "                   [0.5, 1.0]]  # (1,0): addition, (1,1): no hypothesis\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          hypothesis: A `SparseTensor` containing hypothesis sequences.\n",
      "          truth: A `SparseTensor` containing truth sequences.\n",
      "          normalize: A `bool`. If `True`, normalizes the Levenshtein distance by\n",
      "            length of `truth.`\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A dense `Tensor` with rank `R - 1`, where R is the rank of the\n",
      "          `SparseTensor` inputs `hypothesis` and `truth`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If either `hypothesis` or `truth` are not a `SparseTensor`.\n",
      "    \n",
      "    einsum(equation, *inputs, **kwargs)\n",
      "        Tensor contraction over specified indices and outer product.\n",
      "        \n",
      "        This function returns a tensor whose elements are defined by `equation`,\n",
      "        which is written in a shorthand form inspired by the Einstein summation\n",
      "        convention.  As an example, consider multiplying two matrices\n",
      "        A and B to form a matrix C.  The elements of C are given by:\n",
      "        \n",
      "        ```\n",
      "          C[i,k] = sum_j A[i,j] * B[j,k]\n",
      "        ```\n",
      "        \n",
      "        The corresponding `equation` is:\n",
      "        \n",
      "        ```\n",
      "          ij,jk->ik\n",
      "        ```\n",
      "        \n",
      "        In general, the `equation` is obtained from the more familiar element-wise\n",
      "        equation by\n",
      "          1. removing variable names, brackets, and commas,\n",
      "          2. replacing \"*\" with \",\",\n",
      "          3. dropping summation signs, and\n",
      "          4. moving the output to the right, and replacing \"=\" with \"->\".\n",
      "        \n",
      "        Many common operations can be expressed in this way.  For example:\n",
      "        \n",
      "        ```python\n",
      "        # Matrix multiplication\n",
      "        >>> einsum('ij,jk->ik', m0, m1)  # output[i,k] = sum_j m0[i,j] * m1[j, k]\n",
      "        \n",
      "        # Dot product\n",
      "        >>> einsum('i,i->', u, v)  # output = sum_i u[i]*v[i]\n",
      "        \n",
      "        # Outer product\n",
      "        >>> einsum('i,j->ij', u, v)  # output[i,j] = u[i]*v[j]\n",
      "        \n",
      "        # Transpose\n",
      "        >>> einsum('ij->ji', m)  # output[j,i] = m[i,j]\n",
      "        \n",
      "        # Trace\n",
      "        >>> einsum('ii', m)  # output[j,i] = trace(m) = sum_i m[i, i]\n",
      "        \n",
      "        # Batch matrix multiplication\n",
      "        >>> einsum('aij,ajk->aik', s, t)  # out[a,i,k] = sum_j s[a,i,j] * t[a, j, k]\n",
      "        ```\n",
      "        \n",
      "        To enable and control broadcasting, use an ellipsis.  For example, to do\n",
      "        batch matrix multiplication, you could use:\n",
      "        \n",
      "        ```python\n",
      "        >>> einsum('...ij,...jk->...ik', u, v)\n",
      "        ```\n",
      "        \n",
      "        This function behaves like `numpy.einsum`, but does not support:\n",
      "        \n",
      "        * Subscripts where an axis appears more than once for a single input\n",
      "          (e.g. `ijj,k->ik`) unless it is a trace (e.g. `ijji`).\n",
      "        \n",
      "        Args:\n",
      "          equation: a `str` describing the contraction, in the same format as\n",
      "            `numpy.einsum`.\n",
      "          *inputs: the inputs to contract (each one a `Tensor`), whose shapes should\n",
      "            be consistent with `equation`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          The contracted `Tensor`, with shape determined by `equation`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If\n",
      "            - the format of `equation` is incorrect,\n",
      "            - the number of inputs implied by `equation` does not match `len(inputs)`,\n",
      "            - an axis appears in the output subscripts but not in any of the inputs,\n",
      "            - the number of dimensions of an input differs from the number of\n",
      "              indices in its subscript, or\n",
      "            - the input shapes are inconsistent along a particular axis.\n",
      "    \n",
      "    enable_control_flow_v2()\n",
      "        Use control flow v2.\n",
      "        \n",
      "        control flow v2 (cfv2) is an improved version of control flow in TensorFlow\n",
      "        with support for higher order derivatives. Enabling cfv2 will change the\n",
      "        graph/function representation of control flow, e.g., `tf.while_loop` and\n",
      "        `tf.cond` will generate functional `While` and `If` ops instead of low-level\n",
      "        `Switch`, `Merge` etc. ops. Note: Importing and running graphs exported\n",
      "        with old control flow will still be supported.\n",
      "        \n",
      "        Calling tf.enable_control_flow_v2() lets you opt-in to this TensorFlow 2.0\n",
      "        feature.\n",
      "        \n",
      "        Note: v2 control flow is always enabled inside of tf.function. Calling this\n",
      "        function is not required.\n",
      "    \n",
      "    enable_eager_execution(config=None, device_policy=None, execution_mode=None)\n",
      "        Enables eager execution for the lifetime of this program.\n",
      "        \n",
      "        Eager execution provides an imperative interface to TensorFlow. With eager\n",
      "        execution enabled, TensorFlow functions execute operations immediately (as\n",
      "        opposed to adding to a graph to be executed later in a `tf.compat.v1.Session`)\n",
      "        and\n",
      "        return concrete values (as opposed to symbolic references to a node in a\n",
      "        computational graph).\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        tf.compat.v1.enable_eager_execution()\n",
      "        \n",
      "        # After eager execution is enabled, operations are executed as they are\n",
      "        # defined and Tensor objects hold concrete values, which can be accessed as\n",
      "        # numpy.ndarray`s through the numpy() method.\n",
      "        assert tf.multiply(6, 7).numpy() == 42\n",
      "        ```\n",
      "        \n",
      "        Eager execution cannot be enabled after TensorFlow APIs have been used to\n",
      "        create or execute graphs. It is typically recommended to invoke this function\n",
      "        at program startup and not in a library (as most libraries should be usable\n",
      "        both with and without eager execution).\n",
      "        \n",
      "        Args:\n",
      "          config: (Optional.) A `tf.compat.v1.ConfigProto` to use to configure the\n",
      "            environment in which operations are executed. Note that\n",
      "            `tf.compat.v1.ConfigProto` is also used to configure graph execution (via\n",
      "            `tf.compat.v1.Session`) and many options within `tf.compat.v1.ConfigProto`\n",
      "            are not implemented (or are irrelevant) when eager execution is enabled.\n",
      "          device_policy: (Optional.) Policy controlling how operations requiring\n",
      "            inputs on a specific device (e.g., a GPU 0) handle inputs on a different\n",
      "            device  (e.g. GPU 1 or CPU). When set to None, an appropriate value will\n",
      "            be picked automatically. The value picked may change between TensorFlow\n",
      "            releases.\n",
      "            Valid values:\n",
      "            - tf.contrib.eager.DEVICE_PLACEMENT_EXPLICIT: raises an error if the\n",
      "              placement is not correct.\n",
      "            - tf.contrib.eager.DEVICE_PLACEMENT_WARN: copies the tensors which are not\n",
      "              on the right device but logs a warning.\n",
      "            - tf.contrib.eager.DEVICE_PLACEMENT_SILENT: silently copies the tensors.\n",
      "              Note that this may hide performance problems as there is no notification\n",
      "              provided when operations are blocked on the tensor being copied between\n",
      "              devices.\n",
      "            - tf.contrib.eager.DEVICE_PLACEMENT_SILENT_FOR_INT32: silently copies\n",
      "              int32 tensors, raising errors on the other ones.\n",
      "          execution_mode: (Optional.) Policy controlling how operations dispatched are\n",
      "            actually executed. When set to None, an appropriate value will be picked\n",
      "            automatically. The value picked may change between TensorFlow releases.\n",
      "            Valid values:\n",
      "            - tf.contrib.eager.SYNC: executes each operation synchronously.\n",
      "            - tf.contrib.eager.ASYNC: executes each operation asynchronously. These\n",
      "              operations may return \"non-ready\" handles.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If eager execution is enabled after creating/executing a\n",
      "           TensorFlow graph, or if options provided conflict with a previous call\n",
      "           to this function.\n",
      "    \n",
      "    enable_resource_variables()\n",
      "        Creates resource variables by default.\n",
      "        \n",
      "        Resource variables are improved versions of TensorFlow variables with a\n",
      "        well-defined memory model. Accessing a resource variable reads its value, and\n",
      "        all ops which access a specific read value of the variable are guaranteed to\n",
      "        see the same value for that tensor. Writes which happen after a read (by\n",
      "        having a control or data dependency on the read) are guaranteed not to affect\n",
      "        the value of the read tensor, and similarly writes which happen before a read\n",
      "        are guaranteed to affect the value. No guarantees are made about unordered\n",
      "        read/write pairs.\n",
      "        \n",
      "        Calling tf.enable_resource_variables() lets you opt-in to this TensorFlow 2.0\n",
      "        feature.\n",
      "    \n",
      "    enable_tensor_equality()\n",
      "        Compare Tensors with element-wise comparison and thus be unhashable.\n",
      "        \n",
      "        Comparing tensors with element-wise allows comparisons such as\n",
      "        tf.Variable(1.0) == 1.0. Element-wise equality implies that tensors are\n",
      "        unhashable. Thus tensors can no longer be directly used in sets or as a key in\n",
      "        a dictionary.\n",
      "    \n",
      "    enable_v2_behavior()\n",
      "        Enables TensorFlow 2.x behaviors.\n",
      "        \n",
      "        This function can be called at the beginning of the program (before `Tensors`,\n",
      "        `Graphs` or other structures have been created, and before devices have been\n",
      "        initialized. It switches all global behaviors that are different between\n",
      "        TensorFlow 1.x and 2.x to behave as intended for 2.x.\n",
      "        \n",
      "        This function is called in the main TensorFlow `__init__.py` file, user should\n",
      "        not need to call it, except during complex migrations.\n",
      "    \n",
      "    enable_v2_tensorshape()\n",
      "        In TensorFlow 2.0, iterating over a TensorShape instance returns values.\n",
      "        \n",
      "        This enables the new behavior.\n",
      "        \n",
      "        Concretely, `tensor_shape[i]` returned a Dimension instance in V1, but\n",
      "        it V2 it returns either an integer, or None.\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "        ```\n",
      "        #######################\n",
      "        # If you had this in V1:\n",
      "        value = tensor_shape[i].value\n",
      "        \n",
      "        # Do this in V2 instead:\n",
      "        value = tensor_shape[i]\n",
      "        \n",
      "        #######################\n",
      "        # If you had this in V1:\n",
      "        for dim in tensor_shape:\n",
      "          value = dim.value\n",
      "          print(value)\n",
      "        \n",
      "        # Do this in V2 instead:\n",
      "        for value in tensor_shape:\n",
      "          print(value)\n",
      "        \n",
      "        #######################\n",
      "        # If you had this in V1:\n",
      "        dim = tensor_shape[i]\n",
      "        dim.assert_is_compatible_with(other_shape)  # or using any other shape method\n",
      "        \n",
      "        # Do this in V2 instead:\n",
      "        if tensor_shape.rank is None:\n",
      "          dim = Dimension(None)\n",
      "        else:\n",
      "          dim = tensor_shape.dims[i]\n",
      "        dim.assert_is_compatible_with(other_shape)  # or using any other shape method\n",
      "        \n",
      "        # The V2 suggestion above is more explicit, which will save you from\n",
      "        # the following trap (present in V1):\n",
      "        # you might do in-place modifications to `dim` and expect them to be reflected\n",
      "        # in `tensor_shape[i]`, but they would not be.\n",
      "        ```\n",
      "    \n",
      "    encode_base64(input, pad=False, name=None)\n",
      "        Encode strings into web-safe base64 format.\n",
      "        \n",
      "        Refer to the following article for more information on base64 format:\n",
      "        en.wikipedia.org/wiki/Base64. Base64 strings may have padding with '=' at the\n",
      "        end so that the encoded has length multiple of 4. See Padding section of the\n",
      "        link above.\n",
      "        \n",
      "        Web-safe means that the encoder uses - and _ instead of + and /.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor` of type `string`. Strings to be encoded.\n",
      "          pad: An optional `bool`. Defaults to `False`.\n",
      "            Bool whether padding is applied at the ends.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `string`.\n",
      "    \n",
      "    ensure_shape(x, shape, name=None)\n",
      "        Updates the shape of a tensor and checks at runtime that the shape holds.\n",
      "        \n",
      "        For example:\n",
      "        ```python\n",
      "        x = tf.compat.v1.placeholder(tf.int32)\n",
      "        print(x.shape)\n",
      "        ==> TensorShape(None)\n",
      "        y = x * 2\n",
      "        print(y.shape)\n",
      "        ==> TensorShape(None)\n",
      "        \n",
      "        y = tf.ensure_shape(y, (None, 3, 3))\n",
      "        print(y.shape)\n",
      "        ==> TensorShape([Dimension(None), Dimension(3), Dimension(3)])\n",
      "        \n",
      "        with tf.compat.v1.Session() as sess:\n",
      "          # Raises tf.errors.InvalidArgumentError, because the shape (3,) is not\n",
      "          # compatible with the shape (None, 3, 3)\n",
      "          sess.run(y, feed_dict={x: [1, 2, 3]})\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        NOTE: This differs from `Tensor.set_shape` in that it sets the static shape\n",
      "        of the resulting tensor and enforces it at runtime, raising an error if the\n",
      "        tensor's runtime shape is incompatible with the specified shape.\n",
      "        `Tensor.set_shape` sets the static shape of the tensor without enforcing it\n",
      "        at runtime, which may result in inconsistencies between the statically-known\n",
      "        shape of tensors and the runtime value of tensors.\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`.\n",
      "          shape: A `TensorShape` representing the shape of this tensor, a\n",
      "            `TensorShapeProto`, a list, a tuple, or None.\n",
      "          name: A name for this operation (optional). Defaults to \"EnsureShape\".\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type and contents as `x`. At runtime, raises a\n",
      "          `tf.errors.InvalidArgumentError` if `shape` is incompatible with the shape\n",
      "          of `x`.\n",
      "    \n",
      "    equal(x, y, name=None)\n",
      "        Returns the truth value of (x == y) element-wise.\n",
      "        \n",
      "        Usage:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([2, 4])\n",
      "        y = tf.constant(2)\n",
      "        tf.math.equal(x, y) ==> array([True, False])\n",
      "        \n",
      "        x = tf.constant([2, 4])\n",
      "        y = tf.constant([2, 4])\n",
      "        tf.math.equal(x, y) ==> array([True,  True])\n",
      "        ```\n",
      "        \n",
      "        **NOTE**: `Equal` supports broadcasting. More about broadcasting [here](\n",
      "        https://docs.scipy.org/doc/numpy-1.13.0/user/basics.broadcasting.html)\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor` or `SparseTensor` or `IndexedSlices`.\n",
      "          y: A `Tensor` or `SparseTensor` or `IndexedSlices`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type bool with the same size as that of x or y.\n",
      "    \n",
      "    erf(x, name=None)\n",
      "        Computes the Gauss error function of `x` element-wise.\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "        \n",
      "          If `x` is a `SparseTensor`, returns\n",
      "          `SparseTensor(x.indices, tf.math.erf(x.values, ...), x.dense_shape)`\n",
      "    \n",
      "    erfc(x, name=None)\n",
      "        Computes the complementary error function of `x` element-wise.\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    executing_eagerly()\n",
      "        Returns True if the current thread has eager execution enabled.\n",
      "        \n",
      "        Eager execution is typically enabled via\n",
      "        `tf.compat.v1.enable_eager_execution`, but may also be enabled within the\n",
      "        context of a Python function via tf.contrib.eager.py_func.\n",
      "    \n",
      "    exp(x, name=None)\n",
      "        Computes exponential of x element-wise.  \\\\(y = e^x\\\\).\n",
      "        \n",
      "          This function computes the exponential of every element in the input tensor.\n",
      "          i.e. `exp(x)` or `e^(x)`, where `x` is the input tensor.\n",
      "          `e` denotes Euler's number and is approximately equal to 2.718281.\n",
      "          Output is positive for any real input.\n",
      "        \n",
      "          ```python\n",
      "          x = tf.constant(2.0)\n",
      "          tf.math.exp(x) ==> 7.389056\n",
      "        \n",
      "          x = tf.constant([2.0, 8.0])\n",
      "          tf.math.exp(x) ==> array([7.389056, 2980.958], dtype=float32)\n",
      "          ```\n",
      "        \n",
      "          For complex numbers, the exponential value is calculated as follows:\n",
      "        \n",
      "          ```\n",
      "          e^(x+iy) = e^x * e^iy = e^x * (cos y + i sin y)\n",
      "          ```\n",
      "        \n",
      "          Let's consider complex number 1+1j as an example.\n",
      "          e^1 * (cos 1 + i sin 1) = 2.7182818284590 * (0.54030230586+0.8414709848j)\n",
      "        \n",
      "          ```python\n",
      "          x = tf.constant(1 + 1j)\n",
      "          tf.math.exp(x) ==> 1.4686939399158851+2.2873552871788423j\n",
      "          ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    expand_dims(input, axis=None, name=None, dim=None)\n",
      "        Inserts a dimension of 1 into a tensor's shape. (deprecated arguments)\n",
      "        \n",
      "        Warning: SOME ARGUMENTS ARE DEPRECATED: `(dim)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Use the `axis` argument instead\n",
      "        \n",
      "        Given a tensor `input`, this operation inserts a dimension of 1 at the\n",
      "        dimension index `axis` of `input`'s shape. The dimension index `axis` starts\n",
      "        at zero; if you specify a negative number for `axis` it is counted backward\n",
      "        from the end.\n",
      "        \n",
      "        This operation is useful if you want to add a batch dimension to a single\n",
      "        element. For example, if you have a single image of shape `[height, width,\n",
      "        channels]`, you can make it a batch of 1 image with `expand_dims(image, 0)`,\n",
      "        which will make the shape `[1, height, width, channels]`.\n",
      "        \n",
      "        Other examples:\n",
      "        \n",
      "        ```python\n",
      "        # 't' is a tensor of shape [2]\n",
      "        tf.shape(tf.expand_dims(t, 0))  # [1, 2]\n",
      "        tf.shape(tf.expand_dims(t, 1))  # [2, 1]\n",
      "        tf.shape(tf.expand_dims(t, -1))  # [2, 1]\n",
      "        \n",
      "        # 't2' is a tensor of shape [2, 3, 5]\n",
      "        tf.shape(tf.expand_dims(t2, 0))  # [1, 2, 3, 5]\n",
      "        tf.shape(tf.expand_dims(t2, 2))  # [2, 3, 1, 5]\n",
      "        tf.shape(tf.expand_dims(t2, 3))  # [2, 3, 5, 1]\n",
      "        ```\n",
      "        \n",
      "        This operation requires that:\n",
      "        \n",
      "        `-1-input.dims() <= dim <= input.dims()`\n",
      "        \n",
      "        This operation is related to `squeeze()`, which removes dimensions of\n",
      "        size 1.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`.\n",
      "          axis: 0-D (scalar). Specifies the dimension index at which to expand the\n",
      "            shape of `input`. Must be in the range `[-rank(input) - 1, rank(input)]`.\n",
      "          name: The name of the output `Tensor` (optional).\n",
      "          dim: 0-D (scalar). Equivalent to `axis`, to be deprecated.\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` with the same data as `input`, but its shape has an additional\n",
      "          dimension of size 1 added.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: if either both or neither of `dim` and `axis` are specified.\n",
      "    \n",
      "    expm1(x, name=None)\n",
      "        Computes `exp(x) - 1` element-wise.\n",
      "        \n",
      "          i.e. `exp(x) - 1` or `e^(x) - 1`, where `x` is the input tensor.\n",
      "          `e` denotes Euler's number and is approximately equal to 2.718281.\n",
      "        \n",
      "          ```python\n",
      "          x = tf.constant(2.0)\n",
      "          tf.math.expm1(x) ==> 6.389056\n",
      "        \n",
      "          x = tf.constant([2.0, 8.0])\n",
      "          tf.math.expm1(x) ==> array([6.389056, 2979.958], dtype=float32)\n",
      "        \n",
      "          x = tf.constant(1 + 1j)\n",
      "          tf.math.expm1(x) ==> (0.46869393991588515+2.2873552871788423j)\n",
      "          ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    extract_image_patches(images, ksizes=None, strides=None, rates=None, padding=None, name=None, sizes=None)\n",
      "        Extract `patches` from `images` and put them in the \"depth\" output dimension.\n",
      "        \n",
      "        Args:\n",
      "          images: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "            4-D Tensor with shape `[batch, in_rows, in_cols, depth]`.\n",
      "          ksizes: A list of `ints` that has length `>= 4`.\n",
      "            The size of the sliding window for each dimension of `images`.\n",
      "          strides: A list of `ints` that has length `>= 4`.\n",
      "            How far the centers of two consecutive patches are in\n",
      "            the images. Must be: `[1, stride_rows, stride_cols, 1]`.\n",
      "          rates: A list of `ints` that has length `>= 4`.\n",
      "            Must be: `[1, rate_rows, rate_cols, 1]`. This is the\n",
      "            input stride, specifying how far two consecutive patch samples are in the\n",
      "            input. Equivalent to extracting patches with\n",
      "            `patch_sizes_eff = patch_sizes + (patch_sizes - 1) * (rates - 1)`, followed by\n",
      "            subsampling them spatially by a factor of `rates`. This is equivalent to\n",
      "            `rate` in dilated (a.k.a. Atrous) convolutions.\n",
      "          padding: A `string` from: `\"SAME\", \"VALID\"`.\n",
      "            The type of padding algorithm to use.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `images`.\n",
      "    \n",
      "    extract_volume_patches(input, ksizes, strides, padding, name=None)\n",
      "        Extract `patches` from `input` and put them in the \"depth\" output dimension. 3D extension of `extract_image_patches`.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "            5-D Tensor with shape `[batch, in_planes, in_rows, in_cols, depth]`.\n",
      "          ksizes: A list of `ints` that has length `>= 5`.\n",
      "            The size of the sliding window for each dimension of `input`.\n",
      "          strides: A list of `ints` that has length `>= 5`.\n",
      "            1-D of length 5. How far the centers of two consecutive patches are in\n",
      "            `input`. Must be: `[1, stride_planes, stride_rows, stride_cols, 1]`.\n",
      "          padding: A `string` from: `\"SAME\", \"VALID\"`.\n",
      "            The type of padding algorithm to use.\n",
      "        \n",
      "            We specify the size-related attributes as:\n",
      "        \n",
      "            ```python\n",
      "                  ksizes = [1, ksize_planes, ksize_rows, ksize_cols, 1]\n",
      "                  strides = [1, stride_planes, strides_rows, strides_cols, 1]\n",
      "            ```\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    eye(num_rows, num_columns=None, batch_shape=None, dtype=tf.float32, name=None)\n",
      "        Construct an identity matrix, or a batch of matrices.\n",
      "        \n",
      "        ```python\n",
      "        # Construct one identity matrix.\n",
      "        tf.eye(2)\n",
      "        ==> [[1., 0.],\n",
      "             [0., 1.]]\n",
      "        \n",
      "        # Construct a batch of 3 identity matricies, each 2 x 2.\n",
      "        # batch_identity[i, :, :] is a 2 x 2 identity matrix, i = 0, 1, 2.\n",
      "        batch_identity = tf.eye(2, batch_shape=[3])\n",
      "        \n",
      "        # Construct one 2 x 3 \"identity\" matrix\n",
      "        tf.eye(2, num_columns=3)\n",
      "        ==> [[ 1.,  0.,  0.],\n",
      "             [ 0.,  1.,  0.]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          num_rows: Non-negative `int32` scalar `Tensor` giving the number of rows\n",
      "            in each batch matrix.\n",
      "          num_columns: Optional non-negative `int32` scalar `Tensor` giving the number\n",
      "            of columns in each batch matrix.  Defaults to `num_rows`.\n",
      "          batch_shape:  A list or tuple of Python integers or a 1-D `int32` `Tensor`.\n",
      "            If provided, the returned `Tensor` will have leading batch dimensions of\n",
      "            this shape.\n",
      "          dtype:  The type of an element in the resulting `Tensor`\n",
      "          name:  A name for this `Op`.  Defaults to \"eye\".\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of shape `batch_shape + [num_rows, num_columns]`\n",
      "    \n",
      "    fake_quant_with_min_max_args(inputs, min=-6, max=6, num_bits=8, narrow_range=False, name=None)\n",
      "        Fake-quantize the 'inputs' tensor, type float to 'outputs' tensor of same type.\n",
      "        \n",
      "        Attributes `[min; max]` define the clamping range for the `inputs` data.\n",
      "        `inputs` values are quantized into the quantization range (`[0; 2^num_bits - 1]`\n",
      "        when `narrow_range` is false and `[1; 2^num_bits - 1]` when it is true) and\n",
      "        then de-quantized and output as floats in `[min; max]` interval.\n",
      "        `num_bits` is the bitwidth of the quantization; between 2 and 16, inclusive.\n",
      "        \n",
      "        Before quantization, `min` and `max` values are adjusted with the following\n",
      "        logic.\n",
      "        It is suggested to have `min <= 0 <= max`. If `0` is not in the range of values,\n",
      "        the behavior can be unexpected:\n",
      "        If `0 < min < max`: `min_adj = 0` and `max_adj = max - min`.\n",
      "        If `min < max < 0`: `min_adj = min - max` and `max_adj = 0`.\n",
      "        If `min <= 0 <= max`: `scale = (max - min) / (2^num_bits - 1) `,\n",
      "        `min_adj = scale * round(min / scale)` and `max_adj = max + min_adj - min`.\n",
      "        \n",
      "        Quantization is called fake since the output is still in floating point.\n",
      "        \n",
      "        Args:\n",
      "          inputs: A `Tensor` of type `float32`.\n",
      "          min: An optional `float`. Defaults to `-6`.\n",
      "          max: An optional `float`. Defaults to `6`.\n",
      "          num_bits: An optional `int`. Defaults to `8`.\n",
      "          narrow_range: An optional `bool`. Defaults to `False`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `float32`.\n",
      "    \n",
      "    fake_quant_with_min_max_args_gradient(gradients, inputs, min=-6, max=6, num_bits=8, narrow_range=False, name=None)\n",
      "        Compute gradients for a FakeQuantWithMinMaxArgs operation.\n",
      "        \n",
      "        Args:\n",
      "          gradients: A `Tensor` of type `float32`.\n",
      "            Backpropagated gradients above the FakeQuantWithMinMaxArgs operation.\n",
      "          inputs: A `Tensor` of type `float32`.\n",
      "            Values passed as inputs to the FakeQuantWithMinMaxArgs operation.\n",
      "          min: An optional `float`. Defaults to `-6`.\n",
      "          max: An optional `float`. Defaults to `6`.\n",
      "          num_bits: An optional `int`. Defaults to `8`.\n",
      "          narrow_range: An optional `bool`. Defaults to `False`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `float32`.\n",
      "    \n",
      "    fake_quant_with_min_max_vars(inputs, min, max, num_bits=8, narrow_range=False, name=None)\n",
      "        Fake-quantize the 'inputs' tensor of type float via global float scalars `min`\n",
      "        \n",
      "        and `max` to 'outputs' tensor of same shape as `inputs`.\n",
      "        \n",
      "        `[min; max]` define the clamping range for the `inputs` data.\n",
      "        `inputs` values are quantized into the quantization range (`[0; 2^num_bits - 1]`\n",
      "        when `narrow_range` is false and `[1; 2^num_bits - 1]` when it is true) and\n",
      "        then de-quantized and output as floats in `[min; max]` interval.\n",
      "        `num_bits` is the bitwidth of the quantization; between 2 and 16, inclusive.\n",
      "        \n",
      "        Before quantization, `min` and `max` values are adjusted with the following\n",
      "        logic.\n",
      "        It is suggested to have `min <= 0 <= max`. If `0` is not in the range of values,\n",
      "        the behavior can be unexpected:\n",
      "        If `0 < min < max`: `min_adj = 0` and `max_adj = max - min`.\n",
      "        If `min < max < 0`: `min_adj = min - max` and `max_adj = 0`.\n",
      "        If `min <= 0 <= max`: `scale = (max - min) / (2^num_bits - 1) `,\n",
      "        `min_adj = scale * round(min / scale)` and `max_adj = max + min_adj - min`.\n",
      "        \n",
      "        This operation has a gradient and thus allows for training `min` and `max`\n",
      "        values.\n",
      "        \n",
      "        Args:\n",
      "          inputs: A `Tensor` of type `float32`.\n",
      "          min: A `Tensor` of type `float32`.\n",
      "          max: A `Tensor` of type `float32`.\n",
      "          num_bits: An optional `int`. Defaults to `8`.\n",
      "          narrow_range: An optional `bool`. Defaults to `False`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `float32`.\n",
      "    \n",
      "    fake_quant_with_min_max_vars_gradient(gradients, inputs, min, max, num_bits=8, narrow_range=False, name=None)\n",
      "        Compute gradients for a FakeQuantWithMinMaxVars operation.\n",
      "        \n",
      "        Args:\n",
      "          gradients: A `Tensor` of type `float32`.\n",
      "            Backpropagated gradients above the FakeQuantWithMinMaxVars operation.\n",
      "          inputs: A `Tensor` of type `float32`.\n",
      "            Values passed as inputs to the FakeQuantWithMinMaxVars operation.\n",
      "            min, max: Quantization interval, scalar floats.\n",
      "          min: A `Tensor` of type `float32`.\n",
      "          max: A `Tensor` of type `float32`.\n",
      "          num_bits: An optional `int`. Defaults to `8`.\n",
      "            The bitwidth of the quantization; between 2 and 8, inclusive.\n",
      "          narrow_range: An optional `bool`. Defaults to `False`.\n",
      "            Whether to quantize into 2^num_bits - 1 distinct values.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A tuple of `Tensor` objects (backprops_wrt_input, backprop_wrt_min, backprop_wrt_max).\n",
      "        \n",
      "          backprops_wrt_input: A `Tensor` of type `float32`.\n",
      "          backprop_wrt_min: A `Tensor` of type `float32`.\n",
      "          backprop_wrt_max: A `Tensor` of type `float32`.\n",
      "    \n",
      "    fake_quant_with_min_max_vars_per_channel(inputs, min, max, num_bits=8, narrow_range=False, name=None)\n",
      "        Fake-quantize the 'inputs' tensor of type float and one of the shapes: `[d]`,\n",
      "        \n",
      "        `[b, d]` `[b, h, w, d]` via per-channel floats `min` and `max` of shape `[d]`\n",
      "        to 'outputs' tensor of same shape as `inputs`.\n",
      "        \n",
      "        `[min; max]` define the clamping range for the `inputs` data.\n",
      "        `inputs` values are quantized into the quantization range (`[0; 2^num_bits - 1]`\n",
      "        when `narrow_range` is false and `[1; 2^num_bits - 1]` when it is true) and\n",
      "        then de-quantized and output as floats in `[min; max]` interval.\n",
      "        `num_bits` is the bitwidth of the quantization; between 2 and 16, inclusive.\n",
      "        \n",
      "        Before quantization, `min` and `max` values are adjusted with the following\n",
      "        logic.\n",
      "        It is suggested to have `min <= 0 <= max`. If `0` is not in the range of values,\n",
      "        the behavior can be unexpected:\n",
      "        If `0 < min < max`: `min_adj = 0` and `max_adj = max - min`.\n",
      "        If `min < max < 0`: `min_adj = min - max` and `max_adj = 0`.\n",
      "        If `min <= 0 <= max`: `scale = (max - min) / (2^num_bits - 1) `,\n",
      "        `min_adj = scale * round(min / scale)` and `max_adj = max + min_adj - min`.\n",
      "        \n",
      "        This operation has a gradient and thus allows for training `min` and `max`\n",
      "        values.\n",
      "        \n",
      "        Args:\n",
      "          inputs: A `Tensor` of type `float32`.\n",
      "          min: A `Tensor` of type `float32`.\n",
      "          max: A `Tensor` of type `float32`.\n",
      "          num_bits: An optional `int`. Defaults to `8`.\n",
      "          narrow_range: An optional `bool`. Defaults to `False`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `float32`.\n",
      "    \n",
      "    fake_quant_with_min_max_vars_per_channel_gradient(gradients, inputs, min, max, num_bits=8, narrow_range=False, name=None)\n",
      "        Compute gradients for a FakeQuantWithMinMaxVarsPerChannel operation.\n",
      "        \n",
      "        Args:\n",
      "          gradients: A `Tensor` of type `float32`.\n",
      "            Backpropagated gradients above the FakeQuantWithMinMaxVars operation,\n",
      "            shape one of: `[d]`, `[b, d]`,  `[b, h, w, d]`.\n",
      "          inputs: A `Tensor` of type `float32`.\n",
      "            Values passed as inputs to the FakeQuantWithMinMaxVars operation, shape\n",
      "              same as `gradients`.\n",
      "            min, max: Quantization interval, floats of shape `[d]`.\n",
      "          min: A `Tensor` of type `float32`.\n",
      "          max: A `Tensor` of type `float32`.\n",
      "          num_bits: An optional `int`. Defaults to `8`.\n",
      "            The bitwidth of the quantization; between 2 and 16, inclusive.\n",
      "          narrow_range: An optional `bool`. Defaults to `False`.\n",
      "            Whether to quantize into 2^num_bits - 1 distinct values.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A tuple of `Tensor` objects (backprops_wrt_input, backprop_wrt_min, backprop_wrt_max).\n",
      "        \n",
      "          backprops_wrt_input: A `Tensor` of type `float32`.\n",
      "          backprop_wrt_min: A `Tensor` of type `float32`.\n",
      "          backprop_wrt_max: A `Tensor` of type `float32`.\n",
      "    \n",
      "    fft(input, name=None)\n",
      "        Fast Fourier transform.\n",
      "        \n",
      "        Computes the 1-dimensional discrete Fourier transform over the inner-most\n",
      "        dimension of `input`.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `complex64`, `complex128`.\n",
      "            A complex tensor.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    fft2d(input, name=None)\n",
      "        2D fast Fourier transform.\n",
      "        \n",
      "        Computes the 2-dimensional discrete Fourier transform over the inner-most\n",
      "        2 dimensions of `input`.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `complex64`, `complex128`.\n",
      "            A complex tensor.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    fft3d(input, name=None)\n",
      "        3D fast Fourier transform.\n",
      "        \n",
      "        Computes the 3-dimensional discrete Fourier transform over the inner-most 3\n",
      "        dimensions of `input`.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `complex64`, `complex128`.\n",
      "            A complex64 tensor.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    fill(dims, value, name=None)\n",
      "        Creates a tensor filled with a scalar value.\n",
      "        \n",
      "        This operation creates a tensor of shape `dims` and fills it with `value`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```\n",
      "        # Output tensor has shape [2, 3].\n",
      "        fill([2, 3], 9) ==> [[9, 9, 9]\n",
      "                             [9, 9, 9]]\n",
      "        ```\n",
      "        \n",
      "        `tf.fill` differs from `tf.constant` in a few ways:\n",
      "        \n",
      "        *   `tf.fill` only supports scalar contents, whereas `tf.constant` supports\n",
      "            Tensor values.\n",
      "        *   `tf.fill` creates an Op in the computation graph that constructs the\n",
      "        actual\n",
      "            Tensor value at runtime. This is in contrast to `tf.constant` which embeds\n",
      "            the entire Tensor into the graph with a `Const` node.\n",
      "        *   Because `tf.fill` evaluates at graph runtime, it supports dynamic shapes\n",
      "            based on other runtime Tensors, unlike `tf.constant`.\n",
      "        \n",
      "        Args:\n",
      "          dims: A `Tensor`. Must be one of the following types: `int32`, `int64`. 1-D.\n",
      "            Represents the shape of the output tensor.\n",
      "          value: A `Tensor`. 0-D (scalar). Value to fill the returned tensor.\n",
      "            @compatibility(numpy) Equivalent to np.full @end_compatibility\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `value`.\n",
      "    \n",
      "    fingerprint(data, method='farmhash64', name=None)\n",
      "        Generates fingerprint values.\n",
      "        \n",
      "        Generates fingerprint values of `data`.\n",
      "        \n",
      "        Fingerprint op considers the first dimension of `data` as the batch dimension,\n",
      "        and `output[i]` contains the fingerprint value generated from contents in\n",
      "        `data[i, ...]` for all `i`.\n",
      "        \n",
      "        Fingerprint op writes fingerprint values as byte arrays. For example, the\n",
      "        default method `farmhash64` generates a 64-bit fingerprint value at a time.\n",
      "        This 8-byte value is written out as an `tf.uint8` array of size 8, in\n",
      "        little-endian order.\n",
      "        \n",
      "        For example, suppose that `data` has data type `tf.int32` and shape (2, 3, 4),\n",
      "        and that the fingerprint method is `farmhash64`. In this case, the output\n",
      "        shape is (2, 8), where 2 is the batch dimension size of `data`, and 8 is the\n",
      "        size of each fingerprint value in bytes. `output[0, :]` is generated from\n",
      "        12 integers in `data[0, :, :]` and similarly `output[1, :]` is generated from\n",
      "        other 12 integers in `data[1, :, :]`.\n",
      "        \n",
      "        Note that this op fingerprints the raw underlying buffer, and it does not\n",
      "        fingerprint Tensor's metadata such as data type and/or shape. For example, the\n",
      "        fingerprint values are invariant under reshapes and bitcasts as long as the\n",
      "        batch dimension remain the same:\n",
      "        \n",
      "        ```python\n",
      "        tf.fingerprint(data) == tf.fingerprint(tf.reshape(data, ...))\n",
      "        tf.fingerprint(data) == tf.fingerprint(tf.bitcast(data, ...))\n",
      "        ```\n",
      "        \n",
      "        For string data, one should expect `tf.fingerprint(data) !=\n",
      "        tf.fingerprint(tf.string.reduce_join(data))` in general.\n",
      "        \n",
      "        Args:\n",
      "          data: A `Tensor`. Must have rank 1 or higher.\n",
      "          method: A `Tensor` of type `tf.string`. Fingerprint method used by this op.\n",
      "            Currently available method is `farmhash64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A two-dimensional `Tensor` of type `tf.uint8`. The first dimension equals to\n",
      "          `data`'s first dimension, and the second dimension size depends on the\n",
      "          fingerprint algorithm.\n",
      "    \n",
      "    fixed_size_partitioner(num_shards, axis=0)\n",
      "        Partitioner to specify a fixed number of shards along given axis.\n",
      "        \n",
      "        Args:\n",
      "          num_shards: `int`, number of shards to partition variable.\n",
      "          axis: `int`, axis to partition on.\n",
      "        \n",
      "        Returns:\n",
      "          A partition function usable as the `partitioner` argument to\n",
      "          `variable_scope` and `get_variable`.\n",
      "    \n",
      "    floor(x, name=None)\n",
      "        Returns element-wise largest integer not greater than x.\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    floor_div(x, y, name=None)\n",
      "        Returns x // y element-wise.\n",
      "        \n",
      "        *NOTE*: `floor_div` supports broadcasting. More about broadcasting\n",
      "        [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`, `int16`, `int32`, `int64`, `complex64`, `complex128`.\n",
      "          y: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    floordiv(x, y, name=None)\n",
      "        Divides `x / y` elementwise, rounding toward the most negative integer.\n",
      "        \n",
      "        The same as `tf.compat.v1.div(x,y)` for integers, but uses\n",
      "        `tf.floor(tf.compat.v1.div(x,y))` for\n",
      "        floating point arguments so that the result is always an integer (though\n",
      "        possibly an integer represented as floating point).  This op is generated by\n",
      "        `x // y` floor division in Python 3 and in Python 2.7 with\n",
      "        `from __future__ import division`.\n",
      "        \n",
      "        `x` and `y` must have the same type, and the result will have the same type\n",
      "        as well.\n",
      "        \n",
      "        Args:\n",
      "          x: `Tensor` numerator of real numeric type.\n",
      "          y: `Tensor` denominator of real numeric type.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          `x / y` rounded down.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If the inputs are complex.\n",
      "    \n",
      "    floormod = floor_mod(x, y, name=None)\n",
      "        Returns element-wise remainder of division. When `x < 0` xor `y < 0` is\n",
      "        \n",
      "        true, this follows Python semantics in that the result here is consistent\n",
      "        with a flooring divide. E.g. `floor(x / y) * y + mod(x, y) = x`.\n",
      "        \n",
      "        *NOTE*: `math.floormod` supports broadcasting. More about broadcasting\n",
      "        [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `int32`, `int64`, `bfloat16`, `half`, `float32`, `float64`.\n",
      "          y: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    foldl(fn, elems, initializer=None, parallel_iterations=10, back_prop=True, swap_memory=False, name=None)\n",
      "        foldl on the list of tensors unpacked from `elems` on dimension 0.\n",
      "        \n",
      "        This foldl operator repeatedly applies the callable `fn` to a sequence\n",
      "        of elements from first to last. The elements are made of the tensors\n",
      "        unpacked from `elems` on dimension 0. The callable fn takes two tensors as\n",
      "        arguments. The first argument is the accumulated value computed from the\n",
      "        preceding invocation of fn, and the second is the value at the current\n",
      "        position of `elems`. If `initializer` is None, `elems` must contain at least\n",
      "        one element, and its first element is used as the initializer.\n",
      "        \n",
      "        Suppose that `elems` is unpacked into `values`, a list of tensors. The shape\n",
      "        of the result tensor is fn(initializer, values[0]).shape`.\n",
      "        \n",
      "        This method also allows multi-arity `elems` and output of `fn`.  If `elems`\n",
      "        is a (possibly nested) list or tuple of tensors, then each of these tensors\n",
      "        must have a matching first (unpack) dimension.  The signature of `fn` may\n",
      "        match the structure of `elems`.  That is, if `elems` is\n",
      "        `(t1, [t2, t3, [t4, t5]])`, then an appropriate signature for `fn` is:\n",
      "        `fn = lambda (t1, [t2, t3, [t4, t5]]):`.\n",
      "        \n",
      "        Args:\n",
      "          fn: The callable to be performed.\n",
      "          elems: A tensor or (possibly nested) sequence of tensors, each of which will\n",
      "            be unpacked along their first dimension.  The nested sequence of the\n",
      "            resulting slices will be the first argument to `fn`.\n",
      "          initializer: (optional) A tensor or (possibly nested) sequence of tensors,\n",
      "            as the initial value for the accumulator.\n",
      "          parallel_iterations: (optional) The number of iterations allowed to run in\n",
      "            parallel.\n",
      "          back_prop: (optional) True enables support for back propagation.\n",
      "          swap_memory: (optional) True enables GPU-CPU memory swapping.\n",
      "          name: (optional) Name prefix for the returned tensors.\n",
      "        \n",
      "        Returns:\n",
      "          A tensor or (possibly nested) sequence of tensors, resulting from applying\n",
      "          `fn` consecutively to the list of tensors unpacked from `elems`, from first\n",
      "          to last.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: if `fn` is not callable.\n",
      "        \n",
      "        Example:\n",
      "          ```python\n",
      "          elems = tf.constant([1, 2, 3, 4, 5, 6])\n",
      "          sum = foldl(lambda a, x: a + x, elems)\n",
      "          # sum == 21\n",
      "          ```\n",
      "    \n",
      "    foldr(fn, elems, initializer=None, parallel_iterations=10, back_prop=True, swap_memory=False, name=None)\n",
      "        foldr on the list of tensors unpacked from `elems` on dimension 0.\n",
      "        \n",
      "        This foldr operator repeatedly applies the callable `fn` to a sequence\n",
      "        of elements from last to first. The elements are made of the tensors\n",
      "        unpacked from `elems`. The callable fn takes two tensors as arguments.\n",
      "        The first argument is the accumulated value computed from the preceding\n",
      "        invocation of fn, and the second is the value at the current position of\n",
      "        `elems`. If `initializer` is None, `elems` must contain at least one element,\n",
      "        and its first element is used as the initializer.\n",
      "        \n",
      "        Suppose that `elems` is unpacked into `values`, a list of tensors. The shape\n",
      "        of the result tensor is `fn(initializer, values[0]).shape`.\n",
      "        \n",
      "        This method also allows multi-arity `elems` and output of `fn`.  If `elems`\n",
      "        is a (possibly nested) list or tuple of tensors, then each of these tensors\n",
      "        must have a matching first (unpack) dimension.  The signature of `fn` may\n",
      "        match the structure of `elems`.  That is, if `elems` is\n",
      "        `(t1, [t2, t3, [t4, t5]])`, then an appropriate signature for `fn` is:\n",
      "        `fn = lambda (t1, [t2, t3, [t4, t5]]):`.\n",
      "        \n",
      "        Args:\n",
      "          fn: The callable to be performed.\n",
      "          elems: A tensor or (possibly nested) sequence of tensors, each of which will\n",
      "            be unpacked along their first dimension.  The nested sequence of the\n",
      "            resulting slices will be the first argument to `fn`.\n",
      "          initializer: (optional) A tensor or (possibly nested) sequence of tensors,\n",
      "            as the initial value for the accumulator.\n",
      "          parallel_iterations: (optional) The number of iterations allowed to run in\n",
      "            parallel.\n",
      "          back_prop: (optional) True enables support for back propagation.\n",
      "          swap_memory: (optional) True enables GPU-CPU memory swapping.\n",
      "          name: (optional) Name prefix for the returned tensors.\n",
      "        \n",
      "        Returns:\n",
      "          A tensor or (possibly nested) sequence of tensors, resulting from applying\n",
      "          `fn` consecutively to the list of tensors unpacked from `elems`, from last\n",
      "          to first.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: if `fn` is not callable.\n",
      "        \n",
      "        Example:\n",
      "          ```python\n",
      "          elems = [1, 2, 3, 4, 5, 6]\n",
      "          sum = foldr(lambda a, x: a + x, elems)\n",
      "          # sum == 21\n",
      "          ```\n",
      "    \n",
      "    function(func=None, input_signature=None, autograph=True, experimental_autograph_options=None, experimental_relax_shapes=False, experimental_compile=None)\n",
      "        Creates a callable TensorFlow graph from a Python function.\n",
      "        \n",
      "        `function` constructs a callable that executes a TensorFlow graph\n",
      "        (`tf.Graph`) created by tracing the TensorFlow operations in `func`.\n",
      "        This allows the TensorFlow runtime to apply optimizations and exploit\n",
      "        parallelism in the computation defined by `func`.\n",
      "        \n",
      "        _Example Usage_\n",
      "        \n",
      "        ```python\n",
      "        def f(x, y):\n",
      "          return tf.reduce_mean(tf.multiply(x ** 2, 3) + y)\n",
      "        \n",
      "        g = tf.function(f)\n",
      "        \n",
      "        x = tf.constant([[2.0, 3.0]])\n",
      "        y = tf.constant([[3.0, -2.0]])\n",
      "        \n",
      "        # `f` and `g` will return the same value, but `g` will be executed as a\n",
      "        # TensorFlow graph.\n",
      "        assert f(x, y).numpy() == g(x, y).numpy()\n",
      "        \n",
      "        # Tensors and tf.Variables used by the Python function are captured in the\n",
      "        # graph.\n",
      "        @tf.function\n",
      "        def h():\n",
      "          return f(x, y)\n",
      "        \n",
      "        assert (h().numpy() == f(x, y).numpy()).all()\n",
      "        \n",
      "        # Data-dependent control flow is also captured in the graph. Supported\n",
      "        # control flow statements include `if`, `for`, `while`, `break`, `continue`,\n",
      "        # `return`.\n",
      "        @tf.function\n",
      "        def g(x):\n",
      "          if tf.reduce_sum(x) > 0:\n",
      "            return x * x\n",
      "          else:\n",
      "            return -x // 2\n",
      "        \n",
      "        # print and TensorFlow side effects are supported, but exercise caution when\n",
      "        # using Python side effects like mutating objects, saving to files, etc.\n",
      "        l = []\n",
      "        \n",
      "        @tf.function\n",
      "        def g(x):\n",
      "          for i in x:\n",
      "            print(i)                              # Works\n",
      "            tf.compat.v1.assign(v, i)                       # Works\n",
      "            tf.compat.v1.py_func(lambda i: l.append(i))(i)  # Works\n",
      "            l.append(i)                           # Caution! Doesn't work.\n",
      "        ```\n",
      "        \n",
      "        Note that unlike other TensorFlow operations, we don't convert python\n",
      "        numerical inputs to tensors. Moreover, a new graph is generated for each\n",
      "        distinct python numerical value, for example calling `g(2)` and `g(3)` will\n",
      "        generate two new graphs (while only one is generated if you call\n",
      "        `g(tf.constant(2))` and `g(tf.constant(3))`). Therefore, python numerical\n",
      "        inputs should be restricted to arguments that will have few distinct values,\n",
      "        such as hyperparameters like the number of layers in a neural network. This\n",
      "        allows TensorFlow to optimize each variant of the neural network.\n",
      "        \n",
      "        _Referencing `tf.Variable`s_\n",
      "        \n",
      "        The Python function `func` may reference stateful objects (such as\n",
      "        `tf.Variable`).\n",
      "        These are captured as implicit inputs to the callable returned by `function`.\n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        c = tf.Variable(0)\n",
      "        \n",
      "        @tf.function\n",
      "        def f(x):\n",
      "          c.assign_add(1)\n",
      "          return x + tf.compat.v1.to_float(c)\n",
      "        \n",
      "        assert int(c) == 0\n",
      "        assert f(1.0) == 2.0\n",
      "        assert int(c) == 1\n",
      "        assert f(1.0) == 3.0\n",
      "        assert int(c) == 2\n",
      "        ```\n",
      "        \n",
      "        `function` can be applied to methods of an object. For example:\n",
      "        \n",
      "        ```python\n",
      "        class Dense(object):\n",
      "          def __init__(self):\n",
      "            self.W = tf.Variable(tf.compat.v1.glorot_uniform_initializer()((10, 10)))\n",
      "            self.b = tf.Variable(tf.zeros(10))\n",
      "        \n",
      "          @tf.function\n",
      "          def compute(self, x):\n",
      "            return tf.matmul(x, self.W) + self.b\n",
      "        \n",
      "        d1 = Dense()\n",
      "        d2 = Dense()\n",
      "        x = tf.random.uniform((10, 10))\n",
      "        # d1 and d2 are using distinct variables\n",
      "        assert not (d1.compute(x).numpy() == d2.compute(x).numpy()).all()\n",
      "        ```\n",
      "        \n",
      "        _Usage with `tf.keras`_\n",
      "        \n",
      "        The `call` methods of a `tf.keras.Model` subclass can be decorated with\n",
      "        `function` in order to apply graph execution optimizations on it.\n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        class MyModel(tf.keras.Model):\n",
      "          def __init__(self, keep_probability=0.2):\n",
      "            super(MyModel, self).__init__()\n",
      "            self.dense1 = tf.keras.layers.Dense(4)\n",
      "            self.dense2 = tf.keras.layers.Dense(5)\n",
      "            self.keep_probability = keep_probability\n",
      "        \n",
      "          @tf.function\n",
      "          def call(self, inputs, training=True):\n",
      "            y = self.dense2(self.dense1(inputs))\n",
      "            if training:\n",
      "              return tf.nn.dropout(y, self.keep_probability)\n",
      "            else:\n",
      "              return y\n",
      "        \n",
      "        model = MyModel()\n",
      "        model(x, training=True)  # executes a graph, with dropout\n",
      "        model(x, training=False) # executes a graph, without dropout\n",
      "        ```\n",
      "        \n",
      "        _Input Signatures_\n",
      "        \n",
      "        `function` instantiates a separate graph for every unique set of input\n",
      "        shapes and datatypes. For example, the following code snippet will result\n",
      "        in three distinct graphs being traced, as each input has a different\n",
      "        shape.\n",
      "        \n",
      "        ```python\n",
      "        @tf.function\n",
      "        def f(x): return tf.add(x, 1.)\n",
      "        \n",
      "        scalar = tf.constant(1.0)\n",
      "        vector = tf.constant([1.0, 1.0])\n",
      "        matrix = tf.constant([[3.0]])\n",
      "        \n",
      "        f(scalar)\n",
      "        f(vector)\n",
      "        f(matrix)\n",
      "        ```\n",
      "        \n",
      "        An \"input signature\" can be optionally provided to `function` to control\n",
      "        the graphs traced. The input signature specifies the shape and type of each\n",
      "        `Tensor` argument to the function using a `tf.TensorSpec` object. For example,\n",
      "        the following code snippet ensures that a single graph is created where the\n",
      "        input `Tensor` is required to be a floating point tensor with no restrictions\n",
      "        on shape.\n",
      "        \n",
      "        ```python\n",
      "        @tf.function(input_signature=[tf.TensorSpec(shape=None, dtype=tf.float32)])\n",
      "        def f(x): return tf.add(x, 1.)\n",
      "        ```\n",
      "        \n",
      "        When an `input_signature` is specified, the callable will convert the inputs\n",
      "        to the specified TensorSpecs.\n",
      "        \n",
      "        _Tracing and staging_\n",
      "        \n",
      "        When `autograph` is `True`, all Python control flow that depends on `Tensor`\n",
      "        values is staged into a TensorFlow graph. When `autograph` is `False`, the\n",
      "        function is traced and control flow is not allowed to depend on data.\n",
      "        \n",
      "        Note that `function` only stages TensorFlow operations, all Python code that\n",
      "        `func` executes and does not depend on data will shape the _construction_ of\n",
      "        the graph.\n",
      "        For example, consider the following:\n",
      "        \n",
      "        ```python\n",
      "        import numpy as np\n",
      "        \n",
      "        def add_noise():\n",
      "          return tf.eye(5) + np.random.randn(5, 5)\n",
      "        \n",
      "        traced = tf.function(add_noise)\n",
      "        ```\n",
      "        \n",
      "        `add_noise()` will return a different output every time it is invoked.\n",
      "        However, `traced()` will return the same value every time it is called,\n",
      "        since a particular random value generated by the `np.random.randn` call will\n",
      "        be inserted in the traced/staged TensorFlow graph as a constant. In this\n",
      "        particular example, replacing `np.random.randn(5, 5)` with\n",
      "        `tf.random.normal((5, 5))` will result in the same behavior for `add_noise()`\n",
      "        and `traced()`.\n",
      "        \n",
      "        _Python Side-Effects_\n",
      "        \n",
      "        A corollary of the previous discussion on tracing is the following: If a\n",
      "        Python function `func` has Python side-effects, then executing `func` multiple\n",
      "        times may not be semantically equivalent to executing `F = tf.function(func)`\n",
      "        multiple times; this difference is due to the fact that `function` only\n",
      "        captures the subgraph of TensorFlow operations that is constructed when `func`\n",
      "        is invoked to trace a graph.\n",
      "        \n",
      "        The same is true if code with Python side effects is used inside control flow,\n",
      "        such as a loop. If your code uses side effects that are not intended to\n",
      "        control graph construction, wrap them inside `tf.compat.v1.py_func`.\n",
      "        \n",
      "        _Retracing_\n",
      "        \n",
      "        A single tf.function object might need to map to multiple computation graphs\n",
      "        under the hood. This should be visible only as performance (tracing graphs has\n",
      "        a nonzero computational and memory cost) but should not affect the correctness\n",
      "        of the program. A traced function should return the same result as it would\n",
      "        when run eagerly, assuming no unintended Python side-effects.\n",
      "        \n",
      "        Calling a `tf.function` with tensor arguments of different dtypes should lead\n",
      "        to at least one computational graph per distinct set of dtypes. Alternatively,\n",
      "        always calling a `tf.function` with tensor arguments of the same shapes and\n",
      "        dtypes and the same non-tensor arguments should not lead to additional\n",
      "        retracings of your function.\n",
      "        \n",
      "        Other than that, TensorFlow reserves the right to retrace functions as many\n",
      "        times as needed, to ensure that traced functions behave as they would when run\n",
      "        eagerly and to provide the best end-to-end performance. For example, the\n",
      "        behavior of how many traces TensorFlow will do when the function is repeatedly\n",
      "        called with different python scalars as arguments is left undefined to allow\n",
      "        for future optimizations.\n",
      "        \n",
      "        To control the tracing behavior, use the following tools:\n",
      "         - different `tf.function` objects are guaranteed to not share traces; and\n",
      "         - specifying a signature or using concrete function objects returned from\n",
      "           get_concrete_function() guarantees that only one function graph will be\n",
      "           built.\n",
      "        \n",
      "        Args:\n",
      "          func: function to be compiled. If `func` is None, returns a decorator that\n",
      "            can be invoked with a single argument - `func`. The end result is\n",
      "            equivalent to providing all the arguments up front. In other words,\n",
      "            `tf.function(input_signature=...)(func)` is equivalent to\n",
      "            `tf.function(func, input_signature=...)`. The former can be used to\n",
      "            decorate Python functions, for example:\n",
      "              @tf.function(input_signature=...)\n",
      "              def foo(...): ...\n",
      "          input_signature: A possibly nested sequence of `tf.TensorSpec` objects\n",
      "            specifying the shapes and dtypes of the Tensors that will be supplied to\n",
      "            this function. If `None`, a separate function is instantiated for each\n",
      "            inferred input signature.  If input_signature is specified, every input to\n",
      "            `func` must be a `Tensor`, and `func` cannot accept `**kwargs`.\n",
      "          autograph: Whether autograph should be applied on `func` before tracing a\n",
      "            graph. This allows for dynamic control flow (Python if's, loops etc.)\n",
      "            in the traced graph. See https://www.tensorflow.org/guide/autograph for\n",
      "              more information.\n",
      "          experimental_autograph_options: Experimental knobs (in the form of a tuple\n",
      "            of tensorflow.autograph.Feature values) to control behavior when\n",
      "            autograph=True.\n",
      "          experimental_relax_shapes: When true, argument shapes may be relaxed to\n",
      "            avoid unecessary retracing.\n",
      "          experimental_compile: If false, execute the function in a regular way. The\n",
      "            function is optimized by some graph rewrite passes (some ops might be\n",
      "            clustered into a single op) and interpreted by the standard TensorFlow\n",
      "            executor, which dispatches op kernels one by one as they become\n",
      "            executable. Set it to false when directly running a multi-device function\n",
      "            on TPUs (e.g. two TPU cores, one TPU core and its host CPU). If True, the\n",
      "            function is compiled directly by XLA (https://www.tensorflow.org/xla).\n",
      "            XLA would fuse all the ops and emit more efficient code to run for some\n",
      "            devices (e.g. TPU, XLA_GPU) and some use cases (e.g. dense tensor\n",
      "            computation). It requires that the whole function is compilable by XLA\n",
      "            (e.g. static tensor shape, a subset of operations, no string, compile-time\n",
      "            constant input, etc). If None (default), compile the function with XLA\n",
      "            when running on TPU and go through the regular function execution path\n",
      "            when running on other devices. Note: TensorArrays on TPU don't work with\n",
      "            standard TensorFlow executor.\n",
      "        \n",
      "        Returns:\n",
      "           If `func` is not None, returns a callable that will execute the compiled\n",
      "           function (and return zero or more `tf.Tensor` objects).\n",
      "           If `func` is None, returns a decorator that, when invoked with a single\n",
      "           `func` argument, returns a callable equivalent to the case above.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `input_signature` is neither `None` nor a sequence of\n",
      "            `TensorSpec` objects.\n",
      "    \n",
      "    gather(params, indices, validate_indices=None, name=None, axis=None, batch_dims=0)\n",
      "        Gather slices from params axis axis according to indices.\n",
      "        \n",
      "        Gather slices from params axis `axis` according to `indices`.  `indices` must\n",
      "        be an integer tensor of any dimension (usually 0-D or 1-D).\n",
      "        \n",
      "        For 0-D (scalar) `indices`:\n",
      "        \n",
      "        > `output`$$[p_0,          ..., p_{axis-1},        \\hspace{5.1em}\n",
      "        >            p_{axis + 1}, ..., p_{N-1}]$$ =\\\n",
      "        > `params`$$[p_0,          ..., p_{axis-1},        \\hspace{1em}\n",
      "        >            indices,                              \\hspace{1em}\n",
      "        >            p_{axis + 1}, ..., p_{N-1}]$$.\n",
      "        \n",
      "        For 1-D (vector) `indices` with `batch_dims=0`:\n",
      "        \n",
      "        > `output`$$[p_0,          ..., p_{axis-1},        \\hspace{2.6em}\n",
      "        >            i,                                    \\hspace{2.6em}\n",
      "        >            p_{axis + 1}, ..., p_{N-1}]$$ =\\\n",
      "        > `params`$$[p_0,          ..., p_{axis-1},        \\hspace{1em}\n",
      "        >            indices[i],                           \\hspace{1em}\n",
      "        >            p_{axis + 1}, ..., p_{N-1}]$$.\n",
      "        \n",
      "        In the general case, produces an output tensor where:\n",
      "        \n",
      "        $$\\begin{align*}\n",
      "        output[p_0,             &..., p_{axis-1},                       &\n",
      "             &i_{B},           ..., i_{M-1},                          &\n",
      "             p_{axis + 1},    &..., p_{N-1}]                          = \\\\\n",
      "        params[p_0,             &..., p_{axis-1},                       &\n",
      "             indices[p_0, ..., p_{B-1}, &i_{B}, ..., i_{M-1}],        &\n",
      "             p_{axis + 1},    &..., p_{N-1}]\n",
      "        \\end{align*}$$\n",
      "        \n",
      "        Where $$N$$=`ndims(params)`, $$M$$=`ndims(indices)`, and $$B$$=`batch_dims`.\n",
      "        Note that params.shape[:batch_dims] must be identical to\n",
      "        indices.shape[:batch_dims].\n",
      "        \n",
      "        The shape of the output tensor is:\n",
      "        \n",
      "        > `output.shape = params.shape[:axis] + indices.shape[batch_dims:] +\n",
      "        > params.shape[axis + 1:]`.\n",
      "        \n",
      "        Note that on CPU, if an out of bound index is found, an error is returned.\n",
      "        On GPU, if an out of bound index is found, a 0 is stored in the corresponding\n",
      "        output value.\n",
      "        \n",
      "        See also `tf.gather_nd`.\n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        <img style=\"width:100%\" src=\"https://www.tensorflow.org/images/Gather.png\"\n",
      "        alt>\n",
      "        </div>\n",
      "        \n",
      "        Args:\n",
      "          params: The `Tensor` from which to gather values. Must be at least rank\n",
      "            `axis + 1`.\n",
      "          indices: The index `Tensor`.  Must be one of the following types: `int32`,\n",
      "            `int64`. Must be in range `[0, params.shape[axis])`.\n",
      "          validate_indices: Deprecated, does nothing.\n",
      "          axis: A `Tensor`. Must be one of the following types: `int32`, `int64`. The\n",
      "            `axis` in `params` to gather `indices` from. Must be greater than or equal\n",
      "            to `batch_dims`.  Defaults to the first non-batch dimension. Supports\n",
      "            negative indexes.\n",
      "          batch_dims: An `integer`.  The number of batch dimensions.  Must be less\n",
      "            than `rank(indices)`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `params`.\n",
      "    \n",
      "    gather_nd(params, indices, name=None, batch_dims=0)\n",
      "        Gather slices from `params` into a Tensor with shape specified by `indices`.\n",
      "        \n",
      "        `indices` is an K-dimensional integer tensor, best thought of as a\n",
      "        (K-1)-dimensional tensor of indices into `params`, where each element defines\n",
      "        a slice of `params`:\n",
      "        \n",
      "            output[\\\\(i_0, ..., i_{K-2}\\\\)] = params[indices[\\\\(i_0, ..., i_{K-2}\\\\)]]\n",
      "        \n",
      "        Whereas in `tf.gather` `indices` defines slices into the first\n",
      "        dimension of `params`, in `tf.gather_nd`, `indices` defines slices into the\n",
      "        first `N` dimensions of `params`, where `N = indices.shape[-1]`.\n",
      "        \n",
      "        The last dimension of `indices` can be at most the rank of\n",
      "        `params`:\n",
      "        \n",
      "            indices.shape[-1] <= params.rank\n",
      "        \n",
      "        The last dimension of `indices` corresponds to elements\n",
      "        (if `indices.shape[-1] == params.rank`) or slices\n",
      "        (if `indices.shape[-1] < params.rank`) along dimension `indices.shape[-1]`\n",
      "        of `params`.  The output tensor has shape\n",
      "        \n",
      "            indices.shape[:-1] + params.shape[indices.shape[-1]:]\n",
      "        \n",
      "        Additionally both 'params' and 'indices' can have M leading batch\n",
      "        dimensions that exactly match. In this case 'batch_dims' must be M.\n",
      "        \n",
      "        Note that on CPU, if an out of bound index is found, an error is returned.\n",
      "        On GPU, if an out of bound index is found, a 0 is stored in the\n",
      "        corresponding output value.\n",
      "        \n",
      "        Some examples below.\n",
      "        \n",
      "        Simple indexing into a matrix:\n",
      "        \n",
      "        ```python\n",
      "            indices = [[0, 0], [1, 1]]\n",
      "            params = [['a', 'b'], ['c', 'd']]\n",
      "            output = ['a', 'd']\n",
      "        ```\n",
      "        \n",
      "        Slice indexing into a matrix:\n",
      "        \n",
      "        ```python\n",
      "            indices = [[1], [0]]\n",
      "            params = [['a', 'b'], ['c', 'd']]\n",
      "            output = [['c', 'd'], ['a', 'b']]\n",
      "        ```\n",
      "        \n",
      "        Indexing into a 3-tensor:\n",
      "        \n",
      "        ```python\n",
      "            indices = [[1]]\n",
      "            params = [[['a0', 'b0'], ['c0', 'd0']],\n",
      "                      [['a1', 'b1'], ['c1', 'd1']]]\n",
      "            output = [[['a1', 'b1'], ['c1', 'd1']]]\n",
      "        \n",
      "        \n",
      "            indices = [[0, 1], [1, 0]]\n",
      "            params = [[['a0', 'b0'], ['c0', 'd0']],\n",
      "                      [['a1', 'b1'], ['c1', 'd1']]]\n",
      "            output = [['c0', 'd0'], ['a1', 'b1']]\n",
      "        \n",
      "        \n",
      "            indices = [[0, 0, 1], [1, 0, 1]]\n",
      "            params = [[['a0', 'b0'], ['c0', 'd0']],\n",
      "                      [['a1', 'b1'], ['c1', 'd1']]]\n",
      "            output = ['b0', 'b1']\n",
      "        ```\n",
      "        \n",
      "        The examples below are for the case when only indices have leading extra\n",
      "        dimensions. If both 'params' and 'indices' have leading batch dimensions, use\n",
      "        the 'batch_dims' parameter to run gather_nd in batch mode.\n",
      "        \n",
      "        Batched indexing into a matrix:\n",
      "        \n",
      "        ```python\n",
      "            indices = [[[0, 0]], [[0, 1]]]\n",
      "            params = [['a', 'b'], ['c', 'd']]\n",
      "            output = [['a'], ['b']]\n",
      "        ```\n",
      "        \n",
      "        Batched slice indexing into a matrix:\n",
      "        \n",
      "        ```python\n",
      "            indices = [[[1]], [[0]]]\n",
      "            params = [['a', 'b'], ['c', 'd']]\n",
      "            output = [[['c', 'd']], [['a', 'b']]]\n",
      "        ```\n",
      "        \n",
      "        Batched indexing into a 3-tensor:\n",
      "        \n",
      "        ```python\n",
      "            indices = [[[1]], [[0]]]\n",
      "            params = [[['a0', 'b0'], ['c0', 'd0']],\n",
      "                      [['a1', 'b1'], ['c1', 'd1']]]\n",
      "            output = [[[['a1', 'b1'], ['c1', 'd1']]],\n",
      "                      [[['a0', 'b0'], ['c0', 'd0']]]]\n",
      "        \n",
      "            indices = [[[0, 1], [1, 0]], [[0, 0], [1, 1]]]\n",
      "            params = [[['a0', 'b0'], ['c0', 'd0']],\n",
      "                      [['a1', 'b1'], ['c1', 'd1']]]\n",
      "            output = [[['c0', 'd0'], ['a1', 'b1']],\n",
      "                      [['a0', 'b0'], ['c1', 'd1']]]\n",
      "        \n",
      "        \n",
      "            indices = [[[0, 0, 1], [1, 0, 1]], [[0, 1, 1], [1, 1, 0]]]\n",
      "            params = [[['a0', 'b0'], ['c0', 'd0']],\n",
      "                      [['a1', 'b1'], ['c1', 'd1']]]\n",
      "            output = [['b0', 'b1'], ['d0', 'c1']]\n",
      "        ```\n",
      "        \n",
      "        Examples with batched 'params' and 'indices':\n",
      "        \n",
      "        ```python\n",
      "            batch_dims = 1\n",
      "            indices = [[1], [0]]\n",
      "            params = [[['a0', 'b0'], ['c0', 'd0']],\n",
      "                      [['a1', 'b1'], ['c1', 'd1']]]\n",
      "            output = [['c0', 'd0'], ['a1', 'b1']]\n",
      "        \n",
      "            batch_dims = 1\n",
      "            indices = [[[1]], [[0]]]\n",
      "            params = [[['a0', 'b0'], ['c0', 'd0']],\n",
      "                      [['a1', 'b1'], ['c1', 'd1']]]\n",
      "            output = [[['c0', 'd0']], [['a1', 'b1']]]\n",
      "        \n",
      "            batch_dims = 1\n",
      "            indices = [[[1, 0]], [[0, 1]]]\n",
      "            params = [[['a0', 'b0'], ['c0', 'd0']],\n",
      "                      [['a1', 'b1'], ['c1', 'd1']]]\n",
      "            output = [['c0'], ['b1']]\n",
      "        ```\n",
      "        \n",
      "        See also `tf.gather`.\n",
      "        \n",
      "        Args:\n",
      "          params: A `Tensor`. The tensor from which to gather values.\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            Index tensor.\n",
      "          name: A name for the operation (optional).\n",
      "          batch_dims: An integer or a scalar 'Tensor'. The number of batch dimensions.\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `params`.\n",
      "    \n",
      "    get_collection(key, scope=None)\n",
      "        Wrapper for `Graph.get_collection()` using the default graph.\n",
      "        \n",
      "        See `tf.Graph.get_collection`\n",
      "        for more details.\n",
      "        \n",
      "        Args:\n",
      "          key: The key for the collection. For example, the `GraphKeys` class contains\n",
      "            many standard names for collections.\n",
      "          scope: (Optional.) If supplied, the resulting list is filtered to include\n",
      "            only items whose `name` attribute matches using `re.match`. Items without\n",
      "            a `name` attribute are never returned if a scope is supplied and the\n",
      "            choice or `re.match` means that a `scope` without special tokens filters\n",
      "            by prefix.\n",
      "        \n",
      "        Returns:\n",
      "          The list of values in the collection with the given `name`, or\n",
      "          an empty list if no value has been added to that collection. The\n",
      "          list contains the values in the order under which they were\n",
      "          collected.\n",
      "        \n",
      "        @compatibility(eager)\n",
      "        Collections are not supported when eager execution is enabled.\n",
      "        @end_compatibility\n",
      "    \n",
      "    get_collection_ref(key)\n",
      "        Wrapper for `Graph.get_collection_ref()` using the default graph.\n",
      "        \n",
      "        See `tf.Graph.get_collection_ref`\n",
      "        for more details.\n",
      "        \n",
      "        Args:\n",
      "          key: The key for the collection. For example, the `GraphKeys` class contains\n",
      "            many standard names for collections.\n",
      "        \n",
      "        Returns:\n",
      "          The list of values in the collection with the given `name`, or an empty\n",
      "          list if no value has been added to that collection.  Note that this returns\n",
      "          the collection list itself, which can be modified in place to change the\n",
      "          collection.\n",
      "        \n",
      "        @compatibility(eager)\n",
      "        Collections are not supported when eager execution is enabled.\n",
      "        @end_compatibility\n",
      "    \n",
      "    get_default_graph()\n",
      "        Returns the default graph for the current thread.\n",
      "        \n",
      "        The returned graph will be the innermost graph on which a\n",
      "        `Graph.as_default()` context has been entered, or a global default\n",
      "        graph if none has been explicitly created.\n",
      "        \n",
      "        NOTE: The default graph is a property of the current thread. If you\n",
      "        create a new thread, and wish to use the default graph in that\n",
      "        thread, you must explicitly add a `with g.as_default():` in that\n",
      "        thread's function.\n",
      "        \n",
      "        Returns:\n",
      "          The default `Graph` being used in the current thread.\n",
      "    \n",
      "    get_default_session()\n",
      "        Returns the default session for the current thread.\n",
      "        \n",
      "        The returned `Session` will be the innermost session on which a\n",
      "        `Session` or `Session.as_default()` context has been entered.\n",
      "        \n",
      "        NOTE: The default session is a property of the current thread. If you\n",
      "        create a new thread, and wish to use the default session in that\n",
      "        thread, you must explicitly add a `with sess.as_default():` in that\n",
      "        thread's function.\n",
      "        \n",
      "        Returns:\n",
      "          The default `Session` being used in the current thread.\n",
      "    \n",
      "    get_local_variable(name, shape=None, dtype=None, initializer=None, regularizer=None, trainable=False, collections=None, caching_device=None, partitioner=None, validate_shape=True, use_resource=None, custom_getter=None, constraint=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregation.NONE: 0>)\n",
      "        Gets an existing *local* variable or creates a new one.\n",
      "        \n",
      "        Behavior is the same as in `get_variable`, except that variables are\n",
      "        added to the `LOCAL_VARIABLES` collection and `trainable` is set to\n",
      "        `False`.\n",
      "        This function prefixes the name with the current variable scope\n",
      "        and performs reuse checks. See the\n",
      "        [Variable Scope How To](https://tensorflow.org/guide/variables)\n",
      "        for an extensive description of how reusing works. Here is a basic example:\n",
      "        \n",
      "        ```python\n",
      "        def foo():\n",
      "          with tf.variable_scope(\"foo\", reuse=tf.AUTO_REUSE):\n",
      "            v = tf.get_variable(\"v\", [1])\n",
      "          return v\n",
      "        \n",
      "        v1 = foo()  # Creates v.\n",
      "        v2 = foo()  # Gets the same, existing v.\n",
      "        assert v1 == v2\n",
      "        ```\n",
      "        \n",
      "        If initializer is `None` (the default), the default initializer passed in\n",
      "        the variable scope will be used. If that one is `None` too, a\n",
      "        `glorot_uniform_initializer` will be used. The initializer can also be\n",
      "        a Tensor, in which case the variable is initialized to this value and shape.\n",
      "        \n",
      "        Similarly, if the regularizer is `None` (the default), the default regularizer\n",
      "        passed in the variable scope will be used (if that is `None` too,\n",
      "        then by default no regularization is performed).\n",
      "        \n",
      "        If a partitioner is provided, a `PartitionedVariable` is returned.\n",
      "        Accessing this object as a `Tensor` returns the shards concatenated along\n",
      "        the partition axis.\n",
      "        \n",
      "        Some useful partitioners are available.  See, e.g.,\n",
      "        `variable_axis_size_partitioner` and `min_max_variable_partitioner`.\n",
      "        \n",
      "        Args:\n",
      "          name: The name of the new or existing variable.\n",
      "          shape: Shape of the new or existing variable.\n",
      "          dtype: Type of the new or existing variable (defaults to `DT_FLOAT`).\n",
      "          initializer: Initializer for the variable if one is created. Can either be\n",
      "            an initializer object or a Tensor. If it's a Tensor, its shape must be known\n",
      "            unless validate_shape is False.\n",
      "          regularizer: A (Tensor -> Tensor or None) function; the result of\n",
      "            applying it on a newly created variable will be added to the collection\n",
      "            `tf.GraphKeys.REGULARIZATION_LOSSES` and can be used for regularization.\n",
      "          collections: List of graph collections keys to add the Variable to.\n",
      "            Defaults to `[GraphKeys.LOCAL_VARIABLES]` (see `tf.Variable`).\n",
      "          caching_device: Optional device string or function describing where the\n",
      "            Variable should be cached for reading.  Defaults to the Variable's\n",
      "            device.  If not `None`, caches on another device.  Typical use is to\n",
      "            cache on the device where the Ops using the Variable reside, to\n",
      "            deduplicate copying through `Switch` and other conditional statements.\n",
      "          partitioner: Optional callable that accepts a fully defined `TensorShape`\n",
      "            and `dtype` of the Variable to be created, and returns a list of\n",
      "            partitions for each axis (currently only one axis can be partitioned).\n",
      "          validate_shape: If False, allows the variable to be initialized with a\n",
      "              value of unknown shape. If True, the default, the shape of initial_value\n",
      "              must be known. For this to be used the initializer must be a Tensor and\n",
      "              not an initializer object.\n",
      "          use_resource: If False, creates a regular Variable. If true, creates an\n",
      "            experimental ResourceVariable instead with well-defined semantics.\n",
      "            Defaults to False (will later change to True). When eager execution is\n",
      "            enabled this argument is always forced to be True.\n",
      "          custom_getter: Callable that takes as a first argument the true getter, and\n",
      "            allows overwriting the internal get_variable method.\n",
      "            The signature of `custom_getter` should match that of this method,\n",
      "            but the most future-proof version will allow for changes:\n",
      "            `def custom_getter(getter, *args, **kwargs)`.  Direct access to\n",
      "            all `get_variable` parameters is also allowed:\n",
      "            `def custom_getter(getter, name, *args, **kwargs)`.  A simple identity\n",
      "            custom getter that simply creates variables with modified names is:\n",
      "            ```python\n",
      "            def custom_getter(getter, name, *args, **kwargs):\n",
      "              return getter(name + '_suffix', *args, **kwargs)\n",
      "            ```\n",
      "          constraint: An optional projection function to be applied to the variable\n",
      "            after being updated by an `Optimizer` (e.g. used to implement norm\n",
      "            constraints or value constraints for layer weights). The function must\n",
      "            take as input the unprojected Tensor representing the value of the\n",
      "            variable and return the Tensor for the projected value\n",
      "            (which must have the same shape). Constraints are not safe to\n",
      "            use when doing asynchronous distributed training.\n",
      "          synchronization: Indicates when a distributed a variable will be\n",
      "            aggregated. Accepted values are constants defined in the class\n",
      "            `tf.VariableSynchronization`. By default the synchronization is set to\n",
      "            `AUTO` and the current `DistributionStrategy` chooses\n",
      "            when to synchronize.\n",
      "          aggregation: Indicates how a distributed variable will be aggregated.\n",
      "            Accepted values are constants defined in the class\n",
      "            `tf.VariableAggregation`.\n",
      "        \n",
      "        Returns:\n",
      "          The created or existing `Variable` (or `PartitionedVariable`, if a\n",
      "          partitioner was used).\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: when creating a new variable and shape is not declared,\n",
      "            when violating reuse during variable creation, or when `initializer` dtype\n",
      "            and `dtype` don't match. Reuse is set inside `variable_scope`.\n",
      "    \n",
      "    get_logger()\n",
      "        Return TF logger instance.\n",
      "    \n",
      "    get_seed(op_seed)\n",
      "        Returns the local seeds an operation should use given an op-specific seed.\n",
      "        \n",
      "        Given operation-specific seed, `op_seed`, this helper function returns two\n",
      "        seeds derived from graph-level and op-level seeds. Many random operations\n",
      "        internally use the two seeds to allow user to change the seed globally for a\n",
      "        graph, or for only specific operations.\n",
      "        \n",
      "        For details on how the graph-level seed interacts with op seeds, see\n",
      "        `tf.compat.v1.random.set_random_seed`.\n",
      "        \n",
      "        Args:\n",
      "          op_seed: integer.\n",
      "        \n",
      "        Returns:\n",
      "          A tuple of two integers that should be used for the local seed of this\n",
      "          operation.\n",
      "    \n",
      "    get_session_handle(data, name=None)\n",
      "        Return the handle of `data`.\n",
      "        \n",
      "        This is EXPERIMENTAL and subject to change.\n",
      "        \n",
      "        Keep `data` \"in-place\" in the runtime and create a handle that can be\n",
      "        used to retrieve `data` in a subsequent run().\n",
      "        \n",
      "        Combined with `get_session_tensor`, we can keep a tensor produced in\n",
      "        one run call in place, and use it as the input in a future run call.\n",
      "        \n",
      "        Args:\n",
      "          data: A tensor to be stored in the session.\n",
      "          name: Optional name prefix for the return tensor.\n",
      "        \n",
      "        Returns:\n",
      "          A scalar string tensor representing a unique handle for `data`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: if `data` is not a Tensor.\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        ```python\n",
      "        c = tf.multiply(a, b)\n",
      "        h = tf.compat.v1.get_session_handle(c)\n",
      "        h = sess.run(h)\n",
      "        \n",
      "        p, a = tf.compat.v1.get_session_tensor(h.handle, tf.float32)\n",
      "        b = tf.multiply(a, 10)\n",
      "        c = sess.run(b, feed_dict={p: h.handle})\n",
      "        ```\n",
      "    \n",
      "    get_session_tensor(handle, dtype, name=None)\n",
      "        Get the tensor of type `dtype` by feeding a tensor handle.\n",
      "        \n",
      "        This is EXPERIMENTAL and subject to change.\n",
      "        \n",
      "        Get the value of the tensor from a tensor handle. The tensor\n",
      "        is produced in a previous run() and stored in the state of the\n",
      "        session.\n",
      "        \n",
      "        Args:\n",
      "          handle: The string representation of a persistent tensor handle.\n",
      "          dtype: The type of the output tensor.\n",
      "          name: Optional name prefix for the return tensor.\n",
      "        \n",
      "        Returns:\n",
      "          A pair of tensors. The first is a placeholder for feeding a\n",
      "          tensor handle and the second is the tensor in the session state\n",
      "          keyed by the tensor handle.\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        ```python\n",
      "        c = tf.multiply(a, b)\n",
      "        h = tf.compat.v1.get_session_handle(c)\n",
      "        h = sess.run(h)\n",
      "        \n",
      "        p, a = tf.compat.v1.get_session_tensor(h.handle, tf.float32)\n",
      "        b = tf.multiply(a, 10)\n",
      "        c = sess.run(b, feed_dict={p: h.handle})\n",
      "        ```\n",
      "    \n",
      "    get_static_value = constant_value(tensor, partial=False)\n",
      "        Returns the constant value of the given tensor, if efficiently calculable.\n",
      "        \n",
      "        This function attempts to partially evaluate the given tensor, and\n",
      "        returns its value as a numpy ndarray if this succeeds.\n",
      "        \n",
      "        Compatibility(V1): If `constant_value(tensor)` returns a non-`None` result, it\n",
      "        will no longer be possible to feed a different value for `tensor`. This allows\n",
      "        the result of this function to influence the graph that is constructed, and\n",
      "        permits static shape optimizations.\n",
      "        \n",
      "        Args:\n",
      "          tensor: The Tensor to be evaluated.\n",
      "          partial: If True, the returned numpy array is allowed to have partially\n",
      "            evaluated values. Values that can't be evaluated will be None.\n",
      "        \n",
      "        Returns:\n",
      "          A numpy ndarray containing the constant value of the given `tensor`,\n",
      "          or None if it cannot be calculated.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: if tensor is not an ops.Tensor.\n",
      "    \n",
      "    get_variable(name, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, collections=None, caching_device=None, partitioner=None, validate_shape=True, use_resource=None, custom_getter=None, constraint=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregation.NONE: 0>)\n",
      "        Gets an existing variable with these parameters or create a new one.\n",
      "        \n",
      "        This function prefixes the name with the current variable scope\n",
      "        and performs reuse checks. See the\n",
      "        [Variable Scope How To](https://tensorflow.org/guide/variables)\n",
      "        for an extensive description of how reusing works. Here is a basic example:\n",
      "        \n",
      "        ```python\n",
      "        def foo():\n",
      "          with tf.variable_scope(\"foo\", reuse=tf.AUTO_REUSE):\n",
      "            v = tf.get_variable(\"v\", [1])\n",
      "          return v\n",
      "        \n",
      "        v1 = foo()  # Creates v.\n",
      "        v2 = foo()  # Gets the same, existing v.\n",
      "        assert v1 == v2\n",
      "        ```\n",
      "        \n",
      "        If initializer is `None` (the default), the default initializer passed in\n",
      "        the variable scope will be used. If that one is `None` too, a\n",
      "        `glorot_uniform_initializer` will be used. The initializer can also be\n",
      "        a Tensor, in which case the variable is initialized to this value and shape.\n",
      "        \n",
      "        Similarly, if the regularizer is `None` (the default), the default regularizer\n",
      "        passed in the variable scope will be used (if that is `None` too,\n",
      "        then by default no regularization is performed).\n",
      "        \n",
      "        If a partitioner is provided, a `PartitionedVariable` is returned.\n",
      "        Accessing this object as a `Tensor` returns the shards concatenated along\n",
      "        the partition axis.\n",
      "        \n",
      "        Some useful partitioners are available.  See, e.g.,\n",
      "        `variable_axis_size_partitioner` and `min_max_variable_partitioner`.\n",
      "        \n",
      "        Args:\n",
      "          name: The name of the new or existing variable.\n",
      "          shape: Shape of the new or existing variable.\n",
      "          dtype: Type of the new or existing variable (defaults to `DT_FLOAT`).\n",
      "          initializer: Initializer for the variable if one is created. Can either be\n",
      "            an initializer object or a Tensor. If it's a Tensor, its shape must be known\n",
      "            unless validate_shape is False.\n",
      "          regularizer: A (Tensor -> Tensor or None) function; the result of\n",
      "            applying it on a newly created variable will be added to the collection\n",
      "            `tf.GraphKeys.REGULARIZATION_LOSSES` and can be used for regularization.\n",
      "          trainable: If `True` also add the variable to the graph collection\n",
      "            `GraphKeys.TRAINABLE_VARIABLES` (see `tf.Variable`).\n",
      "          collections: List of graph collections keys to add the Variable to.\n",
      "            Defaults to `[GraphKeys.GLOBAL_VARIABLES]` (see `tf.Variable`).\n",
      "          caching_device: Optional device string or function describing where the\n",
      "            Variable should be cached for reading.  Defaults to the Variable's\n",
      "            device.  If not `None`, caches on another device.  Typical use is to\n",
      "            cache on the device where the Ops using the Variable reside, to\n",
      "            deduplicate copying through `Switch` and other conditional statements.\n",
      "          partitioner: Optional callable that accepts a fully defined `TensorShape`\n",
      "            and `dtype` of the Variable to be created, and returns a list of\n",
      "            partitions for each axis (currently only one axis can be partitioned).\n",
      "          validate_shape: If False, allows the variable to be initialized with a\n",
      "              value of unknown shape. If True, the default, the shape of initial_value\n",
      "              must be known. For this to be used the initializer must be a Tensor and\n",
      "              not an initializer object.\n",
      "          use_resource: If False, creates a regular Variable. If true, creates an\n",
      "            experimental ResourceVariable instead with well-defined semantics.\n",
      "            Defaults to False (will later change to True). When eager execution is\n",
      "            enabled this argument is always forced to be True.\n",
      "          custom_getter: Callable that takes as a first argument the true getter, and\n",
      "            allows overwriting the internal get_variable method.\n",
      "            The signature of `custom_getter` should match that of this method,\n",
      "            but the most future-proof version will allow for changes:\n",
      "            `def custom_getter(getter, *args, **kwargs)`.  Direct access to\n",
      "            all `get_variable` parameters is also allowed:\n",
      "            `def custom_getter(getter, name, *args, **kwargs)`.  A simple identity\n",
      "            custom getter that simply creates variables with modified names is:\n",
      "            ```python\n",
      "            def custom_getter(getter, name, *args, **kwargs):\n",
      "              return getter(name + '_suffix', *args, **kwargs)\n",
      "            ```\n",
      "          constraint: An optional projection function to be applied to the variable\n",
      "            after being updated by an `Optimizer` (e.g. used to implement norm\n",
      "            constraints or value constraints for layer weights). The function must\n",
      "            take as input the unprojected Tensor representing the value of the\n",
      "            variable and return the Tensor for the projected value\n",
      "            (which must have the same shape). Constraints are not safe to\n",
      "            use when doing asynchronous distributed training.\n",
      "          synchronization: Indicates when a distributed a variable will be\n",
      "            aggregated. Accepted values are constants defined in the class\n",
      "            `tf.VariableSynchronization`. By default the synchronization is set to\n",
      "            `AUTO` and the current `DistributionStrategy` chooses\n",
      "            when to synchronize.\n",
      "          aggregation: Indicates how a distributed variable will be aggregated.\n",
      "            Accepted values are constants defined in the class\n",
      "            `tf.VariableAggregation`.\n",
      "        \n",
      "        Returns:\n",
      "          The created or existing `Variable` (or `PartitionedVariable`, if a\n",
      "          partitioner was used).\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: when creating a new variable and shape is not declared,\n",
      "            when violating reuse during variable creation, or when `initializer` dtype\n",
      "            and `dtype` don't match. Reuse is set inside `variable_scope`.\n",
      "    \n",
      "    get_variable_scope()\n",
      "        Returns the current variable scope.\n",
      "    \n",
      "    global_norm(t_list, name=None)\n",
      "        Computes the global norm of multiple tensors.\n",
      "        \n",
      "        Given a tuple or list of tensors `t_list`, this operation returns the\n",
      "        global norm of the elements in all tensors in `t_list`. The global norm is\n",
      "        computed as:\n",
      "        \n",
      "        `global_norm = sqrt(sum([l2norm(t)**2 for t in t_list]))`\n",
      "        \n",
      "        Any entries in `t_list` that are of type None are ignored.\n",
      "        \n",
      "        Args:\n",
      "          t_list: A tuple or list of mixed `Tensors`, `IndexedSlices`, or None.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A 0-D (scalar) `Tensor` of type `float`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `t_list` is not a sequence.\n",
      "    \n",
      "    global_variables(scope=None)\n",
      "        Returns global variables.\n",
      "        \n",
      "        Global variables are variables that are shared across machines in a\n",
      "        distributed environment. The `Variable()` constructor or `get_variable()`\n",
      "        automatically adds new variables to the graph collection\n",
      "        `GraphKeys.GLOBAL_VARIABLES`.\n",
      "        This convenience function returns the contents of that collection.\n",
      "        \n",
      "        An alternative to global variables are local variables. See\n",
      "        `tf.compat.v1.local_variables`\n",
      "        \n",
      "        Args:\n",
      "          scope: (Optional.) A string. If supplied, the resulting list is filtered to\n",
      "            include only items whose `name` attribute matches `scope` using\n",
      "            `re.match`. Items without a `name` attribute are never returned if a scope\n",
      "            is supplied. The choice of `re.match` means that a `scope` without special\n",
      "            tokens filters by prefix.\n",
      "        \n",
      "        Returns:\n",
      "          A list of `Variable` objects.\n",
      "    \n",
      "    global_variables_initializer()\n",
      "        Returns an Op that initializes global variables.\n",
      "        \n",
      "        This is just a shortcut for `variables_initializer(global_variables())`\n",
      "        \n",
      "        Returns:\n",
      "          An Op that initializes global variables in the graph.\n",
      "    \n",
      "    grad_pass_through(f)\n",
      "        Creates a grad-pass-through op with the forward behavior provided in f.\n",
      "        \n",
      "        Use this function to wrap any op, maintaining its behavior in the forward\n",
      "        pass, but replacing the original op in the backward graph with an identity.\n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.Variable(1.0, name=\"x\")\n",
      "        z = tf.Variable(3.0, name=\"z\")\n",
      "        \n",
      "        with tf.GradientTape() as tape:\n",
      "          # y will evaluate to 9.0\n",
      "          y = tf.grad_pass_through(x.assign)(z**2)\n",
      "        # grads will evaluate to 6.0\n",
      "        grads = tape.gradient(y, z)\n",
      "        ```\n",
      "        \n",
      "        Another example is a 'differentiable' moving average approximation, where\n",
      "        gradients are allowed to flow into the last value fed to the moving average,\n",
      "        but the moving average is still used for the forward pass:\n",
      "        \n",
      "        ```python\n",
      "        x = ... # Some scalar value\n",
      "        # A moving average object, we don't need to know how this is implemented\n",
      "        moving_average = MovingAverage()\n",
      "        with backprop.GradientTape() as tape:\n",
      "          # mavg_x will evaluate to the current running average value\n",
      "          mavg_x = tf.grad_pass_through(moving_average)(x)\n",
      "        grads = tape.gradient(mavg_x, x) # grads will evaluate to 1.0\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          f: function `f(*x)` that returns a `Tensor` or nested structure of `Tensor`\n",
      "            outputs.\n",
      "        \n",
      "        Returns:\n",
      "         A function `h(x)` which returns the same values as `f(x)` and whose\n",
      "         gradients are the same as those of an identity function.\n",
      "    \n",
      "    gradients(ys, xs, grad_ys=None, name='gradients', colocate_gradients_with_ops=False, gate_gradients=False, aggregation_method=None, stop_gradients=None, unconnected_gradients=<UnconnectedGradients.NONE: 'none'>)\n",
      "        Constructs symbolic derivatives of sum of `ys` w.r.t. x in `xs`.\n",
      "        \n",
      "        `ys` and `xs` are each a `Tensor` or a list of tensors.  `grad_ys`\n",
      "        is a list of `Tensor`, holding the gradients received by the\n",
      "        `ys`. The list must be the same length as `ys`.\n",
      "        \n",
      "        `gradients()` adds ops to the graph to output the derivatives of `ys` with\n",
      "        respect to `xs`.  It returns a list of `Tensor` of length `len(xs)` where\n",
      "        each tensor is the `sum(dy/dx)` for y in `ys`.\n",
      "        \n",
      "        `grad_ys` is a list of tensors of the same length as `ys` that holds\n",
      "        the initial gradients for each y in `ys`.  When `grad_ys` is None,\n",
      "        we fill in a tensor of '1's of the shape of y for each y in `ys`.  A\n",
      "        user can provide their own initial `grad_ys` to compute the\n",
      "        derivatives using a different initial gradient for each y (e.g., if\n",
      "        one wanted to weight the gradient differently for each value in\n",
      "        each y).\n",
      "        \n",
      "        `stop_gradients` is a `Tensor` or a list of tensors to be considered constant\n",
      "        with respect to all `xs`. These tensors will not be backpropagated through,\n",
      "        as though they had been explicitly disconnected using `stop_gradient`.  Among\n",
      "        other things, this allows computation of partial derivatives as opposed to\n",
      "        total derivatives. For example:\n",
      "        \n",
      "        ```python\n",
      "        a = tf.constant(0.)\n",
      "        b = 2 * a\n",
      "        g = tf.gradients(a + b, [a, b], stop_gradients=[a, b])\n",
      "        ```\n",
      "        \n",
      "        Here the partial derivatives `g` evaluate to `[1.0, 1.0]`, compared to the\n",
      "        total derivatives `tf.gradients(a + b, [a, b])`, which take into account the\n",
      "        influence of `a` on `b` and evaluate to `[3.0, 1.0]`.  Note that the above is\n",
      "        equivalent to:\n",
      "        \n",
      "        ```python\n",
      "        a = tf.stop_gradient(tf.constant(0.))\n",
      "        b = tf.stop_gradient(2 * a)\n",
      "        g = tf.gradients(a + b, [a, b])\n",
      "        ```\n",
      "        \n",
      "        `stop_gradients` provides a way of stopping gradient after the graph has\n",
      "        already been constructed, as compared to `tf.stop_gradient` which is used\n",
      "        during graph construction.  When the two approaches are combined,\n",
      "        backpropagation stops at both `tf.stop_gradient` nodes and nodes in\n",
      "        `stop_gradients`, whichever is encountered first.\n",
      "        \n",
      "        All integer tensors are considered constant with respect to all `xs`, as if\n",
      "        they were included in `stop_gradients`.\n",
      "        \n",
      "        `unconnected_gradients` determines the value returned for each x in xs if it\n",
      "        is unconnected in the graph to ys. By default this is None to safeguard\n",
      "        against errors. MAthematically these gradients are zero which can be requested\n",
      "        using the `'zero'` option. `tf.UnconnectedGradients` provides the\n",
      "        following options and behaviors:\n",
      "        \n",
      "        ```python\n",
      "        a = tf.ones([1, 2])\n",
      "        b = tf.ones([3, 1])\n",
      "        g1 = tf.gradients([b], [a], unnconnected_gradients='none')\n",
      "        sess.run(g1)  # [None]\n",
      "        \n",
      "        g2 = tf.gradients([b], [a], unconnected_gradients='zero')\n",
      "        sess.run(g2)  # [array([[0., 0.]], dtype=float32)]\n",
      "        ```\n",
      "        \n",
      "        \n",
      "        Args:\n",
      "          ys: A `Tensor` or list of tensors to be differentiated.\n",
      "          xs: A `Tensor` or list of tensors to be used for differentiation.\n",
      "          grad_ys: Optional. A `Tensor` or list of tensors the same size as\n",
      "            `ys` and holding the gradients computed for each y in `ys`.\n",
      "          name: Optional name to use for grouping all the gradient ops together.\n",
      "            defaults to 'gradients'.\n",
      "          colocate_gradients_with_ops: If True, try colocating gradients with\n",
      "            the corresponding op.\n",
      "          gate_gradients: If True, add a tuple around the gradients returned\n",
      "            for an operations.  This avoids some race conditions.\n",
      "          aggregation_method: Specifies the method used to combine gradient terms.\n",
      "            Accepted values are constants defined in the class `AggregationMethod`.\n",
      "          stop_gradients: Optional. A `Tensor` or list of tensors not to differentiate\n",
      "            through.\n",
      "          unconnected_gradients: Optional. Specifies the gradient value returned when\n",
      "            the given input tensors are unconnected. Accepted values are constants\n",
      "            defined in the class `tf.UnconnectedGradients` and the default value is\n",
      "            `none`.\n",
      "        \n",
      "        Returns:\n",
      "          A list of `sum(dy/dx)` for each x in `xs`.\n",
      "        \n",
      "        Raises:\n",
      "          LookupError: if one of the operations between `x` and `y` does not\n",
      "            have a registered gradient function.\n",
      "          ValueError: if the arguments are invalid.\n",
      "          RuntimeError: if called in Eager mode.\n",
      "    \n",
      "    greater(x, y, name=None)\n",
      "        Returns the truth value of (x > y) element-wise.\n",
      "        \n",
      "        *NOTE*: `math.greater` supports broadcasting. More about broadcasting\n",
      "        [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "          y: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `bool`.\n",
      "    \n",
      "    greater_equal(x, y, name=None)\n",
      "        Returns the truth value of (x >= y) element-wise.\n",
      "        \n",
      "        *NOTE*: `math.greater_equal` supports broadcasting. More about broadcasting\n",
      "        [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "          y: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `bool`.\n",
      "    \n",
      "    group(*inputs, **kwargs)\n",
      "        Create an op that groups multiple operations.\n",
      "        \n",
      "        When this op finishes, all ops in `inputs` have finished. This op has no\n",
      "        output.\n",
      "        \n",
      "        See also `tf.tuple` and\n",
      "        `tf.control_dependencies`.\n",
      "        \n",
      "        Args:\n",
      "          *inputs: Zero or more tensors to group.\n",
      "          name: A name for this operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          An Operation that executes all its inputs.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If an unknown keyword argument is provided.\n",
      "    \n",
      "    guarantee_const(input, name=None)\n",
      "        Gives a guarantee to the TF runtime that the input tensor is a constant.\n",
      "        \n",
      "        The runtime is then free to make optimizations based on this.\n",
      "        \n",
      "        Only accepts value typed tensors as inputs and rejects resource variable handles\n",
      "        as input.\n",
      "        \n",
      "        Returns the input tensor without modification.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    hessians(ys, xs, name='hessians', colocate_gradients_with_ops=False, gate_gradients=False, aggregation_method=None)\n",
      "        Constructs the Hessian of sum of `ys` with respect to `x` in `xs`.\n",
      "        \n",
      "        `hessians()` adds ops to the graph to output the Hessian matrix of `ys`\n",
      "        with respect to `xs`.  It returns a list of `Tensor` of length `len(xs)`\n",
      "        where each tensor is the Hessian of `sum(ys)`.\n",
      "        \n",
      "        The Hessian is a matrix of second-order partial derivatives of a scalar\n",
      "        tensor (see https://en.wikipedia.org/wiki/Hessian_matrix for more details).\n",
      "        \n",
      "        Args:\n",
      "          ys: A `Tensor` or list of tensors to be differentiated.\n",
      "          xs: A `Tensor` or list of tensors to be used for differentiation.\n",
      "          name: Optional name to use for grouping all the gradient ops together.\n",
      "            defaults to 'hessians'.\n",
      "          colocate_gradients_with_ops: See `gradients()` documentation for details.\n",
      "          gate_gradients: See `gradients()` documentation for details.\n",
      "          aggregation_method: See `gradients()` documentation for details.\n",
      "        \n",
      "        Returns:\n",
      "          A list of Hessian matrices of `sum(ys)` for each `x` in `xs`.\n",
      "        \n",
      "        Raises:\n",
      "          LookupError: if one of the operations between `xs` and `ys` does not\n",
      "            have a registered gradient function.\n",
      "    \n",
      "    histogram_fixed_width(values, value_range, nbins=100, dtype=tf.int32, name=None)\n",
      "        Return histogram of values.\n",
      "        \n",
      "        Given the tensor `values`, this operation returns a rank 1 histogram counting\n",
      "        the number of entries in `values` that fell into every bin.  The bins are\n",
      "        equal width and determined by the arguments `value_range` and `nbins`.\n",
      "        \n",
      "        Args:\n",
      "          values:  Numeric `Tensor`.\n",
      "          value_range:  Shape [2] `Tensor` of same `dtype` as `values`.\n",
      "            values <= value_range[0] will be mapped to hist[0],\n",
      "            values >= value_range[1] will be mapped to hist[-1].\n",
      "          nbins:  Scalar `int32 Tensor`.  Number of histogram bins.\n",
      "          dtype:  dtype for returned histogram.\n",
      "          name:  A name for this operation (defaults to 'histogram_fixed_width').\n",
      "        \n",
      "        Returns:\n",
      "          A 1-D `Tensor` holding histogram of values.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If any unsupported dtype is provided.\n",
      "          tf.errors.InvalidArgumentError: If value_range does not\n",
      "              satisfy value_range[0] < value_range[1].\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "        ```python\n",
      "        # Bins will be:  (-inf, 1), [1, 2), [2, 3), [3, 4), [4, inf)\n",
      "        nbins = 5\n",
      "        value_range = [0.0, 5.0]\n",
      "        new_values = [-1.0, 0.0, 1.5, 2.0, 5.0, 15]\n",
      "        \n",
      "        with tf.compat.v1.get_default_session() as sess:\n",
      "          hist = tf.histogram_fixed_width(new_values, value_range, nbins=5)\n",
      "          variables.global_variables_initializer().run()\n",
      "          sess.run(hist) => [2, 1, 1, 0, 2]\n",
      "        ```\n",
      "    \n",
      "    histogram_fixed_width_bins(values, value_range, nbins=100, dtype=tf.int32, name=None)\n",
      "        Bins the given values for use in a histogram.\n",
      "        \n",
      "        Given the tensor `values`, this operation returns a rank 1 `Tensor`\n",
      "        representing the indices of a histogram into which each element\n",
      "        of `values` would be binned. The bins are equal width and\n",
      "        determined by the arguments `value_range` and `nbins`.\n",
      "        \n",
      "        Args:\n",
      "          values:  Numeric `Tensor`.\n",
      "          value_range:  Shape [2] `Tensor` of same `dtype` as `values`.\n",
      "            values <= value_range[0] will be mapped to hist[0],\n",
      "            values >= value_range[1] will be mapped to hist[-1].\n",
      "          nbins:  Scalar `int32 Tensor`.  Number of histogram bins.\n",
      "          dtype:  dtype for returned histogram.\n",
      "          name:  A name for this operation (defaults to 'histogram_fixed_width').\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` holding the indices of the binned values whose shape matches\n",
      "          `values`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If any unsupported dtype is provided.\n",
      "          tf.errors.InvalidArgumentError: If value_range does not\n",
      "              satisfy value_range[0] < value_range[1].\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "        ```python\n",
      "        # Bins will be:  (-inf, 1), [1, 2), [2, 3), [3, 4), [4, inf)\n",
      "        nbins = 5\n",
      "        value_range = [0.0, 5.0]\n",
      "        new_values = [-1.0, 0.0, 1.5, 2.0, 5.0, 15]\n",
      "        \n",
      "        with tf.compat.v1.get_default_session() as sess:\n",
      "          indices = tf.histogram_fixed_width_bins(new_values, value_range, nbins=5)\n",
      "          variables.global_variables_initializer().run()\n",
      "          sess.run(indices) # [0, 0, 1, 2, 4, 4]\n",
      "        ```\n",
      "    \n",
      "    identity(input, name=None)\n",
      "        Return a tensor with the same shape and contents as input.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        import tensorflow as tf\n",
      "        val0 = tf.ones((1,), dtype=tf.float32)\n",
      "        a = tf.atan2(val0, val0)\n",
      "        a_identity = tf.identity(a)\n",
      "        print(a.numpy())          #[0.7853982]\n",
      "        print(a_identity.numpy()) #[0.7853982]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    identity_n(input, name=None)\n",
      "        Returns a list of tensors with the same shapes and contents as the input\n",
      "        \n",
      "        tensors.\n",
      "        \n",
      "        This op can be used to override the gradient for complicated functions. For\n",
      "        example, suppose y = f(x) and we wish to apply a custom function g for backprop\n",
      "        such that dx = g(dy). In Python,\n",
      "        \n",
      "        ```python\n",
      "        with tf.get_default_graph().gradient_override_map(\n",
      "            {'IdentityN': 'OverrideGradientWithG'}):\n",
      "          y, _ = identity_n([f(x), x])\n",
      "        \n",
      "        @tf.RegisterGradient('OverrideGradientWithG')\n",
      "        def ApplyG(op, dy, _):\n",
      "          return [None, g(dy)]  # Do not backprop to f(x).\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input: A list of `Tensor` objects.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A list of `Tensor` objects. Has the same type as `input`.\n",
      "    \n",
      "    ifft(input, name=None)\n",
      "        Inverse fast Fourier transform.\n",
      "        \n",
      "        Computes the inverse 1-dimensional discrete Fourier transform over the\n",
      "        inner-most dimension of `input`.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `complex64`, `complex128`.\n",
      "            A complex tensor.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    ifft2d(input, name=None)\n",
      "        Inverse 2D fast Fourier transform.\n",
      "        \n",
      "        Computes the inverse 2-dimensional discrete Fourier transform over the\n",
      "        inner-most 2 dimensions of `input`.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `complex64`, `complex128`.\n",
      "            A complex tensor.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    ifft3d(input, name=None)\n",
      "        Inverse 3D fast Fourier transform.\n",
      "        \n",
      "        Computes the inverse 3-dimensional discrete Fourier transform over the\n",
      "        inner-most 3 dimensions of `input`.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `complex64`, `complex128`.\n",
      "            A complex64 tensor.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    igamma(a, x, name=None)\n",
      "        Compute the lower regularized incomplete Gamma function `P(a, x)`.\n",
      "        \n",
      "        The lower regularized incomplete Gamma function is defined as:\n",
      "        \n",
      "        \n",
      "        \\\\(P(a, x) = gamma(a, x) / Gamma(a) = 1 - Q(a, x)\\\\)\n",
      "        \n",
      "        where\n",
      "        \n",
      "        \\\\(gamma(a, x) = \\\\int_{0}^{x} t^{a-1} exp(-t) dt\\\\)\n",
      "        \n",
      "        is the lower incomplete Gamma function.\n",
      "        \n",
      "        Note, above `Q(a, x)` (`Igammac`) is the upper regularized complete\n",
      "        Gamma function.\n",
      "        \n",
      "        Args:\n",
      "          a: A `Tensor`. Must be one of the following types: `float32`, `float64`.\n",
      "          x: A `Tensor`. Must have the same type as `a`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `a`.\n",
      "    \n",
      "    igammac(a, x, name=None)\n",
      "        Compute the upper regularized incomplete Gamma function `Q(a, x)`.\n",
      "        \n",
      "        The upper regularized incomplete Gamma function is defined as:\n",
      "        \n",
      "        \\\\(Q(a, x) = Gamma(a, x) / Gamma(a) = 1 - P(a, x)\\\\)\n",
      "        \n",
      "        where\n",
      "        \n",
      "        \\\\(Gamma(a, x) = int_{x}^{\\infty} t^{a-1} exp(-t) dt\\\\)\n",
      "        \n",
      "        is the upper incomplete Gama function.\n",
      "        \n",
      "        Note, above `P(a, x)` (`Igamma`) is the lower regularized complete\n",
      "        Gamma function.\n",
      "        \n",
      "        Args:\n",
      "          a: A `Tensor`. Must be one of the following types: `float32`, `float64`.\n",
      "          x: A `Tensor`. Must have the same type as `a`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `a`.\n",
      "    \n",
      "    imag(input, name=None)\n",
      "        Returns the imaginary part of a complex (or real) tensor.\n",
      "        \n",
      "        Given a tensor `input`, this operation returns a tensor of type `float` that\n",
      "        is the imaginary part of each element in `input` considered as a complex\n",
      "        number. If `input` is real, a tensor of all zeros is returned.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([-2.25 + 4.75j, 3.25 + 5.75j])\n",
      "        tf.math.imag(x)  # [4.75, 5.75]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `float`, `double`,\n",
      "            `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `float32` or `float64`.\n",
      "    \n",
      "    import_graph_def(graph_def, input_map=None, return_elements=None, name=None, op_dict=None, producer_op_list=None)\n",
      "        Imports the graph from `graph_def` into the current default `Graph`. (deprecated arguments)\n",
      "        \n",
      "        Warning: SOME ARGUMENTS ARE DEPRECATED: `(op_dict)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Please file an issue at https://github.com/tensorflow/tensorflow/issues if you depend on this feature.\n",
      "        \n",
      "        This function provides a way to import a serialized TensorFlow\n",
      "        [`GraphDef`](https://www.tensorflow.org/code/tensorflow/core/framework/graph.proto)\n",
      "        protocol buffer, and extract individual objects in the `GraphDef` as\n",
      "        `tf.Tensor` and `tf.Operation` objects. Once extracted,\n",
      "        these objects are placed into the current default `Graph`. See\n",
      "        `tf.Graph.as_graph_def` for a way to create a `GraphDef`\n",
      "        proto.\n",
      "        \n",
      "        Args:\n",
      "          graph_def: A `GraphDef` proto containing operations to be imported into\n",
      "            the default graph.\n",
      "          input_map: A dictionary mapping input names (as strings) in `graph_def`\n",
      "            to `Tensor` objects. The values of the named input tensors in the\n",
      "            imported graph will be re-mapped to the respective `Tensor` values.\n",
      "          return_elements: A list of strings containing operation names in\n",
      "            `graph_def` that will be returned as `Operation` objects; and/or\n",
      "            tensor names in `graph_def` that will be returned as `Tensor` objects.\n",
      "          name: (Optional.) A prefix that will be prepended to the names in\n",
      "            `graph_def`. Note that this does not apply to imported function names.\n",
      "            Defaults to `\"import\"`.\n",
      "          op_dict: (Optional.) Deprecated, do not use.\n",
      "          producer_op_list: (Optional.) An `OpList` proto with the (possibly stripped)\n",
      "            list of `OpDef`s used by the producer of the graph. If provided,\n",
      "            unrecognized attrs for ops in `graph_def` that have their default value\n",
      "            according to `producer_op_list` will be removed. This will allow some more\n",
      "            `GraphDef`s produced by later binaries to be accepted by earlier binaries.\n",
      "        \n",
      "        Returns:\n",
      "          A list of `Operation` and/or `Tensor` objects from the imported graph,\n",
      "          corresponding to the names in `return_elements`,\n",
      "          and None if `returns_elements` is None.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `graph_def` is not a `GraphDef` proto,\n",
      "            `input_map` is not a dictionary mapping strings to `Tensor` objects,\n",
      "            or `return_elements` is not a list of strings.\n",
      "          ValueError: If `input_map`, or `return_elements` contains names that\n",
      "            do not appear in `graph_def`, or `graph_def` is not well-formed (e.g.\n",
      "            it refers to an unknown tensor).\n",
      "    \n",
      "    init_scope()\n",
      "        A context manager that lifts ops out of control-flow scopes and function-building graphs.\n",
      "        \n",
      "        There is often a need to lift variable initialization ops out of control-flow\n",
      "        scopes, function-building graphs, and gradient tapes. Entering an\n",
      "        `init_scope` is a mechanism for satisfying these desiderata. In particular,\n",
      "        entering an `init_scope` has three effects:\n",
      "        \n",
      "          (1) All control dependencies are cleared the moment the scope is entered;\n",
      "              this is equivalent to entering the context manager returned from\n",
      "              `control_dependencies(None)`, which has the side-effect of exiting\n",
      "              control-flow scopes like `tf.cond` and `tf.while_loop`.\n",
      "        \n",
      "          (2) All operations that are created while the scope is active are lifted\n",
      "              into the lowest context on the `context_stack` that is not building a\n",
      "              graph function. Here, a context is defined as either a graph or an eager\n",
      "              context. Every context switch, i.e., every installation of a graph as\n",
      "              the default graph and every switch into eager mode, is logged in a\n",
      "              thread-local stack called `context_switches`; the log entry for a\n",
      "              context switch is popped from the stack when the context is exited.\n",
      "              Entering an `init_scope` is equivalent to crawling up\n",
      "              `context_switches`, finding the first context that is not building a\n",
      "              graph function, and entering it. A caveat is that if graph mode is\n",
      "              enabled but the default graph stack is empty, then entering an\n",
      "              `init_scope` will simply install a fresh graph as the default one.\n",
      "        \n",
      "          (3) The gradient tape is paused while the scope is active.\n",
      "        \n",
      "        When eager execution is enabled, code inside an init_scope block runs with\n",
      "        eager execution enabled even when defining graph functions via\n",
      "        tf.contrib.eager.defun. For example:\n",
      "        \n",
      "        ```python\n",
      "        tf.compat.v1.enable_eager_execution()\n",
      "        \n",
      "        @tf.contrib.eager.defun\n",
      "        def func():\n",
      "          # A defun-decorated function constructs TensorFlow graphs,\n",
      "          # it does not execute eagerly.\n",
      "          assert not tf.executing_eagerly()\n",
      "          with tf.init_scope():\n",
      "            # Initialization runs with eager execution enabled\n",
      "            assert tf.executing_eagerly()\n",
      "        ```\n",
      "        \n",
      "        Raises:\n",
      "          RuntimeError: if graph state is incompatible with this initialization.\n",
      "    \n",
      "    initialize_all_tables(name='init_all_tables')\n",
      "        Returns an Op that initializes all tables of the default graph. (deprecated)\n",
      "        \n",
      "        Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Use `tf.tables_initializer` instead.\n",
      "        \n",
      "        Args:\n",
      "          name: Optional name for the initialization op.\n",
      "        \n",
      "        Returns:\n",
      "          An Op that initializes all tables.  Note that if there are\n",
      "          not tables the returned Op is a NoOp.\n",
      "    \n",
      "    initialize_all_variables()\n",
      "        See `tf.compat.v1.global_variables_initializer`. (deprecated)\n",
      "        \n",
      "        Warning: THIS FUNCTION IS DEPRECATED. It will be removed after 2017-03-02.\n",
      "        Instructions for updating:\n",
      "        Use `tf.global_variables_initializer` instead.\n",
      "        \n",
      "          **NOTE** The output of this function should be used.  If it is not, a warning will be logged.  To mark the output as used, call its .mark_used() method.\n",
      "    \n",
      "    initialize_local_variables()\n",
      "        See `tf.compat.v1.local_variables_initializer`. (deprecated)\n",
      "        \n",
      "        Warning: THIS FUNCTION IS DEPRECATED. It will be removed after 2017-03-02.\n",
      "        Instructions for updating:\n",
      "        Use `tf.local_variables_initializer` instead.\n",
      "        \n",
      "          **NOTE** The output of this function should be used.  If it is not, a warning will be logged.  To mark the output as used, call its .mark_used() method.\n",
      "    \n",
      "    initialize_variables(var_list, name='init')\n",
      "        See `tf.compat.v1.variables_initializer`. (deprecated)\n",
      "        \n",
      "        Warning: THIS FUNCTION IS DEPRECATED. It will be removed after 2017-03-02.\n",
      "        Instructions for updating:\n",
      "        Use `tf.variables_initializer` instead.\n",
      "        \n",
      "          **NOTE** The output of this function should be used.  If it is not, a warning will be logged.  To mark the output as used, call its .mark_used() method.\n",
      "    \n",
      "    invert_permutation(x, name=None)\n",
      "        Computes the inverse permutation of a tensor.\n",
      "        \n",
      "        This operation computes the inverse of an index permutation. It takes a 1-D\n",
      "        integer tensor `x`, which represents the indices of a zero-based array, and\n",
      "        swaps each value with its index position. In other words, for an output tensor\n",
      "        `y` and an input tensor `x`, this operation computes the following:\n",
      "        \n",
      "        `y[x[i]] = i for i in [0, 1, ..., len(x) - 1]`\n",
      "        \n",
      "        The values must include 0. There can be no duplicate values or negative values.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```\n",
      "        # tensor `x` is [3, 4, 0, 2, 1]\n",
      "        invert_permutation(x) ==> [2, 4, 3, 0, 1]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `int32`, `int64`. 1-D.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    is_finite(x, name=None)\n",
      "        Returns which elements of x are finite.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Equivalent to np.isfinite\n",
      "        @end_compatibility\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `bool`.\n",
      "    \n",
      "    is_inf(x, name=None)\n",
      "        Returns which elements of x are Inf.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Equivalent to np.isinf\n",
      "        @end_compatibility\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `bool`.\n",
      "    \n",
      "    is_nan(x, name=None)\n",
      "        Returns which elements of x are NaN.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Equivalent to np.isnan\n",
      "        @end_compatibility\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `bool`.\n",
      "    \n",
      "    is_non_decreasing(x, name=None)\n",
      "        Returns `True` if `x` is non-decreasing.\n",
      "        \n",
      "        Elements of `x` are compared in row-major order.  The tensor `[x[0],...]`\n",
      "        is non-decreasing if for every adjacent pair we have `x[i] <= x[i+1]`.\n",
      "        If `x` has less than two elements, it is trivially non-decreasing.\n",
      "        \n",
      "        See also:  `is_strictly_increasing`\n",
      "        \n",
      "        Args:\n",
      "          x: Numeric `Tensor`.\n",
      "          name: A name for this operation (optional).  Defaults to \"is_non_decreasing\"\n",
      "        \n",
      "        Returns:\n",
      "          Boolean `Tensor`, equal to `True` iff `x` is non-decreasing.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: if `x` is not a numeric tensor.\n",
      "    \n",
      "    is_numeric_tensor(tensor)\n",
      "        Returns `True` if the elements of `tensor` are numbers.\n",
      "        \n",
      "        Specifically, returns `True` if the dtype of `tensor` is one of the following:\n",
      "        \n",
      "        * `tf.float32`\n",
      "        * `tf.float64`\n",
      "        * `tf.int8`\n",
      "        * `tf.int16`\n",
      "        * `tf.int32`\n",
      "        * `tf.int64`\n",
      "        * `tf.uint8`\n",
      "        * `tf.qint8`\n",
      "        * `tf.qint32`\n",
      "        * `tf.quint8`\n",
      "        * `tf.complex64`\n",
      "        \n",
      "        Returns `False` if `tensor` is of a non-numeric type or if `tensor` is not\n",
      "        a `tf.Tensor` object.\n",
      "    \n",
      "    is_strictly_increasing(x, name=None)\n",
      "        Returns `True` if `x` is strictly increasing.\n",
      "        \n",
      "        Elements of `x` are compared in row-major order.  The tensor `[x[0],...]`\n",
      "        is strictly increasing if for every adjacent pair we have `x[i] < x[i+1]`.\n",
      "        If `x` has less than two elements, it is trivially strictly increasing.\n",
      "        \n",
      "        See also:  `is_non_decreasing`\n",
      "        \n",
      "        Args:\n",
      "          x: Numeric `Tensor`.\n",
      "          name: A name for this operation (optional).\n",
      "            Defaults to \"is_strictly_increasing\"\n",
      "        \n",
      "        Returns:\n",
      "          Boolean `Tensor`, equal to `True` iff `x` is strictly increasing.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: if `x` is not a numeric tensor.\n",
      "    \n",
      "    is_tensor(x)\n",
      "        Checks whether `x` is a tensor or \"tensor-like\".\n",
      "        \n",
      "        If `is_tensor(x)` returns `True`, it is safe to assume that `x` is a tensor or\n",
      "        can be converted to a tensor using `ops.convert_to_tensor(x)`.\n",
      "        \n",
      "        Args:\n",
      "          x: A python object to check.\n",
      "        \n",
      "        Returns:\n",
      "          `True` if `x` is a tensor or \"tensor-like\", `False` if not.\n",
      "    \n",
      "    is_variable_initialized(variable)\n",
      "        Tests if a variable has been initialized.\n",
      "        \n",
      "        Args:\n",
      "          variable: A `Variable`.\n",
      "        \n",
      "        Returns:\n",
      "          Returns a scalar boolean Tensor, `True` if the variable has been\n",
      "          initialized, `False` otherwise.\n",
      "        \n",
      "        \n",
      "        **NOTE** The output of this function should be used.  If it is not, a warning will be logged.  To mark the output as used, call its .mark_used() method.\n",
      "    \n",
      "    lbeta(x, name=None)\n",
      "        Computes \\\\(ln(|Beta(x)|)\\\\), reducing along the last dimension.\n",
      "        \n",
      "        Given one-dimensional `z = [z_0,...,z_{K-1}]`, we define\n",
      "        \n",
      "        $$Beta(z) = \\prod_j Gamma(z_j) / Gamma(\\sum_j z_j)$$\n",
      "        \n",
      "        And for `n + 1` dimensional `x` with shape `[N1, ..., Nn, K]`, we define\n",
      "        $$lbeta(x)[i1, ..., in] = Log(|Beta(x[i1, ..., in, :])|)$$.\n",
      "        \n",
      "        In other words, the last dimension is treated as the `z` vector.\n",
      "        \n",
      "        Note that if `z = [u, v]`, then\n",
      "        \\\\(Beta(z) = int_0^1 t^{u-1} (1 - t)^{v-1} dt\\\\), which defines the\n",
      "        traditional bivariate beta function.\n",
      "        \n",
      "        If the last dimension is empty, we follow the convention that the sum over\n",
      "        the empty set is zero, and the product is one.\n",
      "        \n",
      "        Args:\n",
      "          x: A rank `n + 1` `Tensor`, `n >= 0` with type `float`, or `double`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          The logarithm of \\\\(|Beta(x)|\\\\) reducing along the last dimension.\n",
      "    \n",
      "    less(x, y, name=None)\n",
      "        Returns the truth value of (x < y) element-wise.\n",
      "        \n",
      "        *NOTE*: `math.less` supports broadcasting. More about broadcasting\n",
      "        [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "          y: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `bool`.\n",
      "    \n",
      "    less_equal(x, y, name=None)\n",
      "        Returns the truth value of (x <= y) element-wise.\n",
      "        \n",
      "        *NOTE*: `math.less_equal` supports broadcasting. More about broadcasting\n",
      "        [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "          y: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `bool`.\n",
      "    \n",
      "    lgamma(x, name=None)\n",
      "        Computes the log of the absolute value of `Gamma(x)` element-wise.\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    lin_space(start, stop, num, name=None)\n",
      "        Generates values in an interval.\n",
      "        \n",
      "        A sequence of `num` evenly-spaced values are generated beginning at `start`.\n",
      "        If `num > 1`, the values in the sequence increase by `stop - start / num - 1`,\n",
      "        so that the last one is exactly `stop`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```\n",
      "        tf.linspace(10.0, 12.0, 3, name=\"linspace\") => [ 10.0  11.0  12.0]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          start: A `Tensor`. Must be one of the following types: `bfloat16`, `float32`, `float64`.\n",
      "            0-D tensor. First entry in the range.\n",
      "          stop: A `Tensor`. Must have the same type as `start`.\n",
      "            0-D tensor. Last entry in the range.\n",
      "          num: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            0-D tensor. Number of values to generate.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `start`.\n",
      "    \n",
      "    linspace = lin_space(start, stop, num, name=None)\n",
      "        Generates values in an interval.\n",
      "        \n",
      "        A sequence of `num` evenly-spaced values are generated beginning at `start`.\n",
      "        If `num > 1`, the values in the sequence increase by `stop - start / num - 1`,\n",
      "        so that the last one is exactly `stop`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```\n",
      "        tf.linspace(10.0, 12.0, 3, name=\"linspace\") => [ 10.0  11.0  12.0]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          start: A `Tensor`. Must be one of the following types: `bfloat16`, `float32`, `float64`.\n",
      "            0-D tensor. First entry in the range.\n",
      "          stop: A `Tensor`. Must have the same type as `start`.\n",
      "            0-D tensor. Last entry in the range.\n",
      "          num: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            0-D tensor. Number of values to generate.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `start`.\n",
      "    \n",
      "    load_file_system_library(library_filename)\n",
      "        Loads a TensorFlow plugin, containing file system implementation. (deprecated)\n",
      "        \n",
      "        Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Use `tf.load_library` instead.\n",
      "        \n",
      "        Pass `library_filename` to a platform-specific mechanism for dynamically\n",
      "        loading a library. The rules for determining the exact location of the\n",
      "        library are platform-specific and are not documented here.\n",
      "        \n",
      "        Args:\n",
      "          library_filename: Path to the plugin.\n",
      "            Relative or absolute filesystem path to a dynamic library file.\n",
      "        \n",
      "        Returns:\n",
      "          None.\n",
      "        \n",
      "        Raises:\n",
      "          RuntimeError: when unable to load the library.\n",
      "    \n",
      "    load_library(library_location)\n",
      "        Loads a TensorFlow plugin.\n",
      "        \n",
      "        \"library_location\" can be a path to a specific shared object, or a folder.\n",
      "        If it is a folder, all shared objects that are named \"libtfkernel*\" will be\n",
      "        loaded. When the library is loaded, kernels registered in the library via the\n",
      "        `REGISTER_*` macros are made available in the TensorFlow process.\n",
      "        \n",
      "        Args:\n",
      "          library_location: Path to the plugin or the folder of plugins.\n",
      "            Relative or absolute filesystem path to a dynamic library file or folder.\n",
      "        \n",
      "        Returns:\n",
      "          None\n",
      "        \n",
      "        Raises:\n",
      "          OSError: When the file to be loaded is not found.\n",
      "          RuntimeError: when unable to load the library.\n",
      "    \n",
      "    load_op_library(library_filename)\n",
      "        Loads a TensorFlow plugin, containing custom ops and kernels.\n",
      "        \n",
      "        Pass \"library_filename\" to a platform-specific mechanism for dynamically\n",
      "        loading a library. The rules for determining the exact location of the\n",
      "        library are platform-specific and are not documented here. When the\n",
      "        library is loaded, ops and kernels registered in the library via the\n",
      "        `REGISTER_*` macros are made available in the TensorFlow process. Note\n",
      "        that ops with the same name as an existing op are rejected and not\n",
      "        registered with the process.\n",
      "        \n",
      "        Args:\n",
      "          library_filename: Path to the plugin.\n",
      "            Relative or absolute filesystem path to a dynamic library file.\n",
      "        \n",
      "        Returns:\n",
      "          A python module containing the Python wrappers for Ops defined in\n",
      "          the plugin.\n",
      "        \n",
      "        Raises:\n",
      "          RuntimeError: when unable to load the library or get the python wrappers.\n",
      "    \n",
      "    local_variables(scope=None)\n",
      "        Returns local variables.\n",
      "        \n",
      "        Local variables - per process variables, usually not saved/restored to\n",
      "        checkpoint and used for temporary or intermediate values.\n",
      "        For example, they can be used as counters for metrics computation or\n",
      "        number of epochs this machine has read data.\n",
      "        The `tf.contrib.framework.local_variable()` function automatically adds the\n",
      "        new variable to `GraphKeys.LOCAL_VARIABLES`.\n",
      "        This convenience function returns the contents of that collection.\n",
      "        \n",
      "        An alternative to local variables are global variables. See\n",
      "        `tf.compat.v1.global_variables`\n",
      "        \n",
      "        Args:\n",
      "          scope: (Optional.) A string. If supplied, the resulting list is filtered to\n",
      "            include only items whose `name` attribute matches `scope` using\n",
      "            `re.match`. Items without a `name` attribute are never returned if a scope\n",
      "            is supplied. The choice of `re.match` means that a `scope` without special\n",
      "            tokens filters by prefix.\n",
      "        \n",
      "        Returns:\n",
      "          A list of local `Variable` objects.\n",
      "    \n",
      "    local_variables_initializer()\n",
      "        Returns an Op that initializes all local variables.\n",
      "        \n",
      "        This is just a shortcut for `variables_initializer(local_variables())`\n",
      "        \n",
      "        Returns:\n",
      "          An Op that initializes all local variables in the graph.\n",
      "    \n",
      "    log(x, name=None)\n",
      "        Computes natural logarithm of x element-wise.\n",
      "        \n",
      "        I.e., \\\\(y = \\log_e x\\\\).\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    log1p(x, name=None)\n",
      "        Computes natural logarithm of (1 + x) element-wise.\n",
      "        \n",
      "        I.e., \\\\(y = \\log_e (1 + x)\\\\).\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    log_sigmoid(x, name=None)\n",
      "        Computes log sigmoid of `x` element-wise.\n",
      "        \n",
      "        Specifically, `y = log(1 / (1 + exp(-x)))`.  For numerical stability,\n",
      "        we use `y = -tf.nn.softplus(-x)`.\n",
      "        \n",
      "        Args:\n",
      "          x: A Tensor with type `float32` or `float64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A Tensor with the same type as `x`.\n",
      "    \n",
      "    logical_and(x, y, name=None)\n",
      "        Returns the truth value of x AND y element-wise.\n",
      "        \n",
      "        *NOTE*: `math.logical_and` supports broadcasting. More about broadcasting\n",
      "        [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor` of type `bool`.\n",
      "          y: A `Tensor` of type `bool`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `bool`.\n",
      "    \n",
      "    logical_not(x, name=None)\n",
      "        Returns the truth value of NOT x element-wise.\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor` of type `bool`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `bool`.\n",
      "    \n",
      "    logical_or(x, y, name=None)\n",
      "        Returns the truth value of x OR y element-wise.\n",
      "        \n",
      "        *NOTE*: `math.logical_or` supports broadcasting. More about broadcasting\n",
      "        [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor` of type `bool`.\n",
      "          y: A `Tensor` of type `bool`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `bool`.\n",
      "    \n",
      "    logical_xor(x, y, name='LogicalXor')\n",
      "        Logical XOR function.\n",
      "        \n",
      "        x ^ y = (x | y) & ~(x & y)\n",
      "        \n",
      "        Inputs are tensor and if the tensors contains more than one element, an\n",
      "        element-wise logical XOR is computed.\n",
      "        \n",
      "        Usage:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([False, False, True, True], dtype = tf.bool)\n",
      "        y = tf.constant([False, True, False, True], dtype = tf.bool)\n",
      "        z = tf.logical_xor(x, y, name=\"LogicalXor\")\n",
      "        #  here z = [False  True  True False]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "            x: A `Tensor` type bool.\n",
      "            y: A `Tensor` of type bool.\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type bool with the same size as that of x or y.\n",
      "    \n",
      "    make_ndarray = MakeNdarray(tensor)\n",
      "        Create a numpy ndarray from a tensor.\n",
      "        \n",
      "        Create a numpy ndarray with the same shape and data as the tensor.\n",
      "        \n",
      "        Args:\n",
      "          tensor: A TensorProto.\n",
      "        \n",
      "        Returns:\n",
      "          A numpy array with the tensor contents.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: if tensor has unsupported type.\n",
      "    \n",
      "    make_template(name_, func_, create_scope_now_=False, unique_name_=None, custom_getter_=None, **kwargs)\n",
      "        Given an arbitrary function, wrap it so that it does variable sharing.\n",
      "        \n",
      "        This wraps `func_` in a Template and partially evaluates it. Templates are\n",
      "        functions that create variables the first time they are called and reuse them\n",
      "        thereafter. In order for `func_` to be compatible with a `Template` it must\n",
      "        have the following properties:\n",
      "        \n",
      "        * The function should create all trainable variables and any variables that\n",
      "           should be reused by calling `tf.compat.v1.get_variable`. If a trainable\n",
      "           variable is\n",
      "           created using `tf.Variable`, then a ValueError will be thrown. Variables\n",
      "           that are intended to be locals can be created by specifying\n",
      "           `tf.Variable(..., trainable=false)`.\n",
      "        * The function may use variable scopes and other templates internally to\n",
      "            create and reuse variables, but it shouldn't use\n",
      "            `tf.compat.v1.global_variables` to\n",
      "            capture variables that are defined outside of the scope of the function.\n",
      "        * Internal scopes and variable names should not depend on any arguments that\n",
      "            are not supplied to `make_template`. In general you will get a ValueError\n",
      "            telling you that you are trying to reuse a variable that doesn't exist\n",
      "            if you make a mistake.\n",
      "        \n",
      "        In the following example, both `z` and `w` will be scaled by the same `y`. It\n",
      "        is important to note that if we didn't assign `scalar_name` and used a\n",
      "        different name for z and w that a `ValueError` would be thrown because it\n",
      "        couldn't reuse the variable.\n",
      "        \n",
      "        ```python\n",
      "        def my_op(x, scalar_name):\n",
      "          var1 = tf.compat.v1.get_variable(scalar_name,\n",
      "                                 shape=[],\n",
      "                                 initializer=tf.compat.v1.constant_initializer(1))\n",
      "          return x * var1\n",
      "        \n",
      "        scale_by_y = tf.compat.v1.make_template('scale_by_y', my_op, scalar_name='y')\n",
      "        \n",
      "        z = scale_by_y(input1)\n",
      "        w = scale_by_y(input2)\n",
      "        ```\n",
      "        \n",
      "        As a safe-guard, the returned function will raise a `ValueError` after the\n",
      "        first call if trainable variables are created by calling `tf.Variable`.\n",
      "        \n",
      "        If all of these are true, then 2 properties are enforced by the template:\n",
      "        \n",
      "        1. Calling the same template multiple times will share all non-local\n",
      "            variables.\n",
      "        2. Two different templates are guaranteed to be unique, unless you reenter the\n",
      "            same variable scope as the initial definition of a template and redefine\n",
      "            it. An examples of this exception:\n",
      "        \n",
      "        ```python\n",
      "        def my_op(x, scalar_name):\n",
      "          var1 = tf.compat.v1.get_variable(scalar_name,\n",
      "                                 shape=[],\n",
      "                                 initializer=tf.compat.v1.constant_initializer(1))\n",
      "          return x * var1\n",
      "        \n",
      "        with tf.compat.v1.variable_scope('scope') as vs:\n",
      "          scale_by_y = tf.compat.v1.make_template('scale_by_y', my_op,\n",
      "          scalar_name='y')\n",
      "          z = scale_by_y(input1)\n",
      "          w = scale_by_y(input2)\n",
      "        \n",
      "        # Creates a template that reuses the variables above.\n",
      "        with tf.compat.v1.variable_scope(vs, reuse=True):\n",
      "          scale_by_y2 = tf.compat.v1.make_template('scale_by_y', my_op,\n",
      "          scalar_name='y')\n",
      "          z2 = scale_by_y2(input1)\n",
      "          w2 = scale_by_y2(input2)\n",
      "        ```\n",
      "        \n",
      "        Depending on the value of `create_scope_now_`, the full variable scope may be\n",
      "        captured either at the time of first call or at the time of construction. If\n",
      "        this option is set to True, then all Tensors created by repeated calls to the\n",
      "        template will have an extra trailing _N+1 to their name, as the first time the\n",
      "        scope is entered in the Template constructor no Tensors are created.\n",
      "        \n",
      "        Note: `name_`, `func_` and `create_scope_now_` have a trailing underscore to\n",
      "        reduce the likelihood of collisions with kwargs.\n",
      "        \n",
      "        Args:\n",
      "          name_: A name for the scope created by this template. If necessary, the name\n",
      "            will be made unique by appending `_N` to the name.\n",
      "          func_: The function to wrap.\n",
      "          create_scope_now_: Boolean controlling whether the scope should be created\n",
      "            when the template is constructed or when the template is called. Default\n",
      "            is False, meaning the scope is created when the template is called.\n",
      "          unique_name_: When used, it overrides name_ and is not made unique. If a\n",
      "            template of the same scope/unique_name already exists and reuse is false,\n",
      "            an error is raised. Defaults to None.\n",
      "          custom_getter_: Optional custom getter for variables used in `func_`. See\n",
      "            the `tf.compat.v1.get_variable` `custom_getter` documentation for more\n",
      "            information.\n",
      "          **kwargs: Keyword arguments to apply to `func_`.\n",
      "        \n",
      "        Returns:\n",
      "          A function to encapsulate a set of variables which should be created once\n",
      "          and reused. An enclosing scope will be created either when `make_template`\n",
      "          is called or when the result is called, depending on the value of\n",
      "          `create_scope_now_`. Regardless of the value, the first time the template\n",
      "          is called it will enter the scope with no reuse, and call `func_` to create\n",
      "          variables, which are guaranteed to be unique. All subsequent calls will\n",
      "          re-enter the scope and reuse those variables.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: if `name_` is None.\n",
      "    \n",
      "    make_tensor_proto(values, dtype=None, shape=None, verify_shape=False, allow_broadcast=False)\n",
      "        Create a TensorProto.\n",
      "        \n",
      "        In TensorFlow 2.0, representing tensors as protos should no longer be a\n",
      "        common workflow. That said, this utility function is still useful for\n",
      "        generating TF Serving request protos:\n",
      "        \n",
      "          request = tensorflow_serving.apis.predict_pb2.PredictRequest()\n",
      "          request.model_spec.name = \"my_model\"\n",
      "          request.model_spec.signature_name = \"serving_default\"\n",
      "          request.inputs[\"images\"].CopyFrom(tf.make_tensor_proto(X_new))\n",
      "        \n",
      "        make_tensor_proto accepts \"values\" of a python scalar, a python list, a\n",
      "        numpy ndarray, or a numpy scalar.\n",
      "        \n",
      "        If \"values\" is a python scalar or a python list, make_tensor_proto\n",
      "        first convert it to numpy ndarray. If dtype is None, the\n",
      "        conversion tries its best to infer the right numpy data\n",
      "        type. Otherwise, the resulting numpy array has a compatible data\n",
      "        type with the given dtype.\n",
      "        \n",
      "        In either case above, the numpy ndarray (either the caller provided\n",
      "        or the auto converted) must have the compatible type with dtype.\n",
      "        \n",
      "        make_tensor_proto then converts the numpy array to a tensor proto.\n",
      "        \n",
      "        If \"shape\" is None, the resulting tensor proto represents the numpy\n",
      "        array precisely.\n",
      "        \n",
      "        Otherwise, \"shape\" specifies the tensor's shape and the numpy array\n",
      "        can not have more elements than what \"shape\" specifies.\n",
      "        \n",
      "        Args:\n",
      "          values:         Values to put in the TensorProto.\n",
      "          dtype:          Optional tensor_pb2 DataType value.\n",
      "          shape:          List of integers representing the dimensions of tensor.\n",
      "          verify_shape:   Boolean that enables verification of a shape of values.\n",
      "          allow_broadcast:  Boolean that enables allowing scalars and 1 length vector\n",
      "              broadcasting. Cannot be true when verify_shape is true.\n",
      "        \n",
      "        Returns:\n",
      "          A `TensorProto`. Depending on the type, it may contain data in the\n",
      "          \"tensor_content\" attribute, which is not directly useful to Python programs.\n",
      "          To access the values you should convert the proto back to a numpy ndarray\n",
      "          with `tf.make_ndarray(proto)`.\n",
      "        \n",
      "          If `values` is a `TensorProto`, it is immediately returned; `dtype` and\n",
      "          `shape` are ignored.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError:  if unsupported types are provided.\n",
      "          ValueError: if arguments have inappropriate values or if verify_shape is\n",
      "           True and shape of values is not equals to a shape from the argument.\n",
      "    \n",
      "    map_fn(fn, elems, dtype=None, parallel_iterations=None, back_prop=True, swap_memory=False, infer_shape=True, name=None)\n",
      "        map on the list of tensors unpacked from `elems` on dimension 0.\n",
      "        \n",
      "        The simplest version of `map_fn` repeatedly applies the callable `fn` to a\n",
      "        sequence of elements from first to last. The elements are made of the\n",
      "        tensors unpacked from `elems`. `dtype` is the data type of the return\n",
      "        value of `fn`. Users must provide `dtype` if it is different from\n",
      "        the data type of `elems`.\n",
      "        \n",
      "        Suppose that `elems` is unpacked into `values`, a list of tensors. The shape\n",
      "        of the result tensor is `[values.shape[0]] + fn(values[0]).shape`.\n",
      "        \n",
      "        This method also allows multi-arity `elems` and output of `fn`.  If `elems`\n",
      "        is a (possibly nested) list or tuple of tensors, then each of these tensors\n",
      "        must have a matching first (unpack) dimension.  The signature of `fn` may\n",
      "        match the structure of `elems`.  That is, if `elems` is\n",
      "        `(t1, [t2, t3, [t4, t5]])`, then an appropriate signature for `fn` is:\n",
      "        `fn = lambda (t1, [t2, t3, [t4, t5]]):`.\n",
      "        \n",
      "        Furthermore, `fn` may emit a different structure than its input.  For example,\n",
      "        `fn` may look like: `fn = lambda t1: return (t1 + 1, t1 - 1)`.  In this case,\n",
      "        the `dtype` parameter is not optional: `dtype` must be a type or (possibly\n",
      "        nested) tuple of types matching the output of `fn`.\n",
      "        \n",
      "        To apply a functional operation to the nonzero elements of a SparseTensor\n",
      "        one of the following methods is recommended. First, if the function is\n",
      "        expressible as TensorFlow ops, use\n",
      "        \n",
      "        ```python\n",
      "          result = SparseTensor(input.indices, fn(input.values), input.dense_shape)\n",
      "        ```\n",
      "        \n",
      "        If, however, the function is not expressible as a TensorFlow op, then use\n",
      "        \n",
      "        ```python\n",
      "        result = SparseTensor(\n",
      "          input.indices, map_fn(fn, input.values), input.dense_shape)\n",
      "        ```\n",
      "        \n",
      "        instead.\n",
      "        \n",
      "        When executing eagerly, map_fn does not execute in parallel even if\n",
      "        `parallel_iterations` is set to a value > 1. You can still get the\n",
      "        performance benefits of running a function in parallel by using the\n",
      "        `tf.contrib.eager.defun` decorator,\n",
      "        \n",
      "        ```python\n",
      "        # Assume the function being used in map_fn is fn.\n",
      "        # To ensure map_fn calls fn in parallel, use the defun decorator.\n",
      "        @tf.contrib.eager.defun\n",
      "        def func(tensor):\n",
      "          return tf.map_fn(fn, tensor)\n",
      "        ```\n",
      "        \n",
      "        Note that if you use the defun decorator, any non-TensorFlow Python code\n",
      "        that you may have written in your function won't get executed. See\n",
      "        `tf.contrib.eager.defun` for more details. The recommendation would be to\n",
      "        debug without defun but switch to defun to get performance benefits of\n",
      "        running map_fn in parallel.\n",
      "        \n",
      "        Args:\n",
      "          fn: The callable to be performed.  It accepts one argument, which will\n",
      "            have the same (possibly nested) structure as `elems`.  Its output\n",
      "            must have the same structure as `dtype` if one is provided, otherwise\n",
      "            it must have the same structure as `elems`.\n",
      "          elems: A tensor or (possibly nested) sequence of tensors, each of which\n",
      "            will be unpacked along their first dimension.  The nested sequence\n",
      "            of the resulting slices will be applied to `fn`.\n",
      "          dtype: (optional) The output type(s) of `fn`.  If `fn` returns a structure\n",
      "            of Tensors differing from the structure of `elems`, then `dtype` is not\n",
      "            optional and must have the same structure as the output of `fn`.\n",
      "          parallel_iterations: (optional) The number of iterations allowed to run\n",
      "            in parallel. When graph building, the default value is 10. While executing\n",
      "            eagerly, the default value is set to 1.\n",
      "          back_prop: (optional) True enables support for back propagation.\n",
      "          swap_memory: (optional) True enables GPU-CPU memory swapping.\n",
      "          infer_shape: (optional) False disables tests for consistent output shapes.\n",
      "          name: (optional) Name prefix for the returned tensors.\n",
      "        \n",
      "        Returns:\n",
      "          A tensor or (possibly nested) sequence of tensors.  Each tensor packs the\n",
      "          results of applying `fn` to tensors unpacked from `elems` along the first\n",
      "          dimension, from first to last.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: if `fn` is not callable or the structure of the output of\n",
      "            `fn` and `dtype` do not match, or if elems is a SparseTensor.\n",
      "          ValueError: if the lengths of the output of `fn` and `dtype` do not match.\n",
      "        \n",
      "        Examples:\n",
      "          ```python\n",
      "          elems = np.array([1, 2, 3, 4, 5, 6])\n",
      "          squares = map_fn(lambda x: x * x, elems)\n",
      "          # squares == [1, 4, 9, 16, 25, 36]\n",
      "          ```\n",
      "        \n",
      "          ```python\n",
      "          elems = (np.array([1, 2, 3]), np.array([-1, 1, -1]))\n",
      "          alternate = map_fn(lambda x: x[0] * x[1], elems, dtype=tf.int64)\n",
      "          # alternate == [-1, 2, -3]\n",
      "          ```\n",
      "        \n",
      "          ```python\n",
      "          elems = np.array([1, 2, 3])\n",
      "          alternates = map_fn(lambda x: (x, -x), elems, dtype=(tf.int64, tf.int64))\n",
      "          # alternates[0] == [1, 2, 3]\n",
      "          # alternates[1] == [-1, -2, -3]\n",
      "          ```\n",
      "    \n",
      "    matching_files(pattern, name=None)\n",
      "        Returns the set of files matching one or more glob patterns.\n",
      "        \n",
      "        Note that this routine only supports wildcard characters in the\n",
      "        basename portion of the pattern, not in the directory portion.\n",
      "        Note also that the order of filenames returned is deterministic.\n",
      "        \n",
      "        Args:\n",
      "          pattern: A `Tensor` of type `string`.\n",
      "            Shell wildcard pattern(s). Scalar or vector of type string.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `string`.\n",
      "    \n",
      "    matmul(a, b, transpose_a=False, transpose_b=False, adjoint_a=False, adjoint_b=False, a_is_sparse=False, b_is_sparse=False, name=None)\n",
      "        Multiplies matrix `a` by matrix `b`, producing `a` * `b`.\n",
      "        \n",
      "        The inputs must, following any transpositions, be tensors of rank >= 2\n",
      "        where the inner 2 dimensions specify valid matrix multiplication arguments,\n",
      "        and any further outer dimensions match.\n",
      "        \n",
      "        Both matrices must be of the same type. The supported types are:\n",
      "        `float16`, `float32`, `float64`, `int32`, `complex64`, `complex128`.\n",
      "        \n",
      "        Either matrix can be transposed or adjointed (conjugated and transposed) on\n",
      "        the fly by setting one of the corresponding flag to `True`. These are `False`\n",
      "        by default.\n",
      "        \n",
      "        If one or both of the matrices contain a lot of zeros, a more efficient\n",
      "        multiplication algorithm can be used by setting the corresponding\n",
      "        `a_is_sparse` or `b_is_sparse` flag to `True`. These are `False` by default.\n",
      "        This optimization is only available for plain matrices (rank-2 tensors) with\n",
      "        datatypes `bfloat16` or `float32`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        # 2-D tensor `a`\n",
      "        # [[1, 2, 3],\n",
      "        #  [4, 5, 6]]\n",
      "        a = tf.constant([1, 2, 3, 4, 5, 6], shape=[2, 3])\n",
      "        \n",
      "        # 2-D tensor `b`\n",
      "        # [[ 7,  8],\n",
      "        #  [ 9, 10],\n",
      "        #  [11, 12]]\n",
      "        b = tf.constant([7, 8, 9, 10, 11, 12], shape=[3, 2])\n",
      "        \n",
      "        # `a` * `b`\n",
      "        # [[ 58,  64],\n",
      "        #  [139, 154]]\n",
      "        c = tf.matmul(a, b)\n",
      "        \n",
      "        \n",
      "        # 3-D tensor `a`\n",
      "        # [[[ 1,  2,  3],\n",
      "        #   [ 4,  5,  6]],\n",
      "        #  [[ 7,  8,  9],\n",
      "        #   [10, 11, 12]]]\n",
      "        a = tf.constant(np.arange(1, 13, dtype=np.int32),\n",
      "                        shape=[2, 2, 3])\n",
      "        \n",
      "        # 3-D tensor `b`\n",
      "        # [[[13, 14],\n",
      "        #   [15, 16],\n",
      "        #   [17, 18]],\n",
      "        #  [[19, 20],\n",
      "        #   [21, 22],\n",
      "        #   [23, 24]]]\n",
      "        b = tf.constant(np.arange(13, 25, dtype=np.int32),\n",
      "                        shape=[2, 3, 2])\n",
      "        \n",
      "        # `a` * `b`\n",
      "        # [[[ 94, 100],\n",
      "        #   [229, 244]],\n",
      "        #  [[508, 532],\n",
      "        #   [697, 730]]]\n",
      "        c = tf.matmul(a, b)\n",
      "        \n",
      "        # Since python >= 3.5 the @ operator is supported (see PEP 465).\n",
      "        # In TensorFlow, it simply calls the `tf.matmul()` function, so the\n",
      "        # following lines are equivalent:\n",
      "        d = a @ b @ [[10.], [11.]]\n",
      "        d = tf.matmul(tf.matmul(a, b), [[10.], [11.]])\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          a: `Tensor` of type `float16`, `float32`, `float64`, `int32`, `complex64`,\n",
      "            `complex128` and rank > 1.\n",
      "          b: `Tensor` with same type and rank as `a`.\n",
      "          transpose_a: If `True`, `a` is transposed before multiplication.\n",
      "          transpose_b: If `True`, `b` is transposed before multiplication.\n",
      "          adjoint_a: If `True`, `a` is conjugated and transposed before\n",
      "            multiplication.\n",
      "          adjoint_b: If `True`, `b` is conjugated and transposed before\n",
      "            multiplication.\n",
      "          a_is_sparse: If `True`, `a` is treated as a sparse matrix.\n",
      "          b_is_sparse: If `True`, `b` is treated as a sparse matrix.\n",
      "          name: Name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of the same type as `a` and `b` where each inner-most matrix is\n",
      "          the product of the corresponding matrices in `a` and `b`, e.g. if all\n",
      "          transpose or adjoint attributes are `False`:\n",
      "        \n",
      "          `output`[..., i, j] = sum_k (`a`[..., i, k] * `b`[..., k, j]),\n",
      "          for all indices i, j.\n",
      "        \n",
      "          Note: This is matrix product, not element-wise product.\n",
      "        \n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If transpose_a and adjoint_a, or transpose_b and adjoint_b\n",
      "            are both set to True.\n",
      "    \n",
      "    matrix_band_part(input, num_lower, num_upper, name=None)\n",
      "        Copy a tensor setting everything outside a central band in each innermost matrix\n",
      "        \n",
      "        to zero.\n",
      "        \n",
      "        The `band` part is computed as follows:\n",
      "        Assume `input` has `k` dimensions `[I, J, K, ..., M, N]`, then the output is a\n",
      "        tensor with the same shape where\n",
      "        \n",
      "        `band[i, j, k, ..., m, n] = in_band(m, n) * input[i, j, k, ..., m, n]`.\n",
      "        \n",
      "        The indicator function\n",
      "        \n",
      "        `in_band(m, n) = (num_lower < 0 || (m-n) <= num_lower)) &&\n",
      "                         (num_upper < 0 || (n-m) <= num_upper)`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```\n",
      "        # if 'input' is [[ 0,  1,  2, 3]\n",
      "                         [-1,  0,  1, 2]\n",
      "                         [-2, -1,  0, 1]\n",
      "                         [-3, -2, -1, 0]],\n",
      "        \n",
      "        tf.matrix_band_part(input, 1, -1) ==> [[ 0,  1,  2, 3]\n",
      "                                               [-1,  0,  1, 2]\n",
      "                                               [ 0, -1,  0, 1]\n",
      "                                               [ 0,  0, -1, 0]],\n",
      "        \n",
      "        tf.matrix_band_part(input, 2, 1) ==> [[ 0,  1,  0, 0]\n",
      "                                              [-1,  0,  1, 0]\n",
      "                                              [-2, -1,  0, 1]\n",
      "                                              [ 0, -2, -1, 0]]\n",
      "        ```\n",
      "        \n",
      "        Useful special cases:\n",
      "        \n",
      "        ```\n",
      "         tf.matrix_band_part(input, 0, -1) ==> Upper triangular part.\n",
      "         tf.matrix_band_part(input, -1, 0) ==> Lower triangular part.\n",
      "         tf.matrix_band_part(input, 0, 0) ==> Diagonal.\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Rank `k` tensor.\n",
      "          num_lower: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            0-D tensor. Number of subdiagonals to keep. If negative, keep entire\n",
      "            lower triangle.\n",
      "          num_upper: A `Tensor`. Must have the same type as `num_lower`.\n",
      "            0-D tensor. Number of superdiagonals to keep. If negative, keep\n",
      "            entire upper triangle.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    matrix_determinant(input, name=None)\n",
      "        Computes the determinant of one or more square matrices.\n",
      "        \n",
      "        The input is a tensor of shape `[..., M, M]` whose inner-most 2 dimensions\n",
      "        form square matrices. The output is a tensor containing the determinants\n",
      "        for all input submatrices `[..., :, :]`.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `half`, `float32`, `float64`, `complex64`, `complex128`.\n",
      "            Shape is `[..., M, M]`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    matrix_diag(diagonal, name='diag', k=0, num_rows=-1, num_cols=-1, padding_value=0)\n",
      "        Returns a batched diagonal tensor with given batched diagonal values.\n",
      "        \n",
      "        Returns a tensor with the contents in `diagonal` as `k[0]`-th to `k[1]`-th\n",
      "        diagonals of a matrix, with everything else padded with `padding`. `num_rows`\n",
      "        and `num_cols` specify the dimension of the innermost matrix of the output. If\n",
      "        both are not specified, the op assumes the innermost matrix is square and\n",
      "        infers its size from `k` and the innermost dimension of `diagonal`. If only\n",
      "        one of them is specified, the op assumes the unspecified value is the smallest\n",
      "        possible based on other criteria.\n",
      "        \n",
      "        Let `diagonal` have `r` dimensions `[I, J, ..., L, M, N]`. The output tensor\n",
      "        has rank `r+1` with shape `[I, J, ..., L, M, num_rows, num_cols]` when only\n",
      "        one diagonal is given (`k` is an integer or `k[0] == k[1]`). Otherwise, it has\n",
      "        rank `r` with shape `[I, J, ..., L, num_rows, num_cols]`.\n",
      "        \n",
      "        The second innermost dimension of `diagonal` has double meaning. When `k` is\n",
      "        scalar or `k[0] == k[1]`, `M` is part of the batch size [I, J, ..., M], and\n",
      "        the output tensor is:\n",
      "        \n",
      "        ```\n",
      "        output[i, j, ..., l, m, n]\n",
      "          = diagonal[i, j, ..., l, n-max(d_upper, 0)] ; if n - m == d_upper\n",
      "            output[i, j, ..., l, m, n]                ; otherwise\n",
      "        ```\n",
      "        \n",
      "        Otherwise, `M` is treated as the number of diagonals for the matrix in the\n",
      "        same batch (`M = k[1]-k[0]+1`), and the output tensor is:\n",
      "        \n",
      "        ```\n",
      "        output[i, j, ..., l, m, n]\n",
      "          = diagonal[i, j, ..., l, k[1]-d, n-max(d, 0)] ; if d_lower <= d <= d_upper\n",
      "            input[i, j, ..., l, m, n]                   ; otherwise\n",
      "        ```\n",
      "        where `d = n - m`\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```\n",
      "        # The main diagonal.\n",
      "        diagonal = np.array([[1, 2, 3, 4],            # Input shape: (2, 4)\n",
      "                             [5, 6, 7, 8]])\n",
      "        tf.matrix_diag(diagonal) ==> [[[1, 0, 0, 0],  # Output shape: (2, 4, 4)\n",
      "                                       [0, 2, 0, 0],\n",
      "                                       [0, 0, 3, 0],\n",
      "                                       [0, 0, 0, 4]],\n",
      "                                      [[5, 0, 0, 0],\n",
      "                                       [0, 6, 0, 0],\n",
      "                                       [0, 0, 7, 0],\n",
      "                                       [0, 0, 0, 8]]]\n",
      "        \n",
      "        # A superdiagonal (per batch).\n",
      "        diagonal = np.array([[1, 2, 3],  # Input shape: (2, 3)\n",
      "                             [4, 5, 6]])\n",
      "        tf.matrix_diag(diagonal, k = 1)\n",
      "          ==> [[[0, 1, 0, 0],  # Output shape: (2, 4, 4)\n",
      "                [0, 0, 2, 0],\n",
      "                [0, 0, 0, 3],\n",
      "                [0, 0, 0, 0]],\n",
      "               [[0, 4, 0, 0],\n",
      "                [0, 0, 5, 0],\n",
      "                [0, 0, 0, 6],\n",
      "                [0, 0, 0, 0]]]\n",
      "        \n",
      "        # A band of diagonals.\n",
      "        diagonals = np.array([[[1, 2, 3],  # Input shape: (2, 2, 3)\n",
      "                               [4, 5, 0]],\n",
      "                              [[6, 7, 9],\n",
      "                               [9, 1, 0]]])\n",
      "        tf.matrix_diag(diagonals, k = (-1, 0))\n",
      "          ==> [[[1, 0, 0],  # Output shape: (2, 3, 3)\n",
      "                [4, 2, 0],\n",
      "                [0, 5, 3]],\n",
      "               [[6, 0, 0],\n",
      "                [9, 7, 0],\n",
      "                [0, 1, 9]]]\n",
      "        \n",
      "        # Rectangular matrix.\n",
      "        diagonal = np.array([1, 2])  # Input shape: (2)\n",
      "        tf.matrix_diag(diagonal, k = -1, num_rows = 3, num_cols = 4)\n",
      "          ==> [[0, 0, 0, 0],  # Output shape: (3, 4)\n",
      "               [1, 0, 0, 0],\n",
      "               [0, 2, 0, 0]]\n",
      "        \n",
      "        # Rectangular matrix with inferred num_cols and padding = 9.\n",
      "        tf.matrix_diag(diagonal, k = -1, num_rows = 3, padding = 9)\n",
      "          ==> [[9, 9],  # Output shape: (3, 2)\n",
      "               [1, 9],\n",
      "               [9, 2]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          diagonal: A `Tensor` with `rank k >= 1`.\n",
      "          name: A name for the operation (optional).\n",
      "          k: Diagonal offset(s). Positive value means superdiagonal, 0 refers to the\n",
      "            main diagonal, and negative value means subdiagonals. `k` can be a single\n",
      "            integer (for a single diagonal) or a pair of integers specifying the low\n",
      "            and high ends of a matrix band. `k[0]` must not be larger than `k[1]`.\n",
      "          num_rows: The number of rows of the output matrix. If it is not provided,\n",
      "            the op assumes the output matrix is a square matrix and infers the matrix\n",
      "            size from `d_lower`, `d_upper`, and the innermost dimension of `diagonal`.\n",
      "          num_cols: The number of columns of the output matrix. If it is not provided,\n",
      "            the op assumes the output matrix is a square matrix and infers the matrix\n",
      "            size from `d_lower`, `d_upper`, and the innermost dimension of `diagonal`.\n",
      "          padding_value: The value to fill the area outside the specified diagonal\n",
      "            band with. Default is 0.\n",
      "        \n",
      "        Returns:\n",
      "          A Tensor. Has the same type as `diagonal`.\n",
      "    \n",
      "    matrix_diag_part(input, name='diag_part', k=0, padding_value=0)\n",
      "        Returns the batched diagonal part of a batched tensor.\n",
      "        \n",
      "        Returns a tensor with the `k[0]`-th to `k[1]`-th diagonals of the batched\n",
      "        `input`.\n",
      "        \n",
      "        Assume `input` has `r` dimensions `[I, J, ..., L, M, N]`.\n",
      "        Let `max_diag_len` be the maximum length among all diagonals to be extracted,\n",
      "        `max_diag_len = min(M + min(k[1], 0), N + min(-k[0], 0))`\n",
      "        Let `num_diags` be the number of diagonals to extract,\n",
      "        `num_diags = k[1] - k[0] + 1`.\n",
      "        \n",
      "        If `num_diags == 1`, the output tensor is of rank `r - 1` with shape\n",
      "        `[I, J, ..., L, max_diag_len]` and values:\n",
      "        \n",
      "        ```\n",
      "        diagonal[i, j, ..., l, n]\n",
      "          = input[i, j, ..., l, n+y, n+x] ; when 0 <= n-y < M and 0 <= n-x < N,\n",
      "            0                             ; otherwise.\n",
      "        ```\n",
      "        where `y = max(-k[1], 0)`, `x = max(k[1], 0)`.\n",
      "        \n",
      "        Otherwise, the output tensor has rank `r` with dimensions\n",
      "        `[I, J, ..., L, num_diags, max_diag_len]` with values:\n",
      "        \n",
      "        ```\n",
      "        diagonal[i, j, ..., l, m, n]\n",
      "          = input[i, j, ..., l, n+y, n+x] ; when 0 <= n-y < M and 0 <= n-x < N,\n",
      "            0                             ; otherwise.\n",
      "        ```\n",
      "        where `d = k[1] - m`, `y = max(-d, 0)`, and `x = max(d, 0)`.\n",
      "        \n",
      "        The input must be at least a matrix.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```\n",
      "        input = np.array([[[1, 2, 3, 4],  # Input shape: (2, 3, 4)\n",
      "                           [5, 6, 7, 8],\n",
      "                           [9, 8, 7, 6]],\n",
      "                          [[5, 4, 3, 2],\n",
      "                           [1, 2, 3, 4],\n",
      "                           [5, 6, 7, 8]]])\n",
      "        \n",
      "        # A main diagonal from each batch.\n",
      "        tf.matrix_diag_part(input) ==> [[1, 6, 7],  # Output shape: (2, 3)\n",
      "                                        [5, 2, 7]]\n",
      "        \n",
      "        # A superdiagonal from each batch.\n",
      "        tf.matrix_diag_part(input, k = 1)\n",
      "          ==> [[2, 7, 6],  # Output shape: (2, 3)\n",
      "               [4, 3, 8]]\n",
      "        \n",
      "        # A tridiagonal band from each batch.\n",
      "        tf.matrix_diag_part(input, k = (-1, 1))\n",
      "          ==> [[[2, 7, 6],  # Output shape: (2, 3, 3)\n",
      "                [1, 6, 7],\n",
      "                [5, 8, 0]],\n",
      "               [[4, 3, 8],\n",
      "                [5, 2, 7],\n",
      "                [1, 6, 0]]]\n",
      "        \n",
      "        # Padding = 9\n",
      "        tf.matrix_diag_part(input, k = (1, 3), padding = 9)\n",
      "          ==> [[[4, 9, 9],  # Output shape: (2, 3, 3)\n",
      "                [3, 8, 9],\n",
      "                [2, 7, 6]],\n",
      "               [[2, 9, 9],\n",
      "                [3, 4, 9],\n",
      "                [4, 3, 8]]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor` with `rank k >= 2`.\n",
      "          name: A name for the operation (optional).\n",
      "          k: Diagonal offset(s). Positive value means superdiagonal, 0 refers to the\n",
      "            main diagonal, and negative value means subdiagonals. `k` can be a single\n",
      "            integer (for a single diagonal) or a pair of integers specifying the low\n",
      "            and high ends of a matrix band. `k[0]` must not be larger than `k[1]`.\n",
      "          padding_value: The value to fill the area outside the specified diagonal\n",
      "            band with. Default is 0.\n",
      "        \n",
      "        Returns:\n",
      "          A Tensor containing diagonals of `input`. Has the same type as `input`.\n",
      "    \n",
      "    matrix_inverse(input, adjoint=False, name=None)\n",
      "        Computes the inverse of one or more square invertible matrices or their\n",
      "        \n",
      "        adjoints (conjugate transposes).\n",
      "        \n",
      "        The input is a tensor of shape `[..., M, M]` whose inner-most 2 dimensions\n",
      "        form square matrices. The output is a tensor of the same shape as the input\n",
      "        containing the inverse for all input submatrices `[..., :, :]`.\n",
      "        \n",
      "        The op uses LU decomposition with partial pivoting to compute the inverses.\n",
      "        \n",
      "        If a matrix is not invertible there is no guarantee what the op does. It\n",
      "        may detect the condition and raise an exception or it may simply return a\n",
      "        garbage result.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `float64`, `float32`, `half`, `complex64`, `complex128`.\n",
      "            Shape is `[..., M, M]`.\n",
      "          adjoint: An optional `bool`. Defaults to `False`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    matrix_set_diag(input, diagonal, name='set_diag', k=0)\n",
      "        Returns a batched matrix tensor with new batched diagonal values.\n",
      "        \n",
      "        Given `input` and `diagonal`, this operation returns a tensor with the\n",
      "        same shape and values as `input`, except for the specified diagonals of the\n",
      "        innermost matrices. These will be overwritten by the values in `diagonal`.\n",
      "        \n",
      "        `input` has `r+1` dimensions `[I, J, ..., L, M, N]`. When `k` is scalar or\n",
      "        `k[0] == k[1]`, `diagonal` has `r` dimensions `[I, J, ..., L, max_diag_len]`.\n",
      "        Otherwise, it has `r+1` dimensions `[I, J, ..., L, num_diags, max_diag_len]`.\n",
      "        `num_diags` is the number of diagonals, `num_diags = k[1] - k[0] + 1`.\n",
      "        `max_diag_len` is the longest diagonal in the range `[k[0], k[1]]`,\n",
      "        `max_diag_len = min(M + min(k[1], 0), N + min(-k[0], 0))`\n",
      "        \n",
      "        The output is a tensor of rank `k+1` with dimensions `[I, J, ..., L, M, N]`.\n",
      "        If `k` is scalar or `k[0] == k[1]`:\n",
      "        \n",
      "        ```\n",
      "        output[i, j, ..., l, m, n]\n",
      "          = diagonal[i, j, ..., l, n-max(k[1], 0)] ; if n - m == k[1]\n",
      "            output[i, j, ..., l, m, n]             ; otherwise\n",
      "        ```\n",
      "        \n",
      "        Otherwise,\n",
      "        \n",
      "        ```\n",
      "        output[i, j, ..., l, m, n]\n",
      "          = diagonal[i, j, ..., l, k[1]-d, n-max(d, 0)] ; if d_lower <= d <= d_upper\n",
      "            input[i, j, ..., l, m, n]                   ; otherwise\n",
      "        ```\n",
      "        where `d = n - m`\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```\n",
      "        # The main diagonal.\n",
      "        input = np.array([[[7, 7, 7, 7],              # Input shape: (2, 3, 4)\n",
      "                           [7, 7, 7, 7],\n",
      "                           [7, 7, 7, 7]],\n",
      "                          [[7, 7, 7, 7],\n",
      "                           [7, 7, 7, 7],\n",
      "                           [7, 7, 7, 7]]])\n",
      "        diagonal = np.array([[1, 2, 3],               # Diagonal shape: (2, 3)\n",
      "                             [4, 5, 6]])\n",
      "        tf.matrix_diag(diagonal) ==> [[[1, 7, 7, 7],  # Output shape: (2, 3, 4)\n",
      "                                       [7, 2, 7, 7],\n",
      "                                       [7, 7, 3, 7]],\n",
      "                                      [[4, 7, 7, 7],\n",
      "                                       [7, 5, 7, 7],\n",
      "                                       [7, 7, 6, 7]]]\n",
      "        \n",
      "        # A superdiagonal (per batch).\n",
      "        tf.matrix_diag(diagonal, k = 1)\n",
      "          ==> [[[7, 1, 7, 7],  # Output shape: (2, 3, 4)\n",
      "                [7, 7, 2, 7],\n",
      "                [7, 7, 7, 3]],\n",
      "               [[7, 4, 7, 7],\n",
      "                [7, 7, 5, 7],\n",
      "                [7, 7, 7, 6]]]\n",
      "        \n",
      "        # A band of diagonals.\n",
      "        diagonals = np.array([[[1, 2, 3],  # Diagonal shape: (2, 2, 3)\n",
      "                               [4, 5, 0]],\n",
      "                              [[6, 1, 2],\n",
      "                               [3, 4, 0]]])\n",
      "        tf.matrix_diag(diagonals, k = (-1, 0))\n",
      "          ==> [[[1, 7, 7, 7],  # Output shape: (2, 3, 4)\n",
      "                [4, 2, 7, 7],\n",
      "                [0, 5, 3, 7]],\n",
      "               [[6, 7, 7, 7],\n",
      "                [3, 1, 7, 7],\n",
      "                [7, 4, 2, 7]]]\n",
      "        \n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor` with rank `k + 1`, where `k >= 1`.\n",
      "          diagonal:  A `Tensor` with rank `k`, when `d_lower == d_upper`, or `k + 1`,\n",
      "            otherwise. `k >= 1`.\n",
      "          name: A name for the operation (optional).\n",
      "          k: Diagonal offset(s). Positive value means superdiagonal, 0 refers to the\n",
      "            main diagonal, and negative value means subdiagonals. `k` can be a single\n",
      "            integer (for a single diagonal) or a pair of integers specifying the low\n",
      "            and high ends of a matrix band. `k[0]` must not be larger than `k[1]`.\n",
      "    \n",
      "    matrix_solve(matrix, rhs, adjoint=False, name=None)\n",
      "        Solves systems of linear equations.\n",
      "        \n",
      "        `Matrix` is a tensor of shape `[..., M, M]` whose inner-most 2 dimensions\n",
      "        form square matrices. `Rhs` is a tensor of shape `[..., M, K]`. The `output` is\n",
      "        a tensor shape `[..., M, K]`.  If `adjoint` is `False` then each output matrix\n",
      "        satisfies `matrix[..., :, :] * output[..., :, :] = rhs[..., :, :]`.\n",
      "        If `adjoint` is `True` then each output matrix satisfies\n",
      "        `adjoint(matrix[..., :, :]) * output[..., :, :] = rhs[..., :, :]`.\n",
      "        \n",
      "        Args:\n",
      "          matrix: A `Tensor`. Must be one of the following types: `float64`, `float32`, `half`, `complex64`, `complex128`.\n",
      "            Shape is `[..., M, M]`.\n",
      "          rhs: A `Tensor`. Must have the same type as `matrix`.\n",
      "            Shape is `[..., M, K]`.\n",
      "          adjoint: An optional `bool`. Defaults to `False`.\n",
      "            Boolean indicating whether to solve with `matrix` or its (block-wise)\n",
      "            adjoint.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `matrix`.\n",
      "    \n",
      "    matrix_solve_ls(matrix, rhs, l2_regularizer=0.0, fast=True, name=None)\n",
      "        Solves one or more linear least-squares problems.\n",
      "        \n",
      "        `matrix` is a tensor of shape `[..., M, N]` whose inner-most 2 dimensions\n",
      "        form `M`-by-`N` matrices. Rhs is a tensor of shape `[..., M, K]` whose\n",
      "        inner-most 2 dimensions form `M`-by-`K` matrices.  The computed output is a\n",
      "        `Tensor` of shape `[..., N, K]` whose inner-most 2 dimensions form `M`-by-`K`\n",
      "        matrices that solve the equations\n",
      "        `matrix[..., :, :] * output[..., :, :] = rhs[..., :, :]` in the least squares\n",
      "        sense.\n",
      "        \n",
      "        Below we will use the following notation for each pair of matrix and\n",
      "        right-hand sides in the batch:\n",
      "        \n",
      "        `matrix`=\\\\(A \\in \\Re^{m \\times n}\\\\),\n",
      "        `rhs`=\\\\(B  \\in \\Re^{m \\times k}\\\\),\n",
      "        `output`=\\\\(X  \\in \\Re^{n \\times k}\\\\),\n",
      "        `l2_regularizer`=\\\\(\\lambda\\\\).\n",
      "        \n",
      "        If `fast` is `True`, then the solution is computed by solving the normal\n",
      "        equations using Cholesky decomposition. Specifically, if \\\\(m \\ge n\\\\) then\n",
      "        \\\\(X = (A^T A + \\lambda I)^{-1} A^T B\\\\), which solves the least-squares\n",
      "        problem \\\\(X = \\mathrm{argmin}_{Z \\in \\Re^{n \\times k}} ||A Z - B||_F^2 +\n",
      "        \\lambda ||Z||_F^2\\\\). If \\\\(m \\lt n\\\\) then `output` is computed as\n",
      "        \\\\(X = A^T (A A^T + \\lambda I)^{-1} B\\\\), which (for \\\\(\\lambda = 0\\\\)) is\n",
      "        the minimum-norm solution to the under-determined linear system, i.e.\n",
      "        \\\\(X = \\mathrm{argmin}_{Z \\in \\Re^{n \\times k}} ||Z||_F^2 \\\\), subject to\n",
      "        \\\\(A Z = B\\\\). Notice that the fast path is only numerically stable when\n",
      "        \\\\(A\\\\) is numerically full rank and has a condition number\n",
      "        \\\\(\\mathrm{cond}(A) \\lt \\frac{1}{\\sqrt{\\epsilon_{mach}}}\\\\) or\\\\(\\lambda\\\\)\n",
      "        is sufficiently large.\n",
      "        \n",
      "        If `fast` is `False` an algorithm based on the numerically robust complete\n",
      "        orthogonal decomposition is used. This computes the minimum-norm\n",
      "        least-squares solution, even when \\\\(A\\\\) is rank deficient. This path is\n",
      "        typically 6-7 times slower than the fast path. If `fast` is `False` then\n",
      "        `l2_regularizer` is ignored.\n",
      "        \n",
      "        Args:\n",
      "          matrix: `Tensor` of shape `[..., M, N]`.\n",
      "          rhs: `Tensor` of shape `[..., M, K]`.\n",
      "          l2_regularizer: 0-D `double` `Tensor`. Ignored if `fast=False`.\n",
      "          fast: bool. Defaults to `True`.\n",
      "          name: string, optional name of the operation.\n",
      "        \n",
      "        Returns:\n",
      "          output: `Tensor` of shape `[..., N, K]` whose inner-most 2 dimensions form\n",
      "            `M`-by-`K` matrices that solve the equations\n",
      "            `matrix[..., :, :] * output[..., :, :] = rhs[..., :, :]` in the least\n",
      "            squares sense.\n",
      "        \n",
      "        Raises:\n",
      "          NotImplementedError: linalg.lstsq is currently disabled for complex128\n",
      "          and l2_regularizer != 0 due to poor accuracy.\n",
      "    \n",
      "    matrix_square_root(input, name=None)\n",
      "        Computes the matrix square root of one or more square matrices:\n",
      "        \n",
      "        matmul(sqrtm(A), sqrtm(A)) = A\n",
      "        \n",
      "        The input matrix should be invertible. If the input matrix is real, it should\n",
      "        have no eigenvalues which are real and negative (pairs of complex conjugate\n",
      "        eigenvalues are allowed).\n",
      "        \n",
      "        The matrix square root is computed by first reducing the matrix to \n",
      "        quasi-triangular form with the real Schur decomposition. The square root \n",
      "        of the quasi-triangular matrix is then computed directly. Details of \n",
      "        the algorithm can be found in: Nicholas J. Higham, \"Computing real \n",
      "        square roots of a real matrix\", Linear Algebra Appl., 1987.\n",
      "        \n",
      "        The input is a tensor of shape `[..., M, M]` whose inner-most 2 dimensions\n",
      "        form square matrices. The output is a tensor of the same shape as the input\n",
      "        containing the matrix square root for all input submatrices `[..., :, :]`.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `float64`, `float32`, `half`, `complex64`, `complex128`.\n",
      "            Shape is `[..., M, M]`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    matrix_transpose(a, name='matrix_transpose', conjugate=False)\n",
      "        Transposes last two dimensions of tensor `a`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
      "        tf.linalg.matrix_transpose(x)  # [[1, 4],\n",
      "                                       #  [2, 5],\n",
      "                                       #  [3, 6]]\n",
      "        \n",
      "        x = tf.constant([[1 + 1j, 2 + 2j, 3 + 3j],\n",
      "                         [4 + 4j, 5 + 5j, 6 + 6j]])\n",
      "        tf.linalg.matrix_transpose(x, conjugate=True)  # [[1 - 1j, 4 - 4j],\n",
      "                                                       #  [2 - 2j, 5 - 5j],\n",
      "                                                       #  [3 - 3j, 6 - 6j]]\n",
      "        \n",
      "        # Matrix with two batch dimensions.\n",
      "        # x.shape is [1, 2, 3, 4]\n",
      "        # tf.linalg.matrix_transpose(x) is shape [1, 2, 4, 3]\n",
      "        ```\n",
      "        \n",
      "        Note that `tf.matmul` provides kwargs allowing for transpose of arguments.\n",
      "        This is done with minimal cost, and is preferable to using this function. E.g.\n",
      "        \n",
      "        ```python\n",
      "        # Good!  Transpose is taken at minimal additional cost.\n",
      "        tf.matmul(matrix, b, transpose_b=True)\n",
      "        \n",
      "        # Inefficient!\n",
      "        tf.matmul(matrix, tf.linalg.matrix_transpose(b))\n",
      "        ```\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        In `numpy` transposes are memory-efficient constant time operations as they\n",
      "        simply return a new view of the same data with adjusted `strides`.\n",
      "        \n",
      "        TensorFlow does not support strides, `linalg.matrix_transpose` returns a new\n",
      "        tensor with the items permuted.\n",
      "        @end_compatibility\n",
      "        \n",
      "        Args:\n",
      "          a: A `Tensor` with `rank >= 2`.\n",
      "          name: A name for the operation (optional).\n",
      "          conjugate: Optional bool. Setting it to `True` is mathematically equivalent\n",
      "            to tf.math.conj(tf.linalg.matrix_transpose(input)).\n",
      "        \n",
      "        Returns:\n",
      "          A transposed batch matrix `Tensor`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError:  If `a` is determined statically to have `rank < 2`.\n",
      "    \n",
      "    matrix_triangular_solve(matrix, rhs, lower=True, adjoint=False, name=None)\n",
      "        Solves systems of linear equations with upper or lower triangular matrices by backsubstitution.\n",
      "        \n",
      "        \n",
      "        `matrix` is a tensor of shape `[..., M, M]` whose inner-most 2 dimensions form\n",
      "        square matrices. If `lower` is `True` then the strictly upper triangular part\n",
      "        of each inner-most matrix is assumed to be zero and not accessed.\n",
      "        If `lower` is False then the strictly lower triangular part of each inner-most\n",
      "        matrix is assumed to be zero and not accessed.\n",
      "        `rhs` is a tensor of shape `[..., M, K]`.\n",
      "        \n",
      "        The output is a tensor of shape `[..., M, K]`. If `adjoint` is\n",
      "        `True` then the innermost matrices in `output` satisfy matrix equations\n",
      "        `matrix[..., :, :] * output[..., :, :] = rhs[..., :, :]`.\n",
      "        If `adjoint` is `False` then the strictly then the  innermost matrices in\n",
      "        `output` satisfy matrix equations\n",
      "        `adjoint(matrix[..., i, k]) * output[..., k, j] = rhs[..., i, j]`.\n",
      "        \n",
      "        Example:\n",
      "        ```python\n",
      "        \n",
      "        a = tf.constant([[3,  0,  0,  0],\n",
      "                         [2,  1,  0,  0],\n",
      "                         [1,  0,  1,  0],\n",
      "                         [1,  1,  1,  1]], dtype=tf.float32)\n",
      "        \n",
      "        b = tf.constant([[4],\n",
      "                         [2],\n",
      "                         [4],\n",
      "                         [2]], dtype=tf.float32)\n",
      "        \n",
      "        x = tf.linalg.triangular_solve(a, b, lower=True)\n",
      "        x\n",
      "        # <tf.Tensor: id=257, shape=(4, 1), dtype=float32, numpy=\n",
      "        # array([[ 1.3333334 ],\n",
      "        #        [-0.66666675],\n",
      "        #        [ 2.6666665 ],\n",
      "        #        [-1.3333331 ]], dtype=float32)>\n",
      "        \n",
      "        # in python3 one can use `a@x`\n",
      "        tf.matmul(a, x)\n",
      "        # <tf.Tensor: id=263, shape=(4, 1), dtype=float32, numpy=\n",
      "        # array([[4.       ],\n",
      "        #        [2.       ],\n",
      "        #        [4.       ],\n",
      "        #        [1.9999999]], dtype=float32)>\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          matrix: A `Tensor`. Must be one of the following types: `float64`, `float32`, `half`, `complex64`, `complex128`.\n",
      "            Shape is `[..., M, M]`.\n",
      "          rhs: A `Tensor`. Must have the same type as `matrix`.\n",
      "            Shape is `[..., M, K]`.\n",
      "          lower: An optional `bool`. Defaults to `True`.\n",
      "            Boolean indicating whether the innermost matrices in `matrix` are\n",
      "            lower or upper triangular.\n",
      "          adjoint: An optional `bool`. Defaults to `False`.\n",
      "            Boolean indicating whether to solve with `matrix` or its (block-wise)\n",
      "                     adjoint.\n",
      "        \n",
      "            @compatibility(numpy)\n",
      "            Equivalent to scipy.linalg.solve_triangular\n",
      "            @end_compatibility\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `matrix`.\n",
      "    \n",
      "    maximum(x, y, name=None)\n",
      "        Returns the max of x and y (i.e. x > y ? x : y) element-wise.\n",
      "        \n",
      "        *NOTE*: `math.maximum` supports broadcasting. More about broadcasting\n",
      "        [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int32`, `int64`.\n",
      "          y: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    meshgrid(*args, **kwargs)\n",
      "        Broadcasts parameters for evaluation on an N-D grid.\n",
      "        \n",
      "        Given N one-dimensional coordinate arrays `*args`, returns a list `outputs`\n",
      "        of N-D coordinate arrays for evaluating expressions on an N-D grid.\n",
      "        \n",
      "        Notes:\n",
      "        \n",
      "        `meshgrid` supports cartesian ('xy') and matrix ('ij') indexing conventions.\n",
      "        When the `indexing` argument is set to 'xy' (the default), the broadcasting\n",
      "        instructions for the first two dimensions are swapped.\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "        Calling `X, Y = meshgrid(x, y)` with the tensors\n",
      "        \n",
      "        ```python\n",
      "        x = [1, 2, 3]\n",
      "        y = [4, 5, 6]\n",
      "        X, Y = tf.meshgrid(x, y)\n",
      "        # X = [[1, 2, 3],\n",
      "        #      [1, 2, 3],\n",
      "        #      [1, 2, 3]]\n",
      "        # Y = [[4, 4, 4],\n",
      "        #      [5, 5, 5],\n",
      "        #      [6, 6, 6]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          *args: `Tensor`s with rank 1.\n",
      "          **kwargs:\n",
      "            - indexing: Either 'xy' or 'ij' (optional, default: 'xy').\n",
      "            - name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          outputs: A list of N `Tensor`s with rank N.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: When no keyword arguments (kwargs) are passed.\n",
      "          ValueError: When indexing keyword argument is not one of `xy` or `ij`.\n",
      "    \n",
      "    min_max_variable_partitioner(max_partitions=1, axis=0, min_slice_size=262144, bytes_per_string_element=16)\n",
      "        Partitioner to allocate minimum size per slice.\n",
      "        \n",
      "        Returns a partitioner that partitions the variable of given shape and dtype\n",
      "        such that each partition has a minimum of `min_slice_size` slice of the\n",
      "        variable. The maximum number of such partitions (upper bound) is given by\n",
      "        `max_partitions`.\n",
      "        \n",
      "        Args:\n",
      "          max_partitions: Upper bound on the number of partitions. Defaults to 1.\n",
      "          axis: Axis along which to partition the variable. Defaults to 0.\n",
      "          min_slice_size: Minimum size of the variable slice per partition. Defaults\n",
      "            to 256K.\n",
      "          bytes_per_string_element: If the `Variable` is of type string, this provides\n",
      "            an estimate of how large each scalar in the `Variable` is.\n",
      "        \n",
      "        Returns:\n",
      "          A partition function usable as the `partitioner` argument to\n",
      "          `variable_scope` and `get_variable`.\n",
      "    \n",
      "    minimum(x, y, name=None)\n",
      "        Returns the min of x and y (i.e. x < y ? x : y) element-wise.\n",
      "        \n",
      "        *NOTE*: `math.minimum` supports broadcasting. More about broadcasting\n",
      "        [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int32`, `int64`.\n",
      "          y: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    mod = floor_mod(x, y, name=None)\n",
      "        Returns element-wise remainder of division. When `x < 0` xor `y < 0` is\n",
      "        \n",
      "        true, this follows Python semantics in that the result here is consistent\n",
      "        with a flooring divide. E.g. `floor(x / y) * y + mod(x, y) = x`.\n",
      "        \n",
      "        *NOTE*: `math.floormod` supports broadcasting. More about broadcasting\n",
      "        [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `int32`, `int64`, `bfloat16`, `half`, `float32`, `float64`.\n",
      "          y: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    model_variables(scope=None)\n",
      "        Returns all variables in the MODEL_VARIABLES collection.\n",
      "        \n",
      "        Args:\n",
      "          scope: (Optional.) A string. If supplied, the resulting list is filtered to\n",
      "            include only items whose `name` attribute matches `scope` using\n",
      "            `re.match`. Items without a `name` attribute are never returned if a scope\n",
      "            is supplied. The choice of `re.match` means that a `scope` without special\n",
      "            tokens filters by prefix.\n",
      "        \n",
      "        Returns:\n",
      "          A list of local Variable objects.\n",
      "    \n",
      "    moving_average_variables(scope=None)\n",
      "        Returns all variables that maintain their moving averages.\n",
      "        \n",
      "        If an `ExponentialMovingAverage` object is created and the `apply()`\n",
      "        method is called on a list of variables, these variables will\n",
      "        be added to the `GraphKeys.MOVING_AVERAGE_VARIABLES` collection.\n",
      "        This convenience function returns the contents of that collection.\n",
      "        \n",
      "        Args:\n",
      "          scope: (Optional.) A string. If supplied, the resulting list is filtered to\n",
      "            include only items whose `name` attribute matches `scope` using\n",
      "            `re.match`. Items without a `name` attribute are never returned if a scope\n",
      "            is supplied. The choice of `re.match` means that a `scope` without special\n",
      "            tokens filters by prefix.\n",
      "        \n",
      "        Returns:\n",
      "          A list of Variable objects.\n",
      "    \n",
      "    multinomial(logits, num_samples, seed=None, name=None, output_dtype=None)\n",
      "        Draws samples from a multinomial distribution. (deprecated)\n",
      "        \n",
      "        Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Use `tf.random.categorical` instead.\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        ```python\n",
      "        # samples has shape [1, 5], where each value is either 0 or 1 with equal\n",
      "        # probability.\n",
      "        samples = tf.random.categorical(tf.math.log([[0.5, 0.5]]), 5)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          logits: 2-D Tensor with shape `[batch_size, num_classes]`.  Each slice\n",
      "            `[i, :]` represents the unnormalized log-probabilities for all classes.\n",
      "          num_samples: 0-D.  Number of independent samples to draw for each row slice.\n",
      "          seed: A Python integer. Used to create a random seed for the distribution.\n",
      "            See `tf.compat.v1.set_random_seed` for behavior.\n",
      "          name: Optional name for the operation.\n",
      "          output_dtype: integer type to use for the output. Defaults to int64.\n",
      "        \n",
      "        Returns:\n",
      "          The drawn samples of shape `[batch_size, num_samples]`.\n",
      "    \n",
      "    multiply(x, y, name=None)\n",
      "        Returns x * y element-wise.\n",
      "        \n",
      "        *NOTE*: `tf.multiply` supports broadcasting. More about broadcasting\n",
      "        [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`, `int16`, `int32`, `int64`, `complex64`, `complex128`.\n",
      "          y: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    negative = neg(x, name=None)\n",
      "        Computes numerical negative value element-wise.\n",
      "        \n",
      "        I.e., \\\\(y = -x\\\\).\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int32`, `int64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "        \n",
      "          If `x` is a `SparseTensor`, returns\n",
      "          `SparseTensor(x.indices, tf.math.negative(x.values, ...), x.dense_shape)`\n",
      "    \n",
      "    no_gradient(op_type)\n",
      "        Specifies that ops of type `op_type` is not differentiable.\n",
      "        \n",
      "        This function should *not* be used for operations that have a\n",
      "        well-defined gradient that is not yet implemented.\n",
      "        \n",
      "        This function is only used when defining a new op type. It may be\n",
      "        used for ops such as `tf.size()` that are not differentiable.  For\n",
      "        example:\n",
      "        \n",
      "        ```python\n",
      "        tf.no_gradient(\"Size\")\n",
      "        ```\n",
      "        \n",
      "        The gradient computed for 'op_type' will then propagate zeros.\n",
      "        \n",
      "        For ops that have a well-defined gradient but are not yet implemented,\n",
      "        no declaration should be made, and an error *must* be thrown if\n",
      "        an attempt to request its gradient is made.\n",
      "        \n",
      "        Args:\n",
      "          op_type: The string type of an operation. This corresponds to the\n",
      "            `OpDef.name` field for the proto that defines the operation.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `op_type` is not a string.\n",
      "    \n",
      "    no_op(name=None)\n",
      "        Does nothing. Only useful as a placeholder for control edges.\n",
      "        \n",
      "        Args:\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          The created Operation.\n",
      "    \n",
      "    no_regularizer(_)\n",
      "        Use this function to prevent regularization of variables.\n",
      "    \n",
      "    nondifferentiable_batch_function = batch_function(num_batch_threads, max_batch_size, batch_timeout_micros, allowed_batch_sizes=None, max_enqueued_batches=10, autograph=True)\n",
      "        Batches the computation done by the decorated function.\n",
      "        \n",
      "        So, for example, in the following code\n",
      "        \n",
      "        ```python\n",
      "        @batch_function(1, 2, 3)\n",
      "        def layer(a):\n",
      "          return tf.matmul(a, a)\n",
      "        \n",
      "        b = layer(w)\n",
      "        ```\n",
      "        \n",
      "        if more than one session.run call is simultaneously trying to compute `b`\n",
      "        the values of `w` will be gathered, non-deterministically concatenated\n",
      "        along the first axis, and only one thread will run the computation. See the\n",
      "        documentation of the `Batch` op for more details.\n",
      "        \n",
      "        Assumes that all arguments of the decorated function are Tensors which will\n",
      "        be batched along their first dimension.\n",
      "        \n",
      "        SparseTensor is not supported. The return value of the decorated function\n",
      "        must be a Tensor or a list/tuple of Tensors.\n",
      "        \n",
      "        Args:\n",
      "          num_batch_threads: Number of scheduling threads for processing batches\n",
      "           of work. Determines the number of batches processed in parallel.\n",
      "          max_batch_size: Batch sizes will never be bigger than this.\n",
      "          batch_timeout_micros: Maximum number of microseconds to wait before\n",
      "           outputting an incomplete batch.\n",
      "          allowed_batch_sizes: Optional list of allowed batch sizes. If left empty,\n",
      "           does nothing. Otherwise, supplies a list of batch sizes, causing the op\n",
      "           to pad batches up to one of those sizes. The entries must increase\n",
      "           monotonically, and the final entry must equal max_batch_size.\n",
      "          max_enqueued_batches: The maximum depth of the batch queue. Defaults to 10.\n",
      "          autograph: Whether to use autograph to compile python and eager style code\n",
      "           for efficient graph-mode execution.\n",
      "        \n",
      "        Returns:\n",
      "          The decorated function will return the unbatched computation output Tensors.\n",
      "    \n",
      "    norm(tensor, ord='euclidean', axis=None, keepdims=None, name=None, keep_dims=None)\n",
      "        Computes the norm of vectors, matrices, and tensors. (deprecated arguments)\n",
      "        \n",
      "        Warning: SOME ARGUMENTS ARE DEPRECATED: `(keep_dims)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        keep_dims is deprecated, use keepdims instead\n",
      "        \n",
      "        This function can compute several different vector norms (the 1-norm, the\n",
      "        Euclidean or 2-norm, the inf-norm, and in general the p-norm for p > 0) and\n",
      "        matrix norms (Frobenius, 1-norm, 2-norm and inf-norm).\n",
      "        \n",
      "        Args:\n",
      "          tensor: `Tensor` of types `float32`, `float64`, `complex64`, `complex128`\n",
      "          ord: Order of the norm. Supported values are 'fro', 'euclidean',\n",
      "            `1`, `2`, `np.inf` and any positive real number yielding the corresponding\n",
      "            p-norm. Default is 'euclidean' which is equivalent to Frobenius norm if\n",
      "            `tensor` is a matrix and equivalent to 2-norm for vectors.\n",
      "            Some restrictions apply:\n",
      "              a) The Frobenius norm `fro` is not defined for vectors,\n",
      "              b) If axis is a 2-tuple (matrix norm), only 'euclidean', 'fro', `1`,\n",
      "                 `2`, `np.inf` are supported.\n",
      "            See the description of `axis` on how to compute norms for a batch of\n",
      "            vectors or matrices stored in a tensor.\n",
      "          axis: If `axis` is `None` (the default), the input is considered a vector\n",
      "            and a single vector norm is computed over the entire set of values in the\n",
      "            tensor, i.e. `norm(tensor, ord=ord)` is equivalent to\n",
      "            `norm(reshape(tensor, [-1]), ord=ord)`.\n",
      "            If `axis` is a Python integer, the input is considered a batch of vectors,\n",
      "            and `axis` determines the axis in `tensor` over which to compute vector\n",
      "            norms.\n",
      "            If `axis` is a 2-tuple of Python integers it is considered a batch of\n",
      "            matrices and `axis` determines the axes in `tensor` over which to compute\n",
      "            a matrix norm.\n",
      "            Negative indices are supported. Example: If you are passing a tensor that\n",
      "            can be either a matrix or a batch of matrices at runtime, pass\n",
      "            `axis=[-2,-1]` instead of `axis=None` to make sure that matrix norms are\n",
      "            computed.\n",
      "          keepdims: If True, the axis indicated in `axis` are kept with size 1.\n",
      "            Otherwise, the dimensions in `axis` are removed from the output shape.\n",
      "          name: The name of the op.\n",
      "          keep_dims: Deprecated alias for `keepdims`.\n",
      "        \n",
      "        Returns:\n",
      "          output: A `Tensor` of the same type as tensor, containing the vector or\n",
      "            matrix norms. If `keepdims` is True then the rank of output is equal to\n",
      "            the rank of `tensor`. Otherwise, if `axis` is none the output is a scalar,\n",
      "            if `axis` is an integer, the rank of `output` is one less than the rank\n",
      "            of `tensor`, if `axis` is a 2-tuple the rank of `output` is two less\n",
      "            than the rank of `tensor`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If `ord` or `axis` is invalid.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Mostly equivalent to numpy.linalg.norm.\n",
      "        Not supported: ord <= 0, 2-norm for matrices, nuclear norm.\n",
      "        Other differences:\n",
      "          a) If axis is `None`, treats the flattened `tensor` as a vector\n",
      "           regardless of rank.\n",
      "          b) Explicitly supports 'euclidean' norm as the default, including for\n",
      "           higher order tensors.\n",
      "        @end_compatibility\n",
      "    \n",
      "    not_equal(x, y, name=None)\n",
      "        Returns the truth value of (x != y) element-wise.\n",
      "        \n",
      "        **NOTE**: `NotEqual` supports broadcasting. More about broadcasting [here](\n",
      "        https://docs.scipy.org/doc/numpy-1.13.0/user/basics.broadcasting.html)\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor` or `SparseTensor` or `IndexedSlices`.\n",
      "          y: A `Tensor` or `SparseTensor` or `IndexedSlices`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type bool with the same size as that of x or y.\n",
      "    \n",
      "    numpy_function(func, inp, Tout, name=None)\n",
      "        Wraps a python function and uses it as a TensorFlow op.\n",
      "        \n",
      "        Given a python function `func`, which takes numpy arrays as its\n",
      "        arguments and returns numpy arrays as its outputs, wrap this function as an\n",
      "        operation in a TensorFlow graph. The following snippet constructs a simple\n",
      "        TensorFlow graph that invokes the `np.sinh()` NumPy function as a operation\n",
      "        in the graph:\n",
      "        \n",
      "        ```python\n",
      "        def my_func(x):\n",
      "          # x will be a numpy array with the contents of the placeholder below\n",
      "          return np.sinh(x)\n",
      "        input = tf.compat.v1.placeholder(tf.float32)\n",
      "        y = tf.compat.v1.numpy_function(my_func, [input], tf.float32)\n",
      "        ```\n",
      "        \n",
      "        **N.B.** The `tf.compat.v1.numpy_function()` operation has the following known\n",
      "        limitations:\n",
      "        \n",
      "        * The body of the function (i.e. `func`) will not be serialized in a\n",
      "          `GraphDef`. Therefore, you should not use this function if you need to\n",
      "          serialize your model and restore it in a different environment.\n",
      "        \n",
      "        * The operation must run in the same address space as the Python program\n",
      "          that calls `tf.compat.v1.numpy_function()`. If you are using distributed\n",
      "          TensorFlow, you\n",
      "          must run a `tf.distribute.Server` in the same process as the program that\n",
      "          calls\n",
      "          `tf.compat.v1.numpy_function()` and you must pin the created operation to a device\n",
      "          in that\n",
      "          server (e.g. using `with tf.device():`).\n",
      "        \n",
      "        Args:\n",
      "          func: A Python function, which accepts `ndarray` objects as arguments and\n",
      "            returns a list of `ndarray` objects (or a single `ndarray`). This function\n",
      "            must accept as many arguments as there are tensors in `inp`, and these\n",
      "            argument types will match the corresponding `tf.Tensor` objects in `inp`.\n",
      "            The returns `ndarray`s must match the number and types defined `Tout`.\n",
      "            Important Note: Input and output numpy `ndarray`s of `func` are not\n",
      "              guaranteed to be copies. In some cases their underlying memory will be\n",
      "              shared with the corresponding TensorFlow tensors. In-place modification\n",
      "              or storing `func` input or return values in python datastructures\n",
      "              without explicit (np.)copy can have non-deterministic consequences.\n",
      "          inp: A list of `Tensor` objects.\n",
      "          Tout: A list or tuple of tensorflow data types or a single tensorflow data\n",
      "            type if there is only one, indicating what `func` returns.\n",
      "          stateful: (Boolean.) If True, the function should be considered stateful. If\n",
      "            a function is stateless, when given the same input it will return the same\n",
      "            output and have no observable side effects. Optimizations such as common\n",
      "            subexpression elimination are only performed on stateless operations.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A list of `Tensor` or a single `Tensor` which `func` computes.\n",
      "    \n",
      "    one_hot(indices, depth, on_value=None, off_value=None, axis=None, dtype=None, name=None)\n",
      "        Returns a one-hot tensor.\n",
      "        \n",
      "        The locations represented by indices in `indices` take value `on_value`,\n",
      "        while all other locations take value `off_value`.\n",
      "        \n",
      "        `on_value` and `off_value` must have matching data types. If `dtype` is also\n",
      "        provided, they must be the same data type as specified by `dtype`.\n",
      "        \n",
      "        If `on_value` is not provided, it will default to the value `1` with type\n",
      "        `dtype`\n",
      "        \n",
      "        If `off_value` is not provided, it will default to the value `0` with type\n",
      "        `dtype`\n",
      "        \n",
      "        If the input `indices` is rank `N`, the output will have rank `N+1`. The\n",
      "        new axis is created at dimension `axis` (default: the new axis is appended\n",
      "        at the end).\n",
      "        \n",
      "        If `indices` is a scalar the output shape will be a vector of length `depth`\n",
      "        \n",
      "        If `indices` is a vector of length `features`, the output shape will be:\n",
      "        \n",
      "        ```\n",
      "          features x depth if axis == -1\n",
      "          depth x features if axis == 0\n",
      "        ```\n",
      "        \n",
      "        If `indices` is a matrix (batch) with shape `[batch, features]`, the output\n",
      "        shape will be:\n",
      "        \n",
      "        ```\n",
      "          batch x features x depth if axis == -1\n",
      "          batch x depth x features if axis == 1\n",
      "          depth x batch x features if axis == 0\n",
      "        ```\n",
      "        \n",
      "        If `indices` is a RaggedTensor, the 'axis' argument must be positive and refer\n",
      "        to a non-ragged axis. The output will be equivalent to applying 'one_hot' on\n",
      "        the values of the RaggedTensor, and creating a new RaggedTensor from the\n",
      "        result.\n",
      "        \n",
      "        If `dtype` is not provided, it will attempt to assume the data type of\n",
      "        `on_value` or `off_value`, if one or both are passed in. If none of\n",
      "        `on_value`, `off_value`, or `dtype` are provided, `dtype` will default to the\n",
      "        value `tf.float32`.\n",
      "        \n",
      "        Note: If a non-numeric data type output is desired (`tf.string`, `tf.bool`,\n",
      "        etc.), both `on_value` and `off_value` _must_ be provided to `one_hot`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        indices = [0, 1, 2]\n",
      "        depth = 3\n",
      "        tf.one_hot(indices, depth)  # output: [3 x 3]\n",
      "        # [[1., 0., 0.],\n",
      "        #  [0., 1., 0.],\n",
      "        #  [0., 0., 1.]]\n",
      "        \n",
      "        indices = [0, 2, -1, 1]\n",
      "        depth = 3\n",
      "        tf.one_hot(indices, depth,\n",
      "                   on_value=5.0, off_value=0.0,\n",
      "                   axis=-1)  # output: [4 x 3]\n",
      "        # [[5.0, 0.0, 0.0],  # one_hot(0)\n",
      "        #  [0.0, 0.0, 5.0],  # one_hot(2)\n",
      "        #  [0.0, 0.0, 0.0],  # one_hot(-1)\n",
      "        #  [0.0, 5.0, 0.0]]  # one_hot(1)\n",
      "        \n",
      "        indices = [[0, 2], [1, -1]]\n",
      "        depth = 3\n",
      "        tf.one_hot(indices, depth,\n",
      "                   on_value=1.0, off_value=0.0,\n",
      "                   axis=-1)  # output: [2 x 2 x 3]\n",
      "        # [[[1.0, 0.0, 0.0],   # one_hot(0)\n",
      "        #   [0.0, 0.0, 1.0]],  # one_hot(2)\n",
      "        #  [[0.0, 1.0, 0.0],   # one_hot(1)\n",
      "        #   [0.0, 0.0, 0.0]]]  # one_hot(-1)\n",
      "        \n",
      "        indices = tf.ragged.constant([[0, 1], [2]])\n",
      "        depth = 3\n",
      "        tf.one_hot(indices, depth)  # output: [2 x None x 3]\n",
      "        # [[[1., 0., 0.],\n",
      "        #   [0., 1., 0.]],\n",
      "        #  [[0., 0., 1.]]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          indices: A `Tensor` of indices.\n",
      "          depth: A scalar defining the depth of the one hot dimension.\n",
      "          on_value: A scalar defining the value to fill in output when `indices[j]\n",
      "            = i`. (default: 1)\n",
      "          off_value: A scalar defining the value to fill in output when `indices[j]\n",
      "            != i`. (default: 0)\n",
      "          axis: The axis to fill (default: -1, a new inner-most axis).\n",
      "          dtype: The data type of the output tensor.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          output: The one-hot tensor.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If dtype of either `on_value` or `off_value` don't match `dtype`\n",
      "          TypeError: If dtype of `on_value` and `off_value` don't match one another\n",
      "    \n",
      "    ones(shape, dtype=tf.float32, name=None)\n",
      "        Creates a tensor with all elements set to 1.\n",
      "        \n",
      "        This operation returns a tensor of type `dtype` with shape `shape` and all\n",
      "        elements set to 1.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        tf.ones([2, 3], tf.int32)  # [[1, 1, 1], [1, 1, 1]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          shape: A list of integers, a tuple of integers, or a 1-D `Tensor` of type\n",
      "            `int32`.\n",
      "          dtype: The type of an element in the resulting `Tensor`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` with all elements set to 1.\n",
      "    \n",
      "    ones_like(tensor, dtype=None, name=None, optimize=True)\n",
      "        Creates a tensor with all elements set to 1.\n",
      "        \n",
      "        Given a single tensor (`tensor`), this operation returns a tensor of the same\n",
      "        type and shape as `tensor` with all elements set to 1. Optionally, you can\n",
      "        specify a new type (`dtype`) for the returned tensor.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        tensor = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
      "        tf.ones_like(tensor)  # [[1, 1, 1], [1, 1, 1]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          tensor: A `Tensor`.\n",
      "          dtype: A type for the returned `Tensor`. Must be `float32`, `float64`,\n",
      "            `int8`, `uint8`, `int16`, `uint16`, `int32`, `int64`, `complex64`,\n",
      "            `complex128` or `bool`.\n",
      "          name: A name for the operation (optional).\n",
      "          optimize: if true, attempt to statically determine the shape of 'tensor' and\n",
      "            encode it as a constant.\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` with all elements set to 1.\n",
      "    \n",
      "    op_scope(values, name, default_name=None)\n",
      "        DEPRECATED. Same as name_scope above, just different argument order.\n",
      "    \n",
      "    pad(tensor, paddings, mode='CONSTANT', name=None, constant_values=0)\n",
      "        Pads a tensor.\n",
      "        \n",
      "        This operation pads a `tensor` according to the `paddings` you specify.\n",
      "        `paddings` is an integer tensor with shape `[n, 2]`, where n is the rank of\n",
      "        `tensor`. For each dimension D of `input`, `paddings[D, 0]` indicates how\n",
      "        many values to add before the contents of `tensor` in that dimension, and\n",
      "        `paddings[D, 1]` indicates how many values to add after the contents of\n",
      "        `tensor` in that dimension. If `mode` is \"REFLECT\" then both `paddings[D, 0]`\n",
      "        and `paddings[D, 1]` must be no greater than `tensor.dim_size(D) - 1`. If\n",
      "        `mode` is \"SYMMETRIC\" then both `paddings[D, 0]` and `paddings[D, 1]` must be\n",
      "        no greater than `tensor.dim_size(D)`.\n",
      "        \n",
      "        The padded size of each dimension D of the output is:\n",
      "        \n",
      "        `paddings[D, 0] + tensor.dim_size(D) + paddings[D, 1]`\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        t = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
      "        paddings = tf.constant([[1, 1,], [2, 2]])\n",
      "        # 'constant_values' is 0.\n",
      "        # rank of 't' is 2.\n",
      "        tf.pad(t, paddings, \"CONSTANT\")  # [[0, 0, 0, 0, 0, 0, 0],\n",
      "                                         #  [0, 0, 1, 2, 3, 0, 0],\n",
      "                                         #  [0, 0, 4, 5, 6, 0, 0],\n",
      "                                         #  [0, 0, 0, 0, 0, 0, 0]]\n",
      "        \n",
      "        tf.pad(t, paddings, \"REFLECT\")  # [[6, 5, 4, 5, 6, 5, 4],\n",
      "                                        #  [3, 2, 1, 2, 3, 2, 1],\n",
      "                                        #  [6, 5, 4, 5, 6, 5, 4],\n",
      "                                        #  [3, 2, 1, 2, 3, 2, 1]]\n",
      "        \n",
      "        tf.pad(t, paddings, \"SYMMETRIC\")  # [[2, 1, 1, 2, 3, 3, 2],\n",
      "                                          #  [2, 1, 1, 2, 3, 3, 2],\n",
      "                                          #  [5, 4, 4, 5, 6, 6, 5],\n",
      "                                          #  [5, 4, 4, 5, 6, 6, 5]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          tensor: A `Tensor`.\n",
      "          paddings: A `Tensor` of type `int32`.\n",
      "          mode: One of \"CONSTANT\", \"REFLECT\", or \"SYMMETRIC\" (case-insensitive)\n",
      "          name: A name for the operation (optional).\n",
      "          constant_values: In \"CONSTANT\" mode, the scalar pad value to use. Must be\n",
      "            same type as `tensor`.\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `tensor`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: When mode is not one of \"CONSTANT\", \"REFLECT\", or \"SYMMETRIC\".\n",
      "    \n",
      "    parallel_stack(values, name='parallel_stack')\n",
      "        Stacks a list of rank-`R` tensors into one rank-`(R+1)` tensor in parallel.\n",
      "        \n",
      "        Requires that the shape of inputs be known at graph construction time.\n",
      "        \n",
      "        Packs the list of tensors in `values` into a tensor with rank one higher than\n",
      "        each tensor in `values`, by packing them along the first dimension.\n",
      "        Given a list of length `N` of tensors of shape `(A, B, C)`; the `output`\n",
      "        tensor will have the shape `(N, A, B, C)`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([1, 4])\n",
      "        y = tf.constant([2, 5])\n",
      "        z = tf.constant([3, 6])\n",
      "        tf.parallel_stack([x, y, z])  # [[1, 4], [2, 5], [3, 6]]\n",
      "        ```\n",
      "        \n",
      "        The difference between `stack` and `parallel_stack` is that `stack` requires\n",
      "        all the inputs be computed before the operation will begin but doesn't require\n",
      "        that the input shapes be known during graph construction.\n",
      "        \n",
      "        `parallel_stack` will copy pieces of the input into the output as they become\n",
      "        available, in some situations this can provide a performance benefit.\n",
      "        \n",
      "        Unlike `stack`, `parallel_stack` does NOT support backpropagation.\n",
      "        \n",
      "        This is the opposite of unstack.  The numpy equivalent is\n",
      "        \n",
      "            tf.parallel_stack([x, y, z]) = np.asarray([x, y, z])\n",
      "        \n",
      "        Args:\n",
      "          values: A list of `Tensor` objects with the same shape and type.\n",
      "          name: A name for this operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          output: A stacked `Tensor` with the same type as `values`.\n",
      "    \n",
      "    parse_example(serialized, features, name=None, example_names=None)\n",
      "        Parses `Example` protos into a `dict` of tensors.\n",
      "        \n",
      "        Parses a number of serialized [`Example`](https://www.tensorflow.org/code/tensorflow/core/example/example.proto)\n",
      "        protos given in `serialized`. We refer to `serialized` as a batch with\n",
      "        `batch_size` many entries of individual `Example` protos.\n",
      "        \n",
      "        `example_names` may contain descriptive names for the corresponding serialized\n",
      "        protos. These may be useful for debugging purposes, but they have no effect on\n",
      "        the output. If not `None`, `example_names` must be the same length as\n",
      "        `serialized`.\n",
      "        \n",
      "        This op parses serialized examples into a dictionary mapping keys to `Tensor`\n",
      "        and `SparseTensor` objects. `features` is a dict from keys to `VarLenFeature`,\n",
      "        `SparseFeature`, and `FixedLenFeature` objects. Each `VarLenFeature`\n",
      "        and `SparseFeature` is mapped to a `SparseTensor`, and each\n",
      "        `FixedLenFeature` is mapped to a `Tensor`.\n",
      "        \n",
      "        Each `VarLenFeature` maps to a `SparseTensor` of the specified type\n",
      "        representing a ragged matrix. Its indices are `[batch, index]` where `batch`\n",
      "        identifies the example in `serialized`, and `index` is the value's index in\n",
      "        the list of values associated with that feature and example.\n",
      "        \n",
      "        Each `SparseFeature` maps to a `SparseTensor` of the specified type\n",
      "        representing a Tensor of `dense_shape` `[batch_size] + SparseFeature.size`.\n",
      "        Its `values` come from the feature in the examples with key `value_key`.\n",
      "        A `values[i]` comes from a position `k` in the feature of an example at batch\n",
      "        entry `batch`. This positional information is recorded in `indices[i]` as\n",
      "        `[batch, index_0, index_1, ...]` where `index_j` is the `k-th` value of\n",
      "        the feature in the example at with key `SparseFeature.index_key[j]`.\n",
      "        In other words, we split the indices (except the first index indicating the\n",
      "        batch entry) of a `SparseTensor` by dimension into different features of the\n",
      "        `Example`. Due to its complexity a `VarLenFeature` should be preferred over a\n",
      "        `SparseFeature` whenever possible.\n",
      "        \n",
      "        Each `FixedLenFeature` `df` maps to a `Tensor` of the specified type (or\n",
      "        `tf.float32` if not specified) and shape `(serialized.size(),) + df.shape`.\n",
      "        \n",
      "        `FixedLenFeature` entries with a `default_value` are optional. With no default\n",
      "        value, we will fail if that `Feature` is missing from any example in\n",
      "        `serialized`.\n",
      "        \n",
      "        Each `FixedLenSequenceFeature` `df` maps to a `Tensor` of the specified type\n",
      "        (or `tf.float32` if not specified) and shape\n",
      "        `(serialized.size(), None) + df.shape`.\n",
      "        All examples in `serialized` will be padded with `default_value` along the\n",
      "        second dimension.\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "        For example, if one expects a `tf.float32` `VarLenFeature` `ft` and three\n",
      "        serialized `Example`s are provided:\n",
      "        \n",
      "        ```\n",
      "        serialized = [\n",
      "          features\n",
      "            { feature { key: \"ft\" value { float_list { value: [1.0, 2.0] } } } },\n",
      "          features\n",
      "            { feature []},\n",
      "          features\n",
      "            { feature { key: \"ft\" value { float_list { value: [3.0] } } }\n",
      "        ]\n",
      "        ```\n",
      "        \n",
      "        then the output will look like:\n",
      "        \n",
      "        ```python\n",
      "        {\"ft\": SparseTensor(indices=[[0, 0], [0, 1], [2, 0]],\n",
      "                            values=[1.0, 2.0, 3.0],\n",
      "                            dense_shape=(3, 2)) }\n",
      "        ```\n",
      "        \n",
      "        If instead a `FixedLenSequenceFeature` with `default_value = -1.0` and\n",
      "        `shape=[]` is used then the output will look like:\n",
      "        \n",
      "        ```python\n",
      "        {\"ft\": [[1.0, 2.0], [3.0, -1.0]]}\n",
      "        ```\n",
      "        \n",
      "        Given two `Example` input protos in `serialized`:\n",
      "        \n",
      "        ```\n",
      "        [\n",
      "          features {\n",
      "            feature { key: \"kw\" value { bytes_list { value: [ \"knit\", \"big\" ] } } }\n",
      "            feature { key: \"gps\" value { float_list { value: [] } } }\n",
      "          },\n",
      "          features {\n",
      "            feature { key: \"kw\" value { bytes_list { value: [ \"emmy\" ] } } }\n",
      "            feature { key: \"dank\" value { int64_list { value: [ 42 ] } } }\n",
      "            feature { key: \"gps\" value { } }\n",
      "          }\n",
      "        ]\n",
      "        ```\n",
      "        \n",
      "        And arguments\n",
      "        \n",
      "        ```\n",
      "        example_names: [\"input0\", \"input1\"],\n",
      "        features: {\n",
      "            \"kw\": VarLenFeature(tf.string),\n",
      "            \"dank\": VarLenFeature(tf.int64),\n",
      "            \"gps\": VarLenFeature(tf.float32),\n",
      "        }\n",
      "        ```\n",
      "        \n",
      "        Then the output is a dictionary:\n",
      "        \n",
      "        ```python\n",
      "        {\n",
      "          \"kw\": SparseTensor(\n",
      "              indices=[[0, 0], [0, 1], [1, 0]],\n",
      "              values=[\"knit\", \"big\", \"emmy\"]\n",
      "              dense_shape=[2, 2]),\n",
      "          \"dank\": SparseTensor(\n",
      "              indices=[[1, 0]],\n",
      "              values=[42],\n",
      "              dense_shape=[2, 1]),\n",
      "          \"gps\": SparseTensor(\n",
      "              indices=[],\n",
      "              values=[],\n",
      "              dense_shape=[2, 0]),\n",
      "        }\n",
      "        ```\n",
      "        \n",
      "        For dense results in two serialized `Example`s:\n",
      "        \n",
      "        ```\n",
      "        [\n",
      "          features {\n",
      "            feature { key: \"age\" value { int64_list { value: [ 0 ] } } }\n",
      "            feature { key: \"gender\" value { bytes_list { value: [ \"f\" ] } } }\n",
      "           },\n",
      "           features {\n",
      "            feature { key: \"age\" value { int64_list { value: [] } } }\n",
      "            feature { key: \"gender\" value { bytes_list { value: [ \"f\" ] } } }\n",
      "          }\n",
      "        ]\n",
      "        ```\n",
      "        \n",
      "        We can use arguments:\n",
      "        \n",
      "        ```\n",
      "        example_names: [\"input0\", \"input1\"],\n",
      "        features: {\n",
      "            \"age\": FixedLenFeature([], dtype=tf.int64, default_value=-1),\n",
      "            \"gender\": FixedLenFeature([], dtype=tf.string),\n",
      "        }\n",
      "        ```\n",
      "        \n",
      "        And the expected output is:\n",
      "        \n",
      "        ```python\n",
      "        {\n",
      "          \"age\": [[0], [-1]],\n",
      "          \"gender\": [[\"f\"], [\"f\"]],\n",
      "        }\n",
      "        ```\n",
      "        \n",
      "        An alternative to `VarLenFeature` to obtain a `SparseTensor` is\n",
      "        `SparseFeature`. For example, given two `Example` input protos in\n",
      "        `serialized`:\n",
      "        \n",
      "        ```\n",
      "        [\n",
      "          features {\n",
      "            feature { key: \"val\" value { float_list { value: [ 0.5, -1.0 ] } } }\n",
      "            feature { key: \"ix\" value { int64_list { value: [ 3, 20 ] } } }\n",
      "          },\n",
      "          features {\n",
      "            feature { key: \"val\" value { float_list { value: [ 0.0 ] } } }\n",
      "            feature { key: \"ix\" value { int64_list { value: [ 42 ] } } }\n",
      "          }\n",
      "        ]\n",
      "        ```\n",
      "        \n",
      "        And arguments\n",
      "        \n",
      "        ```\n",
      "        example_names: [\"input0\", \"input1\"],\n",
      "        features: {\n",
      "            \"sparse\": SparseFeature(\n",
      "                index_key=\"ix\", value_key=\"val\", dtype=tf.float32, size=100),\n",
      "        }\n",
      "        ```\n",
      "        \n",
      "        Then the output is a dictionary:\n",
      "        \n",
      "        ```python\n",
      "        {\n",
      "          \"sparse\": SparseTensor(\n",
      "              indices=[[0, 3], [0, 20], [1, 42]],\n",
      "              values=[0.5, -1.0, 0.0]\n",
      "              dense_shape=[2, 100]),\n",
      "        }\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          serialized: A vector (1-D Tensor) of strings, a batch of binary\n",
      "            serialized `Example` protos.\n",
      "          features: A `dict` mapping feature keys to `FixedLenFeature`,\n",
      "            `VarLenFeature`, and `SparseFeature` values.\n",
      "          name: A name for this operation (optional).\n",
      "          example_names: A vector (1-D Tensor) of strings (optional), the names of\n",
      "            the serialized protos in the batch.\n",
      "        \n",
      "        Returns:\n",
      "          A `dict` mapping feature keys to `Tensor` and `SparseTensor` values.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: if any feature is invalid.\n",
      "    \n",
      "    parse_single_example(serialized, features, name=None, example_names=None)\n",
      "        Parses a single `Example` proto.\n",
      "        \n",
      "        Similar to `parse_example`, except:\n",
      "        \n",
      "        For dense tensors, the returned `Tensor` is identical to the output of\n",
      "        `parse_example`, except there is no batch dimension, the output shape is the\n",
      "        same as the shape given in `dense_shape`.\n",
      "        \n",
      "        For `SparseTensor`s, the first (batch) column of the indices matrix is removed\n",
      "        (the indices matrix is a column vector), the values vector is unchanged, and\n",
      "        the first (`batch_size`) entry of the shape vector is removed (it is now a\n",
      "        single element vector).\n",
      "        \n",
      "        One might see performance advantages by batching `Example` protos with\n",
      "        `parse_example` instead of using this function directly.\n",
      "        \n",
      "        Args:\n",
      "          serialized: A scalar string Tensor, a single serialized Example.\n",
      "            See `_parse_single_example_raw` documentation for more details.\n",
      "          features: A `dict` mapping feature keys to `FixedLenFeature` or\n",
      "            `VarLenFeature` values.\n",
      "          name: A name for this operation (optional).\n",
      "          example_names: (Optional) A scalar string Tensor, the associated name.\n",
      "            See `_parse_single_example_raw` documentation for more details.\n",
      "        \n",
      "        Returns:\n",
      "          A `dict` mapping feature keys to `Tensor` and `SparseTensor` values.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: if any feature is invalid.\n",
      "    \n",
      "    parse_single_sequence_example(serialized, context_features=None, sequence_features=None, example_name=None, name=None)\n",
      "        Parses a single `SequenceExample` proto.\n",
      "        \n",
      "        Parses a single serialized [`SequenceExample`](https://www.tensorflow.org/code/tensorflow/core/example/example.proto)\n",
      "        proto given in `serialized`.\n",
      "        \n",
      "        This op parses a serialized sequence example into a tuple of dictionaries,\n",
      "        each mapping keys to `Tensor` and `SparseTensor` objects.\n",
      "        The first dictionary contains mappings for keys appearing in\n",
      "        `context_features`, and the second dictionary contains mappings for keys\n",
      "        appearing in `sequence_features`.\n",
      "        \n",
      "        At least one of `context_features` and `sequence_features` must be provided\n",
      "        and non-empty.\n",
      "        \n",
      "        The `context_features` keys are associated with a `SequenceExample` as a\n",
      "        whole, independent of time / frame.  In contrast, the `sequence_features` keys\n",
      "        provide a way to access variable-length data within the `FeatureList` section\n",
      "        of the `SequenceExample` proto.  While the shapes of `context_features` values\n",
      "        are fixed with respect to frame, the frame dimension (the first dimension)\n",
      "        of `sequence_features` values may vary between `SequenceExample` protos,\n",
      "        and even between `feature_list` keys within the same `SequenceExample`.\n",
      "        \n",
      "        `context_features` contains `VarLenFeature` and `FixedLenFeature` objects.\n",
      "        Each `VarLenFeature` is mapped to a `SparseTensor`, and each `FixedLenFeature`\n",
      "        is mapped to a `Tensor`, of the specified type, shape, and default value.\n",
      "        \n",
      "        `sequence_features` contains `VarLenFeature` and `FixedLenSequenceFeature`\n",
      "        objects. Each `VarLenFeature` is mapped to a `SparseTensor`, and each\n",
      "        `FixedLenSequenceFeature` is mapped to a `Tensor`, each of the specified type.\n",
      "        The shape will be `(T,) + df.dense_shape` for `FixedLenSequenceFeature` `df`, where\n",
      "        `T` is the length of the associated `FeatureList` in the `SequenceExample`.\n",
      "        For instance, `FixedLenSequenceFeature([])` yields a scalar 1-D `Tensor` of\n",
      "        static shape `[None]` and dynamic shape `[T]`, while\n",
      "        `FixedLenSequenceFeature([k])` (for `int k >= 1`) yields a 2-D matrix `Tensor`\n",
      "        of static shape `[None, k]` and dynamic shape `[T, k]`.\n",
      "        \n",
      "        Each `SparseTensor` corresponding to `sequence_features` represents a ragged\n",
      "        vector.  Its indices are `[time, index]`, where `time` is the `FeatureList`\n",
      "        entry and `index` is the value's index in the list of values associated with\n",
      "        that time.\n",
      "        \n",
      "        `FixedLenFeature` entries with a `default_value` and `FixedLenSequenceFeature`\n",
      "        entries with `allow_missing=True` are optional; otherwise, we will fail if\n",
      "        that `Feature` or `FeatureList` is missing from any example in `serialized`.\n",
      "        \n",
      "        `example_name` may contain a descriptive name for the corresponding serialized\n",
      "        proto. This may be useful for debugging purposes, but it has no effect on the\n",
      "        output. If not `None`, `example_name` must be a scalar.\n",
      "        \n",
      "        Note that the batch version of this function, `tf.parse_sequence_example`,\n",
      "        is written for better memory efficiency and will be faster on large\n",
      "        `SequenceExample`s.\n",
      "        \n",
      "        Args:\n",
      "          serialized: A scalar (0-D Tensor) of type string, a single binary\n",
      "            serialized `SequenceExample` proto.\n",
      "          context_features: A `dict` mapping feature keys to `FixedLenFeature` or\n",
      "            `VarLenFeature` values. These features are associated with a\n",
      "            `SequenceExample` as a whole.\n",
      "          sequence_features: A `dict` mapping feature keys to\n",
      "            `FixedLenSequenceFeature` or `VarLenFeature` values. These features are\n",
      "            associated with data within the `FeatureList` section of the\n",
      "            `SequenceExample` proto.\n",
      "          example_name: A scalar (0-D Tensor) of strings (optional), the name of\n",
      "            the serialized proto.\n",
      "          name: A name for this operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A tuple of two `dict`s, each mapping keys to `Tensor`s and `SparseTensor`s.\n",
      "          The first dict contains the context key/values.\n",
      "          The second dict contains the feature_list key/values.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: if any feature is invalid.\n",
      "    \n",
      "    parse_tensor(serialized, out_type, name=None)\n",
      "        Transforms a serialized tensorflow.TensorProto proto into a Tensor.\n",
      "        \n",
      "        Args:\n",
      "          serialized: A `Tensor` of type `string`.\n",
      "            A scalar string containing a serialized TensorProto proto.\n",
      "          out_type: A `tf.DType`.\n",
      "            The type of the serialized tensor.  The provided type must match the\n",
      "            type of the serialized tensor and no implicit conversion will take place.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `out_type`.\n",
      "    \n",
      "    placeholder(dtype, shape=None, name=None)\n",
      "        Inserts a placeholder for a tensor that will be always fed.\n",
      "        \n",
      "        **Important**: This tensor will produce an error if evaluated. Its value must\n",
      "        be fed using the `feed_dict` optional argument to `Session.run()`,\n",
      "        `Tensor.eval()`, or `Operation.run()`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.compat.v1.placeholder(tf.float32, shape=(1024, 1024))\n",
      "        y = tf.matmul(x, x)\n",
      "        \n",
      "        with tf.compat.v1.Session() as sess:\n",
      "          print(sess.run(y))  # ERROR: will fail because x was not fed.\n",
      "        \n",
      "          rand_array = np.random.rand(1024, 1024)\n",
      "          print(sess.run(y, feed_dict={x: rand_array}))  # Will succeed.\n",
      "        ```\n",
      "        \n",
      "        @compatibility(eager)\n",
      "        Placeholders are not compatible with eager execution.\n",
      "        @end_compatibility\n",
      "        \n",
      "        Args:\n",
      "          dtype: The type of elements in the tensor to be fed.\n",
      "          shape: The shape of the tensor to be fed (optional). If the shape is not\n",
      "            specified, you can feed a tensor of any shape.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` that may be used as a handle for feeding a value, but not\n",
      "          evaluated directly.\n",
      "        \n",
      "        Raises:\n",
      "          RuntimeError: if eager execution is enabled\n",
      "    \n",
      "    placeholder_with_default(input, shape, name=None)\n",
      "        A placeholder op that passes through `input` when its output is not fed.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. The default value to produce when output is not fed.\n",
      "          shape: A `tf.TensorShape` or list of `int`s. The (possibly partial) shape of\n",
      "            the tensor.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    polygamma(a, x, name=None)\n",
      "        Compute the polygamma function \\\\(\\psi^{(n)}(x)\\\\).\n",
      "        \n",
      "        The polygamma function is defined as:\n",
      "        \n",
      "        \n",
      "        \\\\(\\psi^{(a)}(x) = \\frac{d^a}{dx^a} \\psi(x)\\\\)\n",
      "        \n",
      "        where \\\\(\\psi(x)\\\\) is the digamma function.\n",
      "        The polygamma function is defined only for non-negative integer orders \\\\a\\\\.\n",
      "        \n",
      "        Args:\n",
      "          a: A `Tensor`. Must be one of the following types: `float32`, `float64`.\n",
      "          x: A `Tensor`. Must have the same type as `a`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `a`.\n",
      "    \n",
      "    pow(x, y, name=None)\n",
      "        Computes the power of one value to another.\n",
      "        \n",
      "        Given a tensor `x` and a tensor `y`, this operation computes \\\\(x^y\\\\) for\n",
      "        corresponding elements in `x` and `y`. For example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([[2, 2], [3, 3]])\n",
      "        y = tf.constant([[8, 16], [2, 3]])\n",
      "        tf.pow(x, y)  # [[256, 65536], [9, 27]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor` of type `float16`, `float32`, `float64`, `int32`, `int64`,\n",
      "            `complex64`, or `complex128`.\n",
      "          y: A `Tensor` of type `float16`, `float32`, `float64`, `int32`, `int64`,\n",
      "            `complex64`, or `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`.\n",
      "    \n",
      "    print = print_v2(*inputs, **kwargs)\n",
      "        Print the specified inputs.\n",
      "        \n",
      "        A TensorFlow operator that prints the specified inputs to a desired\n",
      "        output stream or logging level. The inputs may be dense or sparse Tensors,\n",
      "        primitive python objects, data structures that contain tensors, and printable\n",
      "        Python objects. Printed tensors will recursively show the first and last\n",
      "        elements of each dimension to summarize.\n",
      "        \n",
      "        @compatibility(python2)\n",
      "        In python 2.7, make sure to import the following:\n",
      "        `from __future__ import print_function`\n",
      "        @end_compatibility\n",
      "        \n",
      "        Example:\n",
      "          Single-input usage:\n",
      "        \n",
      "          ```python\n",
      "          tensor = tf.range(10)\n",
      "          tf.print(tensor, output_stream=sys.stderr)\n",
      "          ```\n",
      "        \n",
      "          (This prints \"[0 1 2 ... 7 8 9]\" to sys.stderr)\n",
      "        \n",
      "          Multi-input usage:\n",
      "        \n",
      "          ```python\n",
      "          tensor = tf.range(10)\n",
      "          tf.print(\"tensors:\", tensor, {2: tensor * 2}, output_stream=sys.stdout)\n",
      "          ```\n",
      "        \n",
      "          (This prints \"tensors: [0 1 2 ... 7 8 9] {2: [0 2 4 ... 14 16 18]}\" to\n",
      "          sys.stdout)\n",
      "        \n",
      "          Changing the input separator:\n",
      "          ```python\n",
      "          tensor_a = tf.range(2)\n",
      "          tensor_b = tensor_a * 2\n",
      "          tf.print(tensor_a, tensor_b, output_stream=sys.stderr, sep=',')\n",
      "          ```\n",
      "        \n",
      "          (This prints \"[0 1],[0 2]\" to sys.stderr)\n",
      "        \n",
      "          Usage in a `tf.function`:\n",
      "        \n",
      "          ```python\n",
      "          @tf.function\n",
      "          def f():\n",
      "              tensor = tf.range(10)\n",
      "              tf.print(tensor, output_stream=sys.stderr)\n",
      "              return tensor\n",
      "        \n",
      "          range_tensor = f()\n",
      "          ```\n",
      "        \n",
      "          (This prints \"[0 1 2 ... 7 8 9]\" to sys.stderr)\n",
      "        \n",
      "        @compatibility(TF 1.x Graphs and Sessions)\n",
      "        In graphs manually created outside of `tf.function`, this method returns\n",
      "        the created TF operator that prints the data. To make sure the\n",
      "        operator runs, users need to pass the produced op to\n",
      "        `tf.compat.v1.Session`'s run method, or to use the op as a control\n",
      "        dependency for executed ops by specifying\n",
      "        `with tf.compat.v1.control_dependencies([print_op])`.\n",
      "        @end_compatibility\n",
      "        \n",
      "          Compatibility usage in TF 1.x graphs:\n",
      "        \n",
      "          ```python\n",
      "          sess = tf.compat.v1.Session()\n",
      "          with sess.as_default():\n",
      "              tensor = tf.range(10)\n",
      "              print_op = tf.print(\"tensors:\", tensor, {2: tensor * 2},\n",
      "                                  output_stream=sys.stdout)\n",
      "              with tf.control_dependencies([print_op]):\n",
      "                tripled_tensor = tensor * 3\n",
      "              sess.run(tripled_tensor)\n",
      "          ```\n",
      "        \n",
      "          (This prints \"tensors: [0 1 2 ... 7 8 9] {2: [0 2 4 ... 14 16 18]}\" to\n",
      "          sys.stdout)\n",
      "        \n",
      "        Note: In Jupyter notebooks and colabs, `tf.print` prints to the notebook\n",
      "          cell outputs. It will not write to the notebook kernel's console logs.\n",
      "        \n",
      "        Args:\n",
      "          *inputs: Positional arguments that are the inputs to print. Inputs in the\n",
      "            printed output will be separated by spaces. Inputs may be python\n",
      "            primitives, tensors, data structures such as dicts and lists that may\n",
      "            contain tensors (with the data structures possibly nested in arbitrary\n",
      "            ways), and printable python objects.\n",
      "          output_stream: The output stream, logging level, or file to print to.\n",
      "            Defaults to sys.stderr, but sys.stdout, tf.compat.v1.logging.info,\n",
      "            tf.compat.v1.logging.warning, tf.compat.v1.logging.error,\n",
      "            absl.logging.info, absl.logging.warning and absl.loogging,error are also\n",
      "            supported. To print to a file, pass a string started with \"file://\"\n",
      "            followed by the file path, e.g., \"file:///tmp/foo.out\".\n",
      "          summarize: The first and last `summarize` elements within each dimension are\n",
      "            recursively printed per Tensor. If None, then the first 3 and last 3\n",
      "            elements of each dimension are printed for each tensor. If set to -1, it\n",
      "            will print all elements of every tensor.\n",
      "          sep: The string to use to separate the inputs. Defaults to \" \".\n",
      "          end: End character that is appended at the end the printed string.\n",
      "            Defaults to the newline character.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          None when executing eagerly. During graph tracing this returns\n",
      "          a TF operator that prints the specified inputs in the specified output\n",
      "          stream or logging level. This operator will be automatically executed\n",
      "          except inside of `tf.compat.v1` graphs and sessions.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If an unsupported output stream is specified.\n",
      "    \n",
      "    py_func(func, inp, Tout, stateful=True, name=None)\n",
      "        Wraps a python function and uses it as a TensorFlow op.\n",
      "        \n",
      "        Given a python function `func`, which takes numpy arrays as its\n",
      "        arguments and returns numpy arrays as its outputs, wrap this function as an\n",
      "        operation in a TensorFlow graph. The following snippet constructs a simple\n",
      "        TensorFlow graph that invokes the `np.sinh()` NumPy function as a operation\n",
      "        in the graph:\n",
      "        \n",
      "        ```python\n",
      "        def my_func(x):\n",
      "          # x will be a numpy array with the contents of the placeholder below\n",
      "          return np.sinh(x)\n",
      "        input = tf.compat.v1.placeholder(tf.float32)\n",
      "        y = tf.compat.v1.py_func(my_func, [input], tf.float32)\n",
      "        ```\n",
      "        \n",
      "        **N.B.** The `tf.compat.v1.py_func()` operation has the following known\n",
      "        limitations:\n",
      "        \n",
      "        * The body of the function (i.e. `func`) will not be serialized in a\n",
      "          `GraphDef`. Therefore, you should not use this function if you need to\n",
      "          serialize your model and restore it in a different environment.\n",
      "        \n",
      "        * The operation must run in the same address space as the Python program\n",
      "          that calls `tf.compat.v1.py_func()`. If you are using distributed\n",
      "          TensorFlow, you\n",
      "          must run a `tf.distribute.Server` in the same process as the program that\n",
      "          calls\n",
      "          `tf.compat.v1.py_func()` and you must pin the created operation to a device\n",
      "          in that\n",
      "          server (e.g. using `with tf.device():`).\n",
      "        \n",
      "        Args:\n",
      "          func: A Python function, which accepts `ndarray` objects as arguments and\n",
      "            returns a list of `ndarray` objects (or a single `ndarray`). This function\n",
      "            must accept as many arguments as there are tensors in `inp`, and these\n",
      "            argument types will match the corresponding `tf.Tensor` objects in `inp`.\n",
      "            The returns `ndarray`s must match the number and types defined `Tout`.\n",
      "            Important Note: Input and output numpy `ndarray`s of `func` are not\n",
      "              guaranteed to be copies. In some cases their underlying memory will be\n",
      "              shared with the corresponding TensorFlow tensors. In-place modification\n",
      "              or storing `func` input or return values in python datastructures\n",
      "              without explicit (np.)copy can have non-deterministic consequences.\n",
      "          inp: A list of `Tensor` objects.\n",
      "          Tout: A list or tuple of tensorflow data types or a single tensorflow data\n",
      "            type if there is only one, indicating what `func` returns.\n",
      "          stateful: (Boolean.) If True, the function should be considered stateful. If\n",
      "            a function is stateless, when given the same input it will return the same\n",
      "            output and have no observable side effects. Optimizations such as common\n",
      "            subexpression elimination are only performed on stateless operations.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A list of `Tensor` or a single `Tensor` which `func` computes.\n",
      "    \n",
      "    py_function = eager_py_func(func, inp, Tout, name=None)\n",
      "        Wraps a python function into a TensorFlow op that executes it eagerly.\n",
      "        \n",
      "        This function allows expressing computations in a TensorFlow graph as\n",
      "        Python functions. In particular, it wraps a Python function `func`\n",
      "        in a once-differentiable TensorFlow operation that executes it with eager\n",
      "        execution enabled. As a consequence, `tf.py_function` makes it\n",
      "        possible to express control flow using Python constructs (`if`, `while`,\n",
      "        `for`, etc.), instead of TensorFlow control flow constructs (`tf.cond`,\n",
      "        `tf.while_loop`). For example, you might use `tf.py_function` to\n",
      "        implement the log huber function:\n",
      "        \n",
      "        ```python\n",
      "        def log_huber(x, m):\n",
      "          if tf.abs(x) <= m:\n",
      "            return x**2\n",
      "          else:\n",
      "            return m**2 * (1 - 2 * tf.math.log(m) + tf.math.log(x**2))\n",
      "        \n",
      "        x = tf.compat.v1.placeholder(tf.float32)\n",
      "        m = tf.compat.v1.placeholder(tf.float32)\n",
      "        \n",
      "        y = tf.py_function(func=log_huber, inp=[x, m], Tout=tf.float32)\n",
      "        dy_dx = tf.gradients(y, x)[0]\n",
      "        \n",
      "        with tf.compat.v1.Session() as sess:\n",
      "          # The session executes `log_huber` eagerly. Given the feed values below,\n",
      "          # it will take the first branch, so `y` evaluates to 1.0 and\n",
      "          # `dy_dx` evaluates to 2.0.\n",
      "          y, dy_dx = sess.run([y, dy_dx], feed_dict={x: 1.0, m: 2.0})\n",
      "        ```\n",
      "        \n",
      "        You can also use `tf.py_function` to debug your models at runtime\n",
      "        using Python tools, i.e., you can isolate portions of your code that\n",
      "        you want to debug, wrap them in Python functions and insert `pdb` tracepoints\n",
      "        or print statements as desired, and wrap those functions in\n",
      "        `tf.py_function`.\n",
      "        \n",
      "        For more information on eager execution, see the\n",
      "        [Eager guide](https://tensorflow.org/guide/eager).\n",
      "        \n",
      "        `tf.py_function` is similar in spirit to `tf.compat.v1.py_func`, but unlike\n",
      "        the latter, the former lets you use TensorFlow operations in the wrapped\n",
      "        Python function. In particular, while `tf.compat.v1.py_func` only runs on CPUs\n",
      "        and\n",
      "        wraps functions that take NumPy arrays as inputs and return NumPy arrays as\n",
      "        outputs, `tf.py_function` can be placed on GPUs and wraps functions\n",
      "        that take Tensors as inputs, execute TensorFlow operations in their bodies,\n",
      "        and return Tensors as outputs.\n",
      "        \n",
      "        Like `tf.compat.v1.py_func`, `tf.py_function` has the following limitations\n",
      "        with respect to serialization and distribution:\n",
      "        \n",
      "        * The body of the function (i.e. `func`) will not be serialized in a\n",
      "          `GraphDef`. Therefore, you should not use this function if you need to\n",
      "          serialize your model and restore it in a different environment.\n",
      "        \n",
      "        * The operation must run in the same address space as the Python program\n",
      "          that calls `tf.py_function()`. If you are using distributed\n",
      "          TensorFlow, you must run a `tf.distribute.Server` in the same process as the\n",
      "          program that calls `tf.py_function()` and you must pin the created\n",
      "          operation to a device in that server (e.g. using `with tf.device():`).\n",
      "        \n",
      "        \n",
      "        Args:\n",
      "          func: A Python function which accepts a list of `Tensor` objects having\n",
      "            element types that match the corresponding `tf.Tensor` objects in `inp`\n",
      "            and returns a list of `Tensor` objects (or a single `Tensor`, or `None`)\n",
      "            having element types that match the corresponding values in `Tout`.\n",
      "          inp: A list of `Tensor` objects.\n",
      "          Tout: A list or tuple of tensorflow data types or a single tensorflow data\n",
      "            type if there is only one, indicating what `func` returns; an empty list\n",
      "            if no value is returned (i.e., if the return value is `None`).\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A list of `Tensor` or a single `Tensor` which `func` computes; an empty list\n",
      "          if `func` returns None.\n",
      "    \n",
      "    qr(input, full_matrices=False, name=None)\n",
      "        Computes the QR decompositions of one or more matrices.\n",
      "        \n",
      "        Computes the QR decomposition of each inner matrix in `tensor` such that\n",
      "        `tensor[..., :, :] = q[..., :, :] * r[..., :,:])`\n",
      "        \n",
      "        ```python\n",
      "        # a is a tensor.\n",
      "        # q is a tensor of orthonormal matrices.\n",
      "        # r is a tensor of upper triangular matrices.\n",
      "        q, r = qr(a)\n",
      "        q_full, r_full = qr(a, full_matrices=True)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must be one of the following types: `float64`, `float32`, `half`, `complex64`, `complex128`.\n",
      "            A tensor of shape `[..., M, N]` whose inner-most 2 dimensions\n",
      "            form matrices of size `[M, N]`. Let `P` be the minimum of `M` and `N`.\n",
      "          full_matrices: An optional `bool`. Defaults to `False`.\n",
      "            If true, compute full-sized `q` and `r`. If false\n",
      "            (the default), compute only the leading `P` columns of `q`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A tuple of `Tensor` objects (q, r).\n",
      "        \n",
      "          q: A `Tensor`. Has the same type as `input`.\n",
      "          r: A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    quantize(input, min_range, max_range, T, mode='MIN_COMBINED', round_mode='HALF_AWAY_FROM_ZERO', name=None)\n",
      "        Quantize the 'input' tensor of type float to 'output' tensor of type 'T'.\n",
      "        \n",
      "        [min_range, max_range] are scalar floats that specify the range for\n",
      "        the 'input' data. The 'mode' attribute controls exactly which calculations are\n",
      "        used to convert the float values to their quantized equivalents.  The\n",
      "        'round_mode' attribute controls which rounding tie-breaking algorithm is used\n",
      "        when rounding float values to their quantized equivalents.\n",
      "        \n",
      "        In 'MIN_COMBINED' mode, each value of the tensor will undergo the following:\n",
      "        \n",
      "        ```\n",
      "        out[i] = (in[i] - min_range) * range(T) / (max_range - min_range)\n",
      "        if T == qint8: out[i] -= (range(T) + 1) / 2.0\n",
      "        ```\n",
      "        \n",
      "        here `range(T) = numeric_limits<T>::max() - numeric_limits<T>::min()`\n",
      "        \n",
      "        *MIN_COMBINED Mode Example*\n",
      "        \n",
      "        Assume the input is type float and has a possible range of [0.0, 6.0] and the\n",
      "        output type is quint8 ([0, 255]). The min_range and max_range values should be\n",
      "        specified as 0.0 and 6.0. Quantizing from float to quint8 will multiply each\n",
      "        value of the input by 255/6 and cast to quint8.\n",
      "        \n",
      "        If the output type was qint8 ([-128, 127]), the operation will additionally\n",
      "        subtract each value by 128 prior to casting, so that the range of values aligns\n",
      "        with the range of qint8.\n",
      "        \n",
      "        If the mode is 'MIN_FIRST', then this approach is used:\n",
      "        \n",
      "        ```\n",
      "        num_discrete_values = 1 << (# of bits in T)\n",
      "        range_adjust = num_discrete_values / (num_discrete_values - 1)\n",
      "        range = (range_max - range_min) * range_adjust\n",
      "        range_scale = num_discrete_values / range\n",
      "        quantized = round(input * range_scale) - round(range_min * range_scale) +\n",
      "          numeric_limits<T>::min()\n",
      "        quantized = max(quantized, numeric_limits<T>::min())\n",
      "        quantized = min(quantized, numeric_limits<T>::max())\n",
      "        ```\n",
      "        \n",
      "        The biggest difference between this and MIN_COMBINED is that the minimum range\n",
      "        is rounded first, before it's subtracted from the rounded value. With\n",
      "        MIN_COMBINED, a small bias is introduced where repeated iterations of quantizing\n",
      "        and dequantizing will introduce a larger and larger error.\n",
      "        \n",
      "        *SCALED mode Example*\n",
      "        \n",
      "        `SCALED` mode matches the quantization approach used in\n",
      "        `QuantizeAndDequantize{V2|V3}`.\n",
      "        \n",
      "        If the mode is `SCALED`, we do not use the full range of the output type,\n",
      "        choosing to elide the lowest possible value for symmetry (e.g., output range is\n",
      "        -127 to 127, not -128 to 127 for signed 8 bit quantization), so that 0.0 maps to\n",
      "        0.\n",
      "        \n",
      "        We first find the range of values in our tensor. The\n",
      "        range we use is always centered on 0, so we find m such that\n",
      "        \n",
      "        ```c++\n",
      "          m = max(abs(input_min), abs(input_max))\n",
      "        ```\n",
      "        \n",
      "        Our input tensor range is then `[-m, m]`.\n",
      "        \n",
      "        Next, we choose our fixed-point quantization buckets, `[min_fixed, max_fixed]`.\n",
      "        If T is signed, this is\n",
      "        \n",
      "        ```\n",
      "          num_bits = sizeof(T) * 8\n",
      "          [min_fixed, max_fixed] =\n",
      "              [-(1 << (num_bits - 1) - 1), (1 << (num_bits - 1)) - 1]\n",
      "        ```\n",
      "        \n",
      "        Otherwise, if T is unsigned, the fixed-point range is\n",
      "        \n",
      "        ```\n",
      "          [min_fixed, max_fixed] = [0, (1 << num_bits) - 1]\n",
      "        ```\n",
      "        \n",
      "        From this we compute our scaling factor, s:\n",
      "        \n",
      "        ```c++\n",
      "          s = (max_fixed - min_fixed) / (2 * m)\n",
      "        ```\n",
      "        \n",
      "        Now we can quantize the elements of our tensor:\n",
      "        \n",
      "        ```c++\n",
      "        result = round(input * s)\n",
      "        ```\n",
      "        \n",
      "        One thing to watch out for is that the operator may choose to adjust the\n",
      "        requested minimum and maximum values slightly during the quantization process,\n",
      "        so you should always use the output ports as the range for further calculations.\n",
      "        For example, if the requested minimum and maximum values are close to equal,\n",
      "        they will be separated by a small epsilon value to prevent ill-formed quantized\n",
      "        buffers from being created. Otherwise, you can end up with buffers where all the\n",
      "        quantized values map to the same float value, which causes problems for\n",
      "        operations that have to perform further calculations on them.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor` of type `float32`.\n",
      "          min_range: A `Tensor` of type `float32`.\n",
      "            The minimum scalar value possibly produced for the input.\n",
      "          max_range: A `Tensor` of type `float32`.\n",
      "            The maximum scalar value possibly produced for the input.\n",
      "          T: A `tf.DType` from: `tf.qint8, tf.quint8, tf.qint32, tf.qint16, tf.quint16`.\n",
      "          mode: An optional `string` from: `\"MIN_COMBINED\", \"MIN_FIRST\", \"SCALED\"`. Defaults to `\"MIN_COMBINED\"`.\n",
      "          round_mode: An optional `string` from: `\"HALF_AWAY_FROM_ZERO\", \"HALF_TO_EVEN\"`. Defaults to `\"HALF_AWAY_FROM_ZERO\"`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A tuple of `Tensor` objects (output, output_min, output_max).\n",
      "        \n",
      "          output: A `Tensor` of type `T`.\n",
      "          output_min: A `Tensor` of type `float32`.\n",
      "          output_max: A `Tensor` of type `float32`.\n",
      "    \n",
      "    quantize_v2(input, min_range, max_range, T, mode='MIN_COMBINED', name=None, round_mode='HALF_AWAY_FROM_ZERO')\n",
      "        Please use `tf.quantization.quantize` instead.\n",
      "    \n",
      "    quantized_concat(concat_dim, values, input_mins, input_maxes, name=None)\n",
      "        Concatenates quantized tensors along one dimension.\n",
      "        \n",
      "        Args:\n",
      "          concat_dim: A `Tensor` of type `int32`.\n",
      "            0-D.  The dimension along which to concatenate.  Must be in the\n",
      "            range [0, rank(values)).\n",
      "          values: A list of at least 2 `Tensor` objects with the same type.\n",
      "            The `N` Tensors to concatenate. Their ranks and types must match,\n",
      "            and their sizes must match in all dimensions except `concat_dim`.\n",
      "          input_mins: A list with the same length as `values` of `Tensor` objects with type `float32`.\n",
      "            The minimum scalar values for each of the input tensors.\n",
      "          input_maxes: A list with the same length as `values` of `Tensor` objects with type `float32`.\n",
      "            The maximum scalar values for each of the input tensors.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A tuple of `Tensor` objects (output, output_min, output_max).\n",
      "        \n",
      "          output: A `Tensor`. Has the same type as `values`.\n",
      "          output_min: A `Tensor` of type `float32`.\n",
      "          output_max: A `Tensor` of type `float32`.\n",
      "    \n",
      "    random_crop(value, size, seed=None, name=None)\n",
      "        Randomly crops a tensor to a given size.\n",
      "        \n",
      "        Slices a shape `size` portion out of `value` at a uniformly chosen offset.\n",
      "        Requires `value.shape >= size`.\n",
      "        \n",
      "        If a dimension should not be cropped, pass the full size of that dimension.\n",
      "        For example, RGB images can be cropped with\n",
      "        `size = [crop_height, crop_width, 3]`.\n",
      "        \n",
      "        Args:\n",
      "          value: Input tensor to crop.\n",
      "          size: 1-D tensor with size the rank of `value`.\n",
      "          seed: Python integer. Used to create a random seed. See\n",
      "            `tf.compat.v1.set_random_seed`\n",
      "            for behavior.\n",
      "          name: A name for this operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A cropped tensor of the same rank as `value` and shape `size`.\n",
      "    \n",
      "    random_gamma(shape, alpha, beta=None, dtype=tf.float32, seed=None, name=None)\n",
      "        Draws `shape` samples from each of the given Gamma distribution(s).\n",
      "        \n",
      "        `alpha` is the shape parameter describing the distribution(s), and `beta` is\n",
      "        the inverse scale parameter(s).\n",
      "        \n",
      "        Note: Because internal calculations are done using `float64` and casting has\n",
      "        `floor` semantics, we must manually map zero outcomes to the smallest\n",
      "        possible positive floating-point value, i.e., `np.finfo(dtype).tiny`.  This\n",
      "        means that `np.finfo(dtype).tiny` occurs more frequently than it otherwise\n",
      "        should.  This bias can only happen for small values of `alpha`, i.e.,\n",
      "        `alpha << 1` or large values of `beta`, i.e., `beta >> 1`.\n",
      "        \n",
      "        The samples are differentiable w.r.t. alpha and beta.\n",
      "        The derivatives are computed using the approach described in the paper\n",
      "        \n",
      "        [Michael Figurnov, Shakir Mohamed, Andriy Mnih.\n",
      "        Implicit Reparameterization Gradients, 2018](https://arxiv.org/abs/1805.08498)\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        ```python\n",
      "        samples = tf.random.gamma([10], [0.5, 1.5])\n",
      "        # samples has shape [10, 2], where each slice [:, 0] and [:, 1] represents\n",
      "        # the samples drawn from each distribution\n",
      "        \n",
      "        samples = tf.random.gamma([7, 5], [0.5, 1.5])\n",
      "        # samples has shape [7, 5, 2], where each slice [:, :, 0] and [:, :, 1]\n",
      "        # represents the 7x5 samples drawn from each of the two distributions\n",
      "        \n",
      "        alpha = tf.constant([[1.],[3.],[5.]])\n",
      "        beta = tf.constant([[3., 4.]])\n",
      "        samples = tf.random.gamma([30], alpha=alpha, beta=beta)\n",
      "        # samples has shape [30, 3, 2], with 30 samples each of 3x2 distributions.\n",
      "        \n",
      "        loss = tf.reduce_mean(tf.square(samples))\n",
      "        dloss_dalpha, dloss_dbeta = tf.gradients(loss, [alpha, beta])\n",
      "        # unbiased stochastic derivatives of the loss function\n",
      "        alpha.shape == dloss_dalpha.shape  # True\n",
      "        beta.shape == dloss_dbeta.shape  # True\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          shape: A 1-D integer Tensor or Python array. The shape of the output samples\n",
      "            to be drawn per alpha/beta-parameterized distribution.\n",
      "          alpha: A Tensor or Python value or N-D array of type `dtype`. `alpha`\n",
      "            provides the shape parameter(s) describing the gamma distribution(s) to\n",
      "            sample. Must be broadcastable with `beta`.\n",
      "          beta: A Tensor or Python value or N-D array of type `dtype`. Defaults to 1.\n",
      "            `beta` provides the inverse scale parameter(s) of the gamma\n",
      "            distribution(s) to sample. Must be broadcastable with `alpha`.\n",
      "          dtype: The type of alpha, beta, and the output: `float16`, `float32`, or\n",
      "            `float64`.\n",
      "          seed: A Python integer. Used to create a random seed for the distributions.\n",
      "            See\n",
      "            `tf.compat.v1.set_random_seed`\n",
      "            for behavior.\n",
      "          name: Optional name for the operation.\n",
      "        \n",
      "        Returns:\n",
      "          samples: a `Tensor` of shape\n",
      "            `tf.concat([shape, tf.shape(alpha + beta)], axis=0)` with values of type\n",
      "            `dtype`.\n",
      "    \n",
      "    random_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)\n",
      "        Outputs random values from a normal distribution.\n",
      "        \n",
      "        Args:\n",
      "          shape: A 1-D integer Tensor or Python array. The shape of the output tensor.\n",
      "          mean: A 0-D Tensor or Python value of type `dtype`. The mean of the normal\n",
      "            distribution.\n",
      "          stddev: A 0-D Tensor or Python value of type `dtype`. The standard deviation\n",
      "            of the normal distribution.\n",
      "          dtype: The type of the output.\n",
      "          seed: A Python integer. Used to create a random seed for the distribution.\n",
      "            See\n",
      "            `tf.compat.v1.set_random_seed`\n",
      "            for behavior.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A tensor of the specified shape filled with random normal values.\n",
      "    \n",
      "    random_poisson(lam, shape, dtype=tf.float32, seed=None, name=None)\n",
      "        Draws `shape` samples from each of the given Poisson distribution(s).\n",
      "        \n",
      "        `lam` is the rate parameter describing the distribution(s).\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        ```python\n",
      "        samples = tf.random.poisson([0.5, 1.5], [10])\n",
      "        # samples has shape [10, 2], where each slice [:, 0] and [:, 1] represents\n",
      "        # the samples drawn from each distribution\n",
      "        \n",
      "        samples = tf.random.poisson([12.2, 3.3], [7, 5])\n",
      "        # samples has shape [7, 5, 2], where each slice [:, :, 0] and [:, :, 1]\n",
      "        # represents the 7x5 samples drawn from each of the two distributions\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          lam: A Tensor or Python value or N-D array of type `dtype`.\n",
      "            `lam` provides the rate parameter(s) describing the poisson\n",
      "            distribution(s) to sample.\n",
      "          shape: A 1-D integer Tensor or Python array. The shape of the output samples\n",
      "            to be drawn per \"rate\"-parameterized distribution.\n",
      "          dtype: The type of the output: `float16`, `float32`, `float64`, `int32` or\n",
      "            `int64`.\n",
      "          seed: A Python integer. Used to create a random seed for the distributions.\n",
      "            See\n",
      "            `tf.compat.v1.set_random_seed`\n",
      "            for behavior.\n",
      "          name: Optional name for the operation.\n",
      "        \n",
      "        Returns:\n",
      "          samples: a `Tensor` of shape `tf.concat([shape, tf.shape(lam)], axis=0)`\n",
      "            with values of type `dtype`.\n",
      "    \n",
      "    random_shuffle(value, seed=None, name=None)\n",
      "        Randomly shuffles a tensor along its first dimension.\n",
      "        \n",
      "        The tensor is shuffled along dimension 0, such that each `value[j]` is mapped\n",
      "        to one and only one `output[i]`. For example, a mapping that might occur for a\n",
      "        3x2 tensor is:\n",
      "        \n",
      "        ```python\n",
      "        [[1, 2],       [[5, 6],\n",
      "         [3, 4],  ==>   [1, 2],\n",
      "         [5, 6]]        [3, 4]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          value: A Tensor to be shuffled.\n",
      "          seed: A Python integer. Used to create a random seed for the distribution.\n",
      "            See\n",
      "            `tf.compat.v1.set_random_seed`\n",
      "            for behavior.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A tensor of same shape and type as `value`, shuffled along its first\n",
      "          dimension.\n",
      "    \n",
      "    random_uniform(shape, minval=0, maxval=None, dtype=tf.float32, seed=None, name=None)\n",
      "        Outputs random values from a uniform distribution.\n",
      "        \n",
      "        The generated values follow a uniform distribution in the range\n",
      "        `[minval, maxval)`. The lower bound `minval` is included in the range, while\n",
      "        the upper bound `maxval` is excluded.\n",
      "        \n",
      "        For floats, the default range is `[0, 1)`.  For ints, at least `maxval` must\n",
      "        be specified explicitly.\n",
      "        \n",
      "        In the integer case, the random integers are slightly biased unless\n",
      "        `maxval - minval` is an exact power of two.  The bias is small for values of\n",
      "        `maxval - minval` significantly smaller than the range of the output (either\n",
      "        `2**32` or `2**64`).\n",
      "        \n",
      "        Args:\n",
      "          shape: A 1-D integer Tensor or Python array. The shape of the output tensor.\n",
      "          minval: A 0-D Tensor or Python value of type `dtype`. The lower bound on the\n",
      "            range of random values to generate.  Defaults to 0.\n",
      "          maxval: A 0-D Tensor or Python value of type `dtype`. The upper bound on\n",
      "            the range of random values to generate.  Defaults to 1 if `dtype` is\n",
      "            floating point.\n",
      "          dtype: The type of the output: `float16`, `float32`, `float64`, `int32`,\n",
      "            or `int64`.\n",
      "          seed: A Python integer. Used to create a random seed for the distribution.\n",
      "            See `tf.compat.v1.set_random_seed`\n",
      "            for behavior.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A tensor of the specified shape filled with random uniform values.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If `dtype` is integral and `maxval` is not specified.\n",
      "    \n",
      "    range(start, limit=None, delta=1, dtype=None, name='range')\n",
      "        Creates a sequence of numbers.\n",
      "        \n",
      "        Creates a sequence of numbers that begins at `start` and extends by\n",
      "        increments of `delta` up to but not including `limit`.\n",
      "        \n",
      "        The dtype of the resulting tensor is inferred from the inputs unless\n",
      "        it is provided explicitly.\n",
      "        \n",
      "        Like the Python builtin `range`, `start` defaults to 0, so that\n",
      "        `range(n) = range(0, n)`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        start = 3\n",
      "        limit = 18\n",
      "        delta = 3\n",
      "        tf.range(start, limit, delta)  # [3, 6, 9, 12, 15]\n",
      "        \n",
      "        start = 3\n",
      "        limit = 1\n",
      "        delta = -0.5\n",
      "        tf.range(start, limit, delta)  # [3, 2.5, 2, 1.5]\n",
      "        \n",
      "        limit = 5\n",
      "        tf.range(limit)  # [0, 1, 2, 3, 4]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          start: A 0-D `Tensor` (scalar). Acts as first entry in the range if `limit`\n",
      "            is not None; otherwise, acts as range limit and first entry defaults to 0.\n",
      "          limit: A 0-D `Tensor` (scalar). Upper limit of sequence, exclusive. If None,\n",
      "            defaults to the value of `start` while the first entry of the range\n",
      "            defaults to 0.\n",
      "          delta: A 0-D `Tensor` (scalar). Number that increments `start`. Defaults to\n",
      "            1.\n",
      "          dtype: The type of the elements of the resulting tensor.\n",
      "          name: A name for the operation. Defaults to \"range\".\n",
      "        \n",
      "        Returns:\n",
      "          An 1-D `Tensor` of type `dtype`.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Equivalent to np.arange\n",
      "        @end_compatibility\n",
      "    \n",
      "    rank(input, name=None)\n",
      "        Returns the rank of a tensor.\n",
      "        \n",
      "        Returns a 0-D `int32` `Tensor` representing the rank of `input`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        # shape of tensor 't' is [2, 2, 3]\n",
      "        t = tf.constant([[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]])\n",
      "        tf.rank(t)  # 3\n",
      "        ```\n",
      "        \n",
      "        **Note**: The rank of a tensor is not the same as the rank of a matrix. The\n",
      "        rank of a tensor is the number of indices required to uniquely select each\n",
      "        element of the tensor. Rank is also known as \"order\", \"degree\", or \"ndims.\"\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor` or `SparseTensor`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `int32`.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Equivalent to np.ndim\n",
      "        @end_compatibility\n",
      "    \n",
      "    read_file(filename, name=None)\n",
      "        Reads and outputs the entire contents of the input filename.\n",
      "        \n",
      "        Args:\n",
      "          filename: A `Tensor` of type `string`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `string`.\n",
      "    \n",
      "    real(input, name=None)\n",
      "        Returns the real part of a complex (or real) tensor.\n",
      "        \n",
      "        Given a tensor `input`, this operation returns a tensor of type `float` that\n",
      "        is the real part of each element in `input` considered as a complex number.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([-2.25 + 4.75j, 3.25 + 5.75j])\n",
      "        tf.math.real(x)  # [-2.25, 3.25]\n",
      "        ```\n",
      "        \n",
      "        If `input` is already real, it is returned unchanged.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. Must have numeric type.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `float32` or `float64`.\n",
      "    \n",
      "    realdiv = real_div(x, y, name=None)\n",
      "        Returns x / y element-wise for real types.\n",
      "        \n",
      "        If `x` and `y` are reals, this will return the floating-point division.\n",
      "        \n",
      "        *NOTE*: `Div` supports broadcasting. More about broadcasting\n",
      "        [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`, `int16`, `int32`, `int64`, `complex64`, `complex128`.\n",
      "          y: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    reciprocal(x, name=None)\n",
      "        Computes the reciprocal of x element-wise.\n",
      "        \n",
      "        I.e., \\\\(y = 1 / x\\\\).\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int32`, `int64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    recompute_grad(f)\n",
      "        An eager-compatible version of recompute_grad.\n",
      "        \n",
      "        For f(*args, **kwargs), this supports gradients with respect to args, or to\n",
      "        gradients with respect to any variables residing in the kwarg 'variables'.\n",
      "        Note that for keras layer and model objects, this is handled automatically.\n",
      "        \n",
      "        Warning: If `f` was originally a tf.keras Model or Layer object, `g` will not\n",
      "        be able to access the member variables of that object, because `g` returns\n",
      "        through the wrapper function `inner`.  When recomputing gradients through\n",
      "        objects that inherit from keras, we suggest keeping a reference to the\n",
      "        underlying object around for the purpose of accessing these variables.\n",
      "        \n",
      "        Args:\n",
      "          f: function `f(*x)` that returns a `Tensor` or sequence of `Tensor` outputs.\n",
      "        \n",
      "        Returns:\n",
      "         A function `g` that wraps `f`, but which recomputes `f` on the backwards\n",
      "         pass of a gradient call.\n",
      "    \n",
      "    reduce_all = reduce_all_v1(input_tensor, axis=None, keepdims=None, name=None, reduction_indices=None, keep_dims=None)\n",
      "        Computes the \"logical and\" of elements across dimensions of a tensor. (deprecated arguments)\n",
      "        \n",
      "        Warning: SOME ARGUMENTS ARE DEPRECATED: `(keep_dims)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        keep_dims is deprecated, use keepdims instead\n",
      "        \n",
      "        Reduces `input_tensor` along the dimensions given in `axis`.\n",
      "        Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each\n",
      "        entry in `axis`. If `keepdims` is true, the reduced dimensions\n",
      "        are retained with length 1.\n",
      "        \n",
      "        If `axis` is None, all dimensions are reduced, and a\n",
      "        tensor with a single element is returned.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([[True,  True], [False, False]])\n",
      "        tf.reduce_all(x)  # False\n",
      "        tf.reduce_all(x, 0)  # [False, False]\n",
      "        tf.reduce_all(x, 1)  # [True, False]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input_tensor: The boolean tensor to reduce.\n",
      "          axis: The dimensions to reduce. If `None` (the default), reduces all\n",
      "            dimensions. Must be in the range `[-rank(input_tensor),\n",
      "            rank(input_tensor))`.\n",
      "          keepdims: If true, retains reduced dimensions with length 1.\n",
      "          name: A name for the operation (optional).\n",
      "          reduction_indices: The old (deprecated) name for axis.\n",
      "          keep_dims: Deprecated alias for `keepdims`.\n",
      "        \n",
      "        Returns:\n",
      "          The reduced tensor.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Equivalent to np.all\n",
      "        @end_compatibility\n",
      "    \n",
      "    reduce_any = reduce_any_v1(input_tensor, axis=None, keepdims=None, name=None, reduction_indices=None, keep_dims=None)\n",
      "        Computes the \"logical or\" of elements across dimensions of a tensor. (deprecated arguments)\n",
      "        \n",
      "        Warning: SOME ARGUMENTS ARE DEPRECATED: `(keep_dims)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        keep_dims is deprecated, use keepdims instead\n",
      "        \n",
      "        Reduces `input_tensor` along the dimensions given in `axis`.\n",
      "        Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each\n",
      "        entry in `axis`. If `keepdims` is true, the reduced dimensions\n",
      "        are retained with length 1.\n",
      "        \n",
      "        If `axis` is None, all dimensions are reduced, and a\n",
      "        tensor with a single element is returned.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([[True,  True], [False, False]])\n",
      "        tf.reduce_any(x)  # True\n",
      "        tf.reduce_any(x, 0)  # [True, True]\n",
      "        tf.reduce_any(x, 1)  # [True, False]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input_tensor: The boolean tensor to reduce.\n",
      "          axis: The dimensions to reduce. If `None` (the default), reduces all\n",
      "            dimensions. Must be in the range `[-rank(input_tensor),\n",
      "            rank(input_tensor))`.\n",
      "          keepdims: If true, retains reduced dimensions with length 1.\n",
      "          name: A name for the operation (optional).\n",
      "          reduction_indices: The old (deprecated) name for axis.\n",
      "          keep_dims: Deprecated alias for `keepdims`.\n",
      "        \n",
      "        Returns:\n",
      "          The reduced tensor.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Equivalent to np.any\n",
      "        @end_compatibility\n",
      "    \n",
      "    reduce_join(inputs, axis=None, keep_dims=None, separator='', name=None, reduction_indices=None, keepdims=None)\n",
      "        Joins a string Tensor across the given dimensions.\n",
      "        \n",
      "        Computes the string join across dimensions in the given string Tensor of shape\n",
      "        `[\\\\(d_0, d_1, ..., d_{n-1}\\\\)]`.  Returns a new Tensor created by joining the input\n",
      "        strings with the given separator (default: empty string).  Negative indices are\n",
      "        counted backwards from the end, with `-1` being equivalent to `n - 1`.  If\n",
      "        indices are not specified, joins across all dimensions beginning from `n - 1`\n",
      "        through `0`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        # tensor `a` is [[\"a\", \"b\"], [\"c\", \"d\"]]\n",
      "        tf.strings.reduce_join(a, 0) ==> [\"ac\", \"bd\"]\n",
      "        tf.strings.reduce_join(a, 1) ==> [\"ab\", \"cd\"]\n",
      "        tf.strings.reduce_join(a, -2) = tf.strings.reduce_join(a, 0) ==> [\"ac\", \"bd\"]\n",
      "        tf.strings.reduce_join(a, -1) = tf.strings.reduce_join(a, 1) ==> [\"ab\", \"cd\"]\n",
      "        tf.strings.reduce_join(a, 0, keep_dims=True) ==> [[\"ac\", \"bd\"]]\n",
      "        tf.strings.reduce_join(a, 1, keep_dims=True) ==> [[\"ab\"], [\"cd\"]]\n",
      "        tf.strings.reduce_join(a, 0, separator=\".\") ==> [\"a.c\", \"b.d\"]\n",
      "        tf.strings.reduce_join(a, [0, 1]) ==> \"acbd\"\n",
      "        tf.strings.reduce_join(a, [1, 0]) ==> \"abcd\"\n",
      "        tf.strings.reduce_join(a, []) ==> [[\"a\", \"b\"], [\"c\", \"d\"]]\n",
      "        tf.strings.reduce_join(a) = tf.strings.reduce_join(a, [1, 0]) ==> \"abcd\"\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          inputs: A `Tensor` of type `string`.\n",
      "            The input to be joined.  All reduced indices must have non-zero size.\n",
      "          axis: A `Tensor` of type `int32`.\n",
      "            The dimensions to reduce over.  Dimensions are reduced in the\n",
      "            order specified.  Omitting `axis` is equivalent to passing\n",
      "            `[n-1, n-2, ..., 0]`.  Negative indices from `-n` to `-1` are supported.\n",
      "          keep_dims: An optional `bool`. Defaults to `False`.\n",
      "            If `True`, retain reduced dimensions with length `1`.\n",
      "          separator: An optional `string`. Defaults to `\"\"`.\n",
      "            The separator to use when joining.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `string`.\n",
      "    \n",
      "    reduce_logsumexp = reduce_logsumexp_v1(input_tensor, axis=None, keepdims=None, name=None, reduction_indices=None, keep_dims=None)\n",
      "        Computes log(sum(exp(elements across dimensions of a tensor))). (deprecated arguments)\n",
      "        \n",
      "        Warning: SOME ARGUMENTS ARE DEPRECATED: `(keep_dims)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        keep_dims is deprecated, use keepdims instead\n",
      "        \n",
      "        Reduces `input_tensor` along the dimensions given in `axis`.\n",
      "        Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each\n",
      "        entry in `axis`. If `keepdims` is true, the reduced dimensions\n",
      "        are retained with length 1.\n",
      "        \n",
      "        If `axis` has no entries, all dimensions are reduced, and a\n",
      "        tensor with a single element is returned.\n",
      "        \n",
      "        This function is more numerically stable than log(sum(exp(input))). It avoids\n",
      "        overflows caused by taking the exp of large inputs and underflows caused by\n",
      "        taking the log of small inputs.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([[0., 0., 0.], [0., 0., 0.]])\n",
      "        tf.reduce_logsumexp(x)  # log(6)\n",
      "        tf.reduce_logsumexp(x, 0)  # [log(2), log(2), log(2)]\n",
      "        tf.reduce_logsumexp(x, 1)  # [log(3), log(3)]\n",
      "        tf.reduce_logsumexp(x, 1, keepdims=True)  # [[log(3)], [log(3)]]\n",
      "        tf.reduce_logsumexp(x, [0, 1])  # log(6)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input_tensor: The tensor to reduce. Should have numeric type.\n",
      "          axis: The dimensions to reduce. If `None` (the default), reduces all\n",
      "            dimensions. Must be in the range `[-rank(input_tensor),\n",
      "            rank(input_tensor))`.\n",
      "          keepdims: If true, retains reduced dimensions with length 1.\n",
      "          name: A name for the operation (optional).\n",
      "          reduction_indices: The old (deprecated) name for axis.\n",
      "          keep_dims: Deprecated alias for `keepdims`.\n",
      "        \n",
      "        Returns:\n",
      "          The reduced tensor.\n",
      "    \n",
      "    reduce_max = reduce_max_v1(input_tensor, axis=None, keepdims=None, name=None, reduction_indices=None, keep_dims=None)\n",
      "        Computes the maximum of elements across dimensions of a tensor. (deprecated arguments)\n",
      "        \n",
      "        Warning: SOME ARGUMENTS ARE DEPRECATED: `(keep_dims)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        keep_dims is deprecated, use keepdims instead\n",
      "        \n",
      "        Reduces `input_tensor` along the dimensions given in `axis`.\n",
      "        Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each\n",
      "        entry in `axis`. If `keepdims` is true, the reduced dimensions\n",
      "        are retained with length 1.\n",
      "        \n",
      "        If `axis` is None, all dimensions are reduced, and a\n",
      "        tensor with a single element is returned.\n",
      "        \n",
      "        Args:\n",
      "          input_tensor: The tensor to reduce. Should have real numeric type.\n",
      "          axis: The dimensions to reduce. If `None` (the default), reduces all\n",
      "            dimensions. Must be in the range `[-rank(input_tensor),\n",
      "            rank(input_tensor))`.\n",
      "          keepdims: If true, retains reduced dimensions with length 1.\n",
      "          name: A name for the operation (optional).\n",
      "          reduction_indices: The old (deprecated) name for axis.\n",
      "          keep_dims: Deprecated alias for `keepdims`.\n",
      "        \n",
      "        Returns:\n",
      "          The reduced tensor.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Equivalent to np.max\n",
      "        @end_compatibility\n",
      "    \n",
      "    reduce_mean = reduce_mean_v1(input_tensor, axis=None, keepdims=None, name=None, reduction_indices=None, keep_dims=None)\n",
      "        Computes the mean of elements across dimensions of a tensor.\n",
      "        \n",
      "        Reduces `input_tensor` along the dimensions given in `axis`.\n",
      "        Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each\n",
      "        entry in `axis`. If `keepdims` is true, the reduced dimensions\n",
      "        are retained with length 1.\n",
      "        \n",
      "        If `axis` is None, all dimensions are reduced, and a\n",
      "        tensor with a single element is returned.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([[1., 1.], [2., 2.]])\n",
      "        tf.reduce_mean(x)  # 1.5\n",
      "        tf.reduce_mean(x, 0)  # [1.5, 1.5]\n",
      "        tf.reduce_mean(x, 1)  # [1.,  2.]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input_tensor: The tensor to reduce. Should have numeric type.\n",
      "          axis: The dimensions to reduce. If `None` (the default), reduces all\n",
      "            dimensions. Must be in the range `[-rank(input_tensor),\n",
      "            rank(input_tensor))`.\n",
      "          keepdims: If true, retains reduced dimensions with length 1.\n",
      "          name: A name for the operation (optional).\n",
      "          reduction_indices: The old (deprecated) name for axis.\n",
      "          keep_dims: Deprecated alias for `keepdims`.\n",
      "        \n",
      "        Returns:\n",
      "          The reduced tensor.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Equivalent to np.mean\n",
      "        \n",
      "        Please note that `np.mean` has a `dtype` parameter that could be used to\n",
      "        specify the output type. By default this is `dtype=float64`. On the other\n",
      "        hand, `tf.reduce_mean` has an aggressive type inference from `input_tensor`,\n",
      "        for example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([1, 0, 1, 0])\n",
      "        tf.reduce_mean(x)  # 0\n",
      "        y = tf.constant([1., 0., 1., 0.])\n",
      "        tf.reduce_mean(y)  # 0.5\n",
      "        ```\n",
      "        \n",
      "        @end_compatibility\n",
      "    \n",
      "    reduce_min = reduce_min_v1(input_tensor, axis=None, keepdims=None, name=None, reduction_indices=None, keep_dims=None)\n",
      "        Computes the minimum of elements across dimensions of a tensor. (deprecated arguments)\n",
      "        \n",
      "        Warning: SOME ARGUMENTS ARE DEPRECATED: `(keep_dims)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        keep_dims is deprecated, use keepdims instead\n",
      "        \n",
      "        Reduces `input_tensor` along the dimensions given in `axis`.\n",
      "        Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each\n",
      "        entry in `axis`. If `keepdims` is true, the reduced dimensions\n",
      "        are retained with length 1.\n",
      "        \n",
      "        If `axis` is None, all dimensions are reduced, and a\n",
      "        tensor with a single element is returned.\n",
      "        \n",
      "        Args:\n",
      "          input_tensor: The tensor to reduce. Should have real numeric type.\n",
      "          axis: The dimensions to reduce. If `None` (the default), reduces all\n",
      "            dimensions. Must be in the range `[-rank(input_tensor),\n",
      "            rank(input_tensor))`.\n",
      "          keepdims: If true, retains reduced dimensions with length 1.\n",
      "          name: A name for the operation (optional).\n",
      "          reduction_indices: The old (deprecated) name for axis.\n",
      "          keep_dims: Deprecated alias for `keepdims`.\n",
      "        \n",
      "        Returns:\n",
      "          The reduced tensor.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Equivalent to np.min\n",
      "        @end_compatibility\n",
      "    \n",
      "    reduce_prod = reduce_prod_v1(input_tensor, axis=None, keepdims=None, name=None, reduction_indices=None, keep_dims=None)\n",
      "        Computes the product of elements across dimensions of a tensor. (deprecated arguments)\n",
      "        \n",
      "        Warning: SOME ARGUMENTS ARE DEPRECATED: `(keep_dims)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        keep_dims is deprecated, use keepdims instead\n",
      "        \n",
      "        Reduces `input_tensor` along the dimensions given in `axis`.\n",
      "        Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each\n",
      "        entry in `axis`. If `keepdims` is true, the reduced dimensions\n",
      "        are retained with length 1.\n",
      "        \n",
      "        If `axis` is None, all dimensions are reduced, and a\n",
      "        tensor with a single element is returned.\n",
      "        \n",
      "        Args:\n",
      "          input_tensor: The tensor to reduce. Should have numeric type.\n",
      "          axis: The dimensions to reduce. If `None` (the default), reduces all\n",
      "            dimensions. Must be in the range `[-rank(input_tensor),\n",
      "            rank(input_tensor))`.\n",
      "          keepdims: If true, retains reduced dimensions with length 1.\n",
      "          name: A name for the operation (optional).\n",
      "          reduction_indices: The old (deprecated) name for axis.\n",
      "          keep_dims: Deprecated alias for `keepdims`.\n",
      "        \n",
      "        Returns:\n",
      "          The reduced tensor.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Equivalent to np.prod\n",
      "        @end_compatibility\n",
      "    \n",
      "    reduce_sum = reduce_sum_v1(input_tensor, axis=None, keepdims=None, name=None, reduction_indices=None, keep_dims=None)\n",
      "        Computes the sum of elements across dimensions of a tensor. (deprecated arguments)\n",
      "        \n",
      "        Warning: SOME ARGUMENTS ARE DEPRECATED: `(keep_dims)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        keep_dims is deprecated, use keepdims instead\n",
      "        \n",
      "        Reduces `input_tensor` along the dimensions given in `axis`.\n",
      "        Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each\n",
      "        entry in `axis`. If `keepdims` is true, the reduced dimensions\n",
      "        are retained with length 1.\n",
      "        \n",
      "        If `axis` is None, all dimensions are reduced, and a\n",
      "        tensor with a single element is returned.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([[1, 1, 1], [1, 1, 1]])\n",
      "        tf.reduce_sum(x)  # 6\n",
      "        tf.reduce_sum(x, 0)  # [2, 2, 2]\n",
      "        tf.reduce_sum(x, 1)  # [3, 3]\n",
      "        tf.reduce_sum(x, 1, keepdims=True)  # [[3], [3]]\n",
      "        tf.reduce_sum(x, [0, 1])  # 6\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input_tensor: The tensor to reduce. Should have numeric type.\n",
      "          axis: The dimensions to reduce. If `None` (the default), reduces all\n",
      "            dimensions. Must be in the range `[-rank(input_tensor),\n",
      "            rank(input_tensor))`.\n",
      "          keepdims: If true, retains reduced dimensions with length 1.\n",
      "          name: A name for the operation (optional).\n",
      "          reduction_indices: The old (deprecated) name for axis.\n",
      "          keep_dims: Deprecated alias for `keepdims`.\n",
      "        \n",
      "        Returns:\n",
      "          The reduced tensor, of the same dtype as the input_tensor.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Equivalent to np.sum apart the fact that numpy upcast uint8 and int32 to\n",
      "        int64 while tensorflow returns the same dtype as the input.\n",
      "        @end_compatibility\n",
      "    \n",
      "    regex_replace(input, pattern, rewrite, replace_global=True, name=None)\n",
      "        Replace elements of `input` matching regex `pattern` with `rewrite`.\n",
      "        \n",
      "        Args:\n",
      "          input: string `Tensor`, the source strings to process.\n",
      "          pattern: string or scalar string `Tensor`, regular expression to use,\n",
      "            see more details at https://github.com/google/re2/wiki/Syntax\n",
      "          rewrite: string or scalar string `Tensor`, value to use in match\n",
      "            replacement, supports backslash-escaped digits (\\1 to \\9) can be to insert\n",
      "            text matching corresponding parenthesized group.\n",
      "          replace_global: `bool`, if `True` replace all non-overlapping matches,\n",
      "            else replace only the first match.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          string `Tensor` of the same shape as `input` with specified replacements.\n",
      "    \n",
      "    register_tensor_conversion_function(base_type, conversion_func, priority=100)\n",
      "        Registers a function for converting objects of `base_type` to `Tensor`.\n",
      "        \n",
      "        The conversion function must have the following signature:\n",
      "        \n",
      "        ```python\n",
      "            def conversion_func(value, dtype=None, name=None, as_ref=False):\n",
      "              # ...\n",
      "        ```\n",
      "        \n",
      "        It must return a `Tensor` with the given `dtype` if specified. If the\n",
      "        conversion function creates a new `Tensor`, it should use the given\n",
      "        `name` if specified. All exceptions will be propagated to the caller.\n",
      "        \n",
      "        The conversion function may return `NotImplemented` for some\n",
      "        inputs. In this case, the conversion process will continue to try\n",
      "        subsequent conversion functions.\n",
      "        \n",
      "        If `as_ref` is true, the function must return a `Tensor` reference,\n",
      "        such as a `Variable`.\n",
      "        \n",
      "        NOTE: The conversion functions will execute in order of priority,\n",
      "        followed by order of registration. To ensure that a conversion function\n",
      "        `F` runs before another conversion function `G`, ensure that `F` is\n",
      "        registered with a smaller priority than `G`.\n",
      "        \n",
      "        Args:\n",
      "          base_type: The base type or tuple of base types for all objects that\n",
      "            `conversion_func` accepts.\n",
      "          conversion_func: A function that converts instances of `base_type` to\n",
      "            `Tensor`.\n",
      "          priority: Optional integer that indicates the priority for applying this\n",
      "            conversion function. Conversion functions with smaller priority values run\n",
      "            earlier than conversion functions with larger priority values. Defaults to\n",
      "            100.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If the arguments do not have the appropriate type.\n",
      "    \n",
      "    repeat(input, repeats, axis=None, name=None)\n",
      "        Repeat elements of `input`\n",
      "        \n",
      "        Args:\n",
      "          input: An `N`-dimensional Tensor.\n",
      "          repeats: An 1-D `int` Tensor. The number of repetitions for each element.\n",
      "            repeats is broadcasted to fit the shape of the given axis. `len(repeats)`\n",
      "            must equal `input.shape[axis]` if axis is not None.\n",
      "          axis: An int. The axis along which to repeat values. By default (axis=None),\n",
      "            use the flattened input array, and return a flat output array.\n",
      "          name: A name for the operation.\n",
      "        \n",
      "        Returns:\n",
      "          A Tensor which has the same shape as `input`, except along the given axis.\n",
      "            If axis is None then the output array is flattened to match the flattened\n",
      "            input array.\n",
      "        #### Examples:\n",
      "          ```python\n",
      "          >>> repeat(['a', 'b', 'c'], repeats=[3, 0, 2], axis=0)\n",
      "          ['a', 'a', 'a', 'c', 'c']\n",
      "          >>> repeat([[1, 2], [3, 4]], repeats=[2, 3], axis=0)\n",
      "          [[1, 2], [1, 2], [3, 4], [3, 4], [3, 4]]\n",
      "          >>> repeat([[1, 2], [3, 4]], repeats=[2, 3], axis=1)\n",
      "          [[1, 1, 2, 2, 2], [3, 3, 4, 4, 4]]\n",
      "          >>> repeat(3, repeats=4)\n",
      "          [3, 3, 3, 3]\n",
      "          >>> repeat([[1,2], [3,4]], repeats=2)\n",
      "          [1, 1, 2, 2, 3, 3, 4, 4]\n",
      "          ```\n",
      "    \n",
      "    report_uninitialized_variables(var_list=None, name='report_uninitialized_variables')\n",
      "        Adds ops to list the names of uninitialized variables.\n",
      "        \n",
      "        When run, it returns a 1-D tensor containing the names of uninitialized\n",
      "        variables if there are any, or an empty array if there are none.\n",
      "        \n",
      "        Args:\n",
      "          var_list: List of `Variable` objects to check. Defaults to the value of\n",
      "            `global_variables() + local_variables()`\n",
      "          name: Optional name of the `Operation`.\n",
      "        \n",
      "        Returns:\n",
      "          A 1-D tensor containing names of the uninitialized variables, or an empty\n",
      "          1-D tensor if there are no variables or no uninitialized variables.\n",
      "        \n",
      "        \n",
      "        **NOTE** The output of this function should be used.  If it is not, a warning will be logged.  To mark the output as used, call its .mark_used() method.\n",
      "    \n",
      "    required_space_to_batch_paddings(input_shape, block_shape, base_paddings=None, name=None)\n",
      "        Calculate padding required to make block_shape divide input_shape.\n",
      "        \n",
      "        This function can be used to calculate a suitable paddings argument for use\n",
      "        with space_to_batch_nd and batch_to_space_nd.\n",
      "        \n",
      "        Args:\n",
      "          input_shape: int32 Tensor of shape [N].\n",
      "          block_shape: int32 Tensor of shape [N].\n",
      "          base_paddings: Optional int32 Tensor of shape [N, 2].  Specifies the minimum\n",
      "            amount of padding to use.  All elements must be >= 0.  If not specified,\n",
      "            defaults to 0.\n",
      "          name: string.  Optional name prefix.\n",
      "        \n",
      "        Returns:\n",
      "          (paddings, crops), where:\n",
      "        \n",
      "          `paddings` and `crops` are int32 Tensors of rank 2 and shape [N, 2]\n",
      "          satisfying:\n",
      "        \n",
      "              paddings[i, 0] = base_paddings[i, 0].\n",
      "              0 <= paddings[i, 1] - base_paddings[i, 1] < block_shape[i]\n",
      "              (input_shape[i] + paddings[i, 0] + paddings[i, 1]) % block_shape[i] == 0\n",
      "        \n",
      "              crops[i, 0] = 0\n",
      "              crops[i, 1] = paddings[i, 1] - base_paddings[i, 1]\n",
      "        \n",
      "        Raises: ValueError if called with incompatible shapes.\n",
      "    \n",
      "    reset_default_graph()\n",
      "        Clears the default graph stack and resets the global default graph.\n",
      "        \n",
      "        NOTE: The default graph is a property of the current thread. This\n",
      "        function applies only to the current thread.  Calling this function while\n",
      "        a `tf.compat.v1.Session` or `tf.compat.v1.InteractiveSession` is active will\n",
      "        result in undefined\n",
      "        behavior. Using any previously created `tf.Operation` or `tf.Tensor` objects\n",
      "        after calling this function will result in undefined behavior.\n",
      "        Raises:\n",
      "          AssertionError: If this function is called within a nested graph.\n",
      "    \n",
      "    reshape(tensor, shape, name=None)\n",
      "        Reshapes a tensor.\n",
      "        \n",
      "        Given `tensor`, this operation returns a tensor that has the same values\n",
      "        as `tensor` with shape `shape`.\n",
      "        \n",
      "        If one component of `shape` is the special value -1, the size of that\n",
      "        dimension is computed so that the total size remains constant.  In particular,\n",
      "        a `shape` of `[-1]` flattens into 1-D.  At most one component of `shape` can\n",
      "        be -1.\n",
      "        \n",
      "        If `shape` is 1-D or higher, then the operation returns a tensor with shape\n",
      "        `shape` filled with the values of `tensor`. In this case, the number of\n",
      "        elements implied by `shape` must be the same as the number of elements in\n",
      "        `tensor`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```\n",
      "        # tensor 't' is [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "        # tensor 't' has shape [9]\n",
      "        reshape(t, [3, 3]) ==> [[1, 2, 3],\n",
      "                                [4, 5, 6],\n",
      "                                [7, 8, 9]]\n",
      "        \n",
      "        # tensor 't' is [[[1, 1], [2, 2]],\n",
      "        #                [[3, 3], [4, 4]]]\n",
      "        # tensor 't' has shape [2, 2, 2]\n",
      "        reshape(t, [2, 4]) ==> [[1, 1, 2, 2],\n",
      "                                [3, 3, 4, 4]]\n",
      "        \n",
      "        # tensor 't' is [[[1, 1, 1],\n",
      "        #                 [2, 2, 2]],\n",
      "        #                [[3, 3, 3],\n",
      "        #                 [4, 4, 4]],\n",
      "        #                [[5, 5, 5],\n",
      "        #                 [6, 6, 6]]]\n",
      "        # tensor 't' has shape [3, 2, 3]\n",
      "        # pass '[-1]' to flatten 't'\n",
      "        reshape(t, [-1]) ==> [1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6]\n",
      "        \n",
      "        # -1 can also be used to infer the shape\n",
      "        \n",
      "        # -1 is inferred to be 9:\n",
      "        reshape(t, [2, -1]) ==> [[1, 1, 1, 2, 2, 2, 3, 3, 3],\n",
      "                                 [4, 4, 4, 5, 5, 5, 6, 6, 6]]\n",
      "        # -1 is inferred to be 2:\n",
      "        reshape(t, [-1, 9]) ==> [[1, 1, 1, 2, 2, 2, 3, 3, 3],\n",
      "                                 [4, 4, 4, 5, 5, 5, 6, 6, 6]]\n",
      "        # -1 is inferred to be 3:\n",
      "        reshape(t, [ 2, -1, 3]) ==> [[[1, 1, 1],\n",
      "                                      [2, 2, 2],\n",
      "                                      [3, 3, 3]],\n",
      "                                     [[4, 4, 4],\n",
      "                                      [5, 5, 5],\n",
      "                                      [6, 6, 6]]]\n",
      "        \n",
      "        # tensor 't' is [7]\n",
      "        # shape `[]` reshapes to a scalar\n",
      "        reshape(t, []) ==> 7\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          tensor: A `Tensor`.\n",
      "          shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            Defines the shape of the output tensor.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `tensor`.\n",
      "    \n",
      "    resource_variables_enabled()\n",
      "        Returns `True` if resource variables are enabled.\n",
      "        \n",
      "        Resource variables are improved versions of TensorFlow variables with a\n",
      "        well-defined memory model. Accessing a resource variable reads its value, and\n",
      "        all ops which access a specific read value of the variable are guaranteed to\n",
      "        see the same value for that tensor. Writes which happen after a read (by\n",
      "        having a control or data dependency on the read) are guaranteed not to affect\n",
      "        the value of the read tensor, and similarly writes which happen before a read\n",
      "        are guaranteed to affect the value. No guarantees are made about unordered\n",
      "        read/write pairs.\n",
      "        \n",
      "        Calling tf.enable_resource_variables() lets you opt-in to this TensorFlow 2.0\n",
      "        feature.\n",
      "    \n",
      "    reverse = reverse_v2(tensor, axis, name=None)\n",
      "        Reverses specific dimensions of a tensor.\n",
      "        \n",
      "        NOTE `tf.reverse` has now changed behavior in preparation for 1.0.\n",
      "        `tf.reverse_v2` is currently an alias that will be deprecated before TF 1.0.\n",
      "        \n",
      "        Given a `tensor`, and a `int32` tensor `axis` representing the set of\n",
      "        dimensions of `tensor` to reverse. This operation reverses each dimension\n",
      "        `i` for which there exists `j` s.t. `axis[j] == i`.\n",
      "        \n",
      "        `tensor` can have up to 8 dimensions. The number of dimensions specified\n",
      "        in `axis` may be 0 or more entries. If an index is specified more than\n",
      "        once, a InvalidArgument error is raised.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```\n",
      "        # tensor 't' is [[[[ 0,  1,  2,  3],\n",
      "        #                  [ 4,  5,  6,  7],\n",
      "        #                  [ 8,  9, 10, 11]],\n",
      "        #                 [[12, 13, 14, 15],\n",
      "        #                  [16, 17, 18, 19],\n",
      "        #                  [20, 21, 22, 23]]]]\n",
      "        # tensor 't' shape is [1, 2, 3, 4]\n",
      "        \n",
      "        # 'dims' is [3] or 'dims' is [-1]\n",
      "        reverse(t, dims) ==> [[[[ 3,  2,  1,  0],\n",
      "                                [ 7,  6,  5,  4],\n",
      "                                [ 11, 10, 9, 8]],\n",
      "                               [[15, 14, 13, 12],\n",
      "                                [19, 18, 17, 16],\n",
      "                                [23, 22, 21, 20]]]]\n",
      "        \n",
      "        # 'dims' is '[1]' (or 'dims' is '[-3]')\n",
      "        reverse(t, dims) ==> [[[[12, 13, 14, 15],\n",
      "                                [16, 17, 18, 19],\n",
      "                                [20, 21, 22, 23]\n",
      "                               [[ 0,  1,  2,  3],\n",
      "                                [ 4,  5,  6,  7],\n",
      "                                [ 8,  9, 10, 11]]]]\n",
      "        \n",
      "        # 'dims' is '[2]' (or 'dims' is '[-2]')\n",
      "        reverse(t, dims) ==> [[[[8, 9, 10, 11],\n",
      "                                [4, 5, 6, 7],\n",
      "                                [0, 1, 2, 3]]\n",
      "                               [[20, 21, 22, 23],\n",
      "                                [16, 17, 18, 19],\n",
      "                                [12, 13, 14, 15]]]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          tensor: A `Tensor`. Must be one of the following types: `uint8`, `int8`, `uint16`, `int16`, `int32`, `int64`, `bool`, `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`, `string`.\n",
      "            Up to 8-D.\n",
      "          axis: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            1-D. The indices of the dimensions to reverse. Must be in the range\n",
      "            `[-rank(tensor), rank(tensor))`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `tensor`.\n",
      "    \n",
      "    reverse_sequence(input, seq_lengths, seq_axis=None, batch_axis=None, name=None, seq_dim=None, batch_dim=None)\n",
      "        Reverses variable length slices.\n",
      "        \n",
      "        This op first slices `input` along the dimension `batch_axis`, and for each\n",
      "        slice `i`, reverses the first `seq_lengths[i]` elements along\n",
      "        the dimension `seq_axis`.\n",
      "        \n",
      "        The elements of `seq_lengths` must obey `seq_lengths[i] <= input.dims[seq_dim]`,\n",
      "        and `seq_lengths` must be a vector of length `input.dims[batch_dim]`.\n",
      "        \n",
      "        The output slice `i` along dimension `batch_axis` is then given by input\n",
      "        slice `i`, with the first `seq_lengths[i]` slices along dimension\n",
      "        `seq_axis` reversed.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```\n",
      "        # Given this:\n",
      "        batch_dim = 0\n",
      "        seq_dim = 1\n",
      "        input.dims = (4, 8, ...)\n",
      "        seq_lengths = [7, 2, 3, 5]\n",
      "        \n",
      "        # then slices of input are reversed on seq_dim, but only up to seq_lengths:\n",
      "        output[0, 0:7, :, ...] = input[0, 7:0:-1, :, ...]\n",
      "        output[1, 0:2, :, ...] = input[1, 2:0:-1, :, ...]\n",
      "        output[2, 0:3, :, ...] = input[2, 3:0:-1, :, ...]\n",
      "        output[3, 0:5, :, ...] = input[3, 5:0:-1, :, ...]\n",
      "        \n",
      "        # while entries past seq_lens are copied through:\n",
      "        output[0, 7:, :, ...] = input[0, 7:, :, ...]\n",
      "        output[1, 2:, :, ...] = input[1, 2:, :, ...]\n",
      "        output[2, 3:, :, ...] = input[2, 3:, :, ...]\n",
      "        output[3, 2:, :, ...] = input[3, 2:, :, ...]\n",
      "        ```\n",
      "        \n",
      "        In contrast, if:\n",
      "        \n",
      "        ```\n",
      "        # Given this:\n",
      "        batch_dim = 2\n",
      "        seq_dim = 0\n",
      "        input.dims = (8, ?, 4, ...)\n",
      "        seq_lengths = [7, 2, 3, 5]\n",
      "        \n",
      "        # then slices of input are reversed on seq_dim, but only up to seq_lengths:\n",
      "        output[0:7, :, 0, :, ...] = input[7:0:-1, :, 0, :, ...]\n",
      "        output[0:2, :, 1, :, ...] = input[2:0:-1, :, 1, :, ...]\n",
      "        output[0:3, :, 2, :, ...] = input[3:0:-1, :, 2, :, ...]\n",
      "        output[0:5, :, 3, :, ...] = input[5:0:-1, :, 3, :, ...]\n",
      "        \n",
      "        # while entries past seq_lens are copied through:\n",
      "        output[7:, :, 0, :, ...] = input[7:, :, 0, :, ...]\n",
      "        output[2:, :, 1, :, ...] = input[2:, :, 1, :, ...]\n",
      "        output[3:, :, 2, :, ...] = input[3:, :, 2, :, ...]\n",
      "        output[2:, :, 3, :, ...] = input[2:, :, 3, :, ...]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. The input to reverse.\n",
      "          seq_lengths: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            1-D with length `input.dims(batch_dim)` and\n",
      "            `max(seq_lengths) <= input.dims(seq_dim)`\n",
      "          seq_axis: An `int`. The dimension which is partially reversed.\n",
      "          batch_axis: An optional `int`. Defaults to `0`.\n",
      "            The dimension along which reversal is performed.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    reverse_v2(tensor, axis, name=None)\n",
      "        Reverses specific dimensions of a tensor.\n",
      "        \n",
      "        NOTE `tf.reverse` has now changed behavior in preparation for 1.0.\n",
      "        `tf.reverse_v2` is currently an alias that will be deprecated before TF 1.0.\n",
      "        \n",
      "        Given a `tensor`, and a `int32` tensor `axis` representing the set of\n",
      "        dimensions of `tensor` to reverse. This operation reverses each dimension\n",
      "        `i` for which there exists `j` s.t. `axis[j] == i`.\n",
      "        \n",
      "        `tensor` can have up to 8 dimensions. The number of dimensions specified\n",
      "        in `axis` may be 0 or more entries. If an index is specified more than\n",
      "        once, a InvalidArgument error is raised.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```\n",
      "        # tensor 't' is [[[[ 0,  1,  2,  3],\n",
      "        #                  [ 4,  5,  6,  7],\n",
      "        #                  [ 8,  9, 10, 11]],\n",
      "        #                 [[12, 13, 14, 15],\n",
      "        #                  [16, 17, 18, 19],\n",
      "        #                  [20, 21, 22, 23]]]]\n",
      "        # tensor 't' shape is [1, 2, 3, 4]\n",
      "        \n",
      "        # 'dims' is [3] or 'dims' is [-1]\n",
      "        reverse(t, dims) ==> [[[[ 3,  2,  1,  0],\n",
      "                                [ 7,  6,  5,  4],\n",
      "                                [ 11, 10, 9, 8]],\n",
      "                               [[15, 14, 13, 12],\n",
      "                                [19, 18, 17, 16],\n",
      "                                [23, 22, 21, 20]]]]\n",
      "        \n",
      "        # 'dims' is '[1]' (or 'dims' is '[-3]')\n",
      "        reverse(t, dims) ==> [[[[12, 13, 14, 15],\n",
      "                                [16, 17, 18, 19],\n",
      "                                [20, 21, 22, 23]\n",
      "                               [[ 0,  1,  2,  3],\n",
      "                                [ 4,  5,  6,  7],\n",
      "                                [ 8,  9, 10, 11]]]]\n",
      "        \n",
      "        # 'dims' is '[2]' (or 'dims' is '[-2]')\n",
      "        reverse(t, dims) ==> [[[[8, 9, 10, 11],\n",
      "                                [4, 5, 6, 7],\n",
      "                                [0, 1, 2, 3]]\n",
      "                               [[20, 21, 22, 23],\n",
      "                                [16, 17, 18, 19],\n",
      "                                [12, 13, 14, 15]]]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          tensor: A `Tensor`. Must be one of the following types: `uint8`, `int8`, `uint16`, `int16`, `int32`, `int64`, `bool`, `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`, `string`.\n",
      "            Up to 8-D.\n",
      "          axis: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            1-D. The indices of the dimensions to reverse. Must be in the range\n",
      "            `[-rank(tensor), rank(tensor))`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `tensor`.\n",
      "    \n",
      "    rint(x, name=None)\n",
      "        Returns element-wise integer closest to x.\n",
      "        \n",
      "        If the result is midway between two representable values,\n",
      "        the even representable is chosen.\n",
      "        For example:\n",
      "        \n",
      "        ```\n",
      "        rint(-1.5) ==> -2.0\n",
      "        rint(0.5000001) ==> 1.0\n",
      "        rint([-1.7, -1.5, -0.2, 0.2, 1.5, 1.7, 2.0]) ==> [-2., -2., -0., 0., 2., 2., 2.]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    roll(input, shift, axis, name=None)\n",
      "        Rolls the elements of a tensor along an axis.\n",
      "        \n",
      "        The elements are shifted positively (towards larger indices) by the offset of\n",
      "        `shift` along the dimension of `axis`. Negative `shift` values will shift\n",
      "        elements in the opposite direction. Elements that roll passed the last position\n",
      "        will wrap around to the first and vice versa. Multiple shifts along multiple\n",
      "        axes may be specified.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```\n",
      "        # 't' is [0, 1, 2, 3, 4]\n",
      "        roll(t, shift=2, axis=0) ==> [3, 4, 0, 1, 2]\n",
      "        \n",
      "        # shifting along multiple dimensions\n",
      "        # 't' is [[0, 1, 2, 3, 4], [5, 6, 7, 8, 9]]\n",
      "        roll(t, shift=[1, -2], axis=[0, 1]) ==> [[7, 8, 9, 5, 6], [2, 3, 4, 0, 1]]\n",
      "        \n",
      "        # shifting along the same axis multiple times\n",
      "        # 't' is [[0, 1, 2, 3, 4], [5, 6, 7, 8, 9]]\n",
      "        roll(t, shift=[2, -3], axis=[1, 1]) ==> [[1, 2, 3, 4, 0], [6, 7, 8, 9, 5]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`.\n",
      "          shift: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            Dimension must be 0-D or 1-D. `shift[i]` specifies the number of places by which\n",
      "            elements are shifted positively (towards larger indices) along the dimension\n",
      "            specified by `axis[i]`. Negative shifts will roll the elements in the opposite\n",
      "            direction.\n",
      "          axis: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            Dimension must be 0-D or 1-D. `axis[i]` specifies the dimension that the shift\n",
      "            `shift[i]` should occur. If the same axis is referenced more than once, the\n",
      "            total shift for that axis will be the sum of all the shifts that belong to that\n",
      "            axis.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    round(x, name=None)\n",
      "        Rounds the values of a tensor to the nearest integer, element-wise.\n",
      "        \n",
      "        Rounds half to even.  Also known as bankers rounding. If you want to round\n",
      "        according to the current system rounding mode use tf::cint.\n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([0.9, 2.5, 2.3, 1.5, -4.5])\n",
      "        tf.round(x)  # [ 1.0, 2.0, 2.0, 2.0, -4.0 ]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor` of type `float16`, `float32`, `float64`, `int32`, or `int64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of same shape and type as `x`.\n",
      "    \n",
      "    rsqrt(x, name=None)\n",
      "        Computes reciprocal of square root of x element-wise.\n",
      "        \n",
      "        I.e., \\\\(y = 1 / \\sqrt{x}\\\\).\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    saturate_cast(value, dtype, name=None)\n",
      "        Performs a safe saturating cast of `value` to `dtype`.\n",
      "        \n",
      "        This function casts the input to `dtype` without applying any scaling.  If\n",
      "        there is a danger that values would over or underflow in the cast, this op\n",
      "        applies the appropriate clamping before the cast.\n",
      "        \n",
      "        Args:\n",
      "          value: A `Tensor`.\n",
      "          dtype: The desired output `DType`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          `value` safely cast to `dtype`.\n",
      "    \n",
      "    scalar_mul(scalar, x, name=None)\n",
      "        Multiplies a scalar times a `Tensor` or `IndexedSlices` object.\n",
      "        \n",
      "        Intended for use in gradient code which might deal with `IndexedSlices`\n",
      "        objects, which are easy to multiply by a scalar but more expensive to\n",
      "        multiply with arbitrary tensors.\n",
      "        \n",
      "        Args:\n",
      "          scalar: A 0-D scalar `Tensor`. Must have known shape.\n",
      "          x: A `Tensor` or `IndexedSlices` to be scaled.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          `scalar * x` of the same type (`Tensor` or `IndexedSlices`) as `x`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: if scalar is not a 0-D `scalar`.\n",
      "    \n",
      "    scan(fn, elems, initializer=None, parallel_iterations=10, back_prop=True, swap_memory=False, infer_shape=True, reverse=False, name=None)\n",
      "        scan on the list of tensors unpacked from `elems` on dimension 0.\n",
      "        \n",
      "        The simplest version of `scan` repeatedly applies the callable `fn` to a\n",
      "        sequence of elements from first to last. The elements are made of the tensors\n",
      "        unpacked from `elems` on dimension 0. The callable fn takes two tensors as\n",
      "        arguments. The first argument is the accumulated value computed from the\n",
      "        preceding invocation of fn, and the second is the value at the current\n",
      "        position of `elems`. If `initializer` is None, `elems` must contain at least\n",
      "        one element, and its first element is used as the initializer.\n",
      "        \n",
      "        Suppose that `elems` is unpacked into `values`, a list of tensors. The shape\n",
      "        of the result tensor is `[len(values)] + fn(initializer, values[0]).shape`.\n",
      "        If reverse=True, it's fn(initializer, values[-1]).shape.\n",
      "        \n",
      "        This method also allows multi-arity `elems` and accumulator.  If `elems`\n",
      "        is a (possibly nested) list or tuple of tensors, then each of these tensors\n",
      "        must have a matching first (unpack) dimension.  The second argument of\n",
      "        `fn` must match the structure of `elems`.\n",
      "        \n",
      "        If no `initializer` is provided, the output structure and dtypes of `fn`\n",
      "        are assumed to be the same as its input; and in this case, the first\n",
      "        argument of `fn` must match the structure of `elems`.\n",
      "        \n",
      "        If an `initializer` is provided, then the output of `fn` must have the same\n",
      "        structure as `initializer`; and the first argument of `fn` must match\n",
      "        this structure.\n",
      "        \n",
      "        For example, if `elems` is `(t1, [t2, t3])` and `initializer` is\n",
      "        `[i1, i2]` then an appropriate signature for `fn` in `python2` is:\n",
      "        `fn = lambda (acc_p1, acc_p2), (t1, [t2, t3]):` and `fn` must return a list,\n",
      "        `[acc_n1, acc_n2]`.  An alternative correct signature for `fn`, and the\n",
      "         one that works in `python3`, is:\n",
      "        `fn = lambda a, t:`, where `a` and `t` correspond to the input tuples.\n",
      "        \n",
      "        Args:\n",
      "          fn: The callable to be performed.  It accepts two arguments.  The first will\n",
      "            have the same structure as `initializer` if one is provided, otherwise it\n",
      "            will have the same structure as `elems`.  The second will have the same\n",
      "            (possibly nested) structure as `elems`.  Its output must have the same\n",
      "            structure as `initializer` if one is provided, otherwise it must have the\n",
      "            same structure as `elems`.\n",
      "          elems: A tensor or (possibly nested) sequence of tensors, each of which will\n",
      "            be unpacked along their first dimension.  The nested sequence of the\n",
      "            resulting slices will be the first argument to `fn`.\n",
      "          initializer: (optional) A tensor or (possibly nested) sequence of tensors,\n",
      "            initial value for the accumulator, and the expected output type of `fn`.\n",
      "          parallel_iterations: (optional) The number of iterations allowed to run in\n",
      "            parallel.\n",
      "          back_prop: (optional) True enables support for back propagation.\n",
      "          swap_memory: (optional) True enables GPU-CPU memory swapping.\n",
      "          infer_shape: (optional) False disables tests for consistent output shapes.\n",
      "          reverse: (optional) True scans the tensor last to first (instead of first to\n",
      "            last).\n",
      "          name: (optional) Name prefix for the returned tensors.\n",
      "        \n",
      "        Returns:\n",
      "          A tensor or (possibly nested) sequence of tensors.  Each tensor packs the\n",
      "          results of applying `fn` to tensors unpacked from `elems` along the first\n",
      "          dimension, and the previous accumulator value(s), from first to last (or\n",
      "          last to first, if `reverse=True`).\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: if `fn` is not callable or the structure of the output of\n",
      "            `fn` and `initializer` do not match.\n",
      "          ValueError: if the lengths of the output of `fn` and `initializer`\n",
      "            do not match.\n",
      "        \n",
      "        Examples:\n",
      "          ```python\n",
      "          elems = np.array([1, 2, 3, 4, 5, 6])\n",
      "          sum = scan(lambda a, x: a + x, elems)\n",
      "          # sum == [1, 3, 6, 10, 15, 21]\n",
      "          sum = scan(lambda a, x: a + x, elems, reverse=True)\n",
      "          # sum == [21, 20, 18, 15, 11, 6]\n",
      "          ```\n",
      "        \n",
      "          ```python\n",
      "          elems = np.array([1, 2, 3, 4, 5, 6])\n",
      "          initializer = np.array(0)\n",
      "          sum_one = scan(\n",
      "              lambda a, x: x[0] - x[1] + a, (elems + 1, elems), initializer)\n",
      "          # sum_one == [1, 2, 3, 4, 5, 6]\n",
      "          ```\n",
      "        \n",
      "          ```python\n",
      "          elems = np.array([1, 0, 0, 0, 0, 0])\n",
      "          initializer = (np.array(0), np.array(1))\n",
      "          fibonaccis = scan(lambda a, _: (a[1], a[0] + a[1]), elems, initializer)\n",
      "          # fibonaccis == ([1, 1, 2, 3, 5, 8], [1, 2, 3, 5, 8, 13])\n",
      "          ```\n",
      "    \n",
      "    scatter_add(ref, indices, updates, use_locking=False, name=None)\n",
      "        Adds sparse updates to the variable referenced by `resource`.\n",
      "        \n",
      "        This operation computes\n",
      "        \n",
      "        ```python\n",
      "            # Scalar indices\n",
      "            ref[indices, ...] += updates[...]\n",
      "        \n",
      "            # Vector indices (for each i)\n",
      "            ref[indices[i], ...] += updates[i, ...]\n",
      "        \n",
      "            # High rank indices (for each i, ..., j)\n",
      "            ref[indices[i, ..., j], ...] += updates[i, ..., j, ...]\n",
      "        ```\n",
      "        \n",
      "        This operation outputs `ref` after the update is done.\n",
      "        This makes it easier to chain operations that need to use the updated value.\n",
      "        Duplicate entries are handled correctly: if multiple `indices` reference\n",
      "        the same location, their contributions add.\n",
      "        \n",
      "        Requires `updates.shape = indices.shape + ref.shape[1:]`.\n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        <img style=\"width:100%\" src='https://www.tensorflow.org/images/ScatterAdd.png' alt>\n",
      "        </div>\n",
      "        \n",
      "        Args:\n",
      "          ref: A `Variable`.\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            A tensor of indices into the first dimension of `ref`.\n",
      "          updates: A `Tensor`. Must have the same type as `ref`.\n",
      "            A tensor of updated values to store in `ref`.\n",
      "          use_locking: An optional `bool`. Defaults to `False`.\n",
      "            If True, the assignment will be protected by a lock;\n",
      "            otherwise the behavior is undefined, but may exhibit less contention.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          Same as `ref`.  Returned as a convenience for operations that want\n",
      "          to use the updated values after the update is done.\n",
      "    \n",
      "    scatter_div(ref, indices, updates, use_locking=False, name=None)\n",
      "        Divides a variable reference by sparse updates.\n",
      "        \n",
      "        This operation computes\n",
      "        \n",
      "        ```python\n",
      "            # Scalar indices\n",
      "            ref[indices, ...] /= updates[...]\n",
      "        \n",
      "            # Vector indices (for each i)\n",
      "            ref[indices[i], ...] /= updates[i, ...]\n",
      "        \n",
      "            # High rank indices (for each i, ..., j)\n",
      "            ref[indices[i, ..., j], ...] /= updates[i, ..., j, ...]\n",
      "        ```\n",
      "        \n",
      "        This operation outputs `ref` after the update is done.\n",
      "        This makes it easier to chain operations that need to use the reset value.\n",
      "        \n",
      "        Duplicate entries are handled correctly: if multiple `indices` reference\n",
      "        the same location, their contributions divide.\n",
      "        \n",
      "        Requires `updates.shape = indices.shape + ref.shape[1:]` or `updates.shape =\n",
      "        []`.\n",
      "        \n",
      "        Args:\n",
      "          ref: A mutable `Tensor`. Must be one of the following types: `float32`,\n",
      "            `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`,\n",
      "            `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`,\n",
      "            `uint32`, `uint64`. Should be from a `Variable` node.\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`. A\n",
      "            tensor of indices into the first dimension of `ref`.\n",
      "          updates: A `Tensor`. Must have the same type as `ref`. A tensor of values\n",
      "            that `ref` is divided by.\n",
      "          use_locking: An optional `bool`. Defaults to `False`. If True, the operation\n",
      "            will be protected by a lock; otherwise the behavior is undefined, but may\n",
      "            exhibit less contention.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A mutable `Tensor`. Has the same type as `ref`.\n",
      "    \n",
      "    scatter_max(ref, indices, updates, use_locking=False, name=None)\n",
      "        Reduces sparse updates into a variable reference using the `max` operation.\n",
      "        \n",
      "        This operation computes\n",
      "        \n",
      "            # Scalar indices\n",
      "            ref[indices, ...] = max(ref[indices, ...], updates[...])\n",
      "        \n",
      "            # Vector indices (for each i)\n",
      "            ref[indices[i], ...] = max(ref[indices[i], ...], updates[i, ...])\n",
      "        \n",
      "            # High rank indices (for each i, ..., j)\n",
      "            ref[indices[i, ..., j], ...] = max(ref[indices[i, ..., j], ...],\n",
      "            updates[i, ..., j, ...])\n",
      "        \n",
      "        This operation outputs `ref` after the update is done.\n",
      "        This makes it easier to chain operations that need to use the reset value.\n",
      "        \n",
      "        Duplicate entries are handled correctly: if multiple `indices` reference\n",
      "        the same location, their contributions combine.\n",
      "        \n",
      "        Requires `updates.shape = indices.shape + ref.shape[1:]` or `updates.shape =\n",
      "        []`.\n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        <img style=\"width:100%\" src=\"https://www.tensorflow.org/images/ScatterAdd.png\"\n",
      "        alt>\n",
      "        </div>\n",
      "        \n",
      "        Args:\n",
      "          ref: A mutable `Tensor`. Must be one of the following types: `half`,\n",
      "            `bfloat16`, `float32`, `float64`, `int32`, `int64`. Should be from a\n",
      "            `Variable` node.\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`. A\n",
      "            tensor of indices into the first dimension of `ref`.\n",
      "          updates: A `Tensor`. Must have the same type as `ref`. A tensor of updated\n",
      "            values to reduce into `ref`.\n",
      "          use_locking: An optional `bool`. Defaults to `False`. If True, the update\n",
      "            will be protected by a lock; otherwise the behavior is undefined, but may\n",
      "            exhibit less contention.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A mutable `Tensor`. Has the same type as `ref`.\n",
      "    \n",
      "    scatter_min(ref, indices, updates, use_locking=False, name=None)\n",
      "        Reduces sparse updates into a variable reference using the `min` operation.\n",
      "        \n",
      "        This operation computes\n",
      "        \n",
      "            # Scalar indices\n",
      "            ref[indices, ...] = min(ref[indices, ...], updates[...])\n",
      "        \n",
      "            # Vector indices (for each i)\n",
      "            ref[indices[i], ...] = min(ref[indices[i], ...], updates[i, ...])\n",
      "        \n",
      "            # High rank indices (for each i, ..., j)\n",
      "            ref[indices[i, ..., j], ...] = min(ref[indices[i, ..., j], ...],\n",
      "            updates[i, ..., j, ...])\n",
      "        \n",
      "        This operation outputs `ref` after the update is done.\n",
      "        This makes it easier to chain operations that need to use the reset value.\n",
      "        \n",
      "        Duplicate entries are handled correctly: if multiple `indices` reference\n",
      "        the same location, their contributions combine.\n",
      "        \n",
      "        Requires `updates.shape = indices.shape + ref.shape[1:]` or `updates.shape =\n",
      "        []`.\n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        <img style=\"width:100%\" src=\"https://www.tensorflow.org/images/ScatterAdd.png\"\n",
      "        alt>\n",
      "        </div>\n",
      "        \n",
      "        Args:\n",
      "          ref: A mutable `Tensor`. Must be one of the following types: `half`,\n",
      "            `bfloat16`, `float32`, `float64`, `int32`, `int64`. Should be from a\n",
      "            `Variable` node.\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`. A\n",
      "            tensor of indices into the first dimension of `ref`.\n",
      "          updates: A `Tensor`. Must have the same type as `ref`. A tensor of updated\n",
      "            values to reduce into `ref`.\n",
      "          use_locking: An optional `bool`. Defaults to `False`. If True, the update\n",
      "            will be protected by a lock; otherwise the behavior is undefined, but may\n",
      "            exhibit less contention.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A mutable `Tensor`. Has the same type as `ref`.\n",
      "    \n",
      "    scatter_mul(ref, indices, updates, use_locking=False, name=None)\n",
      "        Multiplies sparse updates into a variable reference.\n",
      "        \n",
      "        This operation computes\n",
      "        \n",
      "        ```python\n",
      "            # Scalar indices\n",
      "            ref[indices, ...] *= updates[...]\n",
      "        \n",
      "            # Vector indices (for each i)\n",
      "            ref[indices[i], ...] *= updates[i, ...]\n",
      "        \n",
      "            # High rank indices (for each i, ..., j)\n",
      "            ref[indices[i, ..., j], ...] *= updates[i, ..., j, ...]\n",
      "        ```\n",
      "        \n",
      "        This operation outputs `ref` after the update is done.\n",
      "        This makes it easier to chain operations that need to use the reset value.\n",
      "        \n",
      "        Duplicate entries are handled correctly: if multiple `indices` reference\n",
      "        the same location, their contributions multiply.\n",
      "        \n",
      "        Requires `updates.shape = indices.shape + ref.shape[1:]` or `updates.shape =\n",
      "        []`.\n",
      "        \n",
      "        Args:\n",
      "          ref: A mutable `Tensor`. Must be one of the following types: `float32`,\n",
      "            `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`,\n",
      "            `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`,\n",
      "            `uint32`, `uint64`. Should be from a `Variable` node.\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`. A\n",
      "            tensor of indices into the first dimension of `ref`.\n",
      "          updates: A `Tensor`. Must have the same type as `ref`. A tensor of updated\n",
      "            values to multiply to `ref`.\n",
      "          use_locking: An optional `bool`. Defaults to `False`. If True, the operation\n",
      "            will be protected by a lock; otherwise the behavior is undefined, but may\n",
      "            exhibit less contention.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A mutable `Tensor`. Has the same type as `ref`.\n",
      "    \n",
      "    scatter_nd(indices, updates, shape, name=None)\n",
      "        Scatter `updates` into a new tensor according to `indices`.\n",
      "        \n",
      "        Creates a new tensor by applying sparse `updates` to individual values or\n",
      "        slices within a tensor (initially zero for numeric, empty for string) of\n",
      "        the given `shape` according to indices.  This operator is the inverse of the\n",
      "        `tf.gather_nd` operator which extracts values or slices from a given tensor.\n",
      "        \n",
      "        This operation is similar to tensor_scatter_add, except that the tensor is\n",
      "        zero-initialized. Calling `tf.scatter_nd(indices, values, shape)` is identical\n",
      "        to `tensor_scatter_add(tf.zeros(shape, values.dtype), indices, values)`\n",
      "        \n",
      "        If `indices` contains duplicates, then their updates are accumulated (summed).\n",
      "        \n",
      "        **WARNING**: The order in which updates are applied is nondeterministic, so the\n",
      "        output will be nondeterministic if `indices` contains duplicates -- because\n",
      "        of some numerical approximation issues, numbers summed in different order\n",
      "        may yield different results.\n",
      "        \n",
      "        `indices` is an integer tensor containing indices into a new tensor of shape\n",
      "        `shape`.  The last dimension of `indices` can be at most the rank of `shape`:\n",
      "        \n",
      "            indices.shape[-1] <= shape.rank\n",
      "        \n",
      "        The last dimension of `indices` corresponds to indices into elements\n",
      "        (if `indices.shape[-1] = shape.rank`) or slices\n",
      "        (if `indices.shape[-1] < shape.rank`) along dimension `indices.shape[-1]` of\n",
      "        `shape`.  `updates` is a tensor with shape\n",
      "        \n",
      "            indices.shape[:-1] + shape[indices.shape[-1]:]\n",
      "        \n",
      "        The simplest form of scatter is to insert individual elements in a tensor by\n",
      "        index. For example, say we want to insert 4 scattered elements in a rank-1\n",
      "        tensor with 8 elements.\n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        <img style=\"width:100%\" src=\"https://www.tensorflow.org/images/ScatterNd1.png\" alt>\n",
      "        </div>\n",
      "        \n",
      "        In Python, this scatter operation would look like this:\n",
      "        \n",
      "        ```python\n",
      "            indices = tf.constant([[4], [3], [1], [7]])\n",
      "            updates = tf.constant([9, 10, 11, 12])\n",
      "            shape = tf.constant([8])\n",
      "            scatter = tf.scatter_nd(indices, updates, shape)\n",
      "            with tf.Session() as sess:\n",
      "              print(sess.run(scatter))\n",
      "        ```\n",
      "        \n",
      "        The resulting tensor would look like this:\n",
      "        \n",
      "            [0, 11, 0, 10, 9, 0, 0, 12]\n",
      "        \n",
      "        We can also, insert entire slices of a higher rank tensor all at once. For\n",
      "        example, if we wanted to insert two slices in the first dimension of a\n",
      "        rank-3 tensor with two matrices of new values.\n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        <img style=\"width:100%\" src=\"https://www.tensorflow.org/images/ScatterNd2.png\" alt>\n",
      "        </div>\n",
      "        \n",
      "        In Python, this scatter operation would look like this:\n",
      "        \n",
      "        ```python\n",
      "            indices = tf.constant([[0], [2]])\n",
      "            updates = tf.constant([[[5, 5, 5, 5], [6, 6, 6, 6],\n",
      "                                    [7, 7, 7, 7], [8, 8, 8, 8]],\n",
      "                                   [[5, 5, 5, 5], [6, 6, 6, 6],\n",
      "                                    [7, 7, 7, 7], [8, 8, 8, 8]]])\n",
      "            shape = tf.constant([4, 4, 4])\n",
      "            scatter = tf.scatter_nd(indices, updates, shape)\n",
      "            with tf.Session() as sess:\n",
      "              print(sess.run(scatter))\n",
      "        ```\n",
      "        \n",
      "        The resulting tensor would look like this:\n",
      "        \n",
      "            [[[5, 5, 5, 5], [6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8]],\n",
      "             [[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]],\n",
      "             [[5, 5, 5, 5], [6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8]],\n",
      "             [[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]]]\n",
      "        \n",
      "        Note that on CPU, if an out of bound index is found, an error is returned.\n",
      "        On GPU, if an out of bound index is found, the index is ignored.\n",
      "        \n",
      "        Args:\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            Index tensor.\n",
      "          updates: A `Tensor`. Updates to scatter into output.\n",
      "          shape: A `Tensor`. Must have the same type as `indices`.\n",
      "            1-D. The shape of the resulting tensor.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `updates`.\n",
      "    \n",
      "    scatter_nd_add(ref, indices, updates, use_locking=False, name=None)\n",
      "        Applies sparse addition to individual values or slices in a Variable.\n",
      "        \n",
      "        `ref` is a `Tensor` with rank `P` and `indices` is a `Tensor` of rank `Q`.\n",
      "        \n",
      "        `indices` must be integer tensor, containing indices into `ref`.\n",
      "        It must be shape `[d_0, ..., d_{Q-2}, K]` where `0 < K <= P`.\n",
      "        \n",
      "        The innermost dimension of `indices` (with length `K`) corresponds to\n",
      "        indices into elements (if `K = P`) or slices (if `K < P`) along the `K`th\n",
      "        dimension of `ref`.\n",
      "        \n",
      "        `updates` is `Tensor` of rank `Q-1+P-K` with shape:\n",
      "        \n",
      "        ```\n",
      "        [d_0, ..., d_{Q-2}, ref.shape[K], ..., ref.shape[P-1]]\n",
      "        ```\n",
      "        \n",
      "        For example, say we want to add 4 scattered elements to a rank-1 tensor to\n",
      "        8 elements. In Python, that addition would look like this:\n",
      "        \n",
      "        ```python\n",
      "        ref = tf.Variable([1, 2, 3, 4, 5, 6, 7, 8])\n",
      "        indices = tf.constant([[4], [3], [1], [7]])\n",
      "        updates = tf.constant([9, 10, 11, 12])\n",
      "        add = tf.compat.v1.scatter_nd_add(ref, indices, updates)\n",
      "        with tf.compat.v1.Session() as sess:\n",
      "          print sess.run(add)\n",
      "        ```\n",
      "        \n",
      "        The resulting update to ref would look like this:\n",
      "        \n",
      "            [1, 13, 3, 14, 14, 6, 7, 20]\n",
      "        \n",
      "        See `tf.scatter_nd` for more details about how to make updates to\n",
      "        slices.\n",
      "        \n",
      "        Args:\n",
      "          ref: A mutable `Tensor`. Must be one of the following types: `float32`,\n",
      "            `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`,\n",
      "            `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`,\n",
      "            `uint32`, `uint64`. A mutable Tensor. Should be from a Variable node.\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            A tensor of indices into ref.\n",
      "          updates: A `Tensor`. Must have the same type as `ref`.\n",
      "            A tensor of updated values to add to ref.\n",
      "          use_locking: An optional `bool`. Defaults to `False`.\n",
      "            If True, the assignment will be protected by a lock;\n",
      "            otherwise the behavior is undefined, but may exhibit less contention.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A mutable `Tensor`. Has the same type as `ref`.\n",
      "    \n",
      "    scatter_nd_sub(ref, indices, updates, use_locking=False, name=None)\n",
      "        Applies sparse subtraction to individual values or slices in a Variable.\n",
      "        \n",
      "        `ref` is a `Tensor` with rank `P` and `indices` is a `Tensor` of rank `Q`.\n",
      "        \n",
      "        `indices` must be integer tensor, containing indices into `ref`.\n",
      "        It must be shape `[d_0, ..., d_{Q-2}, K]` where `0 < K <= P`.\n",
      "        \n",
      "        The innermost dimension of `indices` (with length `K`) corresponds to\n",
      "        indices into elements (if `K = P`) or slices (if `K < P`) along the `K`th\n",
      "        dimension of `ref`.\n",
      "        \n",
      "        `updates` is `Tensor` of rank `Q-1+P-K` with shape:\n",
      "        \n",
      "        ```\n",
      "        [d_0, ..., d_{Q-2}, ref.shape[K], ..., ref.shape[P-1]]\n",
      "        ```\n",
      "        \n",
      "        For example, say we want to subtract 4 scattered elements from a rank-1 tensor\n",
      "        with 8 elements. In Python, that update would look like this:\n",
      "        \n",
      "        ```python\n",
      "        ref = tf.Variable([1, 2, 3, 4, 5, 6, 7, 8])\n",
      "        indices = tf.constant([[4], [3], [1] ,[7]])\n",
      "        updates = tf.constant([9, 10, 11, 12])\n",
      "        op = tf.compat.v1.scatter_nd_sub(ref, indices, updates)\n",
      "        with tf.compat.v1.Session() as sess:\n",
      "          print sess.run(op)\n",
      "        ```\n",
      "        \n",
      "        The resulting update to ref would look like this:\n",
      "        \n",
      "            [1, -9, 3, -6, -6, 6, 7, -4]\n",
      "        \n",
      "        See `tf.scatter_nd` for more details about how to make updates to\n",
      "        slices.\n",
      "        \n",
      "        Args:\n",
      "          ref: A mutable `Tensor`. Must be one of the following types: `float32`,\n",
      "            `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`,\n",
      "            `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`,\n",
      "            `uint32`, `uint64`. A mutable Tensor. Should be from a Variable node.\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            A tensor of indices into ref.\n",
      "          updates: A `Tensor`. Must have the same type as `ref`.\n",
      "            A tensor of updated values to add to ref.\n",
      "          use_locking: An optional `bool`. Defaults to `False`.\n",
      "            An optional bool. Defaults to True. If True, the assignment will\n",
      "            be protected by a lock; otherwise the behavior is undefined,\n",
      "            but may exhibit less contention.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A mutable `Tensor`. Has the same type as `ref`.\n",
      "    \n",
      "    scatter_nd_update(ref, indices, updates, use_locking=True, name=None)\n",
      "        Applies sparse `updates` to individual values or slices in a Variable.\n",
      "        \n",
      "        `ref` is a `Tensor` with rank `P` and `indices` is a `Tensor` of rank `Q`.\n",
      "        \n",
      "        `indices` must be integer tensor, containing indices into `ref`.\n",
      "        It must be shape `[d_0, ..., d_{Q-2}, K]` where `0 < K <= P`.\n",
      "        \n",
      "        The innermost dimension of `indices` (with length `K`) corresponds to\n",
      "        indices into elements (if `K = P`) or slices (if `K < P`) along the `K`th\n",
      "        dimension of `ref`.\n",
      "        \n",
      "        `updates` is `Tensor` of rank `Q-1+P-K` with shape:\n",
      "        \n",
      "        ```\n",
      "        [d_0, ..., d_{Q-2}, ref.shape[K], ..., ref.shape[P-1]].\n",
      "        ```\n",
      "        \n",
      "        For example, say we want to update 4 scattered elements to a rank-1 tensor to\n",
      "        8 elements. In Python, that update would look like this:\n",
      "        \n",
      "        ```python\n",
      "            ref = tf.Variable([1, 2, 3, 4, 5, 6, 7, 8])\n",
      "            indices = tf.constant([[4], [3], [1] ,[7]])\n",
      "            updates = tf.constant([9, 10, 11, 12])\n",
      "            update = tf.compat.v1.scatter_nd_update(ref, indices, updates)\n",
      "            with tf.compat.v1.Session() as sess:\n",
      "              print sess.run(update)\n",
      "        ```\n",
      "        \n",
      "        The resulting update to ref would look like this:\n",
      "        \n",
      "            [1, 11, 3, 10, 9, 6, 7, 12]\n",
      "        \n",
      "        See `tf.scatter_nd` for more details about how to make updates to\n",
      "        slices.\n",
      "        \n",
      "        Args:\n",
      "          ref: A Variable.\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            A tensor of indices into ref.\n",
      "          updates: A `Tensor`. Must have the same type as `ref`.\n",
      "            A Tensor. Must have the same type as ref. A tensor of updated\n",
      "            values to add to ref.\n",
      "          use_locking: An optional `bool`. Defaults to `True`.\n",
      "            An optional bool. Defaults to True. If True, the assignment will\n",
      "            be protected by a lock; otherwise the behavior is undefined,\n",
      "            but may exhibit less contention.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          The value of the variable after the update.\n",
      "    \n",
      "    scatter_sub(ref, indices, updates, use_locking=False, name=None)\n",
      "        Subtracts sparse updates to a variable reference.\n",
      "        \n",
      "        ```python\n",
      "            # Scalar indices\n",
      "            ref[indices, ...] -= updates[...]\n",
      "        \n",
      "            # Vector indices (for each i)\n",
      "            ref[indices[i], ...] -= updates[i, ...]\n",
      "        \n",
      "            # High rank indices (for each i, ..., j)\n",
      "            ref[indices[i, ..., j], ...] -= updates[i, ..., j, ...]\n",
      "        ```\n",
      "        \n",
      "        This operation outputs `ref` after the update is done.\n",
      "        This makes it easier to chain operations that need to use the reset value.\n",
      "        \n",
      "        Duplicate entries are handled correctly: if multiple `indices` reference\n",
      "        the same location, their (negated) contributions add.\n",
      "        \n",
      "        Requires `updates.shape = indices.shape + ref.shape[1:]` or\n",
      "        `updates.shape = []`.\n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        <img style=\"width:100%\"\n",
      "             src=\"https://www.tensorflow.org/images/ScatterSub.png\" alt>\n",
      "        </div>\n",
      "        \n",
      "        Args:\n",
      "          ref: A mutable `Tensor`. Must be one of the following types: `float32`,\n",
      "            `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`,\n",
      "            `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`,\n",
      "            `uint32`, `uint64`. Should be from a `Variable` node.\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            A tensor of indices into the first dimension of `ref`.\n",
      "          updates: A `Tensor`. Must have the same type as `ref`.\n",
      "            A tensor of updated values to subtract from `ref`.\n",
      "          use_locking: An optional `bool`. Defaults to `False`.\n",
      "            If True, the subtraction will be protected by a lock;\n",
      "            otherwise the behavior is undefined, but may exhibit less contention.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A mutable `Tensor`. Has the same type as `ref`.\n",
      "    \n",
      "    scatter_update(ref, indices, updates, use_locking=True, name=None)\n",
      "        Applies sparse updates to a variable reference.\n",
      "        \n",
      "        This operation computes\n",
      "        \n",
      "        ```python\n",
      "            # Scalar indices\n",
      "            ref[indices, ...] = updates[...]\n",
      "        \n",
      "            # Vector indices (for each i)\n",
      "            ref[indices[i], ...] = updates[i, ...]\n",
      "        \n",
      "            # High rank indices (for each i, ..., j)\n",
      "            ref[indices[i, ..., j], ...] = updates[i, ..., j, ...]\n",
      "        ```\n",
      "        \n",
      "        This operation outputs `ref` after the update is done.\n",
      "        This makes it easier to chain operations that need to use the reset value.\n",
      "        \n",
      "        If values in `ref` is to be updated more than once, because there are\n",
      "        duplicate entries in `indices`, the order at which the updates happen\n",
      "        for each value is undefined.\n",
      "        \n",
      "        Requires `updates.shape = indices.shape + ref.shape[1:]`.\n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        <img style=\"width:100%\" src=\"https://www.tensorflow.org/images/ScatterUpdate.png\" alt>\n",
      "        </div>\n",
      "        \n",
      "        Args:\n",
      "          ref: A `Variable`.\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            A tensor of indices into the first dimension of `ref`.\n",
      "          updates: A `Tensor`. Must have the same type as `ref`.\n",
      "            A tensor of updated values to store in `ref`.\n",
      "          use_locking: An optional `bool`. Defaults to `True`.\n",
      "            If True, the assignment will be protected by a lock;\n",
      "            otherwise the behavior is undefined, but may exhibit less contention.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          Same as `ref`.  Returned as a convenience for operations that want\n",
      "          to use the updated values after the update is done.\n",
      "    \n",
      "    searchsorted(sorted_sequence, values, side='left', out_type=tf.int32, name=None)\n",
      "        Searches input tensor for values on the innermost dimension.\n",
      "        \n",
      "        A 2-D example:\n",
      "        \n",
      "        ```\n",
      "          sorted_sequence = [[0, 3, 9, 9, 10],\n",
      "                             [1, 2, 3, 4, 5]]\n",
      "          values = [[2, 4, 9],\n",
      "                    [0, 2, 6]]\n",
      "        \n",
      "          result = searchsorted(sorted_sequence, values, side=\"left\")\n",
      "        \n",
      "          result == [[1, 2, 2],\n",
      "                     [0, 1, 5]]\n",
      "        \n",
      "          result = searchsorted(sorted_sequence, values, side=\"right\")\n",
      "        \n",
      "          result == [[1, 2, 4],\n",
      "                     [0, 2, 5]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          sorted_sequence: N-D `Tensor` containing a sorted sequence.\n",
      "          values: N-D `Tensor` containing the search values.\n",
      "          side: 'left' or 'right'; 'left' corresponds to lower_bound and 'right' to\n",
      "            upper_bound.\n",
      "          out_type: The output type (`int32` or `int64`).  Default is `tf.int32`.\n",
      "          name: Optional name for the operation.\n",
      "        \n",
      "        Returns:\n",
      "          An N-D `Tensor` the size of values containing the result of applying either\n",
      "          lower_bound or upper_bound (depending on side) to each value.  The result\n",
      "          is not a global index to the entire `Tensor`, but the index in the last\n",
      "          dimension.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If the last dimension of `sorted_sequence >= 2^31-1` elements.\n",
      "                      If the total size of values exceeds `2^31 - 1` elements.\n",
      "                      If the first `N-1` dimensions of the two tensors don't match.\n",
      "    \n",
      "    segment_max(data, segment_ids, name=None)\n",
      "        Computes the maximum along segments of a tensor.\n",
      "        \n",
      "        Read\n",
      "        [the section on segmentation](https://tensorflow.org/api_docs/python/tf/math#Segmentation)\n",
      "        for an explanation of segments.\n",
      "        \n",
      "        Computes a tensor such that\n",
      "        \\\\(output_i = \\max_j(data_j)\\\\) where `max` is over `j` such\n",
      "        that `segment_ids[j] == i`.\n",
      "        \n",
      "        If the max is empty for a given segment ID `i`, `output[i] = 0`.\n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        <img style=\"width:100%\" src=\"https://www.tensorflow.org/images/SegmentMax.png\" alt>\n",
      "        </div>\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```\n",
      "        c = tf.constant([[1,2,3,4], [4, 3, 2, 1], [5,6,7,8]])\n",
      "        tf.segment_max(c, tf.constant([0, 0, 1]))\n",
      "        # ==> [[4, 3, 3, 4],\n",
      "        #      [5, 6, 7, 8]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          data: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "          segment_ids: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            A 1-D tensor whose size is equal to the size of `data`'s\n",
      "            first dimension.  Values should be sorted and can be repeated.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `data`.\n",
      "    \n",
      "    segment_mean(data, segment_ids, name=None)\n",
      "        Computes the mean along segments of a tensor.\n",
      "        \n",
      "        Read\n",
      "        [the section on segmentation](https://tensorflow.org/api_docs/python/tf/math#Segmentation)\n",
      "        for an explanation of segments.\n",
      "        \n",
      "        Computes a tensor such that\n",
      "        \\\\(output_i = \\frac{\\sum_j data_j}{N}\\\\) where `mean` is\n",
      "        over `j` such that `segment_ids[j] == i` and `N` is the total number of\n",
      "        values summed.\n",
      "        \n",
      "        If the mean is empty for a given segment ID `i`, `output[i] = 0`.\n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        <img style=\"width:100%\" src=\"https://www.tensorflow.org/images/SegmentMean.png\" alt>\n",
      "        </div>\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```\n",
      "        c = tf.constant([[1.0,2,3,4], [4, 3, 2, 1], [5,6,7,8]])\n",
      "        tf.segment_mean(c, tf.constant([0, 0, 1]))\n",
      "        # ==> [[2.5, 2.5, 2.5, 2.5],\n",
      "        #      [5, 6, 7, 8]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          data: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.\n",
      "          segment_ids: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            A 1-D tensor whose size is equal to the size of `data`'s\n",
      "            first dimension.  Values should be sorted and can be repeated.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `data`.\n",
      "    \n",
      "    segment_min(data, segment_ids, name=None)\n",
      "        Computes the minimum along segments of a tensor.\n",
      "        \n",
      "        Read\n",
      "        [the section on segmentation](https://tensorflow.org/api_docs/python/tf/math#Segmentation)\n",
      "        for an explanation of segments.\n",
      "        \n",
      "        Computes a tensor such that\n",
      "        \\\\(output_i = \\min_j(data_j)\\\\) where `min` is over `j` such\n",
      "        that `segment_ids[j] == i`.\n",
      "        \n",
      "        If the min is empty for a given segment ID `i`, `output[i] = 0`.\n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        <img style=\"width:100%\" src=\"https://www.tensorflow.org/images/SegmentMin.png\" alt>\n",
      "        </div>\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```\n",
      "        c = tf.constant([[1,2,3,4], [4, 3, 2, 1], [5,6,7,8]])\n",
      "        tf.segment_min(c, tf.constant([0, 0, 1]))\n",
      "        # ==> [[1, 2, 2, 1],\n",
      "        #      [5, 6, 7, 8]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          data: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "          segment_ids: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            A 1-D tensor whose size is equal to the size of `data`'s\n",
      "            first dimension.  Values should be sorted and can be repeated.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `data`.\n",
      "    \n",
      "    segment_prod(data, segment_ids, name=None)\n",
      "        Computes the product along segments of a tensor.\n",
      "        \n",
      "        Read\n",
      "        [the section on segmentation](https://tensorflow.org/api_docs/python/tf/math#Segmentation)\n",
      "        for an explanation of segments.\n",
      "        \n",
      "        Computes a tensor such that\n",
      "        \\\\(output_i = \\prod_j data_j\\\\) where the product is over `j` such\n",
      "        that `segment_ids[j] == i`.\n",
      "        \n",
      "        If the product is empty for a given segment ID `i`, `output[i] = 1`.\n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        <img style=\"width:100%\" src=\"https://www.tensorflow.org/images/SegmentProd.png\" alt>\n",
      "        </div>\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```\n",
      "        c = tf.constant([[1,2,3,4], [4, 3, 2, 1], [5,6,7,8]])\n",
      "        tf.segment_prod(c, tf.constant([0, 0, 1]))\n",
      "        # ==> [[4, 6, 6, 4],\n",
      "        #      [5, 6, 7, 8]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          data: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.\n",
      "          segment_ids: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            A 1-D tensor whose size is equal to the size of `data`'s\n",
      "            first dimension.  Values should be sorted and can be repeated.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `data`.\n",
      "    \n",
      "    segment_sum(data, segment_ids, name=None)\n",
      "        Computes the sum along segments of a tensor.\n",
      "        \n",
      "        Read\n",
      "        [the section on segmentation](https://tensorflow.org/api_docs/python/tf/math#Segmentation)\n",
      "        for an explanation of segments.\n",
      "        \n",
      "        Computes a tensor such that\n",
      "        \\\\(output_i = \\sum_j data_j\\\\) where sum is over `j` such\n",
      "        that `segment_ids[j] == i`.\n",
      "        \n",
      "        If the sum is empty for a given segment ID `i`, `output[i] = 0`.\n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        <img style=\"width:100%\" src=\"https://www.tensorflow.org/images/SegmentSum.png\" alt>\n",
      "        </div>\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```\n",
      "        c = tf.constant([[1,2,3,4], [4, 3, 2, 1], [5,6,7,8]])\n",
      "        tf.segment_sum(c, tf.constant([0, 0, 1]))\n",
      "        # ==> [[5, 5, 5, 5],\n",
      "        #      [5, 6, 7, 8]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          data: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.\n",
      "          segment_ids: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            A 1-D tensor whose size is equal to the size of `data`'s\n",
      "            first dimension.  Values should be sorted and can be repeated.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `data`.\n",
      "    \n",
      "    self_adjoint_eig(tensor, name=None)\n",
      "        Computes the eigen decomposition of a batch of self-adjoint matrices.\n",
      "        \n",
      "        Computes the eigenvalues and eigenvectors of the innermost N-by-N matrices\n",
      "        in `tensor` such that\n",
      "        `tensor[...,:,:] * v[..., :,i] = e[..., i] * v[...,:,i]`, for i=0...N-1.\n",
      "        \n",
      "        Args:\n",
      "          tensor: `Tensor` of shape `[..., N, N]`. Only the lower triangular part of\n",
      "            each inner inner matrix is referenced.\n",
      "          name: string, optional name of the operation.\n",
      "        \n",
      "        Returns:\n",
      "          e: Eigenvalues. Shape is `[..., N]`. Sorted in non-decreasing order.\n",
      "          v: Eigenvectors. Shape is `[..., N, N]`. The columns of the inner most\n",
      "            matrices contain eigenvectors of the corresponding matrices in `tensor`\n",
      "    \n",
      "    self_adjoint_eigvals(tensor, name=None)\n",
      "        Computes the eigenvalues of one or more self-adjoint matrices.\n",
      "        \n",
      "        Note: If your program backpropagates through this function, you should replace\n",
      "        it with a call to tf.linalg.eigh (possibly ignoring the second output) to\n",
      "        avoid computing the eigen decomposition twice. This is because the\n",
      "        eigenvectors are used to compute the gradient w.r.t. the eigenvalues. See\n",
      "        _SelfAdjointEigV2Grad in linalg_grad.py.\n",
      "        \n",
      "        Args:\n",
      "          tensor: `Tensor` of shape `[..., N, N]`.\n",
      "          name: string, optional name of the operation.\n",
      "        \n",
      "        Returns:\n",
      "          e: Eigenvalues. Shape is `[..., N]`. The vector `e[..., :]` contains the `N`\n",
      "            eigenvalues of `tensor[..., :, :]`.\n",
      "    \n",
      "    sequence_mask(lengths, maxlen=None, dtype=tf.bool, name=None)\n",
      "        Returns a mask tensor representing the first N positions of each cell.\n",
      "        \n",
      "        If `lengths` has shape `[d_1, d_2, ..., d_n]` the resulting tensor `mask` has\n",
      "        dtype `dtype` and shape `[d_1, d_2, ..., d_n, maxlen]`, with\n",
      "        \n",
      "        ```\n",
      "        mask[i_1, i_2, ..., i_n, j] = (j < lengths[i_1, i_2, ..., i_n])\n",
      "        ```\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "        ```python\n",
      "        tf.sequence_mask([1, 3, 2], 5)  # [[True, False, False, False, False],\n",
      "                                        #  [True, True, True, False, False],\n",
      "                                        #  [True, True, False, False, False]]\n",
      "        \n",
      "        tf.sequence_mask([[1, 3],[2,0]])  # [[[True, False, False],\n",
      "                                          #   [True, True, True]],\n",
      "                                          #  [[True, True, False],\n",
      "                                          #   [False, False, False]]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          lengths: integer tensor, all its values <= maxlen.\n",
      "          maxlen: scalar integer tensor, size of last dimension of returned tensor.\n",
      "            Default is the maximum value in `lengths`.\n",
      "          dtype: output type of the resulting tensor.\n",
      "          name: name of the op.\n",
      "        \n",
      "        Returns:\n",
      "          A mask tensor of shape `lengths.shape + (maxlen,)`, cast to specified dtype.\n",
      "        Raises:\n",
      "          ValueError: if `maxlen` is not a scalar.\n",
      "    \n",
      "    serialize_many_sparse(sp_input, name=None, out_type=tf.string)\n",
      "        Serialize `N`-minibatch `SparseTensor` into an `[N, 3]` `Tensor`.\n",
      "        \n",
      "        The `SparseTensor` must have rank `R` greater than 1, and the first dimension\n",
      "        is treated as the minibatch dimension.  Elements of the `SparseTensor`\n",
      "        must be sorted in increasing order of this first dimension.  The serialized\n",
      "        `SparseTensor` objects going into each row of the output `Tensor` will have\n",
      "        rank `R-1`.\n",
      "        \n",
      "        The minibatch size `N` is extracted from `sparse_shape[0]`.\n",
      "        \n",
      "        Args:\n",
      "          sp_input: The input rank `R` `SparseTensor`.\n",
      "          name: A name prefix for the returned tensors (optional).\n",
      "          out_type: The `dtype` to use for serialization.\n",
      "        \n",
      "        Returns:\n",
      "          A matrix (2-D `Tensor`) with `N` rows and `3` columns. Each column\n",
      "          represents serialized `SparseTensor`'s indices, values, and shape\n",
      "          (respectively).\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `sp_input` is not a `SparseTensor`.\n",
      "    \n",
      "    serialize_sparse(sp_input, name=None, out_type=tf.string)\n",
      "        Serialize a `SparseTensor` into a 3-vector (1-D `Tensor`) object.\n",
      "        \n",
      "        Args:\n",
      "          sp_input: The input `SparseTensor`.\n",
      "          name: A name prefix for the returned tensors (optional).\n",
      "          out_type: The `dtype` to use for serialization.\n",
      "        \n",
      "        Returns:\n",
      "          A 3-vector (1-D `Tensor`), with each column representing the serialized\n",
      "          `SparseTensor`'s indices, values, and shape (respectively).\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `sp_input` is not a `SparseTensor`.\n",
      "    \n",
      "    serialize_tensor(tensor, name=None)\n",
      "        Transforms a Tensor into a serialized TensorProto proto.\n",
      "        \n",
      "        Args:\n",
      "          tensor: A `Tensor`. A Tensor of type `T`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `string`.\n",
      "    \n",
      "    set_random_seed(seed)\n",
      "        Sets the graph-level random seed for the default graph.\n",
      "        \n",
      "        Operations that rely on a random seed actually derive it from two seeds:\n",
      "        the graph-level and operation-level seeds. This sets the graph-level seed.\n",
      "        \n",
      "        Its interactions with operation-level seeds is as follows:\n",
      "        \n",
      "          1. If neither the graph-level nor the operation seed is set:\n",
      "            A random seed is used for this op.\n",
      "          2. If the graph-level seed is set, but the operation seed is not:\n",
      "            The system deterministically picks an operation seed in conjunction\n",
      "            with the graph-level seed so that it gets a unique random sequence.\n",
      "          3. If the graph-level seed is not set, but the operation seed is set:\n",
      "            A default graph-level seed and the specified operation seed are used to\n",
      "            determine the random sequence.\n",
      "          4. If both the graph-level and the operation seed are set:\n",
      "            Both seeds are used in conjunction to determine the random sequence.\n",
      "        \n",
      "        To illustrate the user-visible effects, consider these examples:\n",
      "        \n",
      "        To generate different sequences across sessions, set neither\n",
      "        graph-level nor op-level seeds:\n",
      "        \n",
      "        ```python\n",
      "        a = tf.random.uniform([1])\n",
      "        b = tf.random.normal([1])\n",
      "        \n",
      "        print(\"Session 1\")\n",
      "        with tf.compat.v1.Session() as sess1:\n",
      "          print(sess1.run(a))  # generates 'A1'\n",
      "          print(sess1.run(a))  # generates 'A2'\n",
      "          print(sess1.run(b))  # generates 'B1'\n",
      "          print(sess1.run(b))  # generates 'B2'\n",
      "        \n",
      "        print(\"Session 2\")\n",
      "        with tf.compat.v1.Session() as sess2:\n",
      "          print(sess2.run(a))  # generates 'A3'\n",
      "          print(sess2.run(a))  # generates 'A4'\n",
      "          print(sess2.run(b))  # generates 'B3'\n",
      "          print(sess2.run(b))  # generates 'B4'\n",
      "        ```\n",
      "        \n",
      "        To generate the same repeatable sequence for an op across sessions, set the\n",
      "        seed for the op:\n",
      "        \n",
      "        ```python\n",
      "        a = tf.random.uniform([1], seed=1)\n",
      "        b = tf.random.normal([1])\n",
      "        \n",
      "        # Repeatedly running this block with the same graph will generate the same\n",
      "        # sequence of values for 'a', but different sequences of values for 'b'.\n",
      "        print(\"Session 1\")\n",
      "        with tf.compat.v1.Session() as sess1:\n",
      "          print(sess1.run(a))  # generates 'A1'\n",
      "          print(sess1.run(a))  # generates 'A2'\n",
      "          print(sess1.run(b))  # generates 'B1'\n",
      "          print(sess1.run(b))  # generates 'B2'\n",
      "        \n",
      "        print(\"Session 2\")\n",
      "        with tf.compat.v1.Session() as sess2:\n",
      "          print(sess2.run(a))  # generates 'A1'\n",
      "          print(sess2.run(a))  # generates 'A2'\n",
      "          print(sess2.run(b))  # generates 'B3'\n",
      "          print(sess2.run(b))  # generates 'B4'\n",
      "        ```\n",
      "        \n",
      "        To make the random sequences generated by all ops be repeatable across\n",
      "        sessions, set a graph-level seed:\n",
      "        \n",
      "        ```python\n",
      "        tf.compat.v1.random.set_random_seed(1234)\n",
      "        a = tf.random.uniform([1])\n",
      "        b = tf.random.normal([1])\n",
      "        \n",
      "        # Repeatedly running this block with the same graph will generate the same\n",
      "        # sequences of 'a' and 'b'.\n",
      "        print(\"Session 1\")\n",
      "        with tf.compat.v1.Session() as sess1:\n",
      "          print(sess1.run(a))  # generates 'A1'\n",
      "          print(sess1.run(a))  # generates 'A2'\n",
      "          print(sess1.run(b))  # generates 'B1'\n",
      "          print(sess1.run(b))  # generates 'B2'\n",
      "        \n",
      "        print(\"Session 2\")\n",
      "        with tf.compat.v1.Session() as sess2:\n",
      "          print(sess2.run(a))  # generates 'A1'\n",
      "          print(sess2.run(a))  # generates 'A2'\n",
      "          print(sess2.run(b))  # generates 'B1'\n",
      "          print(sess2.run(b))  # generates 'B2'\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          seed: integer.\n",
      "    \n",
      "    setdiff1d(x, y, index_dtype=tf.int32, name=None)\n",
      "        Computes the difference between two lists of numbers or strings.\n",
      "        \n",
      "        Given a list `x` and a list `y`, this operation returns a list `out` that\n",
      "        represents all values that are in `x` but not in `y`. The returned list `out`\n",
      "        is sorted in the same order that the numbers appear in `x` (duplicates are\n",
      "        preserved). This operation also returns a list `idx` that represents the\n",
      "        position of each `out` element in `x`. In other words:\n",
      "        \n",
      "        `out[i] = x[idx[i]] for i in [0, 1, ..., len(out) - 1]`\n",
      "        \n",
      "        For example, given this input:\n",
      "        \n",
      "        ```\n",
      "        x = [1, 2, 3, 4, 5, 6]\n",
      "        y = [1, 3, 5]\n",
      "        ```\n",
      "        \n",
      "        This operation would return:\n",
      "        \n",
      "        ```\n",
      "        out ==> [2, 4, 6]\n",
      "        idx ==> [1, 3, 5]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. 1-D. Values to keep.\n",
      "          y: A `Tensor`. Must have the same type as `x`. 1-D. Values to remove.\n",
      "          out_idx: An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int32`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A tuple of `Tensor` objects (out, idx).\n",
      "        \n",
      "          out: A `Tensor`. Has the same type as `x`.\n",
      "          idx: A `Tensor` of type `out_idx`.\n",
      "    \n",
      "    shape(input, name=None, out_type=tf.int32)\n",
      "        Returns the shape of a tensor.\n",
      "        \n",
      "        This operation returns a 1-D integer tensor representing the shape of `input`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        t = tf.constant([[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]])\n",
      "        tf.shape(t)  # [2, 2, 3]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor` or `SparseTensor`.\n",
      "          name: A name for the operation (optional).\n",
      "          out_type: (Optional) The specified output type of the operation (`int32` or\n",
      "            `int64`). Defaults to `tf.int32`.\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `out_type`.\n",
      "    \n",
      "    shape_n(input, out_type=tf.int32, name=None)\n",
      "        Returns shape of tensors.\n",
      "        \n",
      "        Args:\n",
      "          input: A list of at least 1 `Tensor` object with the same type.\n",
      "          out_type: The specified output type of the operation (`int32` or `int64`).\n",
      "            Defaults to `tf.int32`(optional).\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A list with the same length as `input` of `Tensor` objects with\n",
      "            type `out_type`.\n",
      "    \n",
      "    sigmoid(x, name=None)\n",
      "        Computes sigmoid of `x` element-wise.\n",
      "        \n",
      "        Specifically, `y = 1 / (1 + exp(-x))`.\n",
      "        \n",
      "        Args:\n",
      "          x: A Tensor with type `float16`, `float32`, `float64`, `complex64`, or\n",
      "            `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A Tensor with the same type as `x`.\n",
      "        \n",
      "        @compatibility(scipy)\n",
      "        Equivalent to scipy.special.expit\n",
      "        @end_compatibility\n",
      "    \n",
      "    sign(x, name=None)\n",
      "        Returns an element-wise indication of the sign of a number.\n",
      "        \n",
      "        `y = sign(x) = -1` if `x < 0`; 0 if `x == 0`; 1 if `x > 0`.\n",
      "        \n",
      "        For complex numbers, `y = sign(x) = x / |x|` if `x != 0`, otherwise `y = 0`.\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int32`, `int64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "        \n",
      "          If `x` is a `SparseTensor`, returns\n",
      "          `SparseTensor(x.indices, tf.math.sign(x.values, ...), x.dense_shape)`\n",
      "    \n",
      "    sin(x, name=None)\n",
      "        Computes sine of x element-wise.\n",
      "        \n",
      "          Given an input tensor, this function computes sine of every\n",
      "          element in the tensor. Input range is `(-inf, inf)` and\n",
      "          output range is `[-1,1]`.\n",
      "        \n",
      "          ```python\n",
      "          x = tf.constant([-float(\"inf\"), -9, -0.5, 1, 1.2, 200, 10, float(\"inf\")])\n",
      "          tf.math.sin(x) ==> [nan -0.4121185 -0.47942555 0.84147096 0.9320391 -0.87329733 -0.54402107 nan]\n",
      "          ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    sinh(x, name=None)\n",
      "        Computes hyperbolic sine of x element-wise.\n",
      "        \n",
      "          Given an input tensor, this function computes hyperbolic sine of every\n",
      "          element in the tensor. Input range is `[-inf,inf]` and output range\n",
      "          is `[-inf,inf]`.\n",
      "        \n",
      "          ```python\n",
      "          x = tf.constant([-float(\"inf\"), -9, -0.5, 1, 1.2, 2, 10, float(\"inf\")])\n",
      "          tf.math.sinh(x) ==> [-inf -4.0515420e+03 -5.2109528e-01 1.1752012e+00 1.5094614e+00 3.6268604e+00 1.1013232e+04 inf]\n",
      "          ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    size(input, name=None, out_type=tf.int32)\n",
      "        Returns the size of a tensor.\n",
      "        \n",
      "        Returns a 0-D `Tensor` representing the number of elements in `input`\n",
      "        of type `out_type`. Defaults to tf.int32.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        t = tf.constant([[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]])\n",
      "        tf.size(t)  # 12\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor` or `SparseTensor`.\n",
      "          name: A name for the operation (optional).\n",
      "          out_type: (Optional) The specified non-quantized numeric output type of the\n",
      "            operation. Defaults to `tf.int32`.\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `out_type`. Defaults to `tf.int32`.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Equivalent to np.size()\n",
      "        @end_compatibility\n",
      "    \n",
      "    slice(input_, begin, size, name=None)\n",
      "        Extracts a slice from a tensor.\n",
      "        \n",
      "        This operation extracts a slice of size `size` from a tensor `input_` starting\n",
      "        at the location specified by `begin`. The slice `size` is represented as a\n",
      "        tensor shape, where `size[i]` is the number of elements of the 'i'th dimension\n",
      "        of `input_` that you want to slice. The starting location (`begin`) for the\n",
      "        slice is represented as an offset in each dimension of `input_`. In other\n",
      "        words, `begin[i]` is the offset into the i'th dimension of `input_` that you\n",
      "        want to slice from.\n",
      "        \n",
      "        Note that `tf.Tensor.__getitem__` is typically a more pythonic way to\n",
      "        perform slices, as it allows you to write `foo[3:7, :-2]` instead of\n",
      "        `tf.slice(foo, [3, 0], [4, foo.get_shape()[1]-2])`.\n",
      "        \n",
      "        `begin` is zero-based; `size` is one-based. If `size[i]` is -1,\n",
      "        all remaining elements in dimension i are included in the\n",
      "        slice. In other words, this is equivalent to setting:\n",
      "        \n",
      "        `size[i] = input_.dim_size(i) - begin[i]`\n",
      "        \n",
      "        This operation requires that:\n",
      "        \n",
      "        `0 <= begin[i] <= begin[i] + size[i] <= Di  for i in [0, n]`\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        t = tf.constant([[[1, 1, 1], [2, 2, 2]],\n",
      "                         [[3, 3, 3], [4, 4, 4]],\n",
      "                         [[5, 5, 5], [6, 6, 6]]])\n",
      "        tf.slice(t, [1, 0, 0], [1, 1, 3])  # [[[3, 3, 3]]]\n",
      "        tf.slice(t, [1, 0, 0], [1, 2, 3])  # [[[3, 3, 3],\n",
      "                                           #   [4, 4, 4]]]\n",
      "        tf.slice(t, [1, 0, 0], [2, 1, 3])  # [[[3, 3, 3]],\n",
      "                                           #  [[5, 5, 5]]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input_: A `Tensor`.\n",
      "          begin: An `int32` or `int64` `Tensor`.\n",
      "          size: An `int32` or `int64` `Tensor`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` the same type as `input_`.\n",
      "    \n",
      "    sort(values, axis=-1, direction='ASCENDING', name=None)\n",
      "        Sorts a tensor.\n",
      "        \n",
      "        Usage:\n",
      "        \n",
      "        ```python\n",
      "        import tensorflow as tf\n",
      "        a = [1, 10, 26.9, 2.8, 166.32, 62.3]\n",
      "        b = tf.sort(a,axis=-1,direction='ASCENDING',name=None)\n",
      "        c = tf.keras.backend.eval(b)\n",
      "        # Here, c = [  1.     2.8   10.    26.9   62.3  166.32]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          values: 1-D or higher numeric `Tensor`.\n",
      "          axis: The axis along which to sort. The default is -1, which sorts the last\n",
      "            axis.\n",
      "          direction: The direction in which to sort the values (`'ASCENDING'` or\n",
      "            `'DESCENDING'`).\n",
      "          name: Optional name for the operation.\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` with the same dtype and shape as `values`, with the elements\n",
      "              sorted along the given `axis`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If axis is not a constant scalar, or the direction is invalid.\n",
      "    \n",
      "    space_to_batch(input, paddings, block_size=None, name=None, block_shape=None)\n",
      "        SpaceToBatch for 4-D tensors of type T.\n",
      "        \n",
      "        This is a legacy version of the more general SpaceToBatchND.\n",
      "        \n",
      "        Zero-pads and then rearranges (permutes) blocks of spatial data into batch.\n",
      "        More specifically, this op outputs a copy of the input tensor where values from\n",
      "        the `height` and `width` dimensions are moved to the `batch` dimension. After\n",
      "        the zero-padding, both `height` and `width` of the input must be divisible by the\n",
      "        block size.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. 4-D with shape `[batch, height, width, depth]`.\n",
      "          paddings: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            2-D tensor of non-negative integers with shape `[2, 2]`. It specifies\n",
      "              the padding of the input with zeros across the spatial dimensions as follows:\n",
      "        \n",
      "                  paddings = [[pad_top, pad_bottom], [pad_left, pad_right]]\n",
      "        \n",
      "              The effective spatial dimensions of the zero-padded input tensor will be:\n",
      "        \n",
      "                  height_pad = pad_top + height + pad_bottom\n",
      "                  width_pad = pad_left + width + pad_right\n",
      "        \n",
      "            The attr `block_size` must be greater than one. It indicates the block size.\n",
      "        \n",
      "              * Non-overlapping blocks of size `block_size x block size` in the height and\n",
      "                width dimensions are rearranged into the batch dimension at each location.\n",
      "              * The batch of the output tensor is `batch * block_size * block_size`.\n",
      "              * Both height_pad and width_pad must be divisible by block_size.\n",
      "        \n",
      "            The shape of the output will be:\n",
      "        \n",
      "                [batch*block_size*block_size, height_pad/block_size, width_pad/block_size,\n",
      "                 depth]\n",
      "        \n",
      "            Some examples:\n",
      "        \n",
      "            (1) For the following input of shape `[1, 2, 2, 1]` and block_size of 2:\n",
      "        \n",
      "            ```\n",
      "            x = [[[[1], [2]], [[3], [4]]]]\n",
      "            ```\n",
      "        \n",
      "            The output tensor has shape `[4, 1, 1, 1]` and value:\n",
      "        \n",
      "            ```\n",
      "            [[[[1]]], [[[2]]], [[[3]]], [[[4]]]]\n",
      "            ```\n",
      "        \n",
      "            (2) For the following input of shape `[1, 2, 2, 3]` and block_size of 2:\n",
      "        \n",
      "            ```\n",
      "            x = [[[[1, 2, 3], [4, 5, 6]],\n",
      "                  [[7, 8, 9], [10, 11, 12]]]]\n",
      "            ```\n",
      "        \n",
      "            The output tensor has shape `[4, 1, 1, 3]` and value:\n",
      "        \n",
      "            ```\n",
      "            [[[[1, 2, 3]]], [[[4, 5, 6]]], [[[7, 8, 9]]], [[[10, 11, 12]]]]\n",
      "            ```\n",
      "        \n",
      "            (3) For the following input of shape `[1, 4, 4, 1]` and block_size of 2:\n",
      "        \n",
      "            ```\n",
      "            x = [[[[1],   [2],  [3],  [4]],\n",
      "                  [[5],   [6],  [7],  [8]],\n",
      "                  [[9],  [10], [11],  [12]],\n",
      "                  [[13], [14], [15],  [16]]]]\n",
      "            ```\n",
      "        \n",
      "            The output tensor has shape `[4, 2, 2, 1]` and value:\n",
      "        \n",
      "            ```\n",
      "            x = [[[[1], [3]], [[9], [11]]],\n",
      "                 [[[2], [4]], [[10], [12]]],\n",
      "                 [[[5], [7]], [[13], [15]]],\n",
      "                 [[[6], [8]], [[14], [16]]]]\n",
      "            ```\n",
      "        \n",
      "            (4) For the following input of shape `[2, 2, 4, 1]` and block_size of 2:\n",
      "        \n",
      "            ```\n",
      "            x = [[[[1],   [2],  [3],  [4]],\n",
      "                  [[5],   [6],  [7],  [8]]],\n",
      "                 [[[9],  [10], [11],  [12]],\n",
      "                  [[13], [14], [15],  [16]]]]\n",
      "            ```\n",
      "        \n",
      "            The output tensor has shape `[8, 1, 2, 1]` and value:\n",
      "        \n",
      "            ```\n",
      "            x = [[[[1], [3]]], [[[9], [11]]], [[[2], [4]]], [[[10], [12]]],\n",
      "                 [[[5], [7]]], [[[13], [15]]], [[[6], [8]]], [[[14], [16]]]]\n",
      "            ```\n",
      "        \n",
      "            Among others, this operation is useful for reducing atrous convolution into\n",
      "            regular convolution.\n",
      "          block_size: An `int` that is `>= 2`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    space_to_batch_nd(input, block_shape, paddings, name=None)\n",
      "        SpaceToBatch for N-D tensors of type T.\n",
      "        \n",
      "        This operation divides \"spatial\" dimensions `[1, ..., M]` of the input into a\n",
      "        grid of blocks of shape `block_shape`, and interleaves these blocks with the\n",
      "        \"batch\" dimension (0) such that in the output, the spatial dimensions\n",
      "        `[1, ..., M]` correspond to the position within the grid, and the batch\n",
      "        dimension combines both the position within a spatial block and the original\n",
      "        batch position.  Prior to division into blocks, the spatial dimensions of the\n",
      "        input are optionally zero padded according to `paddings`.  See below for a\n",
      "        precise description.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`.\n",
      "            N-D with shape `input_shape = [batch] + spatial_shape + remaining_shape`,\n",
      "            where spatial_shape has `M` dimensions.\n",
      "          block_shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            1-D with shape `[M]`, all values must be >= 1.\n",
      "          paddings: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            2-D with shape `[M, 2]`, all values must be >= 0.\n",
      "              `paddings[i] = [pad_start, pad_end]` specifies the padding for input dimension\n",
      "              `i + 1`, which corresponds to spatial dimension `i`.  It is required that\n",
      "              `block_shape[i]` divides `input_shape[i + 1] + pad_start + pad_end`.\n",
      "        \n",
      "            This operation is equivalent to the following steps:\n",
      "        \n",
      "            1. Zero-pad the start and end of dimensions `[1, ..., M]` of the\n",
      "               input according to `paddings` to produce `padded` of shape `padded_shape`.\n",
      "        \n",
      "            2. Reshape `padded` to `reshaped_padded` of shape:\n",
      "        \n",
      "                 [batch] +\n",
      "                 [padded_shape[1] / block_shape[0],\n",
      "                   block_shape[0],\n",
      "                  ...,\n",
      "                  padded_shape[M] / block_shape[M-1],\n",
      "                  block_shape[M-1]] +\n",
      "                 remaining_shape\n",
      "        \n",
      "            3. Permute dimensions of `reshaped_padded` to produce\n",
      "               `permuted_reshaped_padded` of shape:\n",
      "        \n",
      "                 block_shape +\n",
      "                 [batch] +\n",
      "                 [padded_shape[1] / block_shape[0],\n",
      "                  ...,\n",
      "                  padded_shape[M] / block_shape[M-1]] +\n",
      "                 remaining_shape\n",
      "        \n",
      "            4. Reshape `permuted_reshaped_padded` to flatten `block_shape` into the batch\n",
      "               dimension, producing an output tensor of shape:\n",
      "        \n",
      "                 [batch * prod(block_shape)] +\n",
      "                 [padded_shape[1] / block_shape[0],\n",
      "                  ...,\n",
      "                  padded_shape[M] / block_shape[M-1]] +\n",
      "                 remaining_shape\n",
      "        \n",
      "            Some examples:\n",
      "        \n",
      "            (1) For the following input of shape `[1, 2, 2, 1]`, `block_shape = [2, 2]`, and\n",
      "                `paddings = [[0, 0], [0, 0]]`:\n",
      "        \n",
      "            ```\n",
      "            x = [[[[1], [2]], [[3], [4]]]]\n",
      "            ```\n",
      "        \n",
      "            The output tensor has shape `[4, 1, 1, 1]` and value:\n",
      "        \n",
      "            ```\n",
      "            [[[[1]]], [[[2]]], [[[3]]], [[[4]]]]\n",
      "            ```\n",
      "        \n",
      "            (2) For the following input of shape `[1, 2, 2, 3]`, `block_shape = [2, 2]`, and\n",
      "                `paddings = [[0, 0], [0, 0]]`:\n",
      "        \n",
      "            ```\n",
      "            x = [[[[1, 2, 3], [4, 5, 6]],\n",
      "                  [[7, 8, 9], [10, 11, 12]]]]\n",
      "            ```\n",
      "        \n",
      "            The output tensor has shape `[4, 1, 1, 3]` and value:\n",
      "        \n",
      "            ```\n",
      "            [[[[1, 2, 3]]], [[[4, 5, 6]]], [[[7, 8, 9]]], [[[10, 11, 12]]]]\n",
      "            ```\n",
      "        \n",
      "            (3) For the following input of shape `[1, 4, 4, 1]`, `block_shape = [2, 2]`, and\n",
      "                `paddings = [[0, 0], [0, 0]]`:\n",
      "        \n",
      "            ```\n",
      "            x = [[[[1],   [2],  [3],  [4]],\n",
      "                  [[5],   [6],  [7],  [8]],\n",
      "                  [[9],  [10], [11],  [12]],\n",
      "                  [[13], [14], [15],  [16]]]]\n",
      "            ```\n",
      "        \n",
      "            The output tensor has shape `[4, 2, 2, 1]` and value:\n",
      "        \n",
      "            ```\n",
      "            x = [[[[1], [3]], [[9], [11]]],\n",
      "                 [[[2], [4]], [[10], [12]]],\n",
      "                 [[[5], [7]], [[13], [15]]],\n",
      "                 [[[6], [8]], [[14], [16]]]]\n",
      "            ```\n",
      "        \n",
      "            (4) For the following input of shape `[2, 2, 4, 1]`, block_shape = `[2, 2]`, and\n",
      "                paddings = `[[0, 0], [2, 0]]`:\n",
      "        \n",
      "            ```\n",
      "            x = [[[[1],   [2],  [3],  [4]],\n",
      "                  [[5],   [6],  [7],  [8]]],\n",
      "                 [[[9],  [10], [11],  [12]],\n",
      "                  [[13], [14], [15],  [16]]]]\n",
      "            ```\n",
      "        \n",
      "            The output tensor has shape `[8, 1, 3, 1]` and value:\n",
      "        \n",
      "            ```\n",
      "            x = [[[[0], [1], [3]]], [[[0], [9], [11]]],\n",
      "                 [[[0], [2], [4]]], [[[0], [10], [12]]],\n",
      "                 [[[0], [5], [7]]], [[[0], [13], [15]]],\n",
      "                 [[[0], [6], [8]]], [[[0], [14], [16]]]]\n",
      "            ```\n",
      "        \n",
      "            Among others, this operation is useful for reducing atrous convolution into\n",
      "            regular convolution.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    space_to_depth(input, block_size, name=None, data_format='NHWC')\n",
      "        SpaceToDepth for tensors of type T.\n",
      "        \n",
      "        Rearranges blocks of spatial data, into depth. More specifically,\n",
      "        this op outputs a copy of the input tensor where values from the `height`\n",
      "        and `width` dimensions are moved to the `depth` dimension.\n",
      "        The attr `block_size` indicates the input block size.\n",
      "        \n",
      "          * Non-overlapping blocks of size `block_size x block size` are rearranged\n",
      "            into depth at each location.\n",
      "          * The depth of the output tensor is `block_size * block_size * input_depth`.\n",
      "          * The Y, X coordinates within each block of the input become the high order\n",
      "            component of the output channel index.\n",
      "          * The input tensor's height and width must be divisible by block_size.\n",
      "        \n",
      "        The `data_format` attr specifies the layout of the input and output tensors\n",
      "        with the following options:\n",
      "          \"NHWC\": `[ batch, height, width, channels ]`\n",
      "          \"NCHW\": `[ batch, channels, height, width ]`\n",
      "          \"NCHW_VECT_C\":\n",
      "              `qint8 [ batch, channels / 4, height, width, 4 ]`\n",
      "        \n",
      "        It is useful to consider the operation as transforming a 6-D Tensor.\n",
      "        e.g. for data_format = NHWC,\n",
      "             Each element in the input tensor can be specified via 6 coordinates,\n",
      "             ordered by decreasing memory layout significance as:\n",
      "             n,oY,bY,oX,bX,iC  (where n=batch index, oX, oY means X or Y coordinates\n",
      "                                within the output image, bX, bY means coordinates\n",
      "                                within the input block, iC means input channels).\n",
      "             The output would be a transpose to the following layout:\n",
      "             n,oY,oX,bY,bX,iC\n",
      "        \n",
      "        This operation is useful for resizing the activations between convolutions\n",
      "        (but keeping all data), e.g. instead of pooling. It is also useful for training\n",
      "        purely convolutional models.\n",
      "        \n",
      "        For example, given an input of shape `[1, 2, 2, 1]`, data_format = \"NHWC\" and\n",
      "        block_size = 2:\n",
      "        \n",
      "        ```\n",
      "        x = [[[[1], [2]],\n",
      "              [[3], [4]]]]\n",
      "        ```\n",
      "        \n",
      "        This operation will output a tensor of shape `[1, 1, 1, 4]`:\n",
      "        \n",
      "        ```\n",
      "        [[[[1, 2, 3, 4]]]]\n",
      "        ```\n",
      "        \n",
      "        Here, the input has a batch of 1 and each batch element has shape `[2, 2, 1]`,\n",
      "        the corresponding output will have a single element (i.e. width and height are\n",
      "        both 1) and will have a depth of 4 channels (1 * block_size * block_size).\n",
      "        The output element shape is `[1, 1, 4]`.\n",
      "        \n",
      "        For an input tensor with larger depth, here of shape `[1, 2, 2, 3]`, e.g.\n",
      "        \n",
      "        ```\n",
      "        x = [[[[1, 2, 3], [4, 5, 6]],\n",
      "              [[7, 8, 9], [10, 11, 12]]]]\n",
      "        ```\n",
      "        \n",
      "        This operation, for block_size of 2, will return the following tensor of shape\n",
      "        `[1, 1, 1, 12]`\n",
      "        \n",
      "        ```\n",
      "        [[[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]]]]\n",
      "        ```\n",
      "        \n",
      "        Similarly, for the following input of shape `[1 4 4 1]`, and a block size of 2:\n",
      "        \n",
      "        ```\n",
      "        x = [[[[1],   [2],  [5],  [6]],\n",
      "              [[3],   [4],  [7],  [8]],\n",
      "              [[9],  [10], [13],  [14]],\n",
      "              [[11], [12], [15],  [16]]]]\n",
      "        ```\n",
      "        \n",
      "        the operator will return the following tensor of shape `[1 2 2 4]`:\n",
      "        \n",
      "        ```\n",
      "        x = [[[[1, 2, 3, 4],\n",
      "               [5, 6, 7, 8]],\n",
      "              [[9, 10, 11, 12],\n",
      "               [13, 14, 15, 16]]]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`.\n",
      "          block_size: An `int` that is `>= 2`. The size of the spatial block.\n",
      "          data_format: An optional `string` from: `\"NHWC\", \"NCHW\", \"NCHW_VECT_C\"`. Defaults to `\"NHWC\"`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    sparse_add(a, b, threshold=None, thresh=None)\n",
      "        Adds two tensors, at least one of each is a `SparseTensor`. (deprecated arguments)\n",
      "        \n",
      "        Warning: SOME ARGUMENTS ARE DEPRECATED: `(thresh)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        thresh is deprecated, use threshold instead\n",
      "        \n",
      "        If one `SparseTensor` and one `Tensor` are passed in, returns a `Tensor`.  If\n",
      "        both arguments are `SparseTensor`s, this returns a `SparseTensor`.  The order\n",
      "        of arguments does not matter.  Use vanilla `tf.add()` for adding two dense\n",
      "        `Tensor`s.\n",
      "        \n",
      "        The shapes of the two operands must match: broadcasting is not supported.\n",
      "        \n",
      "        The indices of any input `SparseTensor` are assumed ordered in standard\n",
      "        lexicographic order.  If this is not the case, before this step run\n",
      "        `SparseReorder` to restore index ordering.\n",
      "        \n",
      "        If both arguments are sparse, we perform \"clipping\" as follows.  By default,\n",
      "        if two values sum to zero at some index, the output `SparseTensor` would still\n",
      "        include that particular location in its index, storing a zero in the\n",
      "        corresponding value slot.  To override this, callers can specify `thresh`,\n",
      "        indicating that if the sum has a magnitude strictly smaller than `thresh`, its\n",
      "        corresponding value and index would then not be included.  In particular,\n",
      "        `thresh == 0.0` (default) means everything is kept and actual thresholding\n",
      "        happens only for a positive value.\n",
      "        \n",
      "        For example, suppose the logical sum of two sparse operands is (densified):\n",
      "        \n",
      "            [       2]\n",
      "            [.1     0]\n",
      "            [ 6   -.2]\n",
      "        \n",
      "        Then,\n",
      "        \n",
      "        * `thresh == 0` (the default): all 5 index/value pairs will be returned.\n",
      "        * `thresh == 0.11`: only .1 and 0 will vanish, and the remaining three\n",
      "            index/value pairs will be returned.\n",
      "        * `thresh == 0.21`: .1, 0, and -.2 will vanish.\n",
      "        \n",
      "        Args:\n",
      "          a: The first operand; `SparseTensor` or `Tensor`.\n",
      "          b: The second operand; `SparseTensor` or `Tensor`. At least one operand\n",
      "            must be sparse.\n",
      "          threshold: An optional 0-D `Tensor` (defaults to `0`). The magnitude\n",
      "            threshold that determines if an output value/index pair takes space. Its\n",
      "            dtype should match that of the values if they are real; if the latter are\n",
      "            complex64/complex128, then the dtype should be float32/float64,\n",
      "            correspondingly.\n",
      "          thresh: Deprecated alias for `threshold`.\n",
      "        \n",
      "        Returns:\n",
      "          A `SparseTensor` or a `Tensor`, representing the sum.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If both `a` and `b` are `Tensor`s.  Use `tf.add()` instead.\n",
      "    \n",
      "    sparse_concat(axis, sp_inputs, name=None, expand_nonconcat_dim=False, concat_dim=None, expand_nonconcat_dims=None)\n",
      "        Concatenates a list of `SparseTensor` along the specified dimension. (deprecated arguments)\n",
      "        \n",
      "        Warning: SOME ARGUMENTS ARE DEPRECATED: `(concat_dim)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        concat_dim is deprecated, use axis instead\n",
      "        \n",
      "        Concatenation is with respect to the dense versions of each sparse input.\n",
      "        It is assumed that each inputs is a `SparseTensor` whose elements are ordered\n",
      "        along increasing dimension number.\n",
      "        \n",
      "        If expand_nonconcat_dim is False, all inputs' shapes must match, except for\n",
      "        the concat dimension. If expand_nonconcat_dim is True, then inputs' shapes are\n",
      "        allowed to vary among all inputs.\n",
      "        \n",
      "        The `indices`, `values`, and `shapes` lists must have the same length.\n",
      "        \n",
      "        If expand_nonconcat_dim is False, then the output shape is identical to the\n",
      "        inputs', except along the concat dimension, where it is the sum of the inputs'\n",
      "        sizes along that dimension.\n",
      "        \n",
      "        If expand_nonconcat_dim is True, then the output shape along the non-concat\n",
      "        dimensions will be expand to be the largest among all inputs, and it is the\n",
      "        sum of the inputs sizes along the concat dimension.\n",
      "        \n",
      "        The output elements will be resorted to preserve the sort order along\n",
      "        increasing dimension number.\n",
      "        \n",
      "        This op runs in `O(M log M)` time, where `M` is the total number of non-empty\n",
      "        values across all inputs. This is due to the need for an internal sort in\n",
      "        order to concatenate efficiently across an arbitrary dimension.\n",
      "        \n",
      "        For example, if `axis = 1` and the inputs are\n",
      "        \n",
      "            sp_inputs[0]: shape = [2, 3]\n",
      "            [0, 2]: \"a\"\n",
      "            [1, 0]: \"b\"\n",
      "            [1, 1]: \"c\"\n",
      "        \n",
      "            sp_inputs[1]: shape = [2, 4]\n",
      "            [0, 1]: \"d\"\n",
      "            [0, 2]: \"e\"\n",
      "        \n",
      "        then the output will be\n",
      "        \n",
      "            shape = [2, 7]\n",
      "            [0, 2]: \"a\"\n",
      "            [0, 4]: \"d\"\n",
      "            [0, 5]: \"e\"\n",
      "            [1, 0]: \"b\"\n",
      "            [1, 1]: \"c\"\n",
      "        \n",
      "        Graphically this is equivalent to doing\n",
      "        \n",
      "            [    a] concat [  d e  ] = [    a   d e  ]\n",
      "            [b c  ]        [       ]   [b c          ]\n",
      "        \n",
      "        Another example, if 'axis = 1' and the inputs are\n",
      "        \n",
      "            sp_inputs[0]: shape = [3, 3]\n",
      "            [0, 2]: \"a\"\n",
      "            [1, 0]: \"b\"\n",
      "            [2, 1]: \"c\"\n",
      "        \n",
      "            sp_inputs[1]: shape = [2, 4]\n",
      "            [0, 1]: \"d\"\n",
      "            [0, 2]: \"e\"\n",
      "        \n",
      "        if expand_nonconcat_dim = False, this will result in an error. But if\n",
      "        expand_nonconcat_dim = True, this will result in:\n",
      "        \n",
      "            shape = [3, 7]\n",
      "            [0, 2]: \"a\"\n",
      "            [0, 4]: \"d\"\n",
      "            [0, 5]: \"e\"\n",
      "            [1, 0]: \"b\"\n",
      "            [2, 1]: \"c\"\n",
      "        \n",
      "        Graphically this is equivalent to doing\n",
      "        \n",
      "            [    a] concat [  d e  ] = [    a   d e  ]\n",
      "            [b    ]        [       ]   [b            ]\n",
      "            [  c  ]                    [  c          ]\n",
      "        \n",
      "        \n",
      "        Args:\n",
      "          axis: Dimension to concatenate along. Must be in range [-rank, rank),\n",
      "            where rank is the number of dimensions in each input `SparseTensor`.\n",
      "          sp_inputs: List of `SparseTensor` to concatenate.\n",
      "          name: A name prefix for the returned tensors (optional).\n",
      "          expand_nonconcat_dim: Whether to allow the expansion in the non-concat\n",
      "            dimensions. Defaulted to False.\n",
      "          concat_dim: The old (deprecated) name for axis.\n",
      "          expand_nonconcat_dims: alias for expand_nonconcat_dim\n",
      "        \n",
      "        Returns:\n",
      "          A `SparseTensor` with the concatenated output.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `sp_inputs` is not a list of `SparseTensor`.\n",
      "    \n",
      "    sparse_fill_empty_rows(sp_input, default_value, name=None)\n",
      "        Fills empty rows in the input 2-D `SparseTensor` with a default value.\n",
      "        \n",
      "        This op adds entries with the specified `default_value` at index\n",
      "        `[row, 0]` for any row in the input that does not already have a value.\n",
      "        \n",
      "        For example, suppose `sp_input` has shape `[5, 6]` and non-empty values:\n",
      "        \n",
      "            [0, 1]: a\n",
      "            [0, 3]: b\n",
      "            [2, 0]: c\n",
      "            [3, 1]: d\n",
      "        \n",
      "        Rows 1 and 4 are empty, so the output will be of shape `[5, 6]` with values:\n",
      "        \n",
      "            [0, 1]: a\n",
      "            [0, 3]: b\n",
      "            [1, 0]: default_value\n",
      "            [2, 0]: c\n",
      "            [3, 1]: d\n",
      "            [4, 0]: default_value\n",
      "        \n",
      "        Note that the input may have empty columns at the end, with no effect on\n",
      "        this op.\n",
      "        \n",
      "        The output `SparseTensor` will be in row-major order and will have the\n",
      "        same shape as the input.\n",
      "        \n",
      "        This op also returns an indicator vector such that\n",
      "        \n",
      "            empty_row_indicator[i] = True iff row i was an empty row.\n",
      "        \n",
      "        Args:\n",
      "          sp_input: A `SparseTensor` with shape `[N, M]`.\n",
      "          default_value: The value to fill for empty rows, with the same type as\n",
      "            `sp_input.`\n",
      "          name: A name prefix for the returned tensors (optional)\n",
      "        \n",
      "        Returns:\n",
      "          sp_ordered_output: A `SparseTensor` with shape `[N, M]`, and with all empty\n",
      "            rows filled in with `default_value`.\n",
      "          empty_row_indicator: A bool vector of length `N` indicating whether each\n",
      "            input row was empty.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `sp_input` is not a `SparseTensor`.\n",
      "    \n",
      "    sparse_mask(a, mask_indices, name=None)\n",
      "        Masks elements of `IndexedSlices`.\n",
      "        \n",
      "        Given an `IndexedSlices` instance `a`, returns another `IndexedSlices` that\n",
      "        contains a subset of the slices of `a`. Only the slices at indices not\n",
      "        specified in `mask_indices` are returned.\n",
      "        \n",
      "        This is useful when you need to extract a subset of slices in an\n",
      "        `IndexedSlices` object.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        # `a` contains slices at indices [12, 26, 37, 45] from a large tensor\n",
      "        # with shape [1000, 10]\n",
      "        a.indices  # [12, 26, 37, 45]\n",
      "        tf.shape(a.values)  # [4, 10]\n",
      "        \n",
      "        # `b` will be the subset of `a` slices at its second and third indices, so\n",
      "        # we want to mask its first and last indices (which are at absolute\n",
      "        # indices 12, 45)\n",
      "        b = tf.sparse.mask(a, [12, 45])\n",
      "        \n",
      "        b.indices  # [26, 37]\n",
      "        tf.shape(b.values)  # [2, 10]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          a: An `IndexedSlices` instance.\n",
      "          mask_indices: Indices of elements to mask.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          The masked `IndexedSlices` instance.\n",
      "    \n",
      "    sparse_matmul = sparse_mat_mul(a, b, transpose_a=False, transpose_b=False, a_is_sparse=False, b_is_sparse=False, name=None)\n",
      "        Multiply matrix \"a\" by matrix \"b\".\n",
      "        \n",
      "        The inputs must be two-dimensional matrices and the inner dimension of \"a\" must\n",
      "        match the outer dimension of \"b\". Both \"a\" and \"b\" must be `Tensor`s not\n",
      "        `SparseTensor`s.  This op is optimized for the case where at least one of \"a\" or\n",
      "        \"b\" is sparse, in the sense that they have a large proportion of zero values.\n",
      "        The breakeven for using this versus a dense matrix multiply on one platform was\n",
      "        30% zero values in the sparse matrix.\n",
      "        \n",
      "        The gradient computation of this operation will only take advantage of sparsity\n",
      "        in the input gradient when that gradient comes from a Relu.\n",
      "        \n",
      "        Args:\n",
      "          a: A `Tensor`. Must be one of the following types: `float32`, `bfloat16`.\n",
      "          b: A `Tensor`. Must be one of the following types: `float32`, `bfloat16`.\n",
      "          transpose_a: An optional `bool`. Defaults to `False`.\n",
      "          transpose_b: An optional `bool`. Defaults to `False`.\n",
      "          a_is_sparse: An optional `bool`. Defaults to `False`.\n",
      "          b_is_sparse: An optional `bool`. Defaults to `False`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `float32`.\n",
      "    \n",
      "    sparse_maximum(sp_a, sp_b, name=None)\n",
      "        Returns the element-wise max of two SparseTensors.\n",
      "        \n",
      "        Assumes the two SparseTensors have the same shape, i.e., no broadcasting.\n",
      "        Example:\n",
      "        \n",
      "        ```python\n",
      "        sp_zero = sparse_tensor.SparseTensor([[0]], [0], [7])\n",
      "        sp_one = sparse_tensor.SparseTensor([[1]], [1], [7])\n",
      "        res = tf.sparse.maximum(sp_zero, sp_one).eval()\n",
      "        # \"res\" should be equal to SparseTensor([[0], [1]], [0, 1], [7]).\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          sp_a: a `SparseTensor` operand whose dtype is real, and indices\n",
      "            lexicographically ordered.\n",
      "          sp_b: the other `SparseTensor` operand with the same requirements (and the\n",
      "            same shape).\n",
      "          name: optional name of the operation.\n",
      "        Returns:\n",
      "          output: the output SparseTensor.\n",
      "    \n",
      "    sparse_merge(sp_ids, sp_values, vocab_size, name=None, already_sorted=False)\n",
      "        Combines a batch of feature ids and values into a single `SparseTensor`. (deprecated)\n",
      "        \n",
      "        Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        No similar op available at this time.\n",
      "        \n",
      "        The most common use case for this function occurs when feature ids and\n",
      "        their corresponding values are stored in `Example` protos on disk.\n",
      "        `parse_example` will return a batch of ids and a batch of values, and this\n",
      "        function joins them into a single logical `SparseTensor` for use in\n",
      "        functions such as `sparse_tensor_dense_matmul`, `sparse_to_dense`, etc.\n",
      "        \n",
      "        The `SparseTensor` returned by this function has the following properties:\n",
      "        \n",
      "          - `indices` is equivalent to `sp_ids.indices` with the last\n",
      "            dimension discarded and replaced with `sp_ids.values`.\n",
      "          - `values` is simply `sp_values.values`.\n",
      "          - If `sp_ids.dense_shape = [D0, D1, ..., Dn, K]`, then\n",
      "            `output.shape = [D0, D1, ..., Dn, vocab_size]`.\n",
      "        \n",
      "        For example, consider the following feature vectors:\n",
      "        \n",
      "        ```python\n",
      "          vector1 = [-3, 0, 0, 0, 0, 0]\n",
      "          vector2 = [ 0, 1, 0, 4, 1, 0]\n",
      "          vector3 = [ 5, 0, 0, 9, 0, 0]\n",
      "        ```\n",
      "        \n",
      "        These might be stored sparsely in the following Example protos by storing\n",
      "        only the feature ids (column number if the vectors are treated as a matrix)\n",
      "        of the non-zero elements and the corresponding values:\n",
      "        \n",
      "        ```python\n",
      "          examples = [Example(features={\n",
      "                          \"ids\": Feature(int64_list=Int64List(value=[0])),\n",
      "                          \"values\": Feature(float_list=FloatList(value=[-3]))}),\n",
      "                      Example(features={\n",
      "                          \"ids\": Feature(int64_list=Int64List(value=[1, 4, 3])),\n",
      "                          \"values\": Feature(float_list=FloatList(value=[1, 1, 4]))}),\n",
      "                      Example(features={\n",
      "                          \"ids\": Feature(int64_list=Int64List(value=[0, 3])),\n",
      "                          \"values\": Feature(float_list=FloatList(value=[5, 9]))})]\n",
      "        ```\n",
      "        \n",
      "        The result of calling parse_example on these examples will produce a\n",
      "        dictionary with entries for \"ids\" and \"values\". Passing those two objects\n",
      "        to this function along with vocab_size=6, will produce a `SparseTensor` that\n",
      "        sparsely represents all three instances. Namely, the `indices` property will\n",
      "        contain the coordinates of the non-zero entries in the feature matrix (the\n",
      "        first dimension is the row number in the matrix, i.e., the index within the\n",
      "        batch, and the second dimension is the column number, i.e., the feature id);\n",
      "        `values` will contain the actual values. `shape` will be the shape of the\n",
      "        original matrix, i.e., (3, 6). For our example above, the output will be\n",
      "        equal to:\n",
      "        \n",
      "        ```python\n",
      "          SparseTensor(indices=[[0, 0], [1, 1], [1, 3], [1, 4], [2, 0], [2, 3]],\n",
      "                       values=[-3, 1, 4, 1, 5, 9],\n",
      "                       dense_shape=[3, 6])\n",
      "        ```\n",
      "        \n",
      "        This method generalizes to higher-dimensions by simply providing a list for\n",
      "        both the sp_ids as well as the vocab_size.\n",
      "        In this case the resulting `SparseTensor` has the following properties:\n",
      "          - `indices` is equivalent to `sp_ids[0].indices` with the last\n",
      "            dimension discarded and concatenated with\n",
      "            `sp_ids[0].values, sp_ids[1].values, ...`.\n",
      "          - `values` is simply `sp_values.values`.\n",
      "          - If `sp_ids.dense_shape = [D0, D1, ..., Dn, K]`, then\n",
      "            `output.shape = [D0, D1, ..., Dn] + vocab_size`.\n",
      "        \n",
      "        Args:\n",
      "          sp_ids: A single `SparseTensor` with `values` property of type `int32`\n",
      "            or `int64` or a Python list of such `SparseTensor`s or a list thereof.\n",
      "          sp_values: A `SparseTensor` of any type.\n",
      "          vocab_size: A scalar `int64` Tensor (or Python int) containing the new size\n",
      "            of the last dimension, `all(0 <= sp_ids.values < vocab_size)`.\n",
      "            Or a list thereof with `all(0 <= sp_ids[i].values < vocab_size[i])` for\n",
      "            all `i`.\n",
      "          name: A name prefix for the returned tensors (optional)\n",
      "          already_sorted: A boolean to specify whether the per-batch values in\n",
      "           `sp_values` are already sorted. If so skip sorting, False by default\n",
      "           (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `SparseTensor` compactly representing a batch of feature ids and values,\n",
      "          useful for passing to functions that expect such a `SparseTensor`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `sp_values` is not a `SparseTensor`. Or if `sp_ids` is neither\n",
      "            a `SparseTensor` nor a list thereof. Or if `vocab_size` is not a\n",
      "            `Tensor` or a Python int and `sp_ids` is a `SparseTensor`. Or if\n",
      "            `vocab_size` is not a or list thereof and `sp_ids` is a list.\n",
      "          ValueError: If `sp_ids` and `vocab_size` are lists of different lengths.\n",
      "    \n",
      "    sparse_minimum(sp_a, sp_b, name=None)\n",
      "        Returns the element-wise min of two SparseTensors.\n",
      "        \n",
      "        Assumes the two SparseTensors have the same shape, i.e., no broadcasting.\n",
      "        Example:\n",
      "        \n",
      "        ```python\n",
      "        sp_zero = sparse_tensor.SparseTensor([[0]], [0], [7])\n",
      "        sp_one = sparse_tensor.SparseTensor([[1]], [1], [7])\n",
      "        res = tf.sparse.minimum(sp_zero, sp_one).eval()\n",
      "        # \"res\" should be equal to SparseTensor([[0], [1]], [0, 0], [7]).\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          sp_a: a `SparseTensor` operand whose dtype is real, and indices\n",
      "            lexicographically ordered.\n",
      "          sp_b: the other `SparseTensor` operand with the same requirements (and the\n",
      "            same shape).\n",
      "          name: optional name of the operation.\n",
      "        Returns:\n",
      "          output: the output SparseTensor.\n",
      "    \n",
      "    sparse_placeholder(dtype, shape=None, name=None)\n",
      "        Inserts a placeholder for a sparse tensor that will be always fed.\n",
      "        \n",
      "        **Important**: This sparse tensor will produce an error if evaluated.\n",
      "        Its value must be fed using the `feed_dict` optional argument to\n",
      "        `Session.run()`, `Tensor.eval()`, or `Operation.run()`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.compat.v1.sparse.placeholder(tf.float32)\n",
      "        y = tf.sparse.reduce_sum(x)\n",
      "        \n",
      "        with tf.compat.v1.Session() as sess:\n",
      "          print(sess.run(y))  # ERROR: will fail because x was not fed.\n",
      "        \n",
      "          indices = np.array([[3, 2, 0], [4, 5, 1]], dtype=np.int64)\n",
      "          values = np.array([1.0, 2.0], dtype=np.float32)\n",
      "          shape = np.array([7, 9, 2], dtype=np.int64)\n",
      "          print(sess.run(y, feed_dict={\n",
      "            x: tf.compat.v1.SparseTensorValue(indices, values, shape)}))  # Will\n",
      "            succeed.\n",
      "          print(sess.run(y, feed_dict={\n",
      "            x: (indices, values, shape)}))  # Will succeed.\n",
      "        \n",
      "          sp = tf.SparseTensor(indices=indices, values=values, dense_shape=shape)\n",
      "          sp_value = sp.eval(session=sess)\n",
      "          print(sess.run(y, feed_dict={x: sp_value}))  # Will succeed.\n",
      "        ```\n",
      "        \n",
      "        @compatibility{eager} Placeholders are not compatible with eager execution.\n",
      "        \n",
      "        Args:\n",
      "          dtype: The type of `values` elements in the tensor to be fed.\n",
      "          shape: The shape of the tensor to be fed (optional). If the shape is not\n",
      "            specified, you can feed a sparse tensor of any shape.\n",
      "          name: A name for prefixing the operations (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `SparseTensor` that may be used as a handle for feeding a value, but not\n",
      "          evaluated directly.\n",
      "        \n",
      "        Raises:\n",
      "          RuntimeError: if eager execution is enabled\n",
      "    \n",
      "    sparse_reduce_max(sp_input, axis=None, keepdims=None, reduction_axes=None, keep_dims=None)\n",
      "        Computes the max of elements across dimensions of a SparseTensor. (deprecated arguments) (deprecated arguments)\n",
      "        \n",
      "        Warning: SOME ARGUMENTS ARE DEPRECATED: `(keep_dims)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        keep_dims is deprecated, use keepdims instead\n",
      "        \n",
      "        Warning: SOME ARGUMENTS ARE DEPRECATED: `(reduction_axes)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        reduction_axes is deprecated, use axis instead\n",
      "        \n",
      "        This Op takes a SparseTensor and is the sparse counterpart to\n",
      "        `tf.reduce_max()`.  In particular, this Op also returns a dense `Tensor`\n",
      "        instead of a sparse one.\n",
      "        \n",
      "        Note: A gradient is not defined for this function, so it can't be used\n",
      "        in training models that need gradient descent.\n",
      "        \n",
      "        Reduces `sp_input` along the dimensions given in `reduction_axes`.  Unless\n",
      "        `keepdims` is true, the rank of the tensor is reduced by 1 for each entry in\n",
      "        `reduction_axes`. If `keepdims` is true, the reduced dimensions are retained\n",
      "        with length 1.\n",
      "        \n",
      "        If `reduction_axes` has no entries, all dimensions are reduced, and a tensor\n",
      "        with a single element is returned.  Additionally, the axes can be negative,\n",
      "        similar to the indexing rules in Python.\n",
      "        \n",
      "        The values not defined in `sp_input` don't participate in the reduce max,\n",
      "        as opposed to be implicitly assumed 0 -- hence it can return negative values\n",
      "        for sparse `reduction_axes`. But, in case there are no values in\n",
      "        `reduction_axes`, it will reduce to 0. See second example below.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        # 'x' represents [[1, ?, 2]\n",
      "        #                 [?, 3, ?]]\n",
      "        # where ? is implicitly-zero.\n",
      "        tf.sparse.reduce_max(x) ==> 3\n",
      "        tf.sparse.reduce_max(x, 0) ==> [1, 3, 2]\n",
      "        tf.sparse.reduce_max(x, 1) ==> [2, 3]  # Can also use -1 as the axis.\n",
      "        tf.sparse.reduce_max(x, 1, keepdims=True) ==> [[2], [3]]\n",
      "        tf.sparse.reduce_max(x, [0, 1]) ==> 3\n",
      "        \n",
      "        # 'y' represents [[-7, ?]\n",
      "        #                 [ 4, 3]\n",
      "        #                 [ ?, ?]\n",
      "        tf.sparse.reduce_max(x, 1) ==> [-7, 4, 0]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          sp_input: The SparseTensor to reduce. Should have numeric type.\n",
      "          axis: The dimensions to reduce; list or scalar. If `None` (the\n",
      "            default), reduces all dimensions.\n",
      "          keepdims: If true, retain reduced dimensions with length 1.\n",
      "          reduction_axes: Deprecated name of `axis`.\n",
      "          keep_dims:  Deprecated alias for `keepdims`.\n",
      "        \n",
      "        Returns:\n",
      "          The reduced Tensor.\n",
      "    \n",
      "    sparse_reduce_max_sparse(sp_input, axis=None, keepdims=None, reduction_axes=None, keep_dims=None)\n",
      "        Computes the max of elements across dimensions of a SparseTensor. (deprecated arguments)\n",
      "        \n",
      "        Warning: SOME ARGUMENTS ARE DEPRECATED: `(keep_dims)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        keep_dims is deprecated, use keepdims instead\n",
      "        \n",
      "        This Op takes a SparseTensor and is the sparse counterpart to\n",
      "        `tf.reduce_max()`.  In contrast to SparseReduceSum, this Op returns a\n",
      "        SparseTensor.\n",
      "        \n",
      "        Note: A gradient is not defined for this function, so it can't be used\n",
      "        in training models that need gradient descent.\n",
      "        \n",
      "        Reduces `sp_input` along the dimensions given in `reduction_axes`.  Unless\n",
      "        `keepdims` is true, the rank of the tensor is reduced by 1 for each entry in\n",
      "        `reduction_axes`. If `keepdims` is true, the reduced dimensions are retained\n",
      "        with length 1.\n",
      "        \n",
      "        If `reduction_axes` has no entries, all dimensions are reduced, and a tensor\n",
      "        with a single element is returned.  Additionally, the axes can be negative,\n",
      "        which are interpreted according to the indexing rules in Python.\n",
      "        \n",
      "        Args:\n",
      "          sp_input: The SparseTensor to reduce. Should have numeric type.\n",
      "          axis: The dimensions to reduce; list or scalar. If `None` (the\n",
      "            default), reduces all dimensions.\n",
      "          keepdims: If true, retain reduced dimensions with length 1.\n",
      "          reduction_axes: Deprecated name of axis.\n",
      "          keep_dims: Deprecated alias for `keepdims`.\n",
      "        \n",
      "        Returns:\n",
      "          The reduced SparseTensor.\n",
      "    \n",
      "    sparse_reduce_sum(sp_input, axis=None, keepdims=None, reduction_axes=None, keep_dims=None)\n",
      "        Computes the sum of elements across dimensions of a SparseTensor. (deprecated arguments) (deprecated arguments)\n",
      "        \n",
      "        Warning: SOME ARGUMENTS ARE DEPRECATED: `(keep_dims)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        keep_dims is deprecated, use keepdims instead\n",
      "        \n",
      "        Warning: SOME ARGUMENTS ARE DEPRECATED: `(reduction_axes)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        reduction_axes is deprecated, use axis instead\n",
      "        \n",
      "        This Op takes a SparseTensor and is the sparse counterpart to\n",
      "        `tf.reduce_sum()`.  In particular, this Op also returns a dense `Tensor`\n",
      "        instead of a sparse one.\n",
      "        \n",
      "        Reduces `sp_input` along the dimensions given in `reduction_axes`.  Unless\n",
      "        `keepdims` is true, the rank of the tensor is reduced by 1 for each entry in\n",
      "        `reduction_axes`. If `keepdims` is true, the reduced dimensions are retained\n",
      "        with length 1.\n",
      "        \n",
      "        If `reduction_axes` has no entries, all dimensions are reduced, and a tensor\n",
      "        with a single element is returned.  Additionally, the axes can be negative,\n",
      "        similar to the indexing rules in Python.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        # 'x' represents [[1, ?, 1]\n",
      "        #                 [?, 1, ?]]\n",
      "        # where ? is implicitly-zero.\n",
      "        tf.sparse.reduce_sum(x) ==> 3\n",
      "        tf.sparse.reduce_sum(x, 0) ==> [1, 1, 1]\n",
      "        tf.sparse.reduce_sum(x, 1) ==> [2, 1]  # Can also use -1 as the axis.\n",
      "        tf.sparse.reduce_sum(x, 1, keepdims=True) ==> [[2], [1]]\n",
      "        tf.sparse.reduce_sum(x, [0, 1]) ==> 3\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          sp_input: The SparseTensor to reduce. Should have numeric type.\n",
      "          axis: The dimensions to reduce; list or scalar. If `None` (the\n",
      "            default), reduces all dimensions.\n",
      "          keepdims: If true, retain reduced dimensions with length 1.\n",
      "          reduction_axes: Deprecated name of `axis`.\n",
      "          keep_dims: Deprecated alias for `keepdims`.\n",
      "        \n",
      "        Returns:\n",
      "          The reduced Tensor.\n",
      "    \n",
      "    sparse_reduce_sum_sparse(sp_input, axis=None, keepdims=None, reduction_axes=None, keep_dims=None)\n",
      "        Computes the sum of elements across dimensions of a SparseTensor. (deprecated arguments)\n",
      "        \n",
      "        Warning: SOME ARGUMENTS ARE DEPRECATED: `(keep_dims)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        keep_dims is deprecated, use keepdims instead\n",
      "        \n",
      "        This Op takes a SparseTensor and is the sparse counterpart to\n",
      "        `tf.reduce_sum()`.  In contrast to SparseReduceSum, this Op returns a\n",
      "        SparseTensor.\n",
      "        \n",
      "        Note: A gradient is not defined for this function, so it can't be used\n",
      "        in training models that need gradient descent.\n",
      "        \n",
      "        Reduces `sp_input` along the dimensions given in `reduction_axes`.  Unless\n",
      "        `keepdims` is true, the rank of the tensor is reduced by 1 for each entry in\n",
      "        `reduction_axes`. If `keepdims` is true, the reduced dimensions are retained\n",
      "        with length 1.\n",
      "        \n",
      "        If `reduction_axes` has no entries, all dimensions are reduced, and a tensor\n",
      "        with a single element is returned.  Additionally, the axes can be negative,\n",
      "        which are interpreted according to the indexing rules in Python.\n",
      "        \n",
      "        Args:\n",
      "          sp_input: The SparseTensor to reduce. Should have numeric type.\n",
      "          axis: The dimensions to reduce; list or scalar. If `None` (the\n",
      "            default), reduces all dimensions.\n",
      "          keepdims: If true, retain reduced dimensions with length 1.\n",
      "          reduction_axes: Deprecated name of axis.\n",
      "          keep_dims: Deprecated alias for `keepdims`.\n",
      "        \n",
      "        Returns:\n",
      "          The reduced SparseTensor.\n",
      "    \n",
      "    sparse_reorder(sp_input, name=None)\n",
      "        Reorders a `SparseTensor` into the canonical, row-major ordering.\n",
      "        \n",
      "        Note that by convention, all sparse ops preserve the canonical ordering\n",
      "        along increasing dimension number. The only time ordering can be violated\n",
      "        is during manual manipulation of the indices and values to add entries.\n",
      "        \n",
      "        Reordering does not affect the shape of the `SparseTensor`.\n",
      "        \n",
      "        For example, if `sp_input` has shape `[4, 5]` and `indices` / `values`:\n",
      "        \n",
      "            [0, 3]: b\n",
      "            [0, 1]: a\n",
      "            [3, 1]: d\n",
      "            [2, 0]: c\n",
      "        \n",
      "        then the output will be a `SparseTensor` of shape `[4, 5]` and\n",
      "        `indices` / `values`:\n",
      "        \n",
      "            [0, 1]: a\n",
      "            [0, 3]: b\n",
      "            [2, 0]: c\n",
      "            [3, 1]: d\n",
      "        \n",
      "        Args:\n",
      "          sp_input: The input `SparseTensor`.\n",
      "          name: A name prefix for the returned tensors (optional)\n",
      "        \n",
      "        Returns:\n",
      "          A `SparseTensor` with the same shape and non-empty values, but in\n",
      "          canonical ordering.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `sp_input` is not a `SparseTensor`.\n",
      "    \n",
      "    sparse_reset_shape(sp_input, new_shape=None)\n",
      "        Resets the shape of a `SparseTensor` with indices and values unchanged.\n",
      "        \n",
      "        If `new_shape` is None, returns a copy of `sp_input` with its shape reset\n",
      "        to the tight bounding box of `sp_input`. This will be a shape consisting of\n",
      "        all zeros if sp_input has no values.\n",
      "        \n",
      "        If `new_shape` is provided, then it must be larger or equal in all dimensions\n",
      "        compared to the shape of `sp_input`. When this condition is met, the returned\n",
      "        SparseTensor will have its shape reset to `new_shape` and its indices and\n",
      "        values unchanged from that of `sp_input.`\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "          Consider a `sp_input` with shape [2, 3, 5]:\n",
      "        \n",
      "            [0, 0, 1]: a\n",
      "            [0, 1, 0]: b\n",
      "            [0, 2, 2]: c\n",
      "            [1, 0, 3]: d\n",
      "        \n",
      "          - It is an error to set `new_shape` as [3, 7] since this represents a\n",
      "            rank-2 tensor while `sp_input` is rank-3. This is either a ValueError\n",
      "            during graph construction (if both shapes are known) or an OpError during\n",
      "            run time.\n",
      "        \n",
      "          - Setting `new_shape` as [2, 3, 6] will be fine as this shape is larger or\n",
      "            equal in every dimension compared to the original shape [2, 3, 5].\n",
      "        \n",
      "          - On the other hand, setting new_shape as [2, 3, 4] is also an error: The\n",
      "            third dimension is smaller than the original shape [2, 3, 5] (and an\n",
      "            `InvalidArgumentError` will be raised).\n",
      "        \n",
      "          - If `new_shape` is None, the returned SparseTensor will have a shape\n",
      "            [2, 3, 4], which is the tight bounding box of `sp_input`.\n",
      "        \n",
      "        Args:\n",
      "          sp_input: The input `SparseTensor`.\n",
      "          new_shape: None or a vector representing the new shape for the returned\n",
      "            `SparseTensor`.\n",
      "        \n",
      "        Returns:\n",
      "          A `SparseTensor` indices and values unchanged from `input_sp`. Its shape is\n",
      "            `new_shape` if that is set. Otherwise it is the tight bounding box of\n",
      "             `input_sp`\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `sp_input` is not a `SparseTensor`.\n",
      "          ValueError: If `new_shape` represents a tensor with a different rank from\n",
      "            that of `sp_input` (if shapes are known when graph is constructed).\n",
      "          ValueError:  If `new_shape` is determined during graph build to have\n",
      "            dimension sizes that are too small.\n",
      "          OpError:\n",
      "            - If `new_shape` has dimension sizes that are too small.\n",
      "            - If shapes are not known during graph construction time, and during run\n",
      "              time it is found out that the ranks do not match.\n",
      "    \n",
      "    sparse_reshape(sp_input, shape, name=None)\n",
      "        Reshapes a `SparseTensor` to represent values in a new dense shape.\n",
      "        \n",
      "        This operation has the same semantics as `reshape` on the represented dense\n",
      "        tensor.  The indices of non-empty values in `sp_input` are recomputed based\n",
      "        on the new dense shape, and a new `SparseTensor` is returned containing the\n",
      "        new indices and new shape.  The order of non-empty values in `sp_input` is\n",
      "        unchanged.\n",
      "        \n",
      "        If one component of `shape` is the special value -1, the size of that\n",
      "        dimension is computed so that the total dense size remains constant.  At\n",
      "        most one component of `shape` can be -1.  The number of dense elements\n",
      "        implied by `shape` must be the same as the number of dense elements\n",
      "        originally represented by `sp_input`.\n",
      "        \n",
      "        For example, if `sp_input` has shape `[2, 3, 6]` and `indices` / `values`:\n",
      "        \n",
      "            [0, 0, 0]: a\n",
      "            [0, 0, 1]: b\n",
      "            [0, 1, 0]: c\n",
      "            [1, 0, 0]: d\n",
      "            [1, 2, 3]: e\n",
      "        \n",
      "        and `shape` is `[9, -1]`, then the output will be a `SparseTensor` of\n",
      "        shape `[9, 4]` and `indices` / `values`:\n",
      "        \n",
      "            [0, 0]: a\n",
      "            [0, 1]: b\n",
      "            [1, 2]: c\n",
      "            [4, 2]: d\n",
      "            [8, 1]: e\n",
      "        \n",
      "        Args:\n",
      "          sp_input: The input `SparseTensor`.\n",
      "          shape: A 1-D (vector) int64 `Tensor` specifying the new dense shape of the\n",
      "            represented `SparseTensor`.\n",
      "          name: A name prefix for the returned tensors (optional)\n",
      "        \n",
      "        Returns:\n",
      "          A `SparseTensor` with the same non-empty values but with indices calculated\n",
      "          by the new dense shape.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `sp_input` is not a `SparseTensor`.\n",
      "          ValueError:  If argument `shape` requests a `SparseTensor` with a different\n",
      "            number of elements than `sp_input`.\n",
      "          ValueError:  If `shape` has more than one inferred (== -1) dimension.\n",
      "    \n",
      "    sparse_retain(sp_input, to_retain)\n",
      "        Retains specified non-empty values within a `SparseTensor`.\n",
      "        \n",
      "        For example, if `sp_input` has shape `[4, 5]` and 4 non-empty string values:\n",
      "        \n",
      "            [0, 1]: a\n",
      "            [0, 3]: b\n",
      "            [2, 0]: c\n",
      "            [3, 1]: d\n",
      "        \n",
      "        and `to_retain = [True, False, False, True]`, then the output will\n",
      "        be a `SparseTensor` of shape `[4, 5]` with 2 non-empty values:\n",
      "        \n",
      "            [0, 1]: a\n",
      "            [3, 1]: d\n",
      "        \n",
      "        Args:\n",
      "          sp_input: The input `SparseTensor` with `N` non-empty elements.\n",
      "          to_retain: A bool vector of length `N` with `M` true values.\n",
      "        \n",
      "        Returns:\n",
      "          A `SparseTensor` with the same shape as the input and `M` non-empty\n",
      "          elements corresponding to the true positions in `to_retain`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `sp_input` is not a `SparseTensor`.\n",
      "    \n",
      "    sparse_segment_mean(data, indices, segment_ids, name=None, num_segments=None)\n",
      "        Computes the mean along sparse segments of a tensor.\n",
      "        \n",
      "        Read [the section on\n",
      "        segmentation](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/math#about_segmentation)\n",
      "        for an explanation of segments.\n",
      "        \n",
      "        Like `tf.math.segment_mean`, but `segment_ids` can have rank less than\n",
      "        `data`'s first dimension, selecting a subset of dimension 0, specified by\n",
      "        `indices`.\n",
      "        `segment_ids` is allowed to have missing ids, in which case the output will\n",
      "        be zeros at those indices. In those cases `num_segments` is used to determine\n",
      "        the size of the output.\n",
      "        \n",
      "        Args:\n",
      "          data: A `Tensor` with data that will be assembled in the output.\n",
      "          indices: A 1-D `Tensor` with indices into `data`. Has same rank as\n",
      "            `segment_ids`.\n",
      "          segment_ids: A 1-D `Tensor` with indices into the output `Tensor`. Values\n",
      "            should be sorted and can be repeated.\n",
      "          name: A name for the operation (optional).\n",
      "          num_segments: An optional int32 scalar. Indicates the size of the output\n",
      "            `Tensor`.\n",
      "        \n",
      "        Returns:\n",
      "          A `tensor` of the shape as data, except for dimension 0 which\n",
      "          has size `k`, the number of segments specified via `num_segments` or\n",
      "          inferred for the last element in `segments_ids`.\n",
      "    \n",
      "    sparse_segment_sqrt_n(data, indices, segment_ids, name=None, num_segments=None)\n",
      "        Computes the sum along sparse segments of a tensor divided by the sqrt(N).\n",
      "        \n",
      "        `N` is the size of the segment being reduced.\n",
      "        \n",
      "        Args:\n",
      "          data: A `Tensor` with data that will be assembled in the output.\n",
      "          indices: A 1-D `Tensor` with indices into `data`. Has same rank as\n",
      "            `segment_ids`.\n",
      "          segment_ids: A 1-D `Tensor` with indices into the output `Tensor`. Values\n",
      "            should be sorted and can be repeated.\n",
      "          name: A name for the operation (optional).\n",
      "          num_segments: An optional int32 scalar. Indicates the size of the output\n",
      "            `Tensor`.\n",
      "        \n",
      "        Returns:\n",
      "          A `tensor` of the shape as data, except for dimension 0 which\n",
      "          has size `k`, the number of segments specified via `num_segments` or\n",
      "          inferred for the last element in `segments_ids`.\n",
      "    \n",
      "    sparse_segment_sum(data, indices, segment_ids, name=None, num_segments=None)\n",
      "        Computes the sum along sparse segments of a tensor.\n",
      "        \n",
      "        Read [the section on\n",
      "        segmentation](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/math#about_segmentation)\n",
      "        for an explanation of segments.\n",
      "        \n",
      "        Like `tf.math.segment_sum`, but `segment_ids` can have rank less than `data`'s\n",
      "        first dimension, selecting a subset of dimension 0, specified by `indices`.\n",
      "        `segment_ids` is allowed to have missing ids, in which case the output will\n",
      "        be zeros at those indices. In those cases `num_segments` is used to determine\n",
      "        the size of the output.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        c = tf.constant([[1,2,3,4], [-1,-2,-3,-4], [5,6,7,8]])\n",
      "        \n",
      "        # Select two rows, one segment.\n",
      "        tf.sparse.segment_sum(c, tf.constant([0, 1]), tf.constant([0, 0]))\n",
      "        # => [[0 0 0 0]]\n",
      "        \n",
      "        # Select two rows, two segment.\n",
      "        tf.sparse.segment_sum(c, tf.constant([0, 1]), tf.constant([0, 1]))\n",
      "        # => [[ 1  2  3  4]\n",
      "        #     [-1 -2 -3 -4]]\n",
      "        \n",
      "        # With missing segment ids.\n",
      "        tf.sparse.segment_sum(c, tf.constant([0, 1]), tf.constant([0, 2]),\n",
      "                              num_segments=4)\n",
      "        # => [[ 1  2  3  4]\n",
      "        #     [ 0  0  0  0]\n",
      "        #     [-1 -2 -3 -4]\n",
      "        #     [ 0  0  0  0]]\n",
      "        \n",
      "        # Select all rows, two segments.\n",
      "        tf.sparse.segment_sum(c, tf.constant([0, 1, 2]), tf.constant([0, 0, 1]))\n",
      "        # => [[0 0 0 0]\n",
      "        #     [5 6 7 8]]\n",
      "        \n",
      "        # Which is equivalent to:\n",
      "        tf.math.segment_sum(c, tf.constant([0, 0, 1]))\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          data: A `Tensor` with data that will be assembled in the output.\n",
      "          indices: A 1-D `Tensor` with indices into `data`. Has same rank as\n",
      "            `segment_ids`.\n",
      "          segment_ids: A 1-D `Tensor` with indices into the output `Tensor`. Values\n",
      "            should be sorted and can be repeated.\n",
      "          name: A name for the operation (optional).\n",
      "          num_segments: An optional int32 scalar. Indicates the size of the output\n",
      "            `Tensor`.\n",
      "        \n",
      "        Returns:\n",
      "          A `tensor` of the shape as data, except for dimension 0 which\n",
      "          has size `k`, the number of segments specified via `num_segments` or\n",
      "          inferred for the last element in `segments_ids`.\n",
      "    \n",
      "    sparse_slice(sp_input, start, size, name=None)\n",
      "        Slice a `SparseTensor` based on the `start` and `size.\n",
      "        \n",
      "        For example, if the input is\n",
      "        \n",
      "            input_tensor = shape = [2, 7]\n",
      "            [    a   d e  ]\n",
      "            [b c          ]\n",
      "        \n",
      "        Graphically the output tensors are:\n",
      "        \n",
      "            sparse.slice([0, 0], [2, 4]) = shape = [2, 4]\n",
      "            [    a  ]\n",
      "            [b c    ]\n",
      "        \n",
      "            sparse.slice([0, 4], [2, 3]) = shape = [2, 3]\n",
      "            [ d e  ]\n",
      "            [      ]\n",
      "        \n",
      "        Args:\n",
      "          sp_input: The `SparseTensor` to split.\n",
      "          start: 1-D. tensor represents the start of the slice.\n",
      "          size: 1-D. tensor represents the size of the slice.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `SparseTensor` objects resulting from splicing.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `sp_input` is not a `SparseTensor`.\n",
      "    \n",
      "    sparse_softmax(sp_input, name=None)\n",
      "        Applies softmax to a batched N-D `SparseTensor`.\n",
      "        \n",
      "        The inputs represent an N-D SparseTensor with logical shape `[..., B, C]`\n",
      "        (where `N >= 2`), and with indices sorted in the canonical lexicographic\n",
      "        order.\n",
      "        \n",
      "        This op is equivalent to applying the normal `tf.nn.softmax()` to each\n",
      "        innermost logical submatrix with shape `[B, C]`, but with the catch that *the\n",
      "        implicitly zero elements do not participate*.  Specifically, the algorithm is\n",
      "        equivalent to:\n",
      "        \n",
      "          (1) Applies `tf.nn.softmax()` to a densified view of each innermost\n",
      "              submatrix with shape `[B, C]`, along the size-C dimension;\n",
      "          (2) Masks out the original implicitly-zero locations;\n",
      "          (3) Renormalizes the remaining elements.\n",
      "        \n",
      "        Hence, the `SparseTensor` result has exactly the same non-zero indices and\n",
      "        shape.\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        ```python\n",
      "        # First batch:\n",
      "        # [?   e.]\n",
      "        # [1.  ? ]\n",
      "        # Second batch:\n",
      "        # [e   ? ]\n",
      "        # [e   e ]\n",
      "        shape = [2, 2, 2]  # 3-D SparseTensor\n",
      "        values = np.asarray([[[0., np.e], [1., 0.]], [[np.e, 0.], [np.e, np.e]]])\n",
      "        indices = np.vstack(np.where(values)).astype(np.int64).T\n",
      "        \n",
      "        result = tf.sparse.softmax(tf.SparseTensor(indices, values, shape))\n",
      "        # ...returning a 3-D SparseTensor, equivalent to:\n",
      "        # [?   1.]     [1    ?]\n",
      "        # [1.  ? ] and [.5  .5]\n",
      "        # where ? means implicitly zero.\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          sp_input: N-D `SparseTensor`, where `N >= 2`.\n",
      "          name: optional name of the operation.\n",
      "        Returns:\n",
      "          output: N-D `SparseTensor` representing the results.\n",
      "    \n",
      "    sparse_split(keyword_required=KeywordRequired(), sp_input=None, num_split=None, axis=None, name=None, split_dim=None)\n",
      "        Split a `SparseTensor` into `num_split` tensors along `axis`. (deprecated arguments)\n",
      "        \n",
      "        Warning: SOME ARGUMENTS ARE DEPRECATED: `(split_dim)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        split_dim is deprecated, use axis instead\n",
      "        \n",
      "        If the `sp_input.dense_shape[axis]` is not an integer multiple of `num_split`\n",
      "        each slice starting from 0:`shape[axis] % num_split` gets extra one\n",
      "        dimension. For example, if `axis = 1` and `num_split = 2` and the\n",
      "        input is:\n",
      "        \n",
      "            input_tensor = shape = [2, 7]\n",
      "            [    a   d e  ]\n",
      "            [b c          ]\n",
      "        \n",
      "        Graphically the output tensors are:\n",
      "        \n",
      "            output_tensor[0] =\n",
      "            [    a   ]\n",
      "            [b c     ]\n",
      "        \n",
      "            output_tensor[1] =\n",
      "            [ d e  ]\n",
      "            [      ]\n",
      "        \n",
      "        Args:\n",
      "          keyword_required: Python 2 standin for * (temporary for argument reorder)\n",
      "          sp_input: The `SparseTensor` to split.\n",
      "          num_split: A Python integer. The number of ways to split.\n",
      "          axis: A 0-D `int32` `Tensor`. The dimension along which to split.\n",
      "          name: A name for the operation (optional).\n",
      "          split_dim: Deprecated old name for axis.\n",
      "        \n",
      "        Returns:\n",
      "          `num_split` `SparseTensor` objects resulting from splitting `value`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `sp_input` is not a `SparseTensor`.\n",
      "          ValueError: If the deprecated `split_dim` and `axis` are both non None.\n",
      "    \n",
      "    sparse_tensor_dense_matmul(sp_a, b, adjoint_a=False, adjoint_b=False, name=None)\n",
      "        Multiply SparseTensor (of rank 2) \"A\" by dense matrix \"B\".\n",
      "        \n",
      "        No validity checking is performed on the indices of `A`.  However, the\n",
      "        following input format is recommended for optimal behavior:\n",
      "        \n",
      "        * If `adjoint_a == false`: `A` should be sorted in lexicographically\n",
      "          increasing order.  Use `sparse.reorder` if you're not sure.\n",
      "        * If `adjoint_a == true`: `A` should be sorted in order of increasing\n",
      "          dimension 1 (i.e., \"column major\" order instead of \"row major\" order).\n",
      "        \n",
      "        Using `tf.nn.embedding_lookup_sparse` for sparse multiplication:\n",
      "        \n",
      "        It's not obvious but you can consider `embedding_lookup_sparse` as another\n",
      "        sparse and dense multiplication. In some situations, you may prefer to use\n",
      "        `embedding_lookup_sparse` even though you're not dealing with embeddings.\n",
      "        \n",
      "        There are two questions to ask in the decision process: Do you need gradients\n",
      "        computed as sparse too? Is your sparse data represented as two\n",
      "        `SparseTensor`s: ids and values? There is more explanation about data format\n",
      "        below. If you answer any of these questions as yes, consider using\n",
      "        `tf.nn.embedding_lookup_sparse`.\n",
      "        \n",
      "        Following explains differences between the expected SparseTensors:\n",
      "        For example if dense form of your sparse data has shape `[3, 5]` and values:\n",
      "        \n",
      "            [[  a      ]\n",
      "             [b       c]\n",
      "             [    d    ]]\n",
      "        \n",
      "        \n",
      "        `SparseTensor` format expected by `sparse_tensor_dense_matmul`:\n",
      "         `sp_a` (indices, values):\n",
      "        \n",
      "            [0, 1]: a\n",
      "            [1, 0]: b\n",
      "            [1, 4]: c\n",
      "            [2, 2]: d\n",
      "        \n",
      "        `SparseTensor` format expected by `embedding_lookup_sparse`:\n",
      "         `sp_ids`                 `sp_weights`\n",
      "        \n",
      "            [0, 0]: 1                [0, 0]: a\n",
      "            [1, 0]: 0                [1, 0]: b\n",
      "            [1, 1]: 4                [1, 1]: c\n",
      "            [2, 0]: 2                [2, 0]: d\n",
      "        \n",
      "        \n",
      "        Deciding when to use `sparse_tensor_dense_matmul` vs.\n",
      "        `matmul`(a_is_sparse=True):\n",
      "        \n",
      "        There are a number of questions to ask in the decision process, including:\n",
      "        \n",
      "        * Will the SparseTensor `A` fit in memory if densified?\n",
      "        * Is the column count of the product large (>> 1)?\n",
      "        * Is the density of `A` larger than approximately 15%?\n",
      "        \n",
      "        If the answer to several of these questions is yes, consider\n",
      "        converting the `SparseTensor` to a dense one and using `tf.matmul` with\n",
      "        `a_is_sparse=True`.\n",
      "        \n",
      "        This operation tends to perform well when `A` is more sparse, if the column\n",
      "        size of the product is small (e.g. matrix-vector multiplication), if\n",
      "        `sp_a.dense_shape` takes on large values.\n",
      "        \n",
      "        Below is a rough speed comparison between `sparse_tensor_dense_matmul`,\n",
      "        labeled 'sparse', and `matmul`(a_is_sparse=True), labeled 'dense'.  For\n",
      "        purposes of the comparison, the time spent converting from a `SparseTensor` to\n",
      "        a dense `Tensor` is not included, so it is overly conservative with respect to\n",
      "        the time ratio.\n",
      "        \n",
      "        Benchmark system:\n",
      "        CPU: Intel Ivybridge with HyperThreading (6 cores) dL1:32KB dL2:256KB dL3:12MB\n",
      "        GPU: NVidia Tesla k40c\n",
      "        \n",
      "        Compiled with:\n",
      "        `-c opt --config=cuda --copt=-mavx`\n",
      "        \n",
      "        ```\n",
      "        tensorflow/python/sparse_tensor_dense_matmul_op_test --benchmarks\n",
      "        A sparse [m, k] with % nonzero values between 1% and 80%\n",
      "        B dense [k, n]\n",
      "        \n",
      "        % nnz  n   gpu   m     k     dt(dense)     dt(sparse)   dt(sparse)/dt(dense)\n",
      "        0.01   1   True  100   100   0.000221166   0.00010154   0.459112\n",
      "        0.01   1   True  100   1000  0.00033858    0.000109275  0.322745\n",
      "        0.01   1   True  1000  100   0.000310557   9.85661e-05  0.317385\n",
      "        0.01   1   True  1000  1000  0.0008721     0.000100875  0.115669\n",
      "        0.01   1   False 100   100   0.000208085   0.000107603  0.51711\n",
      "        0.01   1   False 100   1000  0.000327112   9.51118e-05  0.290762\n",
      "        0.01   1   False 1000  100   0.000308222   0.00010345   0.335635\n",
      "        0.01   1   False 1000  1000  0.000865721   0.000101397  0.117124\n",
      "        0.01   10  True  100   100   0.000218522   0.000105537  0.482958\n",
      "        0.01   10  True  100   1000  0.000340882   0.000111641  0.327506\n",
      "        0.01   10  True  1000  100   0.000315472   0.000117376  0.372064\n",
      "        0.01   10  True  1000  1000  0.000905493   0.000123263  0.136128\n",
      "        0.01   10  False 100   100   0.000221529   9.82571e-05  0.44354\n",
      "        0.01   10  False 100   1000  0.000330552   0.000112615  0.340687\n",
      "        0.01   10  False 1000  100   0.000341277   0.000114097  0.334324\n",
      "        0.01   10  False 1000  1000  0.000819944   0.000120982  0.147549\n",
      "        0.01   25  True  100   100   0.000207806   0.000105977  0.509981\n",
      "        0.01   25  True  100   1000  0.000322879   0.00012921   0.400181\n",
      "        0.01   25  True  1000  100   0.00038262    0.00014158   0.370035\n",
      "        0.01   25  True  1000  1000  0.000865438   0.000202083  0.233504\n",
      "        0.01   25  False 100   100   0.000209401   0.000104696  0.499979\n",
      "        0.01   25  False 100   1000  0.000321161   0.000130737  0.407076\n",
      "        0.01   25  False 1000  100   0.000377012   0.000136801  0.362856\n",
      "        0.01   25  False 1000  1000  0.000861125   0.00020272   0.235413\n",
      "        0.2    1   True  100   100   0.000206952   9.69219e-05  0.46833\n",
      "        0.2    1   True  100   1000  0.000348674   0.000147475  0.422959\n",
      "        0.2    1   True  1000  100   0.000336908   0.00010122   0.300439\n",
      "        0.2    1   True  1000  1000  0.001022      0.000203274  0.198898\n",
      "        0.2    1   False 100   100   0.000207532   9.5412e-05   0.459746\n",
      "        0.2    1   False 100   1000  0.000356127   0.000146824  0.41228\n",
      "        0.2    1   False 1000  100   0.000322664   0.000100918  0.312764\n",
      "        0.2    1   False 1000  1000  0.000998987   0.000203442  0.203648\n",
      "        0.2    10  True  100   100   0.000211692   0.000109903  0.519165\n",
      "        0.2    10  True  100   1000  0.000372819   0.000164321  0.440753\n",
      "        0.2    10  True  1000  100   0.000338651   0.000144806  0.427596\n",
      "        0.2    10  True  1000  1000  0.00108312    0.000758876  0.70064\n",
      "        0.2    10  False 100   100   0.000215727   0.000110502  0.512231\n",
      "        0.2    10  False 100   1000  0.000375419   0.0001613    0.429653\n",
      "        0.2    10  False 1000  100   0.000336999   0.000145628  0.432132\n",
      "        0.2    10  False 1000  1000  0.00110502    0.000762043  0.689618\n",
      "        0.2    25  True  100   100   0.000218705   0.000129913  0.594009\n",
      "        0.2    25  True  100   1000  0.000394794   0.00029428   0.745402\n",
      "        0.2    25  True  1000  100   0.000404483   0.0002693    0.665788\n",
      "        0.2    25  True  1000  1000  0.0012002     0.00194494   1.62052\n",
      "        0.2    25  False 100   100   0.000221494   0.0001306    0.589632\n",
      "        0.2    25  False 100   1000  0.000396436   0.000297204  0.74969\n",
      "        0.2    25  False 1000  100   0.000409346   0.000270068  0.659754\n",
      "        0.2    25  False 1000  1000  0.00121051    0.00193737   1.60046\n",
      "        0.5    1   True  100   100   0.000214981   9.82111e-05  0.456836\n",
      "        0.5    1   True  100   1000  0.000415328   0.000223073  0.537101\n",
      "        0.5    1   True  1000  100   0.000358324   0.00011269   0.314492\n",
      "        0.5    1   True  1000  1000  0.00137612    0.000437401  0.317851\n",
      "        0.5    1   False 100   100   0.000224196   0.000101423  0.452386\n",
      "        0.5    1   False 100   1000  0.000400987   0.000223286  0.556841\n",
      "        0.5    1   False 1000  100   0.000368825   0.00011224   0.304318\n",
      "        0.5    1   False 1000  1000  0.00136036    0.000429369  0.31563\n",
      "        0.5    10  True  100   100   0.000222125   0.000112308  0.505608\n",
      "        0.5    10  True  100   1000  0.000461088   0.00032357   0.701753\n",
      "        0.5    10  True  1000  100   0.000394624   0.000225497  0.571422\n",
      "        0.5    10  True  1000  1000  0.00158027    0.00190898   1.20801\n",
      "        0.5    10  False 100   100   0.000232083   0.000114978  0.495418\n",
      "        0.5    10  False 100   1000  0.000454574   0.000324632  0.714146\n",
      "        0.5    10  False 1000  100   0.000379097   0.000227768  0.600817\n",
      "        0.5    10  False 1000  1000  0.00160292    0.00190168   1.18638\n",
      "        0.5    25  True  100   100   0.00023429    0.000151703  0.647501\n",
      "        0.5    25  True  100   1000  0.000497462   0.000598873  1.20386\n",
      "        0.5    25  True  1000  100   0.000460778   0.000557038  1.20891\n",
      "        0.5    25  True  1000  1000  0.00170036    0.00467336   2.74845\n",
      "        0.5    25  False 100   100   0.000228981   0.000155334  0.678371\n",
      "        0.5    25  False 100   1000  0.000496139   0.000620789  1.25124\n",
      "        0.5    25  False 1000  100   0.00045473    0.000551528  1.21287\n",
      "        0.5    25  False 1000  1000  0.00171793    0.00467152   2.71927\n",
      "        0.8    1   True  100   100   0.000222037   0.000105301  0.47425\n",
      "        0.8    1   True  100   1000  0.000410804   0.000329327  0.801664\n",
      "        0.8    1   True  1000  100   0.000349735   0.000131225  0.375212\n",
      "        0.8    1   True  1000  1000  0.00139219    0.000677065  0.48633\n",
      "        0.8    1   False 100   100   0.000214079   0.000107486  0.502085\n",
      "        0.8    1   False 100   1000  0.000413746   0.000323244  0.781261\n",
      "        0.8    1   False 1000  100   0.000348983   0.000131983  0.378193\n",
      "        0.8    1   False 1000  1000  0.00136296    0.000685325  0.50282\n",
      "        0.8    10  True  100   100   0.000229159   0.00011825   0.516017\n",
      "        0.8    10  True  100   1000  0.000498845   0.000532618  1.0677\n",
      "        0.8    10  True  1000  100   0.000383126   0.00029935   0.781336\n",
      "        0.8    10  True  1000  1000  0.00162866    0.00307312   1.88689\n",
      "        0.8    10  False 100   100   0.000230783   0.000124958  0.541452\n",
      "        0.8    10  False 100   1000  0.000493393   0.000550654  1.11606\n",
      "        0.8    10  False 1000  100   0.000377167   0.000298581  0.791642\n",
      "        0.8    10  False 1000  1000  0.00165795    0.00305103   1.84024\n",
      "        0.8    25  True  100   100   0.000233496   0.000175241  0.75051\n",
      "        0.8    25  True  100   1000  0.00055654    0.00102658   1.84458\n",
      "        0.8    25  True  1000  100   0.000463814   0.000783267  1.68875\n",
      "        0.8    25  True  1000  1000  0.00186905    0.00755344   4.04132\n",
      "        0.8    25  False 100   100   0.000240243   0.000175047  0.728625\n",
      "        0.8    25  False 100   1000  0.000578102   0.00104499   1.80763\n",
      "        0.8    25  False 1000  100   0.000485113   0.000776849  1.60138\n",
      "        0.8    25  False 1000  1000  0.00211448    0.00752736   3.55992\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          sp_a: SparseTensor A, of rank 2.\n",
      "          b: A dense Matrix with the same dtype as sp_a.\n",
      "          adjoint_a: Use the adjoint of A in the matrix multiply.  If A is complex,\n",
      "            this is transpose(conj(A)).  Otherwise it's transpose(A).\n",
      "          adjoint_b: Use the adjoint of B in the matrix multiply.  If B is complex,\n",
      "            this is transpose(conj(B)).  Otherwise it's transpose(B).\n",
      "          name: A name prefix for the returned tensors (optional)\n",
      "        \n",
      "        Returns:\n",
      "          A dense matrix (pseudo-code in dense np.matrix notation):\n",
      "            `A = A.H if adjoint_a else A`\n",
      "            `B = B.H if adjoint_b else B`\n",
      "            `return A*B`\n",
      "    \n",
      "    sparse_tensor_to_dense(sp_input, default_value=None, validate_indices=True, name=None)\n",
      "        Converts a `SparseTensor` into a dense tensor.\n",
      "        \n",
      "        This op is a convenience wrapper around `sparse_to_dense` for `SparseTensor`s.\n",
      "        \n",
      "        For example, if `sp_input` has shape `[3, 5]` and non-empty string values:\n",
      "        \n",
      "            [0, 1]: a\n",
      "            [0, 3]: b\n",
      "            [2, 0]: c\n",
      "        \n",
      "        and `default_value` is `x`, then the output will be a dense `[3, 5]`\n",
      "        string tensor with values:\n",
      "        \n",
      "            [[x a x b x]\n",
      "             [x x x x x]\n",
      "             [c x x x x]]\n",
      "        \n",
      "        Indices must be without repeats.  This is only\n",
      "        tested if `validate_indices` is `True`.\n",
      "        \n",
      "        Args:\n",
      "          sp_input: The input `SparseTensor`.\n",
      "          default_value: Scalar value to set for indices not specified in\n",
      "            `sp_input`.  Defaults to zero.\n",
      "          validate_indices: A boolean value.  If `True`, indices are checked to make\n",
      "            sure they are sorted in lexicographic order and that there are no repeats.\n",
      "          name: A name prefix for the returned tensors (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A dense tensor with shape `sp_input.dense_shape` and values specified by\n",
      "          the non-empty values in `sp_input`. Indices not in `sp_input` are assigned\n",
      "          `default_value`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `sp_input` is not a `SparseTensor`.\n",
      "    \n",
      "    sparse_to_dense(sparse_indices, output_shape, sparse_values, default_value=0, validate_indices=True, name=None)\n",
      "        Converts a sparse representation into a dense tensor. (deprecated)\n",
      "        \n",
      "        Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "        \n",
      "        Builds an array `dense` with shape `output_shape` such that\n",
      "        \n",
      "        ```python\n",
      "        # If sparse_indices is scalar\n",
      "        dense[i] = (i == sparse_indices ? sparse_values : default_value)\n",
      "        \n",
      "        # If sparse_indices is a vector, then for each i\n",
      "        dense[sparse_indices[i]] = sparse_values[i]\n",
      "        \n",
      "        # If sparse_indices is an n by d matrix, then for each i in [0, n)\n",
      "        dense[sparse_indices[i][0], ..., sparse_indices[i][d-1]] = sparse_values[i]\n",
      "        ```\n",
      "        \n",
      "        All other values in `dense` are set to `default_value`.  If `sparse_values`\n",
      "        is a scalar, all sparse indices are set to this single value.\n",
      "        \n",
      "        Indices should be sorted in lexicographic order, and indices must not\n",
      "        contain any repeats. If `validate_indices` is True, these properties\n",
      "        are checked during execution.\n",
      "        \n",
      "        Args:\n",
      "          sparse_indices: A 0-D, 1-D, or 2-D `Tensor` of type `int32` or `int64`.\n",
      "            `sparse_indices[i]` contains the complete index where `sparse_values[i]`\n",
      "            will be placed.\n",
      "          output_shape: A 1-D `Tensor` of the same type as `sparse_indices`.  Shape\n",
      "            of the dense output tensor.\n",
      "          sparse_values: A 0-D or 1-D `Tensor`.  Values corresponding to each row of\n",
      "            `sparse_indices`, or a scalar value to be used for all sparse indices.\n",
      "          default_value: A 0-D `Tensor` of the same type as `sparse_values`.  Value\n",
      "            to set for indices not specified in `sparse_indices`.  Defaults to zero.\n",
      "          validate_indices: A boolean value.  If True, indices are checked to make\n",
      "            sure they are sorted in lexicographic order and that there are no repeats.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          Dense `Tensor` of shape `output_shape`.  Has the same type as\n",
      "          `sparse_values`.\n",
      "    \n",
      "    sparse_to_indicator(sp_input, vocab_size, name=None)\n",
      "        Converts a `SparseTensor` of ids into a dense bool indicator tensor.\n",
      "        \n",
      "        The last dimension of `sp_input.indices` is discarded and replaced with\n",
      "        the values of `sp_input`.  If `sp_input.dense_shape = [D0, D1, ..., Dn, K]`,\n",
      "        then `output.shape = [D0, D1, ..., Dn, vocab_size]`, where\n",
      "        \n",
      "            output[d_0, d_1, ..., d_n, sp_input[d_0, d_1, ..., d_n, k]] = True\n",
      "        \n",
      "        and False elsewhere in `output`.\n",
      "        \n",
      "        For example, if `sp_input.dense_shape = [2, 3, 4]` with non-empty values:\n",
      "        \n",
      "            [0, 0, 0]: 0\n",
      "            [0, 1, 0]: 10\n",
      "            [1, 0, 3]: 103\n",
      "            [1, 1, 1]: 150\n",
      "            [1, 1, 2]: 149\n",
      "            [1, 1, 3]: 150\n",
      "            [1, 2, 1]: 121\n",
      "        \n",
      "        and `vocab_size = 200`, then the output will be a `[2, 3, 200]` dense bool\n",
      "        tensor with False everywhere except at positions\n",
      "        \n",
      "            (0, 0, 0), (0, 1, 10), (1, 0, 103), (1, 1, 149), (1, 1, 150),\n",
      "            (1, 2, 121).\n",
      "        \n",
      "        Note that repeats are allowed in the input SparseTensor.\n",
      "        This op is useful for converting `SparseTensor`s into dense formats for\n",
      "        compatibility with ops that expect dense tensors.\n",
      "        \n",
      "        The input `SparseTensor` must be in row-major order.\n",
      "        \n",
      "        Args:\n",
      "          sp_input: A `SparseTensor` with `values` property of type `int32` or\n",
      "            `int64`.\n",
      "          vocab_size: A scalar int64 Tensor (or Python int) containing the new size\n",
      "            of the last dimension, `all(0 <= sp_input.values < vocab_size)`.\n",
      "          name: A name prefix for the returned tensors (optional)\n",
      "        \n",
      "        Returns:\n",
      "          A dense bool indicator tensor representing the indices with specified value.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `sp_input` is not a `SparseTensor`.\n",
      "    \n",
      "    sparse_transpose(sp_input, perm=None, name=None)\n",
      "        Transposes a `SparseTensor`\n",
      "        \n",
      "        The returned tensor's dimension i will correspond to the input dimension\n",
      "        `perm[i]`. If `perm` is not given, it is set to (n-1...0), where n is\n",
      "        the rank of the input tensor. Hence by default, this operation performs a\n",
      "        regular matrix transpose on 2-D input Tensors.\n",
      "        \n",
      "        For example, if `sp_input` has shape `[4, 5]` and `indices` / `values`:\n",
      "        \n",
      "            [0, 3]: b\n",
      "            [0, 1]: a\n",
      "            [3, 1]: d\n",
      "            [2, 0]: c\n",
      "        \n",
      "        then the output will be a `SparseTensor` of shape `[5, 4]` and\n",
      "        `indices` / `values`:\n",
      "        \n",
      "            [0, 2]: c\n",
      "            [1, 0]: a\n",
      "            [1, 3]: d\n",
      "            [3, 0]: b\n",
      "        \n",
      "        Args:\n",
      "          sp_input: The input `SparseTensor`.\n",
      "          perm: A permutation of the dimensions of `sp_input`.\n",
      "          name: A name prefix for the returned tensors (optional)\n",
      "        Returns:\n",
      "          A transposed `SparseTensor`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `sp_input` is not a `SparseTensor`.\n",
      "    \n",
      "    split(value, num_or_size_splits, axis=0, num=None, name='split')\n",
      "        Splits a tensor into sub tensors.\n",
      "        \n",
      "        If `num_or_size_splits` is an integer, then `value` is split along dimension\n",
      "        `axis` into `num_split` smaller tensors. This requires that `num_split` evenly\n",
      "        divides `value.shape[axis]`.\n",
      "        \n",
      "        If `num_or_size_splits` is a 1-D Tensor (or list), we call it `size_splits`\n",
      "        and `value` is split into `len(size_splits)` elements. The shape of the `i`-th\n",
      "        element has the same size as the `value` except along dimension `axis` where\n",
      "        the size is `size_splits[i]`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        # 'value' is a tensor with shape [5, 30]\n",
      "        # Split 'value' into 3 tensors with sizes [4, 15, 11] along dimension 1\n",
      "        split0, split1, split2 = tf.split(value, [4, 15, 11], 1)\n",
      "        tf.shape(split0)  # [5, 4]\n",
      "        tf.shape(split1)  # [5, 15]\n",
      "        tf.shape(split2)  # [5, 11]\n",
      "        # Split 'value' into 3 tensors along dimension 1\n",
      "        split0, split1, split2 = tf.split(value, num_or_size_splits=3, axis=1)\n",
      "        tf.shape(split0)  # [5, 10]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          value: The `Tensor` to split.\n",
      "          num_or_size_splits: Either an integer indicating the number of splits along\n",
      "            split_dim or a 1-D integer `Tensor` or Python list containing the sizes of\n",
      "            each output tensor along split_dim. If a scalar then it must evenly divide\n",
      "            `value.shape[axis]`; otherwise the sum of sizes along the split dimension\n",
      "            must match that of the `value`.\n",
      "          axis: An integer or scalar `int32` `Tensor`. The dimension along which to\n",
      "            split. Must be in the range `[-rank(value), rank(value))`. Defaults to 0.\n",
      "          num: Optional, used to specify the number of outputs when it cannot be\n",
      "            inferred from the shape of `size_splits`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          if `num_or_size_splits` is a scalar returns `num_or_size_splits` `Tensor`\n",
      "          objects; if `num_or_size_splits` is a 1-D Tensor returns\n",
      "          `num_or_size_splits.get_shape[0]` `Tensor` objects resulting from splitting\n",
      "          `value`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If `num` is unspecified and cannot be inferred.\n",
      "    \n",
      "    sqrt(x, name=None)\n",
      "        Computes square root of x element-wise.\n",
      "        \n",
      "        I.e., \\\\(y = \\sqrt{x} = x^{1/2}\\\\).\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "        \n",
      "          If `x` is a `SparseTensor`, returns\n",
      "          `SparseTensor(x.indices, tf.math.sqrt(x.values, ...), x.dense_shape)`\n",
      "    \n",
      "    square(x, name=None)\n",
      "        Computes square of x element-wise.\n",
      "        \n",
      "        I.e., \\\\(y = x * x = x^2\\\\).\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int32`, `int64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "        \n",
      "          If `x` is a `SparseTensor`, returns\n",
      "          `SparseTensor(x.indices, tf.math.square(x.values, ...), x.dense_shape)`\n",
      "    \n",
      "    squared_difference(x, y, name=None)\n",
      "        Returns (x - y)(x - y) element-wise.\n",
      "        \n",
      "        *NOTE*: `math.squared_difference` supports broadcasting. More about broadcasting\n",
      "        [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int32`, `int64`, `complex64`, `complex128`.\n",
      "          y: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    squeeze(input, axis=None, name=None, squeeze_dims=None)\n",
      "        Removes dimensions of size 1 from the shape of a tensor. (deprecated arguments)\n",
      "        \n",
      "        Warning: SOME ARGUMENTS ARE DEPRECATED: `(squeeze_dims)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Use the `axis` argument instead\n",
      "        \n",
      "        Given a tensor `input`, this operation returns a tensor of the same type with\n",
      "        all dimensions of size 1 removed. If you don't want to remove all size 1\n",
      "        dimensions, you can remove specific size 1 dimensions by specifying\n",
      "        `axis`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        # 't' is a tensor of shape [1, 2, 1, 3, 1, 1]\n",
      "        tf.shape(tf.squeeze(t))  # [2, 3]\n",
      "        ```\n",
      "        \n",
      "        Or, to remove specific size 1 dimensions:\n",
      "        \n",
      "        ```python\n",
      "        # 't' is a tensor of shape [1, 2, 1, 3, 1, 1]\n",
      "        tf.shape(tf.squeeze(t, [2, 4]))  # [1, 2, 3, 1]\n",
      "        ```\n",
      "        \n",
      "        Note: if `input` is a `tf.RaggedTensor`, then this operation takes `O(N)`\n",
      "        time, where `N` is the number of elements in the squeezed dimensions.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. The `input` to squeeze.\n",
      "          axis: An optional list of `ints`. Defaults to `[]`. If specified, only\n",
      "            squeezes the dimensions listed. The dimension index starts at 0. It is an\n",
      "            error to squeeze a dimension that is not 1. Must be in the range\n",
      "            `[-rank(input), rank(input))`.\n",
      "            Must be specified if `input` is a `RaggedTensor`.\n",
      "          name: A name for the operation (optional).\n",
      "          squeeze_dims: Deprecated keyword argument that is now axis.\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "          Contains the same data as `input`, but has one or more dimensions of\n",
      "          size 1 removed.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: When both `squeeze_dims` and `axis` are specified.\n",
      "    \n",
      "    stack(values, axis=0, name='stack')\n",
      "        Stacks a list of rank-`R` tensors into one rank-`(R+1)` tensor.\n",
      "        \n",
      "        Packs the list of tensors in `values` into a tensor with rank one higher than\n",
      "        each tensor in `values`, by packing them along the `axis` dimension.\n",
      "        Given a list of length `N` of tensors of shape `(A, B, C)`;\n",
      "        \n",
      "        if `axis == 0` then the `output` tensor will have the shape `(N, A, B, C)`.\n",
      "        if `axis == 1` then the `output` tensor will have the shape `(A, N, B, C)`.\n",
      "        Etc.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([1, 4])\n",
      "        y = tf.constant([2, 5])\n",
      "        z = tf.constant([3, 6])\n",
      "        tf.stack([x, y, z])  # [[1, 4], [2, 5], [3, 6]] (Pack along first dim.)\n",
      "        tf.stack([x, y, z], axis=1)  # [[1, 2, 3], [4, 5, 6]]\n",
      "        ```\n",
      "        \n",
      "        This is the opposite of unstack.  The numpy equivalent is\n",
      "        \n",
      "        ```python\n",
      "        tf.stack([x, y, z]) = np.stack([x, y, z])\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          values: A list of `Tensor` objects with the same shape and type.\n",
      "          axis: An `int`. The axis to stack along. Defaults to the first dimension.\n",
      "            Negative values wrap around, so the valid range is `[-(R+1), R+1)`.\n",
      "          name: A name for this operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          output: A stacked `Tensor` with the same type as `values`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If `axis` is out of the range [-(R+1), R+1).\n",
      "    \n",
      "    stop_gradient(input, name=None)\n",
      "        Stops gradient computation.\n",
      "        \n",
      "        When executed in a graph, this op outputs its input tensor as-is.\n",
      "        \n",
      "        When building ops to compute gradients, this op prevents the contribution of\n",
      "        its inputs to be taken into account.  Normally, the gradient generator adds ops\n",
      "        to a graph to compute the derivatives of a specified 'loss' by recursively\n",
      "        finding out inputs that contributed to its computation.  If you insert this op\n",
      "        in the graph it inputs are masked from the gradient generator.  They are not\n",
      "        taken into account for computing gradients.\n",
      "        \n",
      "        This is useful any time you want to compute a value with TensorFlow but need\n",
      "        to pretend that the value was a constant. Some examples include:\n",
      "        \n",
      "        *  The *EM* algorithm where the *M-step* should not involve backpropagation\n",
      "           through the output of the *E-step*.\n",
      "        *  Contrastive divergence training of Boltzmann machines where, when\n",
      "           differentiating the energy function, the training must not backpropagate\n",
      "           through the graph that generated the samples from the model.\n",
      "        *  Adversarial training, where no backprop should happen through the adversarial\n",
      "           example generation process.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    strided_slice(input_, begin, end, strides=None, begin_mask=0, end_mask=0, ellipsis_mask=0, new_axis_mask=0, shrink_axis_mask=0, var=None, name=None)\n",
      "        Extracts a strided slice of a tensor (generalized python array indexing).\n",
      "        \n",
      "        **Instead of calling this op directly most users will want to use the\n",
      "        NumPy-style slicing syntax (e.g. `tensor[..., 3:4:-1, tf.newaxis, 3]`), which\n",
      "        is supported via `tf.Tensor.__getitem__` and `tf.Variable.__getitem__`.**\n",
      "        The interface of this op is a low-level encoding of the slicing syntax.\n",
      "        \n",
      "        Roughly speaking, this op extracts a slice of size `(end-begin)/stride`\n",
      "        from the given `input_` tensor. Starting at the location specified by `begin`\n",
      "        the slice continues by adding `stride` to the index until all dimensions are\n",
      "        not less than `end`.\n",
      "        Note that a stride can be negative, which causes a reverse slice.\n",
      "        \n",
      "        Given a Python slice `input[spec0, spec1, ..., specn]`,\n",
      "        this function will be called as follows.\n",
      "        \n",
      "        `begin`, `end`, and `strides` will be vectors of length n.\n",
      "        n in general is not equal to the rank of the `input_` tensor.\n",
      "        \n",
      "        In each mask field (`begin_mask`, `end_mask`, `ellipsis_mask`,\n",
      "        `new_axis_mask`, `shrink_axis_mask`) the ith bit will correspond to\n",
      "        the ith spec.\n",
      "        \n",
      "        If the ith bit of `begin_mask` is set, `begin[i]` is ignored and\n",
      "        the fullest possible range in that dimension is used instead.\n",
      "        `end_mask` works analogously, except with the end range.\n",
      "        \n",
      "        `foo[5:,:,:3]` on a 7x8x9 tensor is equivalent to `foo[5:7,0:8,0:3]`.\n",
      "        `foo[::-1]` reverses a tensor with shape 8.\n",
      "        \n",
      "        If the ith bit of `ellipsis_mask` is set, as many unspecified dimensions\n",
      "        as needed will be inserted between other dimensions. Only one\n",
      "        non-zero bit is allowed in `ellipsis_mask`.\n",
      "        \n",
      "        For example `foo[3:5,...,4:5]` on a shape 10x3x3x10 tensor is\n",
      "        equivalent to `foo[3:5,:,:,4:5]` and\n",
      "        `foo[3:5,...]` is equivalent to `foo[3:5,:,:,:]`.\n",
      "        \n",
      "        If the ith bit of `new_axis_mask` is set, then `begin`,\n",
      "        `end`, and `stride` are ignored and a new length 1 dimension is\n",
      "        added at this point in the output tensor.\n",
      "        \n",
      "        For example,\n",
      "        `foo[:4, tf.newaxis, :2]` would produce a shape `(4, 1, 2)` tensor.\n",
      "        \n",
      "        If the ith bit of `shrink_axis_mask` is set, it implies that the ith\n",
      "        specification shrinks the dimensionality by 1, taking on the value at index\n",
      "        `begin[i]`. `end[i]` and `strides[i]` are ignored in this case. For example in\n",
      "        Python one might do `foo[:, 3, :]` which would result in `shrink_axis_mask`\n",
      "        equal to 2.\n",
      "        \n",
      "        \n",
      "        NOTE: `begin` and `end` are zero-indexed.\n",
      "        `strides` entries must be non-zero.\n",
      "        \n",
      "        \n",
      "        ```python\n",
      "        t = tf.constant([[[1, 1, 1], [2, 2, 2]],\n",
      "                         [[3, 3, 3], [4, 4, 4]],\n",
      "                         [[5, 5, 5], [6, 6, 6]]])\n",
      "        tf.strided_slice(t, [1, 0, 0], [2, 1, 3], [1, 1, 1])  # [[[3, 3, 3]]]\n",
      "        tf.strided_slice(t, [1, 0, 0], [2, 2, 3], [1, 1, 1])  # [[[3, 3, 3],\n",
      "                                                              #   [4, 4, 4]]]\n",
      "        tf.strided_slice(t, [1, -1, 0], [2, -3, 3], [1, -1, 1])  # [[[4, 4, 4],\n",
      "                                                                 #   [3, 3, 3]]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input_: A `Tensor`.\n",
      "          begin: An `int32` or `int64` `Tensor`.\n",
      "          end: An `int32` or `int64` `Tensor`.\n",
      "          strides: An `int32` or `int64` `Tensor`.\n",
      "          begin_mask: An `int32` mask.\n",
      "          end_mask: An `int32` mask.\n",
      "          ellipsis_mask: An `int32` mask.\n",
      "          new_axis_mask: An `int32` mask.\n",
      "          shrink_axis_mask: An `int32` mask.\n",
      "          var: The variable corresponding to `input_` or None\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` the same type as `input`.\n",
      "    \n",
      "    string_join(inputs, separator='', name=None)\n",
      "        Joins the strings in the given list of string tensors into one tensor;\n",
      "        \n",
      "        with the given separator (default is an empty separator).\n",
      "        \n",
      "        Args:\n",
      "          inputs: A list of at least 1 `Tensor` objects with type `string`.\n",
      "            A list of string tensors.  The tensors must all have the same shape,\n",
      "            or be scalars.  Scalars may be mixed in; these will be broadcast to the shape\n",
      "            of non-scalar inputs.\n",
      "          separator: An optional `string`. Defaults to `\"\"`.\n",
      "            string, an optional join separator.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `string`.\n",
      "    \n",
      "    string_split(source, sep=None, skip_empty=True, delimiter=None, result_type='SparseTensor', name=None)\n",
      "        Split elements of `source` based on `delimiter`. (deprecated arguments)\n",
      "        \n",
      "        Warning: SOME ARGUMENTS ARE DEPRECATED: `(delimiter)`. They will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        delimiter is deprecated, please use sep instead.\n",
      "        \n",
      "        Let N be the size of `source` (typically N will be the batch size). Split each\n",
      "        element of `source` based on `delimiter` and return a `SparseTensor`\n",
      "        or `RaggedTensor` containing the split tokens. Empty tokens are ignored.\n",
      "        \n",
      "        If `sep` is an empty string, each element of the `source` is split\n",
      "        into individual strings, each containing one byte. (This includes splitting\n",
      "        multibyte sequences of UTF-8.) If delimiter contains multiple bytes, it is\n",
      "        treated as a set of delimiters with each considered a potential split point.\n",
      "        \n",
      "        Examples:\n",
      "        \n",
      "        ```python\n",
      "        >>> tf.strings.split(['hello world', 'a b c'])\n",
      "        tf.SparseTensor(indices=[[0, 0], [0, 1], [1, 0], [1, 1], [1, 2]],\n",
      "                        values=['hello', 'world', 'a', 'b', 'c']\n",
      "                        dense_shape=[2, 3])\n",
      "        \n",
      "        >>> tf.strings.split(['hello world', 'a b c'], result_type=\"RaggedTensor\")\n",
      "        <tf.RaggedTensor [['hello', 'world'], ['a', 'b', 'c']]>\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          source: `1-D` string `Tensor`, the strings to split.\n",
      "          sep: `0-D` string `Tensor`, the delimiter character, the string should\n",
      "            be length 0 or 1. Default is ' '.\n",
      "          skip_empty: A `bool`. If `True`, skip the empty strings from the result.\n",
      "          delimiter: deprecated alias for `sep`.\n",
      "          result_type: The tensor type for the result: one of `\"RaggedTensor\"` or\n",
      "            `\"SparseTensor\"`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If delimiter is not a string.\n",
      "        \n",
      "        Returns:\n",
      "          A `SparseTensor` or `RaggedTensor` of rank `2`, the strings split according\n",
      "          to the delimiter.  The first column of the indices corresponds to the row\n",
      "          in `source` and the second column corresponds to the index of the split\n",
      "          component in this row.\n",
      "    \n",
      "    string_strip(input, name=None)\n",
      "        Strip leading and trailing whitespaces from the Tensor.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor` of type `string`. A string `Tensor` of any shape.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `string`.\n",
      "    \n",
      "    string_to_hash_bucket = string_to_hash_bucket_v1(string_tensor=None, num_buckets=None, name=None, input=None)\n",
      "        Converts each string in the input Tensor to its hash mod by a number of buckets.\n",
      "        \n",
      "        The hash function is deterministic on the content of the string within the\n",
      "        process.\n",
      "        \n",
      "        Note that the hash function may change from time to time.\n",
      "        This functionality will be deprecated and it's recommended to use\n",
      "        `tf.string_to_hash_bucket_fast()` or `tf.string_to_hash_bucket_strong()`.\n",
      "        \n",
      "        Args:\n",
      "          string_tensor: A `Tensor` of type `string`.\n",
      "          num_buckets: An `int` that is `>= 1`. The number of buckets.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `int64`.\n",
      "    \n",
      "    string_to_hash_bucket_fast(input, num_buckets, name=None)\n",
      "        Converts each string in the input Tensor to its hash mod by a number of buckets.\n",
      "        \n",
      "        The hash function is deterministic on the content of the string within the\n",
      "        process and will never change. However, it is not suitable for cryptography.\n",
      "        This function may be used when CPU time is scarce and inputs are trusted or\n",
      "        unimportant. There is a risk of adversaries constructing inputs that all hash\n",
      "        to the same bucket. To prevent this problem, use a strong hash function with\n",
      "        `tf.string_to_hash_bucket_strong`.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor` of type `string`. The strings to assign a hash bucket.\n",
      "          num_buckets: An `int` that is `>= 1`. The number of buckets.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `int64`.\n",
      "    \n",
      "    string_to_hash_bucket_strong(input, num_buckets, key, name=None)\n",
      "        Converts each string in the input Tensor to its hash mod by a number of buckets.\n",
      "        \n",
      "        The hash function is deterministic on the content of the string within the\n",
      "        process. The hash function is a keyed hash function, where attribute `key`\n",
      "        defines the key of the hash function. `key` is an array of 2 elements.\n",
      "        \n",
      "        A strong hash is important when inputs may be malicious, e.g. URLs with\n",
      "        additional components. Adversaries could try to make their inputs hash to the\n",
      "        same bucket for a denial-of-service attack or to skew the results. A strong\n",
      "        hash can be used to make it difficult to find inputs with a skewed hash value\n",
      "        distribution over buckets. This requires that the hash function is\n",
      "        seeded by a high-entropy (random) \"key\" unknown to the adversary.\n",
      "        \n",
      "        The additional robustness comes at a cost of roughly 4x higher compute\n",
      "        time than `tf.string_to_hash_bucket_fast`.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor` of type `string`. The strings to assign a hash bucket.\n",
      "          num_buckets: An `int` that is `>= 1`. The number of buckets.\n",
      "          key: A list of `ints`.\n",
      "            The key used to seed the hash function, passed as a list of two uint64\n",
      "            elements.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `int64`.\n",
      "    \n",
      "    string_to_number = string_to_number_v1(string_tensor=None, out_type=tf.float32, name=None, input=None)\n",
      "        Converts each string in the input Tensor to the specified numeric type.\n",
      "        \n",
      "        (Note that int32 overflow results in an error while float overflow\n",
      "        results in a rounded value.)\n",
      "        \n",
      "        Args:\n",
      "          string_tensor: A `Tensor` of type `string`.\n",
      "          out_type: An optional `tf.DType` from: `tf.float32, tf.float64, tf.int32, tf.int64`. Defaults to `tf.float32`.\n",
      "            The numeric type to interpret each string in `string_tensor` as.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `out_type`.\n",
      "    \n",
      "    substr = substr_deprecated(input, pos, len, name=None, unit='BYTE')\n",
      "        Return substrings from `Tensor` of strings.\n",
      "        \n",
      "        For each string in the input `Tensor`, creates a substring starting at index\n",
      "        `pos` with a total length of `len`.\n",
      "        \n",
      "        If `len` defines a substring that would extend beyond the length of the input\n",
      "        string, then as many characters as possible are used.\n",
      "        \n",
      "        A negative `pos` indicates distance within the string backwards from the end.\n",
      "        \n",
      "        If `pos` specifies an index which is out of range for any of the input strings,\n",
      "        then an `InvalidArgumentError` is thrown.\n",
      "        \n",
      "        `pos` and `len` must have the same shape, otherwise a `ValueError` is thrown on\n",
      "        Op creation.\n",
      "        \n",
      "        *NOTE*: `Substr` supports broadcasting up to two dimensions. More about\n",
      "        broadcasting\n",
      "        [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        \n",
      "        ---\n",
      "        \n",
      "        Examples\n",
      "        \n",
      "        Using scalar `pos` and `len`:\n",
      "        \n",
      "        ```python\n",
      "        input = [b'Hello', b'World']\n",
      "        position = 1\n",
      "        length = 3\n",
      "        \n",
      "        output = [b'ell', b'orl']\n",
      "        ```\n",
      "        \n",
      "        Using `pos` and `len` with same shape as `input`:\n",
      "        \n",
      "        ```python\n",
      "        input = [[b'ten', b'eleven', b'twelve'],\n",
      "                 [b'thirteen', b'fourteen', b'fifteen'],\n",
      "                 [b'sixteen', b'seventeen', b'eighteen']]\n",
      "        position = [[1, 2, 3],\n",
      "                    [1, 2, 3],\n",
      "                    [1, 2, 3]]\n",
      "        length =   [[2, 3, 4],\n",
      "                    [4, 3, 2],\n",
      "                    [5, 5, 5]]\n",
      "        \n",
      "        output = [[b'en', b'eve', b'lve'],\n",
      "                  [b'hirt', b'urt', b'te'],\n",
      "                  [b'ixtee', b'vente', b'hteen']]\n",
      "        ```\n",
      "        \n",
      "        Broadcasting `pos` and `len` onto `input`:\n",
      "        \n",
      "        ```\n",
      "        input = [[b'ten', b'eleven', b'twelve'],\n",
      "                 [b'thirteen', b'fourteen', b'fifteen'],\n",
      "                 [b'sixteen', b'seventeen', b'eighteen'],\n",
      "                 [b'nineteen', b'twenty', b'twentyone']]\n",
      "        position = [1, 2, 3]\n",
      "        length =   [1, 2, 3]\n",
      "        \n",
      "        output = [[b'e', b'ev', b'lve'],\n",
      "                  [b'h', b'ur', b'tee'],\n",
      "                  [b'i', b've', b'hte'],\n",
      "                  [b'i', b'en', b'nty']]\n",
      "        ```\n",
      "        \n",
      "        Broadcasting `input` onto `pos` and `len`:\n",
      "        \n",
      "        ```\n",
      "        input = b'thirteen'\n",
      "        position = [1, 5, 7]\n",
      "        length =   [3, 2, 1]\n",
      "        \n",
      "        output = [b'hir', b'ee', b'n']\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor` of type `string`. Tensor of strings\n",
      "          pos: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            Scalar defining the position of first character in each substring\n",
      "          len: A `Tensor`. Must have the same type as `pos`.\n",
      "            Scalar defining the number of characters to include in each substring\n",
      "          unit: An optional `string` from: `\"BYTE\", \"UTF8_CHAR\"`. Defaults to `\"BYTE\"`.\n",
      "            The unit that is used to create the substring.  One of: `\"BYTE\"` (for\n",
      "            defining position and length by bytes) or `\"UTF8_CHAR\"` (for the UTF-8\n",
      "            encoded Unicode code points).  The default is `\"BYTE\"`. Results are undefined if\n",
      "            `unit=UTF8_CHAR` and the `input` strings do not contain structurally valid\n",
      "            UTF-8.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `string`.\n",
      "    \n",
      "    subtract(x, y, name=None)\n",
      "        Returns x - y element-wise.\n",
      "        \n",
      "        *NOTE*: `Subtract` supports broadcasting. More about broadcasting\n",
      "        [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`, `int16`, `int32`, `int64`, `complex64`, `complex128`.\n",
      "          y: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    svd(tensor, full_matrices=False, compute_uv=True, name=None)\n",
      "        Computes the singular value decompositions of one or more matrices.\n",
      "        \n",
      "        Computes the SVD of each inner matrix in `tensor` such that\n",
      "        `tensor[..., :, :] = u[..., :, :] * diag(s[..., :, :]) *\n",
      "         transpose(conj(v[..., :, :]))`\n",
      "        \n",
      "        ```python\n",
      "        # a is a tensor.\n",
      "        # s is a tensor of singular values.\n",
      "        # u is a tensor of left singular vectors.\n",
      "        # v is a tensor of right singular vectors.\n",
      "        s, u, v = svd(a)\n",
      "        s = svd(a, compute_uv=False)\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          tensor: `Tensor` of shape `[..., M, N]`. Let `P` be the minimum of `M` and\n",
      "            `N`.\n",
      "          full_matrices: If true, compute full-sized `u` and `v`. If false\n",
      "            (the default), compute only the leading `P` singular vectors.\n",
      "            Ignored if `compute_uv` is `False`.\n",
      "          compute_uv: If `True` then left and right singular vectors will be\n",
      "            computed and returned in `u` and `v`, respectively. Otherwise, only the\n",
      "            singular values will be computed, which can be significantly faster.\n",
      "          name: string, optional name of the operation.\n",
      "        \n",
      "        Returns:\n",
      "          s: Singular values. Shape is `[..., P]`. The values are sorted in reverse\n",
      "            order of magnitude, so s[..., 0] is the largest value, s[..., 1] is the\n",
      "            second largest, etc.\n",
      "          u: Left singular vectors. If `full_matrices` is `False` (default) then\n",
      "            shape is `[..., M, P]`; if `full_matrices` is `True` then shape is\n",
      "            `[..., M, M]`. Not returned if `compute_uv` is `False`.\n",
      "          v: Right singular vectors. If `full_matrices` is `False` (default) then\n",
      "            shape is `[..., N, P]`. If `full_matrices` is `True` then shape is\n",
      "            `[..., N, N]`. Not returned if `compute_uv` is `False`.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Mostly equivalent to numpy.linalg.svd, except that\n",
      "          * The order of output  arguments here is `s`, `u`, `v` when `compute_uv` is\n",
      "            `True`, as opposed to `u`, `s`, `v` for numpy.linalg.svd.\n",
      "          * full_matrices is `False` by default as opposed to `True` for\n",
      "             numpy.linalg.svd.\n",
      "          * tf.linalg.svd uses the standard definition of the SVD\n",
      "            \\\\(A = U \\Sigma V^H\\\\), such that the left singular vectors of `a` are\n",
      "            the columns of `u`, while the right singular vectors of `a` are the\n",
      "            columns of `v`. On the other hand, numpy.linalg.svd returns the adjoint\n",
      "            \\\\(V^H\\\\) as the third output argument.\n",
      "        ```python\n",
      "        import tensorflow as tf\n",
      "        import numpy as np\n",
      "        s, u, v = tf.linalg.svd(a)\n",
      "        tf_a_approx = tf.matmul(u, tf.matmul(tf.linalg.diag(s), v, adjoint_b=True))\n",
      "        u, s, v_adj = np.linalg.svd(a, full_matrices=False)\n",
      "        np_a_approx = np.dot(u, np.dot(np.diag(s), v_adj))\n",
      "        # tf_a_approx and np_a_approx should be numerically close.\n",
      "        ```\n",
      "        @end_compatibility\n",
      "    \n",
      "    switch_case(branch_index, branch_fns, default=None, name='switch_case')\n",
      "        Create a switch/case operation, i.e. an integer-indexed conditional.\n",
      "        \n",
      "        See also `tf.case`.\n",
      "        \n",
      "        This op can be substantially more efficient than `tf.case` when exactly one\n",
      "        branch will be selected. `tf.switch_case` is more like a C++ switch/case\n",
      "        statement than `tf.case`, which is more like an if/elif/elif/else chain.\n",
      "        \n",
      "        The `branch_fns` parameter is either a list\n",
      "        of (int, callable) pairs, or simply a list of callables (in which case the\n",
      "        index is implicitly the key). The `branch_index` `Tensor` is used to select an\n",
      "        element in `branch_fns` with matching `int` key, falling back to `default`\n",
      "        if none match, or `max(keys)` if no `default` is provided. The keys must form\n",
      "        a contiguous set from `0` to `len(branch_fns) - 1`.\n",
      "        \n",
      "        `tf.switch_case` supports nested structures as implemented in `tf.nest`. All\n",
      "        callables must return the same (possibly nested) value structure of lists,\n",
      "        tuples, and/or named tuples.\n",
      "        \n",
      "        @compatibility(v2)\n",
      "        `branch_fns` could be a dictionary in v1. However, tf.Tensor and\n",
      "        tf.Variable are no longer hashable in v2, so cannot be used as a key for a\n",
      "        dictionary.  Please use a list or a tuple instead.\n",
      "        @end_compatibility\n",
      "        \n",
      "        **Example:**\n",
      "        \n",
      "        Pseudocode:\n",
      "        \n",
      "        ```c++\n",
      "        switch (branch_index) {  // c-style switch\n",
      "          case 0: return 17;\n",
      "          case 1: return 31;\n",
      "          default: return -1;\n",
      "        }\n",
      "        ```\n",
      "        or\n",
      "        ```python\n",
      "        branches = {0: lambda: 17, 1: lambda: 31}\n",
      "        branches.get(branch_index, lambda: -1)()\n",
      "        ```\n",
      "        \n",
      "        Expressions:\n",
      "        \n",
      "        ```python\n",
      "        def f1(): return tf.constant(17)\n",
      "        def f2(): return tf.constant(31)\n",
      "        def f3(): return tf.constant(-1)\n",
      "        r = tf.switch_case(branch_index, branch_fns={0: f1, 1: f2}, default=f3)\n",
      "        # Equivalent: tf.switch_case(branch_index, branch_fns={0: f1, 1: f2, 2: f3})\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          branch_index: An int Tensor specifying which of `branch_fns` should be\n",
      "            executed.\n",
      "          branch_fns: A `list` of (int, callable) pairs, or simply a list of\n",
      "          callables (in which case the index serves as the key). Each callable must\n",
      "          return a matching structure of tensors.\n",
      "          default: Optional callable that returns a structure of tensors.\n",
      "          name: A name for this operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          The tensors returned by the callable identified by `branch_index`, or those\n",
      "          returned by `default` if no key matches and `default` was provided, or those\n",
      "          returned by the max-keyed `branch_fn` if no `default` is provided.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `branch_fns` is not a list/dictionary.\n",
      "          TypeError: If `branch_fns` is a list but does not contain 2-tuples or\n",
      "                     callables.\n",
      "          TypeError: If `fns[i]` is not callable for any i, or `default` is not\n",
      "                     callable.\n",
      "    \n",
      "    tables_initializer(name='init_all_tables')\n",
      "        Returns an Op that initializes all tables of the default graph.\n",
      "        \n",
      "        See the [Low Level\n",
      "        Intro](https://www.tensorflow.org/guide/low_level_intro#feature_columns)\n",
      "        guide, for an example of usage.\n",
      "        \n",
      "        Args:\n",
      "          name: Optional name for the initialization op.\n",
      "        \n",
      "        Returns:\n",
      "          An Op that initializes all tables.  Note that if there are\n",
      "          not tables the returned Op is a NoOp.\n",
      "    \n",
      "    tan(x, name=None)\n",
      "        Computes tan of x element-wise.\n",
      "        \n",
      "          Given an input tensor, this function computes tangent of every\n",
      "          element in the tensor. Input range is `(-inf, inf)` and\n",
      "          output range is `(-inf, inf)`. If input lies outside the boundary, `nan`\n",
      "          is returned.\n",
      "        \n",
      "          ```python\n",
      "          x = tf.constant([-float(\"inf\"), -9, -0.5, 1, 1.2, 200, 10000, float(\"inf\")])\n",
      "          tf.math.tan(x) ==> [nan 0.45231566 -0.5463025 1.5574077 2.572152 -1.7925274 0.32097113 nan]\n",
      "          ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int32`, `int64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    tanh(x, name=None)\n",
      "        Computes hyperbolic tangent of `x` element-wise.\n",
      "        \n",
      "          Given an input tensor, this function computes hyperbolic tangent of every\n",
      "          element in the tensor. Input range is `[-inf, inf]` and\n",
      "          output range is `[-1,1]`.\n",
      "        \n",
      "          ```python\n",
      "          x = tf.constant([-float(\"inf\"), -5, -0.5, 1, 1.2, 2, 3, float(\"inf\")])\n",
      "          tf.math.tanh(x) ==> [-1. -0.99990916 -0.46211717 0.7615942 0.8336547 0.9640276 0.9950547 1.]\n",
      "          ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "        \n",
      "          If `x` is a `SparseTensor`, returns\n",
      "          `SparseTensor(x.indices, tf.math.tanh(x.values, ...), x.dense_shape)`\n",
      "    \n",
      "    tensor_scatter_add(tensor, indices, updates, name=None)\n",
      "        Adds sparse `updates` to an existing tensor according to `indices`.\n",
      "        \n",
      "        This operation creates a new tensor by adding sparse `updates` to the passed\n",
      "        in `tensor`.\n",
      "        This operation is very similar to `tf.scatter_nd_add`, except that the updates\n",
      "        are added onto an existing tensor (as opposed to a variable). If the memory\n",
      "        for the existing tensor cannot be re-used, a copy is made and updated.\n",
      "        \n",
      "        `indices` is an integer tensor containing indices into a new tensor of shape\n",
      "        `shape`.  The last dimension of `indices` can be at most the rank of `shape`:\n",
      "        \n",
      "            indices.shape[-1] <= shape.rank\n",
      "        \n",
      "        The last dimension of `indices` corresponds to indices into elements\n",
      "        (if `indices.shape[-1] = shape.rank`) or slices\n",
      "        (if `indices.shape[-1] < shape.rank`) along dimension `indices.shape[-1]` of\n",
      "        `shape`.  `updates` is a tensor with shape\n",
      "        \n",
      "            indices.shape[:-1] + shape[indices.shape[-1]:]\n",
      "        \n",
      "        The simplest form of tensor_scatter_add is to add individual elements to a\n",
      "        tensor by index. For example, say we want to add 4 elements in a rank-1\n",
      "        tensor with 8 elements.\n",
      "        \n",
      "        In Python, this scatter add operation would look like this:\n",
      "        \n",
      "        ```python\n",
      "            indices = tf.constant([[4], [3], [1], [7]])\n",
      "            updates = tf.constant([9, 10, 11, 12])\n",
      "            tensor = tf.ones([8], dtype=tf.int32)\n",
      "            updated = tf.tensor_scatter_add(tensor, indices, updates)\n",
      "            with tf.Session() as sess:\n",
      "              print(sess.run(scatter))\n",
      "        ```\n",
      "        \n",
      "        The resulting tensor would look like this:\n",
      "        \n",
      "            [1, 12, 1, 11, 10, 1, 1, 13]\n",
      "        \n",
      "        We can also, insert entire slices of a higher rank tensor all at once. For\n",
      "        example, if we wanted to insert two slices in the first dimension of a\n",
      "        rank-3 tensor with two matrices of new values.\n",
      "        \n",
      "        In Python, this scatter add operation would look like this:\n",
      "        \n",
      "        ```python\n",
      "            indices = tf.constant([[0], [2]])\n",
      "            updates = tf.constant([[[5, 5, 5, 5], [6, 6, 6, 6],\n",
      "                                    [7, 7, 7, 7], [8, 8, 8, 8]],\n",
      "                                   [[5, 5, 5, 5], [6, 6, 6, 6],\n",
      "                                    [7, 7, 7, 7], [8, 8, 8, 8]]])\n",
      "            tensor = tf.ones([4, 4, 4])\n",
      "            updated = tf.tensor_scatter_add(tensor, indices, updates)\n",
      "            with tf.Session() as sess:\n",
      "              print(sess.run(scatter))\n",
      "        ```\n",
      "        \n",
      "        The resulting tensor would look like this:\n",
      "        \n",
      "            [[[6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8], [9, 9, 9, 9]],\n",
      "             [[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]],\n",
      "             [[6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8], [9, 9, 9, 9]],\n",
      "             [[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]]]\n",
      "        \n",
      "        Note that on CPU, if an out of bound index is found, an error is returned.\n",
      "        On GPU, if an out of bound index is found, the index is ignored.\n",
      "        \n",
      "        Args:\n",
      "          tensor: A `Tensor`. Tensor to copy/update.\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            Index tensor.\n",
      "          updates: A `Tensor`. Must have the same type as `tensor`.\n",
      "            Updates to scatter into output.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `tensor`.\n",
      "    \n",
      "    tensor_scatter_nd_add = tensor_scatter_add(tensor, indices, updates, name=None)\n",
      "        Adds sparse `updates` to an existing tensor according to `indices`.\n",
      "        \n",
      "        This operation creates a new tensor by adding sparse `updates` to the passed\n",
      "        in `tensor`.\n",
      "        This operation is very similar to `tf.scatter_nd_add`, except that the updates\n",
      "        are added onto an existing tensor (as opposed to a variable). If the memory\n",
      "        for the existing tensor cannot be re-used, a copy is made and updated.\n",
      "        \n",
      "        `indices` is an integer tensor containing indices into a new tensor of shape\n",
      "        `shape`.  The last dimension of `indices` can be at most the rank of `shape`:\n",
      "        \n",
      "            indices.shape[-1] <= shape.rank\n",
      "        \n",
      "        The last dimension of `indices` corresponds to indices into elements\n",
      "        (if `indices.shape[-1] = shape.rank`) or slices\n",
      "        (if `indices.shape[-1] < shape.rank`) along dimension `indices.shape[-1]` of\n",
      "        `shape`.  `updates` is a tensor with shape\n",
      "        \n",
      "            indices.shape[:-1] + shape[indices.shape[-1]:]\n",
      "        \n",
      "        The simplest form of tensor_scatter_add is to add individual elements to a\n",
      "        tensor by index. For example, say we want to add 4 elements in a rank-1\n",
      "        tensor with 8 elements.\n",
      "        \n",
      "        In Python, this scatter add operation would look like this:\n",
      "        \n",
      "        ```python\n",
      "            indices = tf.constant([[4], [3], [1], [7]])\n",
      "            updates = tf.constant([9, 10, 11, 12])\n",
      "            tensor = tf.ones([8], dtype=tf.int32)\n",
      "            updated = tf.tensor_scatter_add(tensor, indices, updates)\n",
      "            with tf.Session() as sess:\n",
      "              print(sess.run(scatter))\n",
      "        ```\n",
      "        \n",
      "        The resulting tensor would look like this:\n",
      "        \n",
      "            [1, 12, 1, 11, 10, 1, 1, 13]\n",
      "        \n",
      "        We can also, insert entire slices of a higher rank tensor all at once. For\n",
      "        example, if we wanted to insert two slices in the first dimension of a\n",
      "        rank-3 tensor with two matrices of new values.\n",
      "        \n",
      "        In Python, this scatter add operation would look like this:\n",
      "        \n",
      "        ```python\n",
      "            indices = tf.constant([[0], [2]])\n",
      "            updates = tf.constant([[[5, 5, 5, 5], [6, 6, 6, 6],\n",
      "                                    [7, 7, 7, 7], [8, 8, 8, 8]],\n",
      "                                   [[5, 5, 5, 5], [6, 6, 6, 6],\n",
      "                                    [7, 7, 7, 7], [8, 8, 8, 8]]])\n",
      "            tensor = tf.ones([4, 4, 4])\n",
      "            updated = tf.tensor_scatter_add(tensor, indices, updates)\n",
      "            with tf.Session() as sess:\n",
      "              print(sess.run(scatter))\n",
      "        ```\n",
      "        \n",
      "        The resulting tensor would look like this:\n",
      "        \n",
      "            [[[6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8], [9, 9, 9, 9]],\n",
      "             [[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]],\n",
      "             [[6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8], [9, 9, 9, 9]],\n",
      "             [[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]]]\n",
      "        \n",
      "        Note that on CPU, if an out of bound index is found, an error is returned.\n",
      "        On GPU, if an out of bound index is found, the index is ignored.\n",
      "        \n",
      "        Args:\n",
      "          tensor: A `Tensor`. Tensor to copy/update.\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            Index tensor.\n",
      "          updates: A `Tensor`. Must have the same type as `tensor`.\n",
      "            Updates to scatter into output.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `tensor`.\n",
      "    \n",
      "    tensor_scatter_nd_sub = tensor_scatter_sub(tensor, indices, updates, name=None)\n",
      "        Subtracts sparse `updates` from an existing tensor according to `indices`.\n",
      "        \n",
      "        This operation creates a new tensor by subtracting sparse `updates` from the\n",
      "        passed in `tensor`.\n",
      "        This operation is very similar to `tf.scatter_nd_sub`, except that the updates\n",
      "        are subtracted from an existing tensor (as opposed to a variable). If the memory\n",
      "        for the existing tensor cannot be re-used, a copy is made and updated.\n",
      "        \n",
      "        `indices` is an integer tensor containing indices into a new tensor of shape\n",
      "        `shape`.  The last dimension of `indices` can be at most the rank of `shape`:\n",
      "        \n",
      "            indices.shape[-1] <= shape.rank\n",
      "        \n",
      "        The last dimension of `indices` corresponds to indices into elements\n",
      "        (if `indices.shape[-1] = shape.rank`) or slices\n",
      "        (if `indices.shape[-1] < shape.rank`) along dimension `indices.shape[-1]` of\n",
      "        `shape`.  `updates` is a tensor with shape\n",
      "        \n",
      "            indices.shape[:-1] + shape[indices.shape[-1]:]\n",
      "        \n",
      "        The simplest form of tensor_scatter_sub is to subtract individual elements\n",
      "        from a tensor by index. For example, say we want to insert 4 scattered elements\n",
      "        in a rank-1 tensor with 8 elements.\n",
      "        \n",
      "        In Python, this scatter subtract operation would look like this:\n",
      "        \n",
      "        ```python\n",
      "            indices = tf.constant([[4], [3], [1], [7]])\n",
      "            updates = tf.constant([9, 10, 11, 12])\n",
      "            tensor = tf.ones([8], dtype=tf.int32)\n",
      "            updated = tf.tensor_scatter_sub(tensor, indices, updates)\n",
      "            with tf.Session() as sess:\n",
      "              print(sess.run(scatter))\n",
      "        ```\n",
      "        \n",
      "        The resulting tensor would look like this:\n",
      "        \n",
      "            [1, -10, 1, -9, -8, 1, 1, -11]\n",
      "        \n",
      "        We can also, insert entire slices of a higher rank tensor all at once. For\n",
      "        example, if we wanted to insert two slices in the first dimension of a\n",
      "        rank-3 tensor with two matrices of new values.\n",
      "        \n",
      "        In Python, this scatter add operation would look like this:\n",
      "        \n",
      "        ```python\n",
      "            indices = tf.constant([[0], [2]])\n",
      "            updates = tf.constant([[[5, 5, 5, 5], [6, 6, 6, 6],\n",
      "                                    [7, 7, 7, 7], [8, 8, 8, 8]],\n",
      "                                   [[5, 5, 5, 5], [6, 6, 6, 6],\n",
      "                                    [7, 7, 7, 7], [8, 8, 8, 8]]])\n",
      "            tensor = tf.ones([4, 4, 4])\n",
      "            updated = tf.tensor_scatter_sub(tensor, indices, updates)\n",
      "            with tf.Session() as sess:\n",
      "              print(sess.run(scatter))\n",
      "        ```\n",
      "        \n",
      "        The resulting tensor would look like this:\n",
      "        \n",
      "            [[[-4, -4, -4, -4], [-5, -5, -5, -5], [-6, -6, -6, -6], [-7, -7, -7, -7]],\n",
      "             [[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]],\n",
      "             [[-4, -4, -4, -4], [-5, -5, -5, -5], [-6, -6, -6, -6], [-7, -7, -7, -7]],\n",
      "             [[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]]]\n",
      "        \n",
      "        Note that on CPU, if an out of bound index is found, an error is returned.\n",
      "        On GPU, if an out of bound index is found, the index is ignored.\n",
      "        \n",
      "        Args:\n",
      "          tensor: A `Tensor`. Tensor to copy/update.\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            Index tensor.\n",
      "          updates: A `Tensor`. Must have the same type as `tensor`.\n",
      "            Updates to scatter into output.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `tensor`.\n",
      "    \n",
      "    tensor_scatter_nd_update = tensor_scatter_update(tensor, indices, updates, name=None)\n",
      "        Scatter `updates` into an existing tensor according to `indices`.\n",
      "        \n",
      "        This operation creates a new tensor by applying sparse `updates` to the passed\n",
      "        in `tensor`.\n",
      "        This operation is very similar to `tf.scatter_nd`, except that the updates are\n",
      "        scattered onto an existing tensor (as opposed to a zero-tensor). If the memory\n",
      "        for the existing tensor cannot be re-used, a copy is made and updated.\n",
      "        \n",
      "        If `indices` contains duplicates, then their updates are accumulated (summed).\n",
      "        \n",
      "        **WARNING**: The order in which updates are applied is nondeterministic, so the\n",
      "        output will be nondeterministic if `indices` contains duplicates -- because\n",
      "        of some numerical approximation issues, numbers summed in different order\n",
      "        may yield different results.\n",
      "        \n",
      "        `indices` is an integer tensor containing indices into a new tensor of shape\n",
      "        `shape`.  The last dimension of `indices` can be at most the rank of `shape`:\n",
      "        \n",
      "            indices.shape[-1] <= shape.rank\n",
      "        \n",
      "        The last dimension of `indices` corresponds to indices into elements\n",
      "        (if `indices.shape[-1] = shape.rank`) or slices\n",
      "        (if `indices.shape[-1] < shape.rank`) along dimension `indices.shape[-1]` of\n",
      "        `shape`.  `updates` is a tensor with shape\n",
      "        \n",
      "            indices.shape[:-1] + shape[indices.shape[-1]:]\n",
      "        \n",
      "        The simplest form of scatter is to insert individual elements in a tensor by\n",
      "        index. For example, say we want to insert 4 scattered elements in a rank-1\n",
      "        tensor with 8 elements.\n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        <img style=\"width:100%\" src=\"https://www.tensorflow.org/images/ScatterNd1.png\" alt>\n",
      "        </div>\n",
      "        \n",
      "        In Python, this scatter operation would look like this:\n",
      "        \n",
      "        ```python\n",
      "            indices = tf.constant([[4], [3], [1], [7]])\n",
      "            updates = tf.constant([9, 10, 11, 12])\n",
      "            tensor = tf.ones([8], dtype=tf.int32)\n",
      "            updated = tf.tensor_scatter_update(tensor, indices, updates)\n",
      "            with tf.Session() as sess:\n",
      "              print(sess.run(scatter))\n",
      "        ```\n",
      "        \n",
      "        The resulting tensor would look like this:\n",
      "        \n",
      "            [1, 11, 1, 10, 9, 1, 1, 12]\n",
      "        \n",
      "        We can also, insert entire slices of a higher rank tensor all at once. For\n",
      "        example, if we wanted to insert two slices in the first dimension of a\n",
      "        rank-3 tensor with two matrices of new values.\n",
      "        \n",
      "        In Python, this scatter operation would look like this:\n",
      "        \n",
      "        ```python\n",
      "            indices = tf.constant([[0], [2]])\n",
      "            updates = tf.constant([[[5, 5, 5, 5], [6, 6, 6, 6],\n",
      "                                    [7, 7, 7, 7], [8, 8, 8, 8]],\n",
      "                                   [[5, 5, 5, 5], [6, 6, 6, 6],\n",
      "                                    [7, 7, 7, 7], [8, 8, 8, 8]]])\n",
      "            tensor = tf.ones([4, 4, 4])\n",
      "            updated = tf.tensor_scatter_update(tensor, indices, updates)\n",
      "            with tf.Session() as sess:\n",
      "              print(sess.run(scatter))\n",
      "        ```\n",
      "        \n",
      "        The resulting tensor would look like this:\n",
      "        \n",
      "            [[[5, 5, 5, 5], [6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8]],\n",
      "             [[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]],\n",
      "             [[5, 5, 5, 5], [6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8]],\n",
      "             [[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]]]\n",
      "        \n",
      "        Note that on CPU, if an out of bound index is found, an error is returned.\n",
      "        On GPU, if an out of bound index is found, the index is ignored.\n",
      "        \n",
      "        Args:\n",
      "          tensor: A `Tensor`. Tensor to copy/update.\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            Index tensor.\n",
      "          updates: A `Tensor`. Must have the same type as `tensor`.\n",
      "            Updates to scatter into output.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `tensor`.\n",
      "    \n",
      "    tensor_scatter_sub(tensor, indices, updates, name=None)\n",
      "        Subtracts sparse `updates` from an existing tensor according to `indices`.\n",
      "        \n",
      "        This operation creates a new tensor by subtracting sparse `updates` from the\n",
      "        passed in `tensor`.\n",
      "        This operation is very similar to `tf.scatter_nd_sub`, except that the updates\n",
      "        are subtracted from an existing tensor (as opposed to a variable). If the memory\n",
      "        for the existing tensor cannot be re-used, a copy is made and updated.\n",
      "        \n",
      "        `indices` is an integer tensor containing indices into a new tensor of shape\n",
      "        `shape`.  The last dimension of `indices` can be at most the rank of `shape`:\n",
      "        \n",
      "            indices.shape[-1] <= shape.rank\n",
      "        \n",
      "        The last dimension of `indices` corresponds to indices into elements\n",
      "        (if `indices.shape[-1] = shape.rank`) or slices\n",
      "        (if `indices.shape[-1] < shape.rank`) along dimension `indices.shape[-1]` of\n",
      "        `shape`.  `updates` is a tensor with shape\n",
      "        \n",
      "            indices.shape[:-1] + shape[indices.shape[-1]:]\n",
      "        \n",
      "        The simplest form of tensor_scatter_sub is to subtract individual elements\n",
      "        from a tensor by index. For example, say we want to insert 4 scattered elements\n",
      "        in a rank-1 tensor with 8 elements.\n",
      "        \n",
      "        In Python, this scatter subtract operation would look like this:\n",
      "        \n",
      "        ```python\n",
      "            indices = tf.constant([[4], [3], [1], [7]])\n",
      "            updates = tf.constant([9, 10, 11, 12])\n",
      "            tensor = tf.ones([8], dtype=tf.int32)\n",
      "            updated = tf.tensor_scatter_sub(tensor, indices, updates)\n",
      "            with tf.Session() as sess:\n",
      "              print(sess.run(scatter))\n",
      "        ```\n",
      "        \n",
      "        The resulting tensor would look like this:\n",
      "        \n",
      "            [1, -10, 1, -9, -8, 1, 1, -11]\n",
      "        \n",
      "        We can also, insert entire slices of a higher rank tensor all at once. For\n",
      "        example, if we wanted to insert two slices in the first dimension of a\n",
      "        rank-3 tensor with two matrices of new values.\n",
      "        \n",
      "        In Python, this scatter add operation would look like this:\n",
      "        \n",
      "        ```python\n",
      "            indices = tf.constant([[0], [2]])\n",
      "            updates = tf.constant([[[5, 5, 5, 5], [6, 6, 6, 6],\n",
      "                                    [7, 7, 7, 7], [8, 8, 8, 8]],\n",
      "                                   [[5, 5, 5, 5], [6, 6, 6, 6],\n",
      "                                    [7, 7, 7, 7], [8, 8, 8, 8]]])\n",
      "            tensor = tf.ones([4, 4, 4])\n",
      "            updated = tf.tensor_scatter_sub(tensor, indices, updates)\n",
      "            with tf.Session() as sess:\n",
      "              print(sess.run(scatter))\n",
      "        ```\n",
      "        \n",
      "        The resulting tensor would look like this:\n",
      "        \n",
      "            [[[-4, -4, -4, -4], [-5, -5, -5, -5], [-6, -6, -6, -6], [-7, -7, -7, -7]],\n",
      "             [[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]],\n",
      "             [[-4, -4, -4, -4], [-5, -5, -5, -5], [-6, -6, -6, -6], [-7, -7, -7, -7]],\n",
      "             [[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]]]\n",
      "        \n",
      "        Note that on CPU, if an out of bound index is found, an error is returned.\n",
      "        On GPU, if an out of bound index is found, the index is ignored.\n",
      "        \n",
      "        Args:\n",
      "          tensor: A `Tensor`. Tensor to copy/update.\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            Index tensor.\n",
      "          updates: A `Tensor`. Must have the same type as `tensor`.\n",
      "            Updates to scatter into output.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `tensor`.\n",
      "    \n",
      "    tensor_scatter_update(tensor, indices, updates, name=None)\n",
      "        Scatter `updates` into an existing tensor according to `indices`.\n",
      "        \n",
      "        This operation creates a new tensor by applying sparse `updates` to the passed\n",
      "        in `tensor`.\n",
      "        This operation is very similar to `tf.scatter_nd`, except that the updates are\n",
      "        scattered onto an existing tensor (as opposed to a zero-tensor). If the memory\n",
      "        for the existing tensor cannot be re-used, a copy is made and updated.\n",
      "        \n",
      "        If `indices` contains duplicates, then their updates are accumulated (summed).\n",
      "        \n",
      "        **WARNING**: The order in which updates are applied is nondeterministic, so the\n",
      "        output will be nondeterministic if `indices` contains duplicates -- because\n",
      "        of some numerical approximation issues, numbers summed in different order\n",
      "        may yield different results.\n",
      "        \n",
      "        `indices` is an integer tensor containing indices into a new tensor of shape\n",
      "        `shape`.  The last dimension of `indices` can be at most the rank of `shape`:\n",
      "        \n",
      "            indices.shape[-1] <= shape.rank\n",
      "        \n",
      "        The last dimension of `indices` corresponds to indices into elements\n",
      "        (if `indices.shape[-1] = shape.rank`) or slices\n",
      "        (if `indices.shape[-1] < shape.rank`) along dimension `indices.shape[-1]` of\n",
      "        `shape`.  `updates` is a tensor with shape\n",
      "        \n",
      "            indices.shape[:-1] + shape[indices.shape[-1]:]\n",
      "        \n",
      "        The simplest form of scatter is to insert individual elements in a tensor by\n",
      "        index. For example, say we want to insert 4 scattered elements in a rank-1\n",
      "        tensor with 8 elements.\n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        <img style=\"width:100%\" src=\"https://www.tensorflow.org/images/ScatterNd1.png\" alt>\n",
      "        </div>\n",
      "        \n",
      "        In Python, this scatter operation would look like this:\n",
      "        \n",
      "        ```python\n",
      "            indices = tf.constant([[4], [3], [1], [7]])\n",
      "            updates = tf.constant([9, 10, 11, 12])\n",
      "            tensor = tf.ones([8], dtype=tf.int32)\n",
      "            updated = tf.tensor_scatter_update(tensor, indices, updates)\n",
      "            with tf.Session() as sess:\n",
      "              print(sess.run(scatter))\n",
      "        ```\n",
      "        \n",
      "        The resulting tensor would look like this:\n",
      "        \n",
      "            [1, 11, 1, 10, 9, 1, 1, 12]\n",
      "        \n",
      "        We can also, insert entire slices of a higher rank tensor all at once. For\n",
      "        example, if we wanted to insert two slices in the first dimension of a\n",
      "        rank-3 tensor with two matrices of new values.\n",
      "        \n",
      "        In Python, this scatter operation would look like this:\n",
      "        \n",
      "        ```python\n",
      "            indices = tf.constant([[0], [2]])\n",
      "            updates = tf.constant([[[5, 5, 5, 5], [6, 6, 6, 6],\n",
      "                                    [7, 7, 7, 7], [8, 8, 8, 8]],\n",
      "                                   [[5, 5, 5, 5], [6, 6, 6, 6],\n",
      "                                    [7, 7, 7, 7], [8, 8, 8, 8]]])\n",
      "            tensor = tf.ones([4, 4, 4])\n",
      "            updated = tf.tensor_scatter_update(tensor, indices, updates)\n",
      "            with tf.Session() as sess:\n",
      "              print(sess.run(scatter))\n",
      "        ```\n",
      "        \n",
      "        The resulting tensor would look like this:\n",
      "        \n",
      "            [[[5, 5, 5, 5], [6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8]],\n",
      "             [[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]],\n",
      "             [[5, 5, 5, 5], [6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8]],\n",
      "             [[1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1], [1, 1, 1, 1]]]\n",
      "        \n",
      "        Note that on CPU, if an out of bound index is found, an error is returned.\n",
      "        On GPU, if an out of bound index is found, the index is ignored.\n",
      "        \n",
      "        Args:\n",
      "          tensor: A `Tensor`. Tensor to copy/update.\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            Index tensor.\n",
      "          updates: A `Tensor`. Must have the same type as `tensor`.\n",
      "            Updates to scatter into output.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `tensor`.\n",
      "    \n",
      "    tensordot(a, b, axes, name=None)\n",
      "        Tensor contraction of a and b along specified axes and outer product.\n",
      "        \n",
      "        Tensordot (also known as tensor contraction) sums the product of elements\n",
      "        from `a` and `b` over the indices specified by `a_axes` and `b_axes`.\n",
      "        The lists `a_axes` and `b_axes` specify those pairs of axes along which to\n",
      "        contract the tensors. The axis `a_axes[i]` of `a` must have the same dimension\n",
      "        as axis `b_axes[i]` of `b` for all `i` in `range(0, len(a_axes))`. The lists\n",
      "        `a_axes` and `b_axes` must have identical length and consist of unique\n",
      "        integers that specify valid axes for each of the tensors. Additionally\n",
      "        outer product is supported by passing `axes=0`.\n",
      "        \n",
      "        This operation corresponds to `numpy.tensordot(a, b, axes)`.\n",
      "        \n",
      "        Example 1: When `a` and `b` are matrices (order 2), the case `axes = 1`\n",
      "        is equivalent to matrix multiplication.\n",
      "        \n",
      "        Example 2: When `a` and `b` are matrices (order 2), the case\n",
      "        `axes = [[1], [0]]` is equivalent to matrix multiplication.\n",
      "        \n",
      "        Example 3: When `a` and `b` are matrices (order 2), the case `axes=0` gives\n",
      "        the outer product, a tensor of order 4.\n",
      "        \n",
      "        Example 4: Suppose that \\\\(a_{ijk}\\\\) and \\\\(b_{lmn}\\\\) represent two\n",
      "        tensors of order 3. Then, `contract(a, b, [[0], [2]])` is the order 4 tensor\n",
      "        \\\\(c_{jklm}\\\\) whose entry\n",
      "        corresponding to the indices \\\\((j,k,l,m)\\\\) is given by:\n",
      "        \n",
      "        \\\\( c_{jklm} = \\sum_i a_{ijk} b_{lmi} \\\\).\n",
      "        \n",
      "        In general, `order(c) = order(a) + order(b) - 2*len(axes[0])`.\n",
      "        \n",
      "        Args:\n",
      "          a: `Tensor` of type `float32` or `float64`.\n",
      "          b: `Tensor` with the same type as `a`.\n",
      "          axes: Either a scalar `N`, or a list or an `int32` `Tensor` of shape [2, k].\n",
      "            If axes is a scalar, sum over the last N axes of a and the first N axes of\n",
      "            b in order. If axes is a list or `Tensor` the first and second row contain\n",
      "            the set of unique integers specifying axes along which the contraction is\n",
      "            computed, for `a` and `b`, respectively. The number of axes for `a` and\n",
      "            `b` must be equal. If `axes=0`, computes the outer product between `a` and\n",
      "            `b`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` with the same type as `a`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If the shapes of `a`, `b`, and `axes` are incompatible.\n",
      "          IndexError: If the values in axes exceed the rank of the corresponding\n",
      "            tensor.\n",
      "    \n",
      "    tile(input, multiples, name=None)\n",
      "        Constructs a tensor by tiling a given tensor.\n",
      "        \n",
      "        This operation creates a new tensor by replicating `input` `multiples` times.\n",
      "        The output tensor's i'th dimension has `input.dims(i) * multiples[i]` elements,\n",
      "        and the values of `input` are replicated `multiples[i]` times along the 'i'th\n",
      "        dimension. For example, tiling `[a b c d]` by `[2]` produces\n",
      "        `[a b c d a b c d]`.\n",
      "        \n",
      "        Args:\n",
      "          input: A `Tensor`. 1-D or higher.\n",
      "          multiples: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            1-D. Length must be the same as the number of dimensions in `input`\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `input`.\n",
      "    \n",
      "    timestamp(name=None)\n",
      "        Provides the time since epoch in seconds.\n",
      "        \n",
      "        Returns the timestamp as a `float64` for seconds since the Unix epoch.\n",
      "        \n",
      "        Note: the timestamp is computed when the op is executed, not when it is added\n",
      "        to the graph.\n",
      "        \n",
      "        Args:\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` of type `float64`.\n",
      "    \n",
      "    to_bfloat16(x, name='ToBFloat16')\n",
      "        Casts a tensor to type `bfloat16`. (deprecated)\n",
      "        \n",
      "        Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Use `tf.cast` instead.\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor` or `SparseTensor` or `IndexedSlices`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` or `SparseTensor` or `IndexedSlices` with same shape as `x` with\n",
      "          type `bfloat16`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `x` cannot be cast to the `bfloat16`.\n",
      "    \n",
      "    to_complex128(x, name='ToComplex128')\n",
      "        Casts a tensor to type `complex128`. (deprecated)\n",
      "        \n",
      "        Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Use `tf.cast` instead.\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor` or `SparseTensor` or `IndexedSlices`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` or `SparseTensor` or `IndexedSlices` with same shape as `x` with\n",
      "          type `complex128`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `x` cannot be cast to the `complex128`.\n",
      "    \n",
      "    to_complex64(x, name='ToComplex64')\n",
      "        Casts a tensor to type `complex64`. (deprecated)\n",
      "        \n",
      "        Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Use `tf.cast` instead.\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor` or `SparseTensor` or `IndexedSlices`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` or `SparseTensor` or `IndexedSlices` with same shape as `x` with\n",
      "          type `complex64`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `x` cannot be cast to the `complex64`.\n",
      "    \n",
      "    to_double(x, name='ToDouble')\n",
      "        Casts a tensor to type `float64`. (deprecated)\n",
      "        \n",
      "        Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Use `tf.cast` instead.\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor` or `SparseTensor` or `IndexedSlices`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` or `SparseTensor` or `IndexedSlices` with same shape as `x` with\n",
      "          type `float64`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `x` cannot be cast to the `float64`.\n",
      "    \n",
      "    to_float(x, name='ToFloat')\n",
      "        Casts a tensor to type `float32`. (deprecated)\n",
      "        \n",
      "        Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Use `tf.cast` instead.\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor` or `SparseTensor` or `IndexedSlices`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` or `SparseTensor` or `IndexedSlices` with same shape as `x` with\n",
      "          type `float32`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `x` cannot be cast to the `float32`.\n",
      "    \n",
      "    to_int32(x, name='ToInt32')\n",
      "        Casts a tensor to type `int32`. (deprecated)\n",
      "        \n",
      "        Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Use `tf.cast` instead.\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor` or `SparseTensor` or `IndexedSlices`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` or `SparseTensor` or `IndexedSlices` with same shape as `x` with\n",
      "          type `int32`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `x` cannot be cast to the `int32`.\n",
      "    \n",
      "    to_int64(x, name='ToInt64')\n",
      "        Casts a tensor to type `int64`. (deprecated)\n",
      "        \n",
      "        Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Use `tf.cast` instead.\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor` or `SparseTensor` or `IndexedSlices`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` or `SparseTensor` or `IndexedSlices` with same shape as `x` with\n",
      "          type `int64`.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `x` cannot be cast to the `int64`.\n",
      "    \n",
      "    trace(x, name=None)\n",
      "        Compute the trace of a tensor `x`.\n",
      "        \n",
      "        `trace(x)` returns the sum along the main diagonal of each inner-most matrix\n",
      "        in x. If x is of rank `k` with shape `[I, J, K, ..., L, M, N]`, then output\n",
      "        is a tensor of rank `k-2` with dimensions `[I, J, K, ..., L]` where\n",
      "        \n",
      "        `output[i, j, k, ..., l] = trace(x[i, j, i, ..., l, :, :])`\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([[1, 2], [3, 4]])\n",
      "        tf.linalg.trace(x)  # 5\n",
      "        \n",
      "        x = tf.constant([[1, 2, 3],\n",
      "                         [4, 5, 6],\n",
      "                         [7, 8, 9]])\n",
      "        tf.linalg.trace(x)  # 15\n",
      "        \n",
      "        x = tf.constant([[[1, 2, 3],\n",
      "                          [4, 5, 6],\n",
      "                          [7, 8, 9]],\n",
      "                         [[-1, -2, -3],\n",
      "                          [-4, -5, -6],\n",
      "                          [-7, -8, -9]]])\n",
      "        tf.linalg.trace(x)  # [15, -15]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: tensor.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          The trace of input tensor.\n",
      "    \n",
      "    trainable_variables(scope=None)\n",
      "        Returns all variables created with `trainable=True`.\n",
      "        \n",
      "        When passed `trainable=True`, the `Variable()` constructor automatically\n",
      "        adds new variables to the graph collection\n",
      "        `GraphKeys.TRAINABLE_VARIABLES`. This convenience function returns the\n",
      "        contents of that collection.\n",
      "        \n",
      "        Args:\n",
      "          scope: (Optional.) A string. If supplied, the resulting list is filtered to\n",
      "            include only items whose `name` attribute matches `scope` using\n",
      "            `re.match`. Items without a `name` attribute are never returned if a scope\n",
      "            is supplied. The choice of `re.match` means that a `scope` without special\n",
      "            tokens filters by prefix.\n",
      "        \n",
      "        Returns:\n",
      "          A list of Variable objects.\n",
      "    \n",
      "    transpose(a, perm=None, name='transpose', conjugate=False)\n",
      "        Transposes `a`.\n",
      "        \n",
      "        Permutes the dimensions according to `perm`.\n",
      "        \n",
      "        The returned tensor's dimension i will correspond to the input dimension\n",
      "        `perm[i]`. If `perm` is not given, it is set to (n-1...0), where n is\n",
      "        the rank of the input tensor. Hence by default, this operation performs a\n",
      "        regular matrix transpose on 2-D input Tensors. If conjugate is True and\n",
      "        `a.dtype` is either `complex64` or `complex128` then the values of `a`\n",
      "        are conjugated and transposed.\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        In `numpy` transposes are memory-efficient constant time operations as they\n",
      "        simply return a new view of the same data with adjusted `strides`.\n",
      "        \n",
      "        TensorFlow does not support strides, so `transpose` returns a new tensor with\n",
      "        the items permuted.\n",
      "        @end_compatibility\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        x = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
      "        tf.transpose(x)  # [[1, 4]\n",
      "                         #  [2, 5]\n",
      "                         #  [3, 6]]\n",
      "        \n",
      "        # Equivalently\n",
      "        tf.transpose(x, perm=[1, 0])  # [[1, 4]\n",
      "                                      #  [2, 5]\n",
      "                                      #  [3, 6]]\n",
      "        \n",
      "        # If x is complex, setting conjugate=True gives the conjugate transpose\n",
      "        x = tf.constant([[1 + 1j, 2 + 2j, 3 + 3j],\n",
      "                         [4 + 4j, 5 + 5j, 6 + 6j]])\n",
      "        tf.transpose(x, conjugate=True)  # [[1 - 1j, 4 - 4j],\n",
      "                                         #  [2 - 2j, 5 - 5j],\n",
      "                                         #  [3 - 3j, 6 - 6j]]\n",
      "        \n",
      "        # 'perm' is more useful for n-dimensional tensors, for n > 2\n",
      "        x = tf.constant([[[ 1,  2,  3],\n",
      "                          [ 4,  5,  6]],\n",
      "                         [[ 7,  8,  9],\n",
      "                          [10, 11, 12]]])\n",
      "        \n",
      "        # Take the transpose of the matrices in dimension-0\n",
      "        # (this common operation has a shorthand `linalg.matrix_transpose`)\n",
      "        tf.transpose(x, perm=[0, 2, 1])  # [[[1,  4],\n",
      "                                         #   [2,  5],\n",
      "                                         #   [3,  6]],\n",
      "                                         #  [[7, 10],\n",
      "                                         #   [8, 11],\n",
      "                                         #   [9, 12]]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          a: A `Tensor`.\n",
      "          perm: A permutation of the dimensions of `a`.\n",
      "          name: A name for the operation (optional).\n",
      "          conjugate: Optional bool. Setting it to `True` is mathematically equivalent\n",
      "            to tf.math.conj(tf.transpose(input)).\n",
      "        \n",
      "        Returns:\n",
      "          A transposed `Tensor`.\n",
      "    \n",
      "    truediv(x, y, name=None)\n",
      "        Divides x / y elementwise (using Python 3 division operator semantics).\n",
      "        \n",
      "        NOTE: Prefer using the Tensor operator or tf.divide which obey Python\n",
      "        division operator semantics.\n",
      "        \n",
      "        This function forces Python 3 division operator semantics where all integer\n",
      "        arguments are cast to floating types first.   This op is generated by normal\n",
      "        `x / y` division in Python 3 and in Python 2.7 with\n",
      "        `from __future__ import division`.  If you want integer division that rounds\n",
      "        down, use `x // y` or `tf.math.floordiv`.\n",
      "        \n",
      "        `x` and `y` must have the same numeric type.  If the inputs are floating\n",
      "        point, the output will have the same type.  If the inputs are integral, the\n",
      "        inputs are cast to `float32` for `int8` and `int16` and `float64` for `int32`\n",
      "        and `int64` (matching the behavior of Numpy).\n",
      "        \n",
      "        Args:\n",
      "          x: `Tensor` numerator of numeric type.\n",
      "          y: `Tensor` denominator of numeric type.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          `x / y` evaluated in floating point.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: If `x` and `y` have different dtypes.\n",
      "    \n",
      "    truncated_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)\n",
      "        Outputs random values from a truncated normal distribution.\n",
      "        \n",
      "        The generated values follow a normal distribution with specified mean and\n",
      "        standard deviation, except that values whose magnitude is more than 2 standard\n",
      "        deviations from the mean are dropped and re-picked.\n",
      "        \n",
      "        Args:\n",
      "          shape: A 1-D integer Tensor or Python array. The shape of the output tensor.\n",
      "          mean: A 0-D Tensor or Python value of type `dtype`. The mean of the\n",
      "            truncated normal distribution.\n",
      "          stddev: A 0-D Tensor or Python value of type `dtype`. The standard deviation\n",
      "            of the normal distribution, before truncation.\n",
      "          dtype: The type of the output.\n",
      "          seed: A Python integer. Used to create a random seed for the distribution.\n",
      "            See\n",
      "            `tf.compat.v1.set_random_seed`\n",
      "            for behavior.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A tensor of the specified shape filled with random truncated normal values.\n",
      "    \n",
      "    truncatediv = truncate_div(x, y, name=None)\n",
      "        Returns x / y element-wise for integer types.\n",
      "        \n",
      "        Truncation designates that negative numbers will round fractional quantities\n",
      "        toward zero. I.e. -7 / 5 = -1. This matches C semantics but it is different\n",
      "        than Python semantics. See `FloorDiv` for a division function that matches\n",
      "        Python Semantics.\n",
      "        \n",
      "        *NOTE*: `truncatediv` supports broadcasting. More about broadcasting\n",
      "        [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`, `int16`, `int32`, `int64`, `complex64`, `complex128`.\n",
      "          y: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    truncatemod = truncate_mod(x, y, name=None)\n",
      "        Returns element-wise remainder of division. This emulates C semantics in that\n",
      "        \n",
      "        the result here is consistent with a truncating divide. E.g. `truncate(x / y) *\n",
      "        y + truncate_mod(x, y) = x`.\n",
      "        \n",
      "        *NOTE*: `truncatemod` supports broadcasting. More about broadcasting\n",
      "        [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `int32`, `int64`, `bfloat16`, `half`, `float32`, `float64`.\n",
      "          y: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "    tuple(tensors, name=None, control_inputs=None)\n",
      "        Group tensors together.\n",
      "        \n",
      "        This creates a tuple of tensors with the same values as the `tensors`\n",
      "        argument, except that the value of each tensor is only returned after the\n",
      "        values of all tensors have been computed.\n",
      "        \n",
      "        `control_inputs` contains additional ops that have to finish before this op\n",
      "        finishes, but whose outputs are not returned.\n",
      "        \n",
      "        This can be used as a \"join\" mechanism for parallel computations: all the\n",
      "        argument tensors can be computed in parallel, but the values of any tensor\n",
      "        returned by `tuple` are only available after all the parallel computations\n",
      "        are done.\n",
      "        \n",
      "        See also `tf.group` and\n",
      "        `tf.control_dependencies`.\n",
      "        \n",
      "        Args:\n",
      "          tensors: A list of `Tensor`s or `IndexedSlices`, some entries can be `None`.\n",
      "          name: (optional) A name to use as a `name_scope` for the operation.\n",
      "          control_inputs: List of additional ops to finish before returning.\n",
      "        \n",
      "        Returns:\n",
      "          Same as `tensors`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If `tensors` does not contain any `Tensor` or `IndexedSlices`.\n",
      "          TypeError: If `control_inputs` is not a list of `Operation` or `Tensor`\n",
      "            objects.\n",
      "    \n",
      "    unique(x, out_idx=tf.int32, name=None)\n",
      "        Finds unique elements in a 1-D tensor.\n",
      "        \n",
      "        This operation returns a tensor `y` containing all of the unique elements of `x`\n",
      "        sorted in the same order that they occur in `x`. This operation also returns a\n",
      "        tensor `idx` the same size as `x` that contains the index of each value of `x`\n",
      "        in the unique output `y`. In other words:\n",
      "        \n",
      "        `y[idx[i]] = x[i] for i in [0, 1,...,rank(x) - 1]`\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```\n",
      "        # tensor 'x' is [1, 1, 2, 4, 4, 4, 7, 8, 8]\n",
      "        y, idx = unique(x)\n",
      "        y ==> [1, 2, 4, 7, 8]\n",
      "        idx ==> [0, 0, 1, 2, 2, 2, 3, 4, 4]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. 1-D.\n",
      "          out_idx: An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int32`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A tuple of `Tensor` objects (y, idx).\n",
      "        \n",
      "          y: A `Tensor`. Has the same type as `x`.\n",
      "          idx: A `Tensor` of type `out_idx`.\n",
      "    \n",
      "    unique_with_counts(x, out_idx=tf.int32, name=None)\n",
      "        Finds unique elements in a 1-D tensor.\n",
      "        \n",
      "        This operation returns a tensor `y` containing all of the unique elements of `x`\n",
      "        sorted in the same order that they occur in `x`. This operation also returns a\n",
      "        tensor `idx` the same size as `x` that contains the index of each value of `x`\n",
      "        in the unique output `y`. Finally, it returns a third tensor `count` that\n",
      "        contains the count of each element of `y` in `x`. In other words:\n",
      "        \n",
      "        `y[idx[i]] = x[i] for i in [0, 1,...,rank(x) - 1]`\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```\n",
      "        # tensor 'x' is [1, 1, 2, 4, 4, 4, 7, 8, 8]\n",
      "        y, idx, count = unique_with_counts(x)\n",
      "        y ==> [1, 2, 4, 7, 8]\n",
      "        idx ==> [0, 0, 1, 2, 2, 2, 3, 4, 4]\n",
      "        count ==> [2, 1, 3, 1, 2]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. 1-D.\n",
      "          out_idx: An optional `tf.DType` from: `tf.int32, tf.int64`. Defaults to `tf.int32`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A tuple of `Tensor` objects (y, idx, count).\n",
      "        \n",
      "          y: A `Tensor`. Has the same type as `x`.\n",
      "          idx: A `Tensor` of type `out_idx`.\n",
      "          count: A `Tensor` of type `out_idx`.\n",
      "    \n",
      "    unravel_index(indices, dims, name=None)\n",
      "        Converts an array of flat indices into a tuple of coordinate arrays.\n",
      "        \n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        ```\n",
      "        y = tf.unravel_index(indices=[2, 5, 7], dims=[3, 3])\n",
      "        # 'dims' represent a hypothetical (3, 3) tensor of indices:\n",
      "        # [[0, 1, *2*],\n",
      "        #  [3, 4, *5*],\n",
      "        #  [6, *7*, 8]]\n",
      "        # For each entry from 'indices', this operation returns\n",
      "        # its coordinates (marked with '*'), such as\n",
      "        # 2 ==> (0, 2)\n",
      "        # 5 ==> (1, 2)\n",
      "        # 7 ==> (2, 1)\n",
      "        y ==> [[0, 1, 2], [2, 2, 1]]\n",
      "        ```\n",
      "        \n",
      "        @compatibility(numpy)\n",
      "        Equivalent to np.unravel_index\n",
      "        @end_compatibility\n",
      "        \n",
      "        Args:\n",
      "          indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            An 0-D or 1-D `int` Tensor whose elements are indices into the\n",
      "            flattened version of an array of dimensions dims.\n",
      "          dims: A `Tensor`. Must have the same type as `indices`.\n",
      "            An 1-D `int` Tensor. The shape of the array to use for unraveling\n",
      "            indices.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `indices`.\n",
      "    \n",
      "    unsorted_segment_max(data, segment_ids, num_segments, name=None)\n",
      "        Computes the maximum along segments of a tensor.\n",
      "        \n",
      "        Read\n",
      "        [the section on segmentation](https://tensorflow.org/api_docs/python/tf/math#Segmentation)\n",
      "        for an explanation of segments.\n",
      "        \n",
      "        This operator is similar to the unsorted segment sum operator found\n",
      "        [(here)](../../../api_docs/python/math_ops.md#UnsortedSegmentSum).\n",
      "        Instead of computing the sum over segments, it computes the maximum such that:\n",
      "        \n",
      "        \\\\(output_i = \\max_{j...} data[j...]\\\\) where max is over tuples `j...` such\n",
      "        that `segment_ids[j...] == i`.\n",
      "        \n",
      "        If the maximum is empty for a given segment ID `i`, it outputs the smallest\n",
      "        possible value for the specific numeric type,\n",
      "        `output[i] = numeric_limits<T>::lowest()`.\n",
      "        \n",
      "        If the given segment ID `i` is negative, then the corresponding value is\n",
      "        dropped, and will not be included in the result.\n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        <img style=\"width:100%\" src=\"https://www.tensorflow.org/images/UnsortedSegmentMax.png\" alt>\n",
      "        </div>\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ``` python\n",
      "        c = tf.constant([[1,2,3,4], [5,6,7,8], [4,3,2,1]])\n",
      "        tf.unsorted_segment_max(c, tf.constant([0, 1, 0]), num_segments=2)\n",
      "        # ==> [[ 4,  3, 3, 4],\n",
      "        #       [5,  6, 7, 8]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          data: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "          segment_ids: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            A tensor whose shape is a prefix of `data.shape`.\n",
      "          num_segments: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `data`.\n",
      "    \n",
      "    unsorted_segment_mean(data, segment_ids, num_segments, name=None)\n",
      "        Computes the mean along segments of a tensor.\n",
      "        \n",
      "        Read [the section on\n",
      "        segmentation](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/math#about_segmentation)\n",
      "        for an explanation of segments.\n",
      "        \n",
      "        This operator is similar to the unsorted segment sum operator found\n",
      "        [here](../../../api_docs/python/math_ops.md#UnsortedSegmentSum).\n",
      "        Instead of computing the sum over segments, it computes the mean of all\n",
      "        entries belonging to a segment such that:\n",
      "        \n",
      "        \\\\(output_i = 1/N_i \\sum_{j...} data[j...]\\\\) where the sum is over tuples\n",
      "        `j...` such that `segment_ids[j...] == i` with \\\\N_i\\\\ being the number of\n",
      "        occurrences of id \\\\i\\\\.\n",
      "        \n",
      "        If there is no entry for a given segment ID `i`, it outputs 0.\n",
      "        \n",
      "        If the given segment ID `i` is negative, the value is dropped and will not\n",
      "        be added to the sum of the segment.\n",
      "        \n",
      "        Args:\n",
      "          data: A `Tensor` with floating point or complex dtype.\n",
      "          segment_ids: An integer tensor whose shape is a prefix of `data.shape`.\n",
      "          num_segments: An integer scalar `Tensor`.  The number of distinct segment\n",
      "            IDs.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`.  Has same shape as data, except for the first `segment_ids.rank`\n",
      "          dimensions, which are replaced with a single dimension which has size\n",
      "         `num_segments`.\n",
      "    \n",
      "    unsorted_segment_min(data, segment_ids, num_segments, name=None)\n",
      "        Computes the minimum along segments of a tensor.\n",
      "        \n",
      "        Read\n",
      "        [the section on segmentation](https://tensorflow.org/api_docs/python/tf/math#Segmentation)\n",
      "        for an explanation of segments.\n",
      "        \n",
      "        This operator is similar to the unsorted segment sum operator found\n",
      "        [(here)](../../../api_docs/python/math_ops.md#UnsortedSegmentSum).\n",
      "        Instead of computing the sum over segments, it computes the minimum such that:\n",
      "        \n",
      "        \\\\(output_i = \\min_{j...} data_[j...]\\\\) where min is over tuples `j...` such\n",
      "        that `segment_ids[j...] == i`.\n",
      "        \n",
      "        If the minimum is empty for a given segment ID `i`, it outputs the largest\n",
      "        possible value for the specific numeric type,\n",
      "        `output[i] = numeric_limits<T>::max()`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ``` python\n",
      "        c = tf.constant([[1,2,3,4], [5,6,7,8], [4,3,2,1]])\n",
      "        tf.unsorted_segment_min(c, tf.constant([0, 1, 0]), num_segments=2)\n",
      "        # ==> [[ 1,  2, 2, 1],\n",
      "        #       [5,  6, 7, 8]]\n",
      "        ```\n",
      "        \n",
      "        If the given segment ID `i` is negative, then the corresponding value is\n",
      "        dropped, and will not be included in the result.\n",
      "        \n",
      "        Args:\n",
      "          data: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
      "          segment_ids: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            A tensor whose shape is a prefix of `data.shape`.\n",
      "          num_segments: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `data`.\n",
      "    \n",
      "    unsorted_segment_prod(data, segment_ids, num_segments, name=None)\n",
      "        Computes the product along segments of a tensor.\n",
      "        \n",
      "        Read\n",
      "        [the section on segmentation](https://tensorflow.org/api_docs/python/tf/math#Segmentation)\n",
      "        for an explanation of segments.\n",
      "        \n",
      "        This operator is similar to the unsorted segment sum operator found\n",
      "        [(here)](../../../api_docs/python/math_ops.md#UnsortedSegmentSum).\n",
      "        Instead of computing the sum over segments, it computes the product of all\n",
      "        entries belonging to a segment such that:\n",
      "        \n",
      "        \\\\(output_i = \\prod_{j...} data[j...]\\\\) where the product is over tuples\n",
      "        `j...` such that `segment_ids[j...] == i`.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ``` python\n",
      "        c = tf.constant([[1,2,3,4], [5,6,7,8], [4,3,2,1]])\n",
      "        tf.unsorted_segment_prod(c, tf.constant([0, 1, 0]), num_segments=2)\n",
      "        # ==> [[ 4,  6, 6, 4],\n",
      "        #       [5,  6, 7, 8]]\n",
      "        ```\n",
      "        \n",
      "        If there is no entry for a given segment ID `i`, it outputs 1.\n",
      "        \n",
      "        If the given segment ID `i` is negative, then the corresponding value is\n",
      "        dropped, and will not be included in the result.\n",
      "        \n",
      "        Args:\n",
      "          data: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.\n",
      "          segment_ids: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            A tensor whose shape is a prefix of `data.shape`.\n",
      "          num_segments: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `data`.\n",
      "    \n",
      "    unsorted_segment_sqrt_n(data, segment_ids, num_segments, name=None)\n",
      "        Computes the sum along segments of a tensor divided by the sqrt(N).\n",
      "        \n",
      "        Read [the section on\n",
      "        segmentation](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/math#about_segmentation)\n",
      "        for an explanation of segments.\n",
      "        \n",
      "        This operator is similar to the unsorted segment sum operator found\n",
      "        [here](../../../api_docs/python/math_ops.md#UnsortedSegmentSum).\n",
      "        Additionally to computing the sum over segments, it divides the results by\n",
      "        sqrt(N).\n",
      "        \n",
      "        \\\\(output_i = 1/sqrt(N_i) \\sum_{j...} data[j...]\\\\) where the sum is over\n",
      "        tuples `j...` such that `segment_ids[j...] == i` with \\\\N_i\\\\ being the\n",
      "        number of occurrences of id \\\\i\\\\.\n",
      "        \n",
      "        If there is no entry for a given segment ID `i`, it outputs 0.\n",
      "        \n",
      "        Note that this op only supports floating point and complex dtypes,\n",
      "        due to tf.sqrt only supporting these types.\n",
      "        \n",
      "        If the given segment ID `i` is negative, the value is dropped and will not\n",
      "        be added to the sum of the segment.\n",
      "        \n",
      "        Args:\n",
      "          data: A `Tensor` with floating point or complex dtype.\n",
      "          segment_ids: An integer tensor whose shape is a prefix of `data.shape`.\n",
      "          num_segments: An integer scalar `Tensor`.  The number of distinct segment\n",
      "            IDs.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`.  Has same shape as data, except for the first `segment_ids.rank`\n",
      "          dimensions, which are replaced with a single dimension which has size\n",
      "         `num_segments`.\n",
      "    \n",
      "    unsorted_segment_sum(data, segment_ids, num_segments, name=None)\n",
      "        Computes the sum along segments of a tensor.\n",
      "        \n",
      "        Read\n",
      "        [the section on segmentation](https://tensorflow.org/api_docs/python/tf/math#Segmentation)\n",
      "        for an explanation of segments.\n",
      "        \n",
      "        Computes a tensor such that\n",
      "        \\\\(output[i] = \\sum_{j...} data[j...]\\\\) where the sum is over tuples `j...` such\n",
      "        that `segment_ids[j...] == i`.  Unlike `SegmentSum`, `segment_ids`\n",
      "        need not be sorted and need not cover all values in the full\n",
      "        range of valid values.\n",
      "        \n",
      "        If the sum is empty for a given segment ID `i`, `output[i] = 0`.\n",
      "        If the given segment ID `i` is negative, the value is dropped and will not be\n",
      "        added to the sum of the segment.\n",
      "        \n",
      "        `num_segments` should equal the number of distinct segment IDs.\n",
      "        \n",
      "        <div style=\"width:70%; margin:auto; margin-bottom:10px; margin-top:20px;\">\n",
      "        <img style=\"width:100%\" src=\"https://www.tensorflow.org/images/UnsortedSegmentSum.png\" alt>\n",
      "        </div>\n",
      "        \n",
      "        ``` python\n",
      "        c = tf.constant([[1,2,3,4], [5,6,7,8], [4,3,2,1]])\n",
      "        tf.unsorted_segment_sum(c, tf.constant([0, 1, 0]), num_segments=2)\n",
      "        # ==> [[ 5,  5, 5, 5],\n",
      "        #       [5,  6, 7, 8]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          data: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `complex64`, `int64`, `qint8`, `quint8`, `qint32`, `bfloat16`, `uint16`, `complex128`, `half`, `uint32`, `uint64`.\n",
      "          segment_ids: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "            A tensor whose shape is a prefix of `data.shape`.\n",
      "          num_segments: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `data`.\n",
      "    \n",
      "    unstack(value, num=None, axis=0, name='unstack')\n",
      "        Unpacks the given dimension of a rank-`R` tensor into rank-`(R-1)` tensors.\n",
      "        \n",
      "        Unpacks `num` tensors from `value` by chipping it along the `axis` dimension.\n",
      "        If `num` is not specified (the default), it is inferred from `value`'s shape.\n",
      "        If `value.shape[axis]` is not known, `ValueError` is raised.\n",
      "        \n",
      "        For example, given a tensor of shape `(A, B, C, D)`;\n",
      "        \n",
      "        If `axis == 0` then the i'th tensor in `output` is the slice\n",
      "          `value[i, :, :, :]` and each tensor in `output` will have shape `(B, C, D)`.\n",
      "          (Note that the dimension unpacked along is gone, unlike `split`).\n",
      "        \n",
      "        If `axis == 1` then the i'th tensor in `output` is the slice\n",
      "          `value[:, i, :, :]` and each tensor in `output` will have shape `(A, C, D)`.\n",
      "        Etc.\n",
      "        \n",
      "        This is the opposite of stack.\n",
      "        \n",
      "        Args:\n",
      "          value: A rank `R > 0` `Tensor` to be unstacked.\n",
      "          num: An `int`. The length of the dimension `axis`. Automatically inferred if\n",
      "            `None` (the default).\n",
      "          axis: An `int`. The axis to unstack along. Defaults to the first dimension.\n",
      "            Negative values wrap around, so the valid range is `[-R, R)`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          The list of `Tensor` objects unstacked from `value`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If `num` is unspecified and cannot be inferred.\n",
      "          ValueError: If `axis` is out of the range [-R, R).\n",
      "    \n",
      "    variable_axis_size_partitioner(max_shard_bytes, axis=0, bytes_per_string_element=16, max_shards=None)\n",
      "        Get a partitioner for VariableScope to keep shards below `max_shard_bytes`.\n",
      "        \n",
      "        This partitioner will shard a Variable along one axis, attempting to keep\n",
      "        the maximum shard size below `max_shard_bytes`.  In practice, this is not\n",
      "        always possible when sharding along only one axis.  When this happens,\n",
      "        this axis is sharded as much as possible (i.e., every dimension becomes\n",
      "        a separate shard).\n",
      "        \n",
      "        If the partitioner hits the `max_shards` limit, then each shard may end up\n",
      "        larger than `max_shard_bytes`. By default `max_shards` equals `None` and no\n",
      "        limit on the number of shards is enforced.\n",
      "        \n",
      "        One reasonable value for `max_shard_bytes` is `(64 << 20) - 1`, or almost\n",
      "        `64MB`, to keep below the protobuf byte limit.\n",
      "        \n",
      "        Args:\n",
      "          max_shard_bytes: The maximum size any given shard is allowed to be.\n",
      "          axis: The axis to partition along.  Default: outermost axis.\n",
      "          bytes_per_string_element: If the `Variable` is of type string, this provides\n",
      "            an estimate of how large each scalar in the `Variable` is.\n",
      "          max_shards: The maximum number of shards in int created taking precedence\n",
      "            over `max_shard_bytes`.\n",
      "        \n",
      "        Returns:\n",
      "          A partition function usable as the `partitioner` argument to\n",
      "          `variable_scope` and `get_variable`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: If any of the byte counts are non-positive.\n",
      "    \n",
      "    variable_creator_scope = variable_creator_scope_v1(variable_creator)\n",
      "        Scope which defines a variable creation function to be used by variable().\n",
      "        \n",
      "        variable_creator is expected to be a function with the following signature:\n",
      "        \n",
      "        ```\n",
      "          def variable_creator(next_creator, **kwargs)\n",
      "        ```\n",
      "        \n",
      "        The creator is supposed to eventually call the next_creator to create a\n",
      "        variable if it does want to create a variable and not call Variable or\n",
      "        ResourceVariable directly. This helps make creators composable. A creator may\n",
      "        choose to create multiple variables, return already existing variables, or\n",
      "        simply register that a variable was created and defer to the next creators in\n",
      "        line. Creators can also modify the keyword arguments seen by the next\n",
      "        creators.\n",
      "        \n",
      "        Custom getters in the variable scope will eventually resolve down to these\n",
      "        custom creators when they do create variables.\n",
      "        \n",
      "        The valid keyword arguments in kwds are:\n",
      "            initial_value: A `Tensor`, or Python object convertible to a `Tensor`,\n",
      "              which is the initial value for the Variable. The initial value must have\n",
      "              a shape specified unless `validate_shape` is set to False. Can also be a\n",
      "              callable with no argument that returns the initial value when called. In\n",
      "              that case, `dtype` must be specified. (Note that initializer functions\n",
      "              from init_ops.py must first be bound to a shape before being used here.)\n",
      "            trainable: If `True`, the default, also adds the variable to the graph\n",
      "              collection `GraphKeys.TRAINABLE_VARIABLES`. This collection is used as\n",
      "              the default list of variables to use by the `Optimizer` classes.\n",
      "              `trainable` defaults to `True`, unless `synchronization` is\n",
      "              set to `ON_READ`, in which case it defaults to `False`.\n",
      "            collections: List of graph collections keys. The new variable is added to\n",
      "              these collections. Defaults to `[GraphKeys.GLOBAL_VARIABLES]`.\n",
      "            validate_shape: If `False`, allows the variable to be initialized with a\n",
      "              value of unknown shape. If `True`, the default, the shape of\n",
      "              `initial_value` must be known.\n",
      "            caching_device: Optional device string describing where the Variable\n",
      "              should be cached for reading.  Defaults to the Variable's device.\n",
      "              If not `None`, caches on another device.  Typical use is to cache\n",
      "              on the device where the Ops using the Variable reside, to deduplicate\n",
      "              copying through `Switch` and other conditional statements.\n",
      "            name: Optional name for the variable. Defaults to `'Variable'` and gets\n",
      "              uniquified automatically.\n",
      "            dtype: If set, initial_value will be converted to the given type.\n",
      "              If `None`, either the datatype will be kept (if `initial_value` is\n",
      "              a Tensor), or `convert_to_tensor` will decide.\n",
      "            constraint: A constraint function to be applied to the variable after\n",
      "              updates by some algorithms.\n",
      "            use_resource: if True, a ResourceVariable is always created.\n",
      "            synchronization: Indicates when a distributed a variable will be\n",
      "              aggregated. Accepted values are constants defined in the class\n",
      "              `tf.VariableSynchronization`. By default the synchronization is set to\n",
      "              `AUTO` and the current `DistributionStrategy` chooses\n",
      "              when to synchronize.\n",
      "            aggregation: Indicates how a distributed variable will be aggregated.\n",
      "              Accepted values are constants defined in the class\n",
      "              `tf.VariableAggregation`.\n",
      "        \n",
      "        This set may grow over time, so it's important the signature of creators is as\n",
      "        mentioned above.\n",
      "        \n",
      "        Args:\n",
      "          variable_creator: the passed creator\n",
      "        \n",
      "        Yields:\n",
      "          A scope in which the creator is active\n",
      "    \n",
      "    variable_op_scope(values, name_or_scope, default_name=None, initializer=None, regularizer=None, caching_device=None, partitioner=None, custom_getter=None, reuse=None, dtype=None, use_resource=None, constraint=None)\n",
      "        Deprecated: context manager for defining an op that creates variables.\n",
      "    \n",
      "    variables_initializer(var_list, name='init')\n",
      "        Returns an Op that initializes a list of variables.\n",
      "        \n",
      "        After you launch the graph in a session, you can run the returned Op to\n",
      "        initialize all the variables in `var_list`. This Op runs all the\n",
      "        initializers of the variables in `var_list` in parallel.\n",
      "        \n",
      "        Calling `initialize_variables()` is equivalent to passing the list of\n",
      "        initializers to `Group()`.\n",
      "        \n",
      "        If `var_list` is empty, however, the function still returns an Op that can\n",
      "        be run. That Op just has no effect.\n",
      "        \n",
      "        Args:\n",
      "          var_list: List of `Variable` objects to initialize.\n",
      "          name: Optional name for the returned operation.\n",
      "        \n",
      "        Returns:\n",
      "          An Op that run the initializers of all the specified variables.\n",
      "    \n",
      "    vectorized_map(fn, elems)\n",
      "        Parallel map on the list of tensors unpacked from `elems` on dimension 0.\n",
      "        \n",
      "        \n",
      "        This method works similar to tf.map_fn but is optimized to run much faster,\n",
      "        possibly with a much larger memory footprint. The speedups are obtained by\n",
      "        vectorization (see https://arxiv.org/pdf/1903.04243.pdf). The idea behind\n",
      "        vectorization is to semantically launch all the invocations of `fn` in\n",
      "        parallel and fuse corresponding operations across all these invocations. This\n",
      "        fusion is done statically at graph generation time and the generated code is\n",
      "        often similar in performance to a manually fused version.\n",
      "        \n",
      "        Because `tf.vectorized_map` fully parallelizes the batch, this method will\n",
      "        generally be significantly faster than using `tf.map_fn`, especially in eager\n",
      "        mode. However this is an experimental feature and currently has a lot of\n",
      "        limitations:\n",
      "          - There should be no data dependency between the different semantic\n",
      "            invocations of `fn`, i.e. it should be safe to map the elements of the\n",
      "            inputs in any order.\n",
      "          - Stateful kernels may mostly not be supported since these often imply a\n",
      "            data dependency. We do support a limited set of such stateful kernels\n",
      "            though (like RandomFoo, Variable operations like reads, etc).\n",
      "          - `fn` has limited support for control flow operations. `tf.cond` in\n",
      "            particular is not supported.\n",
      "          - `fn` should return nested structure of Tensors or Operations. However\n",
      "            if an Operation is returned, it should have zero outputs.\n",
      "          - The shape and dtype of any intermediate or output tensors in the\n",
      "            computation of `fn` should not depend on the input to `fn`.\n",
      "        \n",
      "        Args:\n",
      "          fn: The callable to be performed. It accepts one argument, which will have\n",
      "            the same (possibly nested) structure as `elems`, and returns a possibly\n",
      "            nested structure of Tensors and Operations, which may be different than\n",
      "            the structure of `elems`.\n",
      "          elems: A tensor or (possibly nested) sequence of tensors, each of which will\n",
      "            be unpacked along their first dimension. The nested sequence of the\n",
      "            resulting slices will be mapped over by `fn`.\n",
      "        \n",
      "        Returns:\n",
      "          A tensor or (possibly nested) sequence of tensors. Each tensor packs the\n",
      "          results of applying fn to tensors unpacked from elems along the first\n",
      "          dimension, from first to last.\n",
      "        \n",
      "        Examples:\n",
      "        ```python\n",
      "        def outer_product(a):\n",
      "          return tf.tensordot(a, a, 0)\n",
      "        \n",
      "        batch_size = 100\n",
      "        a = tf.ones((batch_size, 32, 32))\n",
      "        c = tf.vectorized_map(outer_product, a)\n",
      "        assert c.shape == (batch_size, 32, 32, 32, 32)\n",
      "        ```\n",
      "        \n",
      "        ```python\n",
      "        # Computing per-example gradients\n",
      "        \n",
      "        batch_size = 10\n",
      "        num_features = 32\n",
      "        layer = tf.keras.layers.Dense(1)\n",
      "        \n",
      "        def model_fn(arg):\n",
      "          with tf.GradientTape() as g:\n",
      "            inp, label = arg\n",
      "            inp = tf.expand_dims(inp, 0)\n",
      "            label = tf.expand_dims(label, 0)\n",
      "            prediction = layer(inp)\n",
      "            loss = tf.nn.l2_loss(label - prediction)\n",
      "          return g.gradient(loss, (layer.kernel, layer.bias))\n",
      "        \n",
      "        inputs = tf.random_uniform([batch_size, num_features])\n",
      "        labels = tf.random_uniform([batch_size, 1])\n",
      "        per_example_gradients = tf.vectorized_map(model_fn, (inputs, labels))\n",
      "        assert per_example_gradients[0].shape == (batch_size, num_features, 1)\n",
      "        assert per_example_gradients[1].shape == (batch_size, 1)\n",
      "        ```\n",
      "    \n",
      "    verify_tensor_all_finite(t=None, msg=None, name=None, x=None, message=None)\n",
      "        Assert that the tensor does not contain any NaN's or Inf's.\n",
      "        \n",
      "        Args:\n",
      "          t: Tensor to check.\n",
      "          msg: Message to log on failure.\n",
      "          name: A name for this operation (optional).\n",
      "          x: Alias for t.\n",
      "          message: Alias for msg.\n",
      "        \n",
      "        Returns:\n",
      "          Same tensor as `t`.\n",
      "    \n",
      "    where(condition, x=None, y=None, name=None)\n",
      "        Return the elements, either from `x` or `y`, depending on the `condition`. (deprecated)\n",
      "        \n",
      "        Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      "        Instructions for updating:\n",
      "        Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "        \n",
      "        If both `x` and `y` are None, then this operation returns the coordinates of\n",
      "        true elements of `condition`.  The coordinates are returned in a 2-D tensor\n",
      "        where the first dimension (rows) represents the number of true elements, and\n",
      "        the second dimension (columns) represents the coordinates of the true\n",
      "        elements. Keep in mind, the shape of the output tensor can vary depending on\n",
      "        how many true values there are in input. Indices are output in row-major\n",
      "        order.\n",
      "        \n",
      "        If both non-None, `x` and `y` must have the same shape.\n",
      "        The `condition` tensor must be a scalar if `x` and `y` are scalar.\n",
      "        If `x` and `y` are tensors of higher rank, then `condition` must be either a\n",
      "        vector with size matching the first dimension of `x`, or must have the same\n",
      "        shape as `x`.\n",
      "        \n",
      "        The `condition` tensor acts as a mask that chooses, based on the value at each\n",
      "        element, whether the corresponding element / row in the output should be taken\n",
      "        from `x` (if true) or `y` (if false).\n",
      "        \n",
      "        If `condition` is a vector and `x` and `y` are higher rank matrices, then it\n",
      "        chooses which row (outer dimension) to copy from `x` and `y`. If `condition`\n",
      "        has the same shape as `x` and `y`, then it chooses which element to copy from\n",
      "        `x` and `y`.\n",
      "        \n",
      "        Args:\n",
      "          condition: A `Tensor` of type `bool`\n",
      "          x: A Tensor which may have the same shape as `condition`. If `condition` is\n",
      "            rank 1, `x` may have higher rank, but its first dimension must match the\n",
      "            size of `condition`.\n",
      "          y: A `tensor` with the same shape and type as `x`.\n",
      "          name: A name of the operation (optional)\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` with the same type and shape as `x`, `y` if they are non-None.\n",
      "          Otherwise, a `Tensor` with shape `(num_true, rank(condition))`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: When exactly one of `x` or `y` is non-None.\n",
      "    \n",
      "    where_v2(condition, x=None, y=None, name=None)\n",
      "        Return the elements, either from `x` or `y`, depending on the `condition`.\n",
      "        \n",
      "        If both `x` and `y` are None, then this operation returns the coordinates of\n",
      "        true elements of `condition`.  The coordinates are returned in a 2-D tensor\n",
      "        where the first dimension (rows) represents the number of true elements, and\n",
      "        the second dimension (columns) represents the coordinates of the true\n",
      "        elements. Keep in mind, the shape of the output tensor can vary depending on\n",
      "        how many true values there are in input. Indices are output in row-major\n",
      "        order.\n",
      "        \n",
      "        If both non-None, `condition`, `x` and `y` must be broadcastable to the same\n",
      "        shape.\n",
      "        \n",
      "        The `condition` tensor acts as a mask that chooses, based on the value at each\n",
      "        element, whether the corresponding element / row in the output should be taken\n",
      "        from `x` (if true) or `y` (if false).\n",
      "        \n",
      "        Args:\n",
      "          condition: A `Tensor` of type `bool`\n",
      "          x: A Tensor which is of the same type as `y`, and may be broadcastable with\n",
      "            `condition` and `y`.\n",
      "          y: A Tensor which is of the same type as `x`, and may be broadcastable with\n",
      "            `condition` and `x`.\n",
      "          name: A name of the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` with the same type as `x` and `y`, and shape that\n",
      "            is broadcast from `condition`, `x`, and `y`, if `x`, `y` are non-None.\n",
      "          A `Tensor` with shape `(num_true, dim_size(condition))`.\n",
      "        \n",
      "        Raises:\n",
      "          ValueError: When exactly one of `x` or `y` is non-None.\n",
      "    \n",
      "    while_loop(cond, body, loop_vars, shape_invariants=None, parallel_iterations=10, back_prop=True, swap_memory=False, name=None, maximum_iterations=None, return_same_structure=False)\n",
      "        Repeat `body` while the condition `cond` is true.\n",
      "        \n",
      "        `cond` is a callable returning a boolean scalar tensor. `body` is a callable\n",
      "        returning a (possibly nested) tuple, namedtuple or list of tensors of the same\n",
      "        arity (length and structure) and types as `loop_vars`. `loop_vars` is a\n",
      "        (possibly nested) tuple, namedtuple or list of tensors that is passed to both\n",
      "        `cond` and `body`. `cond` and `body` both take as many arguments as there are\n",
      "        `loop_vars`.\n",
      "        \n",
      "        In addition to regular Tensors or IndexedSlices, the body may accept and\n",
      "        return TensorArray objects.  The flows of the TensorArray objects will\n",
      "        be appropriately forwarded between loops and during gradient calculations.\n",
      "        \n",
      "        Note that `while_loop` calls `cond` and `body` *exactly once* (inside the\n",
      "        call to `while_loop`, and not at all during `Session.run()`). `while_loop`\n",
      "        stitches together the graph fragments created during the `cond` and `body`\n",
      "        calls with some additional graph nodes to create the graph flow that\n",
      "        repeats `body` until `cond` returns false.\n",
      "        \n",
      "        For correctness, `tf.while_loop()` strictly enforces shape invariants for\n",
      "        the loop variables. A shape invariant is a (possibly partial) shape that\n",
      "        is unchanged across the iterations of the loop. An error will be raised\n",
      "        if the shape of a loop variable after an iteration is determined to be more\n",
      "        general than or incompatible with its shape invariant. For example, a shape\n",
      "        of [11, None] is more general than a shape of [11, 17], and [11, 21] is not\n",
      "        compatible with [11, 17]. By default (if the argument `shape_invariants` is\n",
      "        not specified), it is assumed that the initial shape of each tensor in\n",
      "        `loop_vars` is the same in every iteration. The `shape_invariants` argument\n",
      "        allows the caller to specify a less specific shape invariant for each loop\n",
      "        variable, which is needed if the shape varies between iterations. The\n",
      "        `tf.Tensor.set_shape`\n",
      "        function may also be used in the `body` function to indicate that\n",
      "        the output loop variable has a particular shape. The shape invariant for\n",
      "        SparseTensor and IndexedSlices are treated specially as follows:\n",
      "        \n",
      "        a) If a loop variable is a SparseTensor, the shape invariant must be\n",
      "        TensorShape([r]) where r is the rank of the dense tensor represented\n",
      "        by the sparse tensor. It means the shapes of the three tensors of the\n",
      "        SparseTensor are ([None], [None, r], [r]). NOTE: The shape invariant here\n",
      "        is the shape of the SparseTensor.dense_shape property. It must be the shape of\n",
      "        a vector.\n",
      "        \n",
      "        b) If a loop variable is an IndexedSlices, the shape invariant must be\n",
      "        a shape invariant of the values tensor of the IndexedSlices. It means\n",
      "        the shapes of the three tensors of the IndexedSlices are (shape, [shape[0]],\n",
      "        [shape.ndims]).\n",
      "        \n",
      "        `while_loop` implements non-strict semantics, enabling multiple iterations\n",
      "        to run in parallel. The maximum number of parallel iterations can be\n",
      "        controlled by `parallel_iterations`, which gives users some control over\n",
      "        memory consumption and execution order. For correct programs, `while_loop`\n",
      "        should return the same result for any parallel_iterations > 0.\n",
      "        \n",
      "        For training, TensorFlow stores the tensors that are produced in the\n",
      "        forward inference and are needed in back propagation. These tensors are a\n",
      "        main source of memory consumption and often cause OOM errors when training\n",
      "        on GPUs. When the flag swap_memory is true, we swap out these tensors from\n",
      "        GPU to CPU. This for example allows us to train RNN models with very long\n",
      "        sequences and large batches.\n",
      "        \n",
      "        Args:\n",
      "          cond: A callable that represents the termination condition of the loop.\n",
      "          body: A callable that represents the loop body.\n",
      "          loop_vars: A (possibly nested) tuple, namedtuple or list of numpy array,\n",
      "            `Tensor`, and `TensorArray` objects.\n",
      "          shape_invariants: The shape invariants for the loop variables.\n",
      "          parallel_iterations: The number of iterations allowed to run in parallel. It\n",
      "            must be a positive integer.\n",
      "          back_prop: Whether backprop is enabled for this while loop.\n",
      "          swap_memory: Whether GPU-CPU memory swap is enabled for this loop.\n",
      "          name: Optional name prefix for the returned tensors.\n",
      "          maximum_iterations: Optional maximum number of iterations of the while loop\n",
      "            to run.  If provided, the `cond` output is AND-ed with an additional\n",
      "            condition ensuring the number of iterations executed is no greater than\n",
      "            `maximum_iterations`.\n",
      "          return_same_structure: If True, output has same structure as `loop_vars`. If\n",
      "            eager execution is enabled, this is ignored (and always treated as True).\n",
      "        \n",
      "        Returns:\n",
      "          The output tensors for the loop variables after the loop.\n",
      "           If `return_same_structure` is True, the return value has the same\n",
      "           structure as `loop_vars`.\n",
      "           If `return_same_structure` is False, the return value is a Tensor,\n",
      "           TensorArray or IndexedSlice if the length of `loop_vars` is 1, or a list\n",
      "           otherwise.\n",
      "        \n",
      "        Raises:\n",
      "          TypeError: if `cond` or `body` is not callable.\n",
      "          ValueError: if `loop_vars` is empty.\n",
      "        \n",
      "        Example:\n",
      "        \n",
      "        ```python\n",
      "        i = tf.constant(0)\n",
      "        c = lambda i: tf.less(i, 10)\n",
      "        b = lambda i: tf.add(i, 1)\n",
      "        r = tf.while_loop(c, b, [i])\n",
      "        ```\n",
      "        \n",
      "        Example with nesting and a namedtuple:\n",
      "        \n",
      "        ```python\n",
      "        import collections\n",
      "        Pair = collections.namedtuple('Pair', 'j, k')\n",
      "        ijk_0 = (tf.constant(0), Pair(tf.constant(1), tf.constant(2)))\n",
      "        c = lambda i, p: i < 10\n",
      "        b = lambda i, p: (i + 1, Pair((p.j + p.k), (p.j - p.k)))\n",
      "        ijk_final = tf.while_loop(c, b, ijk_0)\n",
      "        ```\n",
      "        \n",
      "        Example using shape_invariants:\n",
      "        \n",
      "        ```python\n",
      "        i0 = tf.constant(0)\n",
      "        m0 = tf.ones([2, 2])\n",
      "        c = lambda i, m: i < 10\n",
      "        b = lambda i, m: [i+1, tf.concat([m, m], axis=0)]\n",
      "        tf.while_loop(\n",
      "            c, b, loop_vars=[i0, m0],\n",
      "            shape_invariants=[i0.get_shape(), tf.TensorShape([None, 2])])\n",
      "        ```\n",
      "        \n",
      "        Example which demonstrates non-strict semantics: In the following\n",
      "        example, the final value of the counter `i` does not depend on `x`. So\n",
      "        the `while_loop` can increment the counter parallel to updates of `x`.\n",
      "        However, because the loop counter at one loop iteration depends\n",
      "        on the value at the previous iteration, the loop counter itself cannot\n",
      "        be incremented in parallel. Hence if we just want the final value of the\n",
      "        counter (which we print on the line `print(sess.run(i))`), then\n",
      "        `x` will never be incremented, but the counter will be updated on a\n",
      "        single thread. Conversely, if we want the value of the output (which we\n",
      "        print on the line `print(sess.run(out).shape)`), then the counter may be\n",
      "        incremented on its own thread, while `x` can be incremented in\n",
      "        parallel on a separate thread. In the extreme case, it is conceivable\n",
      "        that the thread incrementing the counter runs until completion before\n",
      "        `x` is incremented even a single time. The only thing that can never\n",
      "        happen is that the thread updating `x` can never get ahead of the\n",
      "        counter thread because the thread incrementing `x` depends on the value\n",
      "        of the counter.\n",
      "        \n",
      "        ```python\n",
      "        import tensorflow as tf\n",
      "        \n",
      "        n = 10000\n",
      "        x = tf.constant(list(range(n)))\n",
      "        c = lambda i, x: i < n\n",
      "        b = lambda i, x: (tf.compat.v1.Print(i + 1, [i]), tf.compat.v1.Print(x + 1,\n",
      "        [i], \"x:\"))\n",
      "        i, out = tf.while_loop(c, b, (0, x))\n",
      "        with tf.compat.v1.Session() as sess:\n",
      "            print(sess.run(i))  # prints [0] ... [9999]\n",
      "        \n",
      "            # The following line may increment the counter and x in parallel.\n",
      "            # The counter thread may get ahead of the other thread, but not the\n",
      "            # other way around. So you may see things like\n",
      "            # [9996] x:[9987]\n",
      "            # meaning that the counter thread is on iteration 9996,\n",
      "            # while the other thread is on iteration 9987\n",
      "            print(sess.run(out).shape)\n",
      "        ```\n",
      "    \n",
      "    wrap_function(fn, signature, name=None)\n",
      "        Wraps the TF 1.x function fn into a graph function.\n",
      "        \n",
      "        The python function `fn` will be called once with symbolic arguments specified\n",
      "        in the `signature`, traced, and turned into a graph function. Any variables\n",
      "        created by `fn` will be owned by the object returned by `wrap_function`. The\n",
      "        resulting graph function can be called with tensors which match the\n",
      "        signature.\n",
      "        \n",
      "        ```python\n",
      "        def f(x, do_add):\n",
      "          v = tf.Variable(5.0)\n",
      "          if do_add:\n",
      "            op = v.assign_add(x)\n",
      "          else:\n",
      "            op = v.assign_sub(x)\n",
      "          with tf.control_dependencies([op]):\n",
      "            return v.read_value()\n",
      "        \n",
      "        f_add = tf.compat.v1.wrap_function(f, [tf.TensorSpec((), tf.float32), True])\n",
      "        \n",
      "        assert float(f_add(1.0)) == 6.0\n",
      "        assert float(f_add(1.0)) == 7.0\n",
      "        \n",
      "        # Can call tf.compat.v1.wrap_function again to get a new trace, a new set\n",
      "        # of variables, and possibly different non-template arguments.\n",
      "        f_sub= tf.compat.v1.wrap_function(f, [tf.TensorSpec((), tf.float32), False])\n",
      "        \n",
      "        assert float(f_sub(1.0)) == 4.0\n",
      "        assert float(f_sub(1.0)) == 3.0\n",
      "        ```\n",
      "        \n",
      "        Both `tf.compat.v1.wrap_function` and `tf.function` create a callable\n",
      "        TensorFlow graph. But while `tf.function` runs all stateful operations\n",
      "        (e.g. `tf.print`) and sequences operations to provide the same semantics as\n",
      "        eager execution, `wrap_function` is closer to the behavior of `session.run` in\n",
      "        TensorFlow 1.x. It will not run any operations unless they are required to\n",
      "        compute the function's outputs, either through a data dependency or a control\n",
      "        dependency. Nor will it sequence operations.\n",
      "        \n",
      "        Unlike `tf.function`, `wrap_function` will only trace the Python function\n",
      "        once. As with placeholders in TF 1.x, shapes and dtypes must be provided to\n",
      "        `wrap_function`'s `signature` argument.\n",
      "        \n",
      "        Since it is only traced once, variables and state may be created inside the\n",
      "        function and owned by the function wrapper object.\n",
      "        \n",
      "        Args:\n",
      "          fn: python function to be wrapped\n",
      "          signature: the placeholder and python arguments to be passed to the wrapped\n",
      "            function\n",
      "          name: Optional. The name of the function.\n",
      "        \n",
      "        Returns:\n",
      "          the wrapped graph function.\n",
      "    \n",
      "    write_file(filename, contents, name=None)\n",
      "        Writes contents to the file at input filename. Creates file and recursively\n",
      "        \n",
      "        creates directory if not existing.\n",
      "        \n",
      "        Args:\n",
      "          filename: A `Tensor` of type `string`.\n",
      "            scalar. The name of the file to which we write the contents.\n",
      "          contents: A `Tensor` of type `string`.\n",
      "            scalar. The content to be written to the output file.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          The created Operation.\n",
      "    \n",
      "    zeros(shape, dtype=tf.float32, name=None)\n",
      "        Creates a tensor with all elements set to zero.\n",
      "        \n",
      "        This operation returns a tensor of type `dtype` with shape `shape` and\n",
      "        all elements set to zero.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        tf.zeros([3, 4], tf.int32)  # [[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          shape: A list of integers, a tuple of integers, or a 1-D `Tensor` of type\n",
      "            `int32`.\n",
      "          dtype: The type of an element in the resulting `Tensor`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` with all elements set to zero.\n",
      "    \n",
      "    zeros_like(tensor, dtype=None, name=None, optimize=True)\n",
      "        Creates a tensor with all elements set to zero.\n",
      "        \n",
      "        Given a single tensor (`tensor`), this operation returns a tensor of the\n",
      "        same type and shape as `tensor` with all elements set to zero. Optionally,\n",
      "        you can use `dtype` to specify a new type for the returned tensor.\n",
      "        \n",
      "        For example:\n",
      "        \n",
      "        ```python\n",
      "        tensor = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
      "        tf.zeros_like(tensor)  # [[0, 0, 0], [0, 0, 0]]\n",
      "        ```\n",
      "        \n",
      "        Args:\n",
      "          tensor: A `Tensor`.\n",
      "          dtype: A type for the returned `Tensor`. Must be `float16`, `float32`,\n",
      "            `float64`, `int8`, `uint8`, `int16`, `uint16`, `int32`, `int64`,\n",
      "            `complex64`, `complex128`, `bool` or `string`.\n",
      "          name: A name for the operation (optional).\n",
      "          optimize: if true, attempt to statically determine the shape of 'tensor' and\n",
      "            encode it as a constant.\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor` with all elements set to zero.\n",
      "    \n",
      "    zeta(x, q, name=None)\n",
      "        Compute the Hurwitz zeta function \\\\(\\zeta(x, q)\\\\).\n",
      "        \n",
      "        The Hurwitz zeta function is defined as:\n",
      "        \n",
      "        \n",
      "        \\\\(\\zeta(x, q) = \\sum_{n=0}^{\\infty} (q + n)^{-x}\\\\)\n",
      "        \n",
      "        Args:\n",
      "          x: A `Tensor`. Must be one of the following types: `float32`, `float64`.\n",
      "          q: A `Tensor`. Must have the same type as `x`.\n",
      "          name: A name for the operation (optional).\n",
      "        \n",
      "        Returns:\n",
      "          A `Tensor`. Has the same type as `x`.\n",
      "\n",
      "DATA\n",
      "    AUTO_REUSE = <_ReuseMode.AUTO_REUSE: 1>\n",
      "    COMPILER_VERSION = '7.3.1 20180303'\n",
      "    CXX11_ABI_FLAG = 0\n",
      "    GIT_VERSION = 'v1.15.0-rc3-22-g590d6ee'\n",
      "    GRAPH_DEF_VERSION = 134\n",
      "    GRAPH_DEF_VERSION_MIN_CONSUMER = 0\n",
      "    GRAPH_DEF_VERSION_MIN_PRODUCER = 0\n",
      "    MONOLITHIC_BUILD = 0\n",
      "    QUANTIZED_DTYPES = frozenset({tf.qint8, tf.quint8, tf.qint32, tf.qint8...\n",
      "    VERSION = '1.15.0'\n",
      "    __all__ = ['AUTO_REUSE', 'AggregationMethod', 'Assert', 'AttrValue', '...\n",
      "    __compiler_version__ = '7.3.1 20180303'\n",
      "    __cxx11_abi_flag__ = 0\n",
      "    __git_version__ = 'v1.15.0-rc3-22-g590d6ee'\n",
      "    __monolithic_build__ = 0\n",
      "    bfloat16 = tf.bfloat16\n",
      "    bool = tf.bool\n",
      "    complex128 = tf.complex128\n",
      "    complex64 = tf.complex64\n",
      "    double = tf.float64\n",
      "    float16 = tf.float16\n",
      "    float32 = tf.float32\n",
      "    float64 = tf.float64\n",
      "    half = tf.float16\n",
      "    int16 = tf.int16\n",
      "    int32 = tf.int32\n",
      "    int64 = tf.int64\n",
      "    int8 = tf.int8\n",
      "    newaxis = None\n",
      "    qint16 = tf.qint16\n",
      "    qint32 = tf.qint32\n",
      "    qint8 = tf.qint8\n",
      "    quint16 = tf.quint16\n",
      "    quint8 = tf.quint8\n",
      "    resource = tf.resource\n",
      "    string = tf.string\n",
      "    uint16 = tf.uint16\n",
      "    uint32 = tf.uint32\n",
      "    uint64 = tf.uint64\n",
      "    uint8 = tf.uint8\n",
      "    variant = tf.variant\n",
      "\n",
      "VERSION\n",
      "    1.15.0\n",
      "\n",
      "FILE\n",
      "    /home/andres/Escritorio/PROYECTOS/entorno1/lib/python3.6/site-packages/tensorflow/__init__.py\n",
      "\n",
      "\n",
      "<class 'tensorflow.python.util.module_wrapper.TFModuleWrapper'>\n"
     ]
    }
   ],
   "source": [
    "help(tf)\n",
    "tf?\n",
    "print(type(tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x <tf.Variable 'x:0' shape=() dtype=int32_ref>\n",
      "tipo de x <class 'tensorflow.python.ops.variables.RefVariable'>\n",
      "f Tensor(\"add_3:0\", shape=(), dtype=int32)\n",
      "tipo de x <class 'tensorflow.python.framework.ops.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(3, name=\"x\")\n",
    "y = tf.Variable(4, name=\"y\")\n",
    "f = x*x*y + y + 2\n",
    "print(\"x\",x)\n",
    "print(\"tipo de x\",type(x))\n",
    "print(\"f\",f)\n",
    "print(\"tipo de x\",type(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Eso es todo al respecto! Lo más importante que hay que entender es que <b>este código no realiza ningún cálculo</b>, a pesar de que parece que lo hace (especialmente la última línea). Simplemente <b>crea un gráfico de cálculo. De hecho, incluso las variables aún no están inicializadas.</b> Para evaluar este gráfico, necesita abrir una sesión de TensorFlow y usarla para inicializar las variables y evaluar f. <b>Una sesión de TensorFlow se encarga de colocar las operaciones en dispositivos como CPU y GPU y de ejecutarlas, y contiene todos los valores de las variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atencion:--->Grafos y sus ventajas<br>\n",
    "Un componente esencial para entender TensorFlow es el grafo. Es importante destacar que con TensorFlow 2.0 se va a mover hacia el modelo de Eager Execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asi de esta manera hay que tener en cuenta que para trabajar en tensorlfor hay que elaborar un grafo, \n",
    "este grafo se elabora con unas variables de entradas y unos nodos, donde los nodos son las operaciones entre los \n",
    "diferentes elementos del grafo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval vs Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z = 7\n",
      "f = 34\n",
      "f = 34\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.Variable(3, name=\"x\")\n",
    "y = tf.Variable(4, name=\"y\")\n",
    "z = x + y\n",
    "f = x*x*y + y - z + 1\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    x.initializer.run()\n",
    "    y.initializer.run()\n",
    "    resultz = z.eval()\n",
    "    resultf1 = f.eval()\n",
    "    resultf2 = sess.run(f)\n",
    "    print('z =',resultz)\n",
    "    print('f =',resultf1)\n",
    "    print('f =',resultf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z = 1\n",
      "f = 2\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.Variable(3, name=\"x\")\n",
    "y = tf.Variable(4, name=\"y\")\n",
    "z = x + y\n",
    "f = x*x*y + y - z + 1\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    resultf,resultz = sess.run([f,z],feed_dict={x:1,y:1,z:1})\n",
    "    print('z =',resultz)\n",
    "    print('f =',resultf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente código crea una sesión, inicializa las variables y las evalúa, y luego de f cierra la sesión ( lo que libera recursos):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(x.initializer)\n",
    "sess.run(y.initializer)\n",
    "result = sess.run(f)\n",
    "print(result)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tener que repetir sess.run () todo el tiempo es un poco engorroso, pero afortunadamente hay una mejor manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    x.initializer.run()\n",
    "    y.initializer.run()\n",
    "    result = f.eval()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dentro del <b>bloque with,</b> la sesión se establece como la sesión predeterminada. Llamar a x.initializer.run () es equivalente a llamar a tf.get_default_session().Run (x.initializer), y de manera similar f.eval() es equivalente a llamar a tf.get_default_session().Run (f). Esto hace que el código sea más fácil de leer. Además, la sesión se cierra automáticamente al final del bloque."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En lugar de ejecutar manualmente el inicializador para cada variable, puede usar la función <b>global_variables_initializer().</b> Tenga en cuenta que en realidad no realiza la inicialización de inmediato, sino que crea un nodo en el gráfico que inicializará todas las variables cuando se ejecute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer() #inicializa todas las variables y no una por una como antes\n",
    "#asi init prepara un nodo que se va a inicializar\n",
    "with tf.Session() as sess:\n",
    "    init.run() #inicializa el nodo e inicializa todas las variables\n",
    "    result = f.eval()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dentro de Jupyter o dentro de un shell de Python, puede preferir crear una sesión interactiva. La única diferencia con una sesión regular es que cuando se crea una sesión interactiva, se configura automáticamente como la sesión predeterminada, por lo que no necesita un bloque (pero necesita cerrar la sesión manualmente cuando haya terminado): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "init.run()\n",
    "result = f.eval()\n",
    "print(result)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un programa TensorFlow generalmente se divide en dos partes:<br>\n",
    "la primera parte construye un gráfico de cómputo (esto se llama la fase de construcción), <br>\n",
    "y la segunda parte lo ejecuta (esta es la fase de ejecución).<br>\n",
    "La fase de construcción generalmente construye un gráfico de cálculo que representa el modelo ML y los cálculos necesarios para entrenarlo. La fase de ejecución generalmente ejecuta un ciclo que evalúa un paso de entrenamiento repetidamente (por ejemplo, un paso por mini lote), mejorando gradualmente los parámetros del modelo. Vamos a pasar por un ejemplo en breve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A manera de conlusion tenga en cuenta que tensorflow se divide en dos partes:\n",
    "La primera parte es la fase de construccion del grafico donde usted declara las variables de entrada \n",
    "y sus respectivas operaciones que se van a realizar entre ellas las cuales son los nodos \n",
    "En el grafo, los nodos representan operaciones, variables y constantes.\n",
    "Las aristas, las conexiones entre los nodos, son tensores. Los tensores representan datos y fluyen a través del grafo. \n",
    "Los datos llegan a nodos que realizan operaciones con ellos. \n",
    "Es por eso que se llama TensorFlow.\n",
    "La segunda parte despues de haber declarado y construido el grafo de tensorflow consiste en la ejecucion del grafo, lo cual corresponde a realizar las diversas operaciones que se impusieron en los nodos.\n",
    "Para que los valores fluyan a través del grafo, se debe hacer con una sesión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"w:0\", shape=(1, 2), dtype=float32)\n",
      "Tensor(\"add:0\", shape=(1, 2), dtype=float32)\n",
      "[[3. 2.]]\n",
      "[[8. 7.]]\n",
      "[[27. 23.]]\n",
      "Tensor(\"w:0\", shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph() #reinicar un grafo  y sus variables\n",
    "w=tf.constant([[3,2]],name=\"w\",dtype=float) #creamos un nodo\n",
    "u=w+5 #creamos un nodo encargado de sumar dos variables\n",
    "v=3*u+w #creamos un nodo encargado de multiplicar y sumar dos variables\n",
    "print(w)\n",
    "print(u)\n",
    "init = tf.global_variables_initializer() # creo un nodo que inicializa todas las variables anteriores\n",
    "with tf.Session() as sess: #elaboramos un bloque with que me permite realizar la fase de ejecucion del grafo\n",
    "#con tf.Session() llamar sess:\n",
    "    init.run() #el nodo init lo inicializo y corro\n",
    "    #ahora es posible aplicando el metodo eval() ver el valor de cada una de mis variables\n",
    "    z=w.eval()\n",
    "    print(z)\n",
    "    u=u.eval()\n",
    "    print(u)\n",
    "    v=v.eval()\n",
    "    print(v)\n",
    "#al finalizar el bloque la sess se cierra automaticamente\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Manejo de grafos</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cualquier nodo que cree se agregará automáticamente al gráfico predeterminado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = tf.Variable(1)\n",
    "x1.graph is tf.get_default_graph() #grafico predeterminado "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la mayoría de los casos, esto está bien, pero a veces es posible que desee administrar múltiples gráficos independientes. Puedes hacer esto creando un nuevo gráfico y convirtiéndolo temporalmente en el gráfico predeterminado dentro de un bloque with, de esta manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=() dtype=int32_ref>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph1 = tf.Graph()\n",
    "with graph1.as_default():\n",
    "    x2 = tf.Variable(2)\n",
    "    print(x2)\n",
    "x2.graph is graph1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>---OJO---</b> <br>\n",
    "En Jupyter (o en un shell de Python), es común ejecutar los mismos comandos más de una vez mientras está experimentando. Como resultado, puede terminar con un gráfico predeterminado que contiene muchos nodos duplicados. Una solución es reiniciar el kernel de Jupyter (o el shell de Python), pero una solución más conveniente es simplemente restablecer el gráfico predeterminado ejecutando tf.reset_default_graph ()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph() #ojo siempre va el inicio de todo grafo para evitar duplicar el grafo a volver a correr celdas en jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"w:0\", shape=(1, 2), dtype=float32)\n",
      "Tensor(\"add:0\", shape=(1, 2), dtype=float32)\n",
      "[[3. 2.]]\n",
      "[[8. 7.]]\n",
      "[[27. 23.]]\n",
      "valor de variables\n",
      "Tensor(\"w:0\", shape=(1, 2), dtype=float32)\n",
      "[[3. 2.]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph() #reinicar un grafo  y sus variables\n",
    "Migrafo=tf.Graph() #nombre mi grafo predetermiando\n",
    "with Migrafo.as_default(): #creo un bloque donde voy a construir mi grafo\n",
    "    w=tf.constant([[3,2]],name=\"w\",dtype=float) #creamos un nodo\n",
    "    u=w+5 #creamos un nodo encargado de sumar dos variables\n",
    "    v=3*u+w #creamos un nodo encargado de multiplicar y sumar dos variables\n",
    "    print(w)\n",
    "    print(u)\n",
    "    init = tf.global_variables_initializer() # creo un nodo que inicializa todas las variables anteriores\n",
    "    with tf.Session() as sess: #elaboramos un bloque with que me permite realizar la fase de ejecucion del grafo\n",
    "#con tf.Session() llamar sess:\n",
    "        init.run() #el nodo init lo inicializo y corro\n",
    "    #ahora es posible aplicando el metodo eval() ver el valor de cada una de mis variables\n",
    "        z=w.eval()\n",
    "        print(z)\n",
    "        u=u.eval()\n",
    "        print(u)\n",
    "        v=v.eval()\n",
    "        print(v)\n",
    "#al finalizar el bloque la sess se cierra automaticamente\n",
    "print(\"valor de variables\")\n",
    "print(w)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vea la documentación de la clase Graph para como manejar explícitamente múltiples grafos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "valor de actualiacion 1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "#ejemplo de un contador con tensorflow\n",
    "tf.reset_default_graph()\n",
    "\n",
    "contador=tf.Variable(0, name=\"conta\")\n",
    "uno=tf.constant(1,name=\"constante\")\n",
    "suma=contador+uno\n",
    "actualizacion=tf.assign(contador,suma)\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    print(suma.eval())\n",
    "    print(\"valor de actualiacion\", actualizacion.eval())\n",
    "    \n",
    "    for i in range(5):\n",
    "        resultadofinal=actualizacion.eval()\n",
    "        print(resultadofinal)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra forma de extraer las salidas de los tensores y de observar sus valores aparte \n",
    "del metodo .eval sobre los tensores, es aplicar el metodo run sobre el objeto sess y pasarle como argumento el\n",
    "tensor del cual quiere el resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "valor de actualiacion 1\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "#ejemplo de un contador con tensorflow\n",
    "tf.reset_default_graph()\n",
    "\n",
    "contador=tf.Variable(0, name=\"conta\")\n",
    "uno=tf.constant(1,name=\"constante\")\n",
    "suma=contador+uno\n",
    "actualizacion=tf.assign(contador,suma)\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    print(suma.eval())\n",
    "    print(\"valor de actualiacion\", actualizacion.eval())\n",
    "    \n",
    "    for i in range(5):\n",
    "        resultadofinal,sumato=sess.run([actualizacion,suma])\n",
    "        print(resultadofinal)\n",
    "        print(sumato)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Ciclo de vida de un valor de nodo </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando evalúa un nodo, TensorFlow determina automáticamente el conjunto de nodos de los que depende y primero evalúa estos nodos. Por ejemplo, considere el siguiente código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "w = tf.constant(3)\n",
    "x = w + 2\n",
    "y = x + 5\n",
    "z = x * 3\n",
    "with tf.Session() as sess:\n",
    "    print(y.eval()) # 10\n",
    "    print(z.eval()) # 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, este código define un gráfico muy simple. Luego inicia una sesión y ejecuta el gráfico para evaluar y: TensorFlow detecta automáticamente que y depende de w, que depende de x, por lo que primero evalúa w, luego x, luego y, y devuelve el valor de y.<br>\n",
    "Finalmente, el código ejecuta el gráfico para evaluar z. Una vez más, TensorFlow detecta que primero debe evaluar w y x. Es importante tener en cuenta que no reutilizará el resultado de la evaluación previa de w y x. En resumen, el código anterior evalúa w y x dos veces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Todos los valores de los nodos se eliminan entre las ejecuciones del gráfico, excepto los valores variables, que la sesión mantiene en las ejecuciones del gráfico</b> (las colas y los lectores también mantienen cierto estado, como veremos en el Capítulo 12).<br>\n",
    "Una variable comienza su vida útil cuando se ejecuta su inicializador, y termina cuando se cierra la sesión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si desea evaluar y y z eficientemente, sin evaluar wyx dos veces como en el código anterior, debe solicitar a TensorFlow que evalúe tanto y como z en solo una ejecución de gráfico, como se muestra en el siguiente código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    y_val, z_val = sess.run([y, z])\n",
    "    print(y_val) # 10\n",
    "    print(z_val) # 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Regresión lineal con TensorFlow</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las operaciones de TensorFlow (también llamadas ops para abreviar) pueden tomar cualquier cantidad de entradas y producir cualquier cantidad de salidas. Por ejemplo, las operaciones de suma y multiplicación toman dos entradas y producen una salida. Las constantes y las variables no toman ninguna entrada (se denominan operaciones de origen). Las entradas y salidas son matrices multidimensionales, llamadas tensores (de ahí el nombre de \"flujo tensor\"). Al igual que las matrices NumPy, los tensores tienen un tipo y una forma. De hecho, en la API de Python, los tensores están representados simplemente por NumPy ndarrays. Por lo general, contienen flotadores, pero también puede usarlos para transportar cadenas (matrices de bytes arbitrarias)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta ahora, en los ejemplos, los tensores solo contenían un único valor escalar, pero, por supuesto, puede realizar cálculos en arreglos de cualquier forma. Por ejemplo, el siguiente código manipula matrices 2D para realizar Regresión lineal en el conjunto de datos de vivienda de California (presentado en el Capítulo 2). Comienza por buscar el conjunto de datos; luego agrega una función de entrada de sesgo adicional (x0 = 1) a todas las instancias de entrenamiento (lo hace usando NumPy para que se ejecute inmediatamente); luego crea dos nodos constantes de TensorFlow, X y y, para mantener estos datos y los objetivos, 4 y utiliza algunas de las operaciones de matriz proporcionadas por Tensor-Flow para definir theta. Estas funciones matriciales (transpose (), matmul () y matrix_inverse ()) se explican por sí mismas, pero como de costumbre no realizan ningún cálculo de inmediato; en su lugar, crean nodos en el gráfico que los realizarán cuando se ejecute el gráfico. Puede reconocer que la definición de theta corresponde a la Ecuación Normal (θ = XT · X) –1 · XT · y; ver capítulo 4). Finalmente, el código crea una sesión y la utiliza para evaluar theta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.6894890e+01]\n",
      " [ 4.3661433e-01]\n",
      " [ 9.4453208e-03]\n",
      " [-1.0704148e-01]\n",
      " [ 6.4345831e-01]\n",
      " [-3.9632569e-06]\n",
      " [-3.7880042e-03]\n",
      " [-4.2093179e-01]\n",
      " [-4.3400639e-01]]\n"
     ]
    }
   ],
   "source": [
    "#REGRESION LINEAL \n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing() #buscamos el conjunto de datos\n",
    "m, n = housing.data.shape\n",
    "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data] #vector de interseccion  y datos\n",
    "X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name=\"X\") #creamos nodo constante\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\") #vector de etiquetas\n",
    "XT = tf.transpose(X) #transpuesta\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), y) #matriz de paramrtros\n",
    "with tf.Session() as sess:\n",
    "    theta_value = theta.eval()\n",
    "print(theta_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Implementando Gradiente Descendente</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intentemos utilizar el Descenso por Gradiente de lotes (presentado en el Capítulo 4) en lugar de la Ecuación Normal. Primero, lo haremos al calcular manualmente los gradientes, luego usaremos la función Autodiff de TensorFlow para permitir que TensorFlow calcule los gradientes automáticamente, y finalmente usaremos un par de optimizadores listos para usar de TensorFlow.\n",
    "Cuando use Gradient Descent, <b>recuerde que es importante normalizar primero los vectores de entidades de entrada, o el entrenamiento puede ser mucho más lento.</b> Puede hacer esto utilizando TensorFlow, NumPy, StandardScaler de Scikit-Learn o cualquier otra solución que prefiera. El siguiente código asume que esta normalización ya se ha realizado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Computando manualmente los gradientes</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/2110/1*f3AVL6VGeoQDKyjl8Bw9KA.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recuerde que J(theta) es la funcion de costo que depende de la variable theta que es la matriz de parametros a entrenar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente código debe ser bastante autoexplicativo, excepto por algunos elementos nuevos:<br>\n",
    "• La función random_uniform () crea un nodo en el gráfico que generará un tensor que contiene valores aleatorios, dada su forma y rango de valores, al igual que la función rand () de NumPy.<br>\n",
    "• La función assign () crea un nodo que asignará un nuevo valor a una variable.<br>\n",
    "En este caso, implementa el paso de Descenso de degradado por lotes θ (siguiente paso) = θ –η∇θMSE (θ).<br>\n",
    "• El bucle principal ejecuta el paso de entrenamiento una y otra vez (n_epochs veces), y cada 100 iteraciones imprime el error cuadrático medio actual (mse). Debería ver el MSE bajar en cada iteración. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   1.            8.3252       41.         ...    2.55555556\n",
      "    37.88       -122.23      ]\n",
      " [   1.            8.3014       21.         ...    2.10984183\n",
      "    37.86       -122.22      ]\n",
      " [   1.            7.2574       52.         ...    2.80225989\n",
      "    37.85       -122.24      ]\n",
      " ...\n",
      " [   1.            1.7          17.         ...    2.3256351\n",
      "    39.43       -121.22      ]\n",
      " [   1.            1.8672       18.         ...    2.12320917\n",
      "    39.43       -121.32      ]\n",
      " [   1.            2.3886       16.         ...    2.61698113\n",
      "    39.37       -121.24      ]]\n",
      "StandardScaler(copy=True, with_mean=True, with_std=True)\n"
     ]
    }
   ],
   "source": [
    "#normalizando datos\n",
    "print(housing_data_plus_bias)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "print(scaler.fit(housing_data_plus_bias))\n",
    "scaled_housing_data_plus_bias=scaler.transform(housing_data_plus_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 8.753064\n",
      "Epoch 100 MSE = 5.078356\n",
      "Epoch 200 MSE = 4.978504\n",
      "Epoch 300 MSE = 4.9330473\n",
      "Epoch 400 MSE = 4.9000673\n",
      "Epoch 500 MSE = 4.875754\n",
      "Epoch 600 MSE = 4.857771\n",
      "Epoch 700 MSE = 4.84443\n",
      "Epoch 800 MSE = 4.834498\n",
      "Epoch 900 MSE = 4.827076\n",
      "[[ 0.36067486]\n",
      " [ 0.87087566]\n",
      " [ 0.16627048]\n",
      " [-0.26906425]\n",
      " [ 0.27589747]\n",
      " [ 0.01224804]\n",
      " [-0.04422565]\n",
      " [-0.51474535]\n",
      " [-0.48660278]]\n"
     ]
    }
   ],
   "source": [
    "#implementando gradiente descendente\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name=\"theta\")#creamos un nodo en el grafico que contiene un tensor aleatorio\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\") #error cuadratico medio\n",
    "gradients = 2/m * tf.matmul(tf.transpose(X), error)\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)#crea un nodo que asignara un nuevo valor a la variable theta (entrenamiento)\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    best_theta = theta.eval()\n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Utilizando autodiff (MUY IMPORTANTE)</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El código anterior funciona bien, pero requiere derivar matemáticamente los gradientes de la función de costo (MSE). En el caso de la Regresión Lineal, es razonablemente fácil, pero si tuviera que hacer esto con redes neuronales profundas, tendría un gran dolor de cabeza: sería tedioso y propenso a errores. Podría usar la diferenciación simbólica para encontrar automáticamente las ecuaciones para las derivadas parciales, pero el código resultante no sería necesariamente muy eficiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afortunadamente, la función Autodiff de TensorFlow viene al rescate: puede calcular los gradientes de forma automática y eficiente. Simplemente reemplace la línea de gradientes = ... en el código de Descenso de degradado en la sección anterior con la siguiente línea, y el código continuará funcionando bien:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 10.505316\n",
      "Epoch 100 MSE = 4.9801135\n",
      "Epoch 200 MSE = 4.913315\n",
      "Epoch 300 MSE = 4.8833055\n",
      "Epoch 400 MSE = 4.861843\n",
      "Epoch 500 MSE = 4.846231\n",
      "Epoch 600 MSE = 4.8348503\n",
      "Epoch 700 MSE = 4.8265414\n",
      "Epoch 800 MSE = 4.8204656\n",
      "Epoch 900 MSE = 4.8160143\n",
      "[[-0.27464008]\n",
      " [ 0.8313095 ]\n",
      " [ 0.15279107]\n",
      " [-0.20564707]\n",
      " [ 0.22844288]\n",
      " [ 0.00785827]\n",
      " [-0.04224183]\n",
      " [-0.65016365]\n",
      " [-0.6179643 ]]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name=\"theta\")#creamos un nodo en el grafico que contiene un tensor aleatorio\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\") #ERROR CUADRATICO MEDIO\n",
    "gradients = tf.gradients(mse, [theta])[0] #calcula los gradientes respecto a una variable\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)#crea un nodo que asginara un nuevo valor a la variable\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    best_theta = theta.eval()\n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>La función gradientes () toma una op (en este caso mse) y una lista de variables (en este caso solo theta), y crea una lista de ops (una por variable) para calcular los gradientes de la op con respecto a cada una variable. Por lo tanto, el nodo de gradientes calculará el vector de gradiente del MSE con respecto a theta.</b><br>\n",
    "Hay cuatro enfoques principales para calcular gradientes automáticamente. Se resumen en la Tabla 9-2. \n",
    "TensorFlow usa el modo automático de modo inverso, que es perfecto (eficiente y preciso) cuando hay muchas entradas y pocas salidas, como suele ser el caso en las redes neuronales. Calcula todas las derivadas parciales de las salidas con respecto a todas las entradas en solo noutputs + 1 gráfico de recorridos. Si está interesado en cómo funciona esta magia, consulte el Apéndice D."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://lh3.googleusercontent.com/proxy/wsvJKuevOy13wUzISr51f41lVvxMV9Wf1_OfFRoBA0s4V1FmvlKJW4aqiC8tRjFoE2bpDG3wmhUHr0jnPEnOllxqj7MGW3BnNXccDwt2AiWZw9N0xXWLAQ\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.048902061818402e-09\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "valx=3\n",
    "x = tf.Variable(valx,dtype=tf.float32)\n",
    "f=x**2\n",
    "df=2*x\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for i in range(1000):\n",
    "        resf,resd=sess.run([f,df],feed_dict={x:valx})\n",
    "        valx-=0.01*resd\n",
    "    print(valx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autodiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.999999771118144 -4.999999771118144\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "valx=3\n",
    "valy=-3\n",
    "x = tf.Variable(valx,dtype=tf.float32)\n",
    "y = tf.Variable(valy,dtype=tf.float32)\n",
    "f=(x-5)**2+(y+5)**2\n",
    "df=tf.gradients(f, [x,y])\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for i in range(1000):\n",
    "        resf,resd=sess.run([f,df],feed_dict={x:valx,y:valy})\n",
    "        valx-=0.01*resd[0]\n",
    "        valy-=0.01*resd[1]\n",
    "    print(valx,valy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Utilizando un optimizador</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces TensorFlow calcula los gradientes por ti. Pero se vuelve aún más fácil: también proporciona una serie de optimizadores listos para usar, incluido un optimizador de gradiente de pendiente. Simplemente puede reemplazar los gradientes anteriores = ... y training_op = ... líneas con el siguiente código, y una vez más, todo funcionará bien: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 6.775647\n",
      "Epoch 100 MSE = 4.9083295\n",
      "Epoch 200 MSE = 4.8687673\n",
      "Epoch 300 MSE = 4.8534102\n",
      "Epoch 400 MSE = 4.84228\n",
      "Epoch 500 MSE = 4.8338013\n",
      "Epoch 600 MSE = 4.827287\n",
      "Epoch 700 MSE = 4.8222556\n",
      "Epoch 800 MSE = 4.818348\n",
      "Epoch 900 MSE = 4.8152986\n",
      "[[ 0.5699029 ]\n",
      " [ 0.8962492 ]\n",
      " [ 0.15066113]\n",
      " [-0.35509664]\n",
      " [ 0.36379096]\n",
      " [ 0.00623999]\n",
      " [-0.04344617]\n",
      " [-0.6047029 ]\n",
      " [-0.58135617]]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name=\"theta\")#creamos un nodo en el grafico que contiene un tensor aleatorio\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    best_theta = theta.eval()\n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si desea utilizar un tipo diferente de optimizador, solo necesita cambiar una línea. Por ejemplo, puede usar un optimizador de impulso (que a menudo converge mucho más rápido que Gradient Descent; consulte el Capítulo 11) definiendo el optimizador de esta manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 8.651561\n",
      "Epoch 100 MSE = 4.809506\n",
      "Epoch 200 MSE = 4.803724\n",
      "Epoch 300 MSE = 4.80331\n",
      "Epoch 400 MSE = 4.8032613\n",
      "Epoch 500 MSE = 4.8032546\n",
      "Epoch 600 MSE = 4.803254\n",
      "Epoch 700 MSE = 4.8032537\n",
      "Epoch 800 MSE = 4.8032546\n",
      "Epoch 900 MSE = 4.803254\n",
      "[[ 0.6296239 ]\n",
      " [ 0.8296268 ]\n",
      " [ 0.11875302]\n",
      " [-0.26554105]\n",
      " [ 0.3057079 ]\n",
      " [-0.00450267]\n",
      " [-0.03932653]\n",
      " [-0.89986926]\n",
      " [-0.8705251 ]]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name=\"theta\")#creamos un nodo en el grafico que contiene un tensor aleatorio\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate,momentum=0.9) #optimizador en gradiente descendente\n",
    "training_op = optimizer.minimize(mse)\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    best_theta = theta.eval()\n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Alimentando datos al algoritmo de entrenamiento (muy importante)</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intentemos modificar el código anterior para implementar Mini-batch Gradient Descent. Para esto, necesitamos una manera de reemplazar X e y en cada iteración con el siguiente mini lote. La forma más sencilla de hacer esto es <b>usar nodos de marcadores de posición (placeholder).</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos nodos son especiales porque en realidad no realizan ningún cálculo, simplemente emiten los datos que usted les indica que generen en tiempo de ejecución. Normalmente se utilizan para pasar los datos de entrenamiento a TensorFlow durante el entrenamiento. Si no especifica un valor en tiempo de ejecución para un encaje, obtendrá una excepción."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para crear un nodo de marcador de posición, debe llamar a la función de PLACEHOLDER() y especificar el tipo de datos del tensor de salida. Opcionalmente, también puede especificar su forma, si desea imponerla. Si especifica Ninguno (None) para una dimensión, significa \"cualquier tamaño\". Por ejemplo, el siguiente código crea un nodo marcador de posición A, y también un nodo B = A + 5. Cuando evaluamos B, pasamos un feed_dict a eval( ) Método que especifica el valor de A.\n",
    "Tenga en cuenta que A debe tener rango 2 (es decir, debe ser bidimensional) y debe haber tres columnas (o, de lo contrario, se genera una excepción), pero puede tener cualquier número de filas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6. 7. 8.]]\n",
      "[[ 9. 10. 11.]\n",
      " [12. 13. 14.]]\n"
     ]
    }
   ],
   "source": [
    "A = tf.placeholder(tf.float32, shape=(None, 3))\n",
    "B = A + 5\n",
    "with tf.Session() as sess:\n",
    "    B_val_1 = B.eval(feed_dict={A: [[1, 2, 3]]})\n",
    "    B_val_2 = B.eval(feed_dict={A: [[4, 5, 6], [7, 8, 9]]})\n",
    "print(B_val_1)\n",
    "print(B_val_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realmente puede alimentar la salida de cualquier operación, no solo marcadores de posición.En este caso, TensorFlow no intenta evaluar estas operaciones; Utiliza los valores que le das."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para implementar Mini-batch Gradient Descent, solo necesitamos modificar un poco el código existente. Primero cambie la definición de X e y en la fase de construcción para convertirlos en nodos de marcadores de posición:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing() #buscamos el conjunto de datos\n",
    "m, n = housing.data.shape\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name=\"theta\")#creamos un nodo en el grafico que contiene un tensor aleatorio\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate,momentum=0.9)\n",
    "training_op = optimizer.minimize(mse)\n",
    "init = tf.global_variables_initializer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego defina el tamaño del lote y calcule el número total de lotes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2064\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "print(n_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.random as rnd\n",
    "def fetch_batch(epoch, batch_index, batch_size):\n",
    "\n",
    "    rnd.seed(epoch * n_batches + batch_index)\n",
    "    indices = rnd.randint(m, size=batch_size)\n",
    "\n",
    "    X_batch = scaled_housing_data_plus_bias[indices]\n",
    "    y_batch = housing.target.reshape(-1, 1)[indices]\n",
    "\n",
    "    return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, en la fase de ejecución, obtenga los mini lotes uno por uno, luego proporcione el valor de X e y mediante el parámetro feed_dict al evaluar un nodo que depende de cualquiera de ellos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 5.058105\n",
      "Epoch 100 MSE = 4.788532\n",
      "Epoch 200 MSE = 4.8319993\n",
      "Epoch 300 MSE = 4.7781167\n",
      "Epoch 400 MSE = 4.8066754\n",
      "Epoch 500 MSE = 4.8184795\n",
      "Epoch 600 MSE = 4.7169046\n",
      "Epoch 700 MSE = 4.689725\n",
      "Epoch 800 MSE = 4.919059\n",
      "Epoch 900 MSE = 4.7802706\n",
      "[[-0.50042367]\n",
      " [ 0.82605994]\n",
      " [ 0.1323493 ]\n",
      " [-0.27672535]\n",
      " [ 0.3296239 ]\n",
      " [-0.01730829]\n",
      " [-0.03424422]\n",
      " [-0.89796126]\n",
      " [-0.88873976]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch1, y_batch1 = fetch_batch(epoch, batch_index, batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch1, y: y_batch1})\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval(feed_dict={X: X_batch1, y: y_batch1}))\n",
    "    best_theta = theta.eval()\n",
    "    print(best_theta )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ATENCION: No necesitamos pasar el valor de X e y al evaluar theta, ya que no depende de ninguno de ellos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3>Guardando y restaurando modelos</H3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que haya entrenado a su modelo, debe guardar sus parámetros en el disco para poder volver a él cuando lo desee, usarlo en otro programa, compararlo con otros modelos, etc. Además, es probable que desee guardar los puntos de control (checkpoints) a intervalos regulares durante el entrenamiento, de modo que si su computadora falla durante el entrenamiento, puede continuar desde el último punto de control en lugar de comenzar de cero.\n",
    "TensorFlow hace que guardar y restaurar un modelo sea muy fácil. Simplemente cree un nodo Saver al final de la fase de construcción (después de crear todos los nodos variables); luego, en la fase de ejecución, simplemente llame a su método save () cuando quiera guardar el modelo, pasándole la sesión y la ruta del archivo de punto de control:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing() #buscamos el conjunto de datos\n",
    "m, n = housing.data.shape\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name=\"theta\")#creamos un nodo en el grafico que contiene un tensor aleatorio\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate) #Optimizador\n",
    "training_op = optimizer.minimize(mse) \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver() #importante poner nodo saver al final de grafo para guardar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 6.821538\n",
      "Epoch 100 MSE = 4.786411\n",
      "Epoch 200 MSE = 4.8272457\n",
      "Epoch 300 MSE = 4.7731595\n",
      "Epoch 400 MSE = 4.810421\n",
      "Epoch 500 MSE = 4.816365\n",
      "Epoch 600 MSE = 4.7150335\n",
      "Epoch 700 MSE = 4.687723\n",
      "Epoch 800 MSE = 4.918627\n",
      "Epoch 900 MSE = 4.778976\n",
      "[[ 0.10532928]\n",
      " [ 0.8271039 ]\n",
      " [ 0.12446978]\n",
      " [-0.28168753]\n",
      " [ 0.30975032]\n",
      " [-0.02107869]\n",
      " [-0.03479116]\n",
      " [-0.89592403]\n",
      " [-0.88862276]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch1, y_batch1 = fetch_batch(epoch, batch_index, batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch1, y: y_batch1})\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval(feed_dict={X: X_batch1, y: y_batch1}))\n",
    "    best_theta = theta.eval()\n",
    "    print(best_theta)\n",
    "    save_path = saver.save(sess, \"/home/andres/Escritorio/modelo_guardado.ckpt\") #guardar modelo se le pasa la sesion y la ruta\n",
    "    #saver = tf.train.Saver({\"pesos\": theta})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.10532928]\n",
      " [ 0.8271039 ]\n",
      " [ 0.12446978]\n",
      " [-0.28168753]\n",
      " [ 0.30975032]\n",
      " [-0.02107869]\n",
      " [-0.03479116]\n",
      " [-0.89592403]\n",
      " [-0.88862276]]\n"
     ]
    }
   ],
   "source": [
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restaurar un modelo es igual de fácil: crea un Saver al final de la fase de construcción como antes, pero al comienzo de la fase de ejecución, en lugar de inicializar las variables con el nodo de inicio, llama al método restore () del objeto Saver:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por defecto, un Saver guarda y restaura todas las variables con su propio nombre, pero si necesita más control, puede especificar qué variables guardar o restaurar, y qué nombres usar. Por ejemplo, el siguiente Saver guardará o restaurará solo la variable theta bajo los pesos de nombre: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing() #buscamos el conjunto de datos\n",
    "m, n = housing.data.shape\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name=\"theta\")#creamos un nodo en el grafico que contiene un tensor aleatorio\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate) #Optimizador\n",
    "training_op = optimizer.minimize(mse) \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver() #importante poner nodo saver al final de grafo para guardar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/andres/Escritorio/modelo_guardado.ckpt\n",
      "4.8043704\n",
      "[[ 0.10532928]\n",
      " [ 0.8271039 ]\n",
      " [ 0.12446978]\n",
      " [-0.28168753]\n",
      " [ 0.30975032]\n",
      " [-0.02107869]\n",
      " [-0.03479116]\n",
      " [-0.89592403]\n",
      " [-0.88862276]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"/home/andres/Escritorio/modelo_guardado.ckpt\")\n",
    "    mejortheta=theta.eval()\n",
    "    print(mse.eval(feed_dict={X: scaled_housing_data_plus_bias, y: housing.target.reshape(-1, 1)}))\n",
    "    print(theta.eval())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Visualización del gráfico y las curvas de entrenamiento con TensorBoard</h3> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://guru99.es/wp-content/uploads/2020/02/080618_0516_Tensorboard1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Así que ahora tenemos un gráfico de cómputo que entrena un modelo de regresión lineal usando un descenso de gradiente de mini lotes, y estamos guardando puntos de control a intervalos regulares.\n",
    "Suena sofisticado, ¿no? Sin embargo, todavía estamos confiando en la función de imprimir () para visualizar el progreso durante el entrenamiento. Hay una mejor manera: entrar en TensorBoard. Si lo alimenta con algunas estadísticas de entrenamiento, mostrará agradables visualizaciones interactivas de estas estadísticas en su navegador web (por ejemplo, curvas de aprendizaje). También puede proporcionarle la definición del gráfo y le dará una gran interfaz para navegar a través de él. Esto es muy útil para identificar errores en el gráfo, para encontrar cuellos de botella, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El primer paso es ajustar un poco su programa para que escriba la definición del gráfo y algunas estadísticas de entrenamiento, por ejemplo, el error de entrenamiento (MSE), en un directorio de registro del que TensorBoard leerá. <b>Debe usar un directorio de registro diferente cada vez que ejecute su programa, de lo contrario, TensorBoard combinará las estadísticas de diferentes ejecuciones, lo que desordenará las visualizaciones. La solución más sencilla para esto es incluir una marca de tiempo en el nombre del directorio de registro.</b> Agregue el siguiente código al inicio del programa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizando el grafo y las curvas de entrenamiento usando TensorBoard\n",
    "from datetime import datetime\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, agregue el siguiente código al final de la fase de construcción:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing() #buscamos el conjunto de datos\n",
    "m, n = housing.data.shape\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name=\"PESOS\")#creamos un nodo en el grafico que contiene un tensor aleatorio\n",
    "y_pred = tf.matmul(X, theta, name=\"PREDICCIONES\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"MSE-JULI\")\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate,momentum=0.9,name=\"OPTIMIZADOR\")\n",
    "training_op = optimizer.minimize(mse,name=\"TRAINING\")\n",
    "mse_summary = tf.summary.scalar('MSE-JULIAN', mse) #nueva linea\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph()) #nueva linea\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La primera línea crea un nodo en el gráfico que evaluará el valor de MSE y lo escribirá en una cadena de registro binario compatible con TensorBoard llamada resumen. La segunda línea crea un FileWriter que utilizará para escribir resúmenes en los archivos de registro en el directorio de registro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El primer parámetro indica la ruta del directorio de registro (en este caso, algo como tf_logs / run-20160906091959 /, relativo al directorio actual). El segundo parámetro (opcional) es el gráfico que desea visualizar. Tras la creación, el Escritor de archivos crea el directorio de registro si aún no existe (y sus directorios principales, si es necesario), y escribe la definición del gráfico en un archivo de registro binario llamado archivo de eventos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, debe actualizar la fase de ejecución para evaluar el nodo mse_summary regularmente durante el entrenamiento (por ejemplo, cada 10 mini lotes). Esto generará un resumen que luego puede escribir en el archivo de eventos usando el file_writer. Aquí está el código actualizado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 6.0267043\n",
      "Epoch 100 MSE = 4.735941\n",
      "Epoch 200 MSE = 4.734802\n",
      "Epoch 300 MSE = 4.733837\n",
      "Epoch 400 MSE = 4.746954\n",
      "Epoch 500 MSE = 4.738476\n",
      "Epoch 600 MSE = 4.7392836\n",
      "Epoch 700 MSE = 4.73564\n",
      "Epoch 800 MSE = 4.7425833\n",
      "Epoch 900 MSE = 4.752271\n",
      "[[-0.7243414 ]\n",
      " [ 0.82605994]\n",
      " [ 0.1323493 ]\n",
      " [-0.27672535]\n",
      " [ 0.3296239 ]\n",
      " [-0.01730829]\n",
      " [-0.03424422]\n",
      " [-0.89796126]\n",
      " [-0.88873976]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            if batch_index % 10 == 0: #nuevas lineas\n",
    "                summary_str = mse_summary.eval(feed_dict={X: X_batch, y: y_batch})#nuevas lineas\n",
    "                step = epoch * n_batches + batch_index#nuevas lineas\n",
    "                file_writer.add_summary(summary_str, step)#nuevas lineas\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval(feed_dict={X: X_batch1, y: y_batch1}))\n",
    "    print(theta.eval())\n",
    "    save_path = saver.save(sess, \"/home/andres/Escritorio/guardando_modelo.ckpt\")\n",
    "    #saver = tf.train.Saver({\"pesos\": theta})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evite registrar estadísticas de entrenamiento en cada paso de entrenamiento, ya que esto ralentizaría significativamente el entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, desea cerrar el FileWriter al final del programa: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora ejecute este programa: <br>\n",
    "creará el directorio de registro y escribirá un archivo de eventos en este directorio, que contiene tanto la definición del grafo como los valores de MSE. Abra un shell y vaya a su directorio de trabajo, luego escriba ls -l tf_logs / run * para listar los contenidos del directorio de registro:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$cd $ML_PATH\n",
    "#Your ML working directory (e.g., $HOME/ml)\n",
    "$ls -l tf_logs/run*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si ejecuta el programa por segunda vez, debería ver un segundo directorio en el directorio tf_logs /:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Genial! Ahora es el momento de encender el servidor TensorBoard. Debe activar su entorno virtualenv si creó uno, luego inicie el servidor ejecutando el comando tensor board, apuntándolo al directorio de registro raíz. Esto inicia el servidor web TensorBoard, escuchando en el puerto 6006 (que es \"goog\" escrito al revés):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ source env/bin/activate\n",
    "$ tensorboard --logdir tf_logs/\n",
    "Starting TensorBoard on port 6006\n",
    "(You can navigate to http://0.0.0.0:6006)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, abra un navegador y vaya a http://0.0.0.0:6006/ (o http: // localhost: 6006 /). Bienvenido a TensorBoard! En la pestaña Eventos, debería ver MSE a la derecha. Si hace clic en él, verá una gráfica del MSE durante el entrenamiento, para ambas ejecuciones (Figura 9-3). Puede marcar o desmarcar las ejecuciones que desea ver, acercar o alejar, desplazarse sobre la curva para obtener detalles, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora haga clic en la pestaña Gráficos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para reducir el desorden, los nodos que tienen muchos bordes (es decir, las conexiones a otros nodos) se separan en un área auxiliar a la derecha (puede mover un nodo de un lado a otro entre el gráfico principal y el área auxiliar haciendo clic con el botón derecho en eso). Algunas partes del gráfico también están colapsadas por defecto. Por ejemplo, intente pasar el cursor sobre el nodo de gradientes, luego haga clic en el icono para expandir este subgrafo. A continuación, en este subgrafo, intente expandir el subgrafo mse_grad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si desea echar un vistazo al gráfico directamente dentro de Jupyter, puede usar la función show_graph () disponible en el cuaderno para este capítulo. Originalmente fue escrito por A. Mordvintsev en su gran cuaderno de tutoriales Deepdream. Otra opción es instalar la herramienta de depuración TensorFlow de E. Jang que incluye una extensión de Jupyter para visualización de gráficos (y más)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nombre de los ámbitos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando se trata de modelos más complejos, como las redes neuronales, el gráfico se puede saturar fácilmente con miles de nodos. Para evitar esto, puede crear ámbitos de nombres para agrupar nodos relacionados. Por ejemplo, modifiquemos el código anterior para definir el error y mse ops dentro de un ámbito de nombre llamado \"pérdida\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nombres de los ambitos \n",
    "with tf.name_scope(\"loss\") as scope:\n",
    "    error = y_pred - y\n",
    "    mse = tf.reduce_mean(tf.square(error), name=\"mse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El nombre de cada operación definida dentro del alcance ahora tiene el prefijo \"pérdida /\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss/sub\n",
      "loss/mse\n"
     ]
    }
   ],
   "source": [
    "print(error.op.name)\n",
    "\n",
    "print(mse.op.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En TensorBoard, los nodos mse y error ahora aparecen dentro del espacio de nombres de pérdida, que aparece colapsado de forma predeterminada "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supongamos que desea crear un gráfico que agregue la salida de dos unidades lineales rectificadas (ReLU). Una ReLU calcula una función lineal de las entradas y genera el resultado si es positivo, y 0 de lo contrario, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente código hace el trabajo, pero es bastante repetitivo: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modularidad\n",
    "n_features = 3\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
    "w1 = tf.Variable(tf.random_normal((n_features, 1)), name=\"weights1\")\n",
    "w2 = tf.Variable(tf.random_normal((n_features, 1)), name=\"weights2\")\n",
    "b1 = tf.Variable(0.0, name=\"bias1\")\n",
    "b2 = tf.Variable(0.0, name=\"bias2\")\n",
    "z1 = tf.add(tf.matmul(X, w1), b1, name=\"z1\")\n",
    "z2 = tf.add(tf.matmul(X, w2), b2, name=\"z2\")\n",
    "relu1 = tf.maximum(z1, 0., name=\"relu1\")\n",
    "relu2 = tf.maximum(z1, 0., name=\"relu2\")\n",
    "output = tf.add(relu1, relu2, name=\"output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código repetitivo es difícil de mantener y es propenso a errores (de hecho, este código contiene un error de cortar y pegar; ¿lo vio?). Sería incluso peor si quisiera agregar algunas ReLU más. Afortunadamente, TensorFlow le permite mantenerse SECO (no se repita): simplemente cree una función para construir una ReLU. El siguiente código crea cinco ReLU y genera su suma (tenga en cuenta que add_n () crea una operación que calculará la suma de una lista de tensores):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(X):\n",
    "    w_shape = (int(X.get_shape()[1]), 1)\n",
    "    w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")\n",
    "    b = tf.Variable(0.0, name=\"bias\")\n",
    "    z = tf.add(tf.matmul(X, w), b, name=\"z\")\n",
    "    return tf.maximum(z, 0., name=\"relu\")\n",
    "n_features = 3\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
    "relus = [relu(X) for i in range(5)]\n",
    "output = tf.add_n(relus, name=\"output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenga en cuenta que cuando crea un nodo, TensorFlow comprueba si su nombre ya existe y, si lo hace, agrega un guión bajo seguido de un índice para que el nombre sea único. Así que la primera ReLU contiene nodos denominados \"pesos\", \"sesgo\", \"z\" y \"relu\" (además de muchos más nodos con su nombre predeterminado, como \"MatMul\"); la segunda ReLU contiene nodos denominados \"pesos_1\", \"sesgo_1\", etc. la tercera ReLU contiene nodos denominados \"pesos_2\", \"sesgo_2\", etc. TensorBoard identifica dichas series y las colapsa para reducir el desorden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando los ámbitos de nombres, puedes hacer el gráfico mucho más claro. Simplemente mueva todo el contenido de la función relu () dentro de un ámbito de nombre. La figura 9-7 muestra el gráfico resultante. Tenga en cuenta que TensorFlow también le da a los ámbitos de nombres nombres únicos al agregar _1, _2, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(X):\n",
    "    with tf.name_scope(\"relu\"):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta aca tenemos el tema de introduccion a la libreria tensorflow. Si tienes alguna duda no olvides escribir a <br>\n",
    "<b>andres.programacion123@gmail.com</b>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
